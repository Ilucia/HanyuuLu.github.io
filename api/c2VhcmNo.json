[{"title":"多线程","date":"2022-04-27T15:24:01.775Z","updated":"2022-04-27T15:24:01.775Z","content":" 使用线程\n有三种使用线程的方法：\n\n实现 Runnable 接口；\n实现 Callable 接口；\n继承 Thread 类。\n\n实现 Runnable 和 Callable 接口的类只能当做一个可以在线程中运行的任务，不是真正意义上的线程，因此最后还需要通过 Thread 来调用。可以理解为任务是通过线程驱动从而执行的。\n 实现 Runnable 接口\n需要实现接口中的 run() 方法。\n123456public class MyRunnable implements Runnable &#123;    @Override    public void run() &#123;        // ...    &#125;&#125;\n使用 Runnable 实例再创建一个 Thread 实例，然后调用 Thread 实例的 start() 方法来启动线程。\n12345public static void main(String[] args) &#123;    MyRunnable instance = new MyRunnable();    Thread thread = new Thread(instance);    thread.start();&#125;\n 实现 Callable 接口\n与 Runnable 相比，Callable 可以有返回值，返回值通过 FutureTask 进行封装。\n123456789101112public class MyCallable implements Callable&lt;Integer&gt; &#123;    public Integer call() &#123;        return 123;    &#125;&#125;public static void main(String[] args) throws ExecutionException, InterruptedException &#123;    MyCallable mc = new MyCallable();    FutureTask&lt;Integer&gt; ft = new FutureTask&lt;&gt;(mc);    Thread thread = new Thread(ft);    thread.start();    System.out.println(ft.get());&#125;\n 继承 Thread 类\n同样也是需要实现 run() 方法，因为 Thread 类也实现了 Runable 接口。\n当调用 start() 方法启动一个线程时，虚拟机会将该线程放入就绪队列中等待被调度，当一个线程被调度时会执行该线程的 run() 方法。\n123456789public class MyThread extends Thread &#123;    public void run() &#123;        // ...    &#125;&#125;public static void main(String[] args) &#123;    MyThread mt = new MyThread();    mt.start();&#125;\n 实现接口 VS 继承 Thread\n实现接口会更好一些，因为：\n\nJava 不支持多重继承，因此继承了 Thread 类就无法继承其它类，但是可以实现多个接口；\n类可能只要求可执行就行，继承整个 Thread 类开销过大。\n\n 基础线程机制\n Executor\nExecutor 管理多个异步任务的执行，而无需程序员显式地管理线程的生命周期。这里的异步是指多个任务的执行互不干扰，不需要进行同步操作。\n主要有三种 Executor：\n\nCachedThreadPool：一个任务创建一个线程；\nFixedThreadPool：所有任务只能使用固定大小的线程；\nSingleThreadExecutor：相当于大小为 1 的 FixedThreadPool。\n\n1234567public static void main(String[] args) &#123;    ExecutorService executorService = Executors.newCachedThreadPool();    for (int i = 0; i &lt; 5; i++) &#123;        executorService.execute(new MyRunnable());    &#125;    executorService.shutdown();&#125;\n Daemon\n守护线程是程序运行时在后台提供服务的线程，不属于程序中不可或缺的部分。\n当所有非守护线程结束时，程序也就终止，同时会杀死所有守护线程。\nmain() 属于非守护线程。\n在线程启动之前使用 setDaemon() 方法可以将一个线程设置为守护线程。\n1234public static void main(String[] args) &#123;    Thread thread = new Thread(new MyRunnable());    thread.setDaemon(true);&#125;\n sleep()\nThread.sleep(millisec) 方法会休眠当前正在执行的线程，millisec 单位为毫秒。\nsleep() 可能会抛出 InterruptedException，因为异常不能跨线程传播回 main() 中，因此必须在本地进行处理。线程中抛出的其它异常也同样需要在本地进行处理。\n1234567public void run() &#123;    try &#123;        Thread.sleep(3000);    &#125; catch (InterruptedException e) &#123;        e.printStackTrace();    &#125;&#125;\n yield()\n对静态方法 Thread.yield() 的调用声明了当前线程已经完成了生命周期中最重要的部分，可以切换给其它线程来执行。该方法只是对线程调度器的一个建议，而且也只是建议具有相同优先级的其它线程可以运行。\n123public void run() &#123;    Thread.yield();&#125;\n 中断\n一个线程执行完毕之后会自动结束，如果在运行过程中发生异常也会提前结束。\n InterruptedException\n通过调用一个线程的 interrupt() 来中断该线程，如果该线程处于阻塞、限期等待或者无限期等待状态，那么就会抛出 InterruptedException，从而提前结束该线程。但是不能中断 I/O 阻塞和 synchronized 锁阻塞。\n对于以下代码，在 main() 中启动一个线程之后再中断它，由于线程中调用了 Thread.sleep() 方法，因此会抛出一个 InterruptedException，从而提前结束线程，不执行之后的语句。\n1234567891011121314151617181920212223242526public class InterruptExample &#123;    private static class MyThread1 extends Thread &#123;        @Override        public void run() &#123;            try &#123;                Thread.sleep(2000);                System.out.println(\"Thread run\");            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;&#125;public static void main(String[] args) throws InterruptedException &#123;    Thread thread1 = new MyThread1();    thread1.start();    thread1.interrupt();    System.out.println(\"Main run\");&#125;Main runjava.lang.InterruptedException: sleep interrupted    at java.lang.Thread.sleep(Native Method)    at InterruptExample.lambda$main$0(InterruptExample.java:5)    at InterruptExample$$Lambda$1/713338599.run(Unknown Source)    at java.lang.Thread.run(Thread.java:745)\n interrupted()\n如果一个线程的 run() 方法执行一个无限循环，并且没有执行 sleep() 等会抛出 InterruptedException 的操作，那么调用线程的 interrupt() 方法就无法使线程提前结束。\n但是调用 interrupt() 方法会设置线程的中断标记，此时调用 interrupted() 方法会返回 true。因此可以在循环体中使用 interrupted() 方法来判断线程是否处于中断状态，从而提前结束线程。\n123456789101112131415161718public class InterruptExample &#123;    private static class MyThread2 extends Thread &#123;        @Override        public void run() &#123;            while (!interrupted()) &#123;                // ..            &#125;            System.out.println(\"Thread end\");        &#125;    &#125;&#125;public static void main(String[] args) throws InterruptedException &#123;    Thread thread2 = new MyThread2();    thread2.start();    thread2.interrupt();&#125;Thread end\n Executor 的中断操作\n调用 Executor 的 shutdown() 方法会等待线程都执行完毕之后再关闭，但是如果调用的是 shutdownNow() 方法，则相当于调用每个线程的 interrupt() 方法。\n以下使用 Lambda 创建线程，相当于创建了一个匿名内部线程。\n123456789101112131415161718192021public static void main(String[] args) &#123;    ExecutorService executorService = Executors.newCachedThreadPool();    executorService.execute(() -&gt; &#123;        try &#123;            Thread.sleep(2000);            System.out.println(\"Thread run\");        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;    &#125;);    executorService.shutdownNow();    System.out.println(\"Main run\");&#125;Main runjava.lang.InterruptedException: sleep interrupted    at java.lang.Thread.sleep(Native Method)    at ExecutorInterruptExample.lambda$main$0(ExecutorInterruptExample.java:9)    at ExecutorInterruptExample$$Lambda$1/1160460865.run(Unknown Source)    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)    at java.lang.Thread.run(Thread.java:745)\n如果只想中断 Executor 中的一个线程，可以通过使用 submit() 方法来提交一个线程，它会返回一个 Future&lt;?&gt; 对象，通过调用该对象的 cancel(true) 方法就可以中断线程。\n1234Future&lt;?&gt; future = executorService.submit(() -&gt; &#123;    // ..&#125;);future.cancel(true);\n 互斥同步\nJava 提供了两种锁机制来控制多个线程对共享资源的互斥访问，第一个是 JVM 实现的 synchronized，而另一个是 JDK 实现的 ReentrantLock。\n synchronized\n1. 同步一个代码块\n12345public void func() &#123;    synchronized (this) &#123;        // ...    &#125;&#125;\n它只作用于同一个对象，如果调用两个对象上的同步代码块，就不会进行同步。\n对于以下代码，使用 ExecutorService 执行了两个线程，由于调用的是同一个对象的同步代码块，因此这两个线程会进行同步，当一个线程进入同步语句块时，另一个线程就必须等待。\n1234567891011121314151617public class SynchronizedExample &#123;    public void func1() &#123;        synchronized (this) &#123;            for (int i = 0; i &lt; 10; i++) &#123;                System.out.print(i + \" \");            &#125;        &#125;    &#125;&#125;public static void main(String[] args) &#123;    SynchronizedExample e1 = new SynchronizedExample();    ExecutorService executorService = Executors.newCachedThreadPool();    executorService.execute(() -&gt; e1.func1());    executorService.execute(() -&gt; e1.func1());&#125;0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9\n对于以下代码，两个线程调用了不同对象的同步代码块，因此这两个线程就不需要同步。从输出结果可以看出，两个线程交叉执行。\n12345678public static void main(String[] args) &#123;    SynchronizedExample e1 = new SynchronizedExample();    SynchronizedExample e2 = new SynchronizedExample();    ExecutorService executorService = Executors.newCachedThreadPool();    executorService.execute(() -&gt; e1.func1());    executorService.execute(() -&gt; e2.func1());&#125;0 0 1 1 2 2 3 3 4 4 5 5 6 6 7 7 8 8 9 9\n2. 同步一个方法\n123public synchronized void func () &#123;    // ...&#125;\n它和同步代码块一样，作用于同一个对象。\n3. 同步一个类\n12345public void func() &#123;    synchronized (SynchronizedExample.class) &#123;        // ...    &#125;&#125;\n作用于整个类，也就是说两个线程调用同一个类的不同对象上的这种同步语句，也会进行同步。\n123456789101112131415161718public class SynchronizedExample &#123;    public void func2() &#123;        synchronized (SynchronizedExample.class) &#123;            for (int i = 0; i &lt; 10; i++) &#123;                System.out.print(i + \" \");            &#125;        &#125;    &#125;&#125;public static void main(String[] args) &#123;    SynchronizedExample e1 = new SynchronizedExample();    SynchronizedExample e2 = new SynchronizedExample();    ExecutorService executorService = Executors.newCachedThreadPool();    executorService.execute(() -&gt; e1.func2());    executorService.execute(() -&gt; e2.func2());&#125;0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9\n4. 同步一个静态方法\n123public synchronized static void fun() &#123;    // ...&#125;\n作用于整个类。\n ReentrantLock\nReentrantLock 是 java.util.concurrent（J.U.C）包中的锁。\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106public class LockExample &#123;    private Lock lock = new ReentrantLock();    public void func() &#123;        lock.lock();        try &#123;            for (int i = 0; i &lt; 10; i++) &#123;                System.out.print(i + \" \");            &#125;        &#125; finally &#123;            lock.unlock(); // 确保释放锁，从而避免发生死锁。        &#125;    &#125;&#125;public static void main(String[] args) &#123;    LockExample lockExample = new LockExample();    ExecutorService executorService = Executors.newCachedThreadPool();    executorService.execute(() -&gt; lockExample.func());    executorService.execute(() -&gt; lockExample.func());&#125;0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9​```java## 比较**1. 锁的实现**synchronized 是 JVM 实现的，而 ReentrantLock 是 JDK 实现的。**2. 性能**新版本 Java 对 synchronized 进行了很多优化，例如自旋锁等，synchronized 与 ReentrantLock 大致相同。**3. 等待可中断**当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情。ReentrantLock 可中断，而 synchronized 不行。**4. 公平锁**公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁。synchronized 中的锁是非公平的，ReentrantLock 默认情况下也是非公平的，但是也可以是公平的。**5. 锁绑定多个条件**一个 ReentrantLock 可以同时绑定多个 Condition 对象。## 使用选择除非需要使用 ReentrantLock 的高级功能，否则优先使用 synchronized。这是因为 synchronized 是 JVM 实现的一种锁机制，JVM 原生地支持它，而 ReentrantLock 不是所有的 JDK 版本都支持。并且使用 synchronized 不用担心没有释放锁而导致死锁问题，因为 JVM 会确保锁的释放。# 五、线程之间的协作当多个线程可以一起工作去解决某个问题时，如果某些部分必须在其它部分之前完成，那么就需要对线程进行协调。## join()在线程中调用另一个线程的 join() 方法，会将当前线程挂起，而不是忙等待，直到目标线程结束。对于以下代码，虽然 b 线程先启动，但是因为在 b 线程中调用了 a 线程的 join() 方法，b 线程会等待 a 线程结束才继续执行，因此最后能够保证 a 线程的输出先于 b 线程的输出。​```javapublic class JoinExample &#123;    private class A extends Thread &#123;        @Override        public void run() &#123;            System.out.println(\"A\");        &#125;    &#125;    private class B extends Thread &#123;        private A a;        B(A a) &#123;            this.a = a;        &#125;        @Override        public void run() &#123;            try &#123;                a.join();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            System.out.println(\"B\");        &#125;    &#125;    public void test() &#123;        A a = new A();        B b = new B(a);        b.start();        a.start();    &#125;&#125;public static void main(String[] args) &#123;    JoinExample example = new JoinExample();    example.test();&#125;AB\n wait() notify() notifyAll()\n调用 wait() 使得线程等待某个条件满足，线程在等待时会被挂起，当其他线程的运行使得这个条件满足时，其它线程会调用 notify() 或者 notifyAll() 来唤醒挂起的线程。\n它们都属于 Object 的一部分，而不属于 Thread。\n只能用在同步方法或者同步控制块中使用，否则会在运行时抛出 IllegalMonitorStateException。\n使用 wait() 挂起期间，线程会释放锁。这是因为，如果没有释放锁，那么其它线程就无法进入对象的同步方法或者同步控制块中，那么就无法执行 notify() 或者 notifyAll() 来唤醒挂起的线程，造成死锁。\n123456789101112131415161718192021222324public class WaitNotifyExample &#123;    public synchronized void before() &#123;        System.out.println(\"before\");        notifyAll();    &#125;    public synchronized void after() &#123;        try &#123;            wait();        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        System.out.println(\"after\");    &#125;&#125;public static void main(String[] args) &#123;    ExecutorService executorService = Executors.newCachedThreadPool();    WaitNotifyExample example = new WaitNotifyExample();    executorService.execute(() -&gt; example.after());    executorService.execute(() -&gt; example.before());&#125;beforeafter\nwait() 和 sleep() 的区别\n\nwait() 是 Object 的方法，而 sleep() 是 Thread 的静态方法；\nwait() 会释放锁，sleep() 不会。\n\n await() signal() signalAll()\njava.util.concurrent 类库中提供了 Condition 类来实现线程之间的协调，可以在 Condition 上调用 await() 方法使线程等待，其它线程调用 signal() 或 signalAll() 方法唤醒等待的线程。\n相比于 wait() 这种等待方式，await() 可以指定等待的条件，因此更加灵活。\n使用 Lock 来获取一个 Condition 对象。\n1234567891011121314151617181920212223242526272829303132333435public class AwaitSignalExample &#123;    private Lock lock = new ReentrantLock();    private Condition condition = lock.newCondition();    public void before() &#123;        lock.lock();        try &#123;            System.out.println(\"before\");            condition.signalAll();        &#125; finally &#123;            lock.unlock();        &#125;    &#125;    public void after() &#123;        lock.lock();        try &#123;            condition.await();            System.out.println(\"after\");        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125; finally &#123;            lock.unlock();        &#125;    &#125;&#125;public static void main(String[] args) &#123;    ExecutorService executorService = Executors.newCachedThreadPool();    AwaitSignalExample example = new AwaitSignalExample();    executorService.execute(() -&gt; example.after());    executorService.execute(() -&gt; example.before());&#125;beforeafter\n 线程状态\n一个线程只能处于一种状态，并且这里的线程状态特指 Java 虚拟机的线程状态，不能反映线程在特定操作系统下的状态。\n 新建（NEW）\n创建后尚未启动。\n 可运行（RUNABLE）\n正在 Java 虚拟机中运行。但是在操作系统层面，它可能处于运行状态，也可能等待资源调度（例如处理器资源），资源调度完成就进入运行状态。所以该状态的可运行是指可以被运行，具体有没有运行要看底层操作系统的资源调度。\n 阻塞（BLOCKED）\n请求获取 monitor lock 从而进入 synchronized 函数或者代码块，但是其它线程已经占用了该 monitor lock，所以出于阻塞状态。要结束该状态进入从而 RUNABLE 需要其他线程释放 monitor lock。\n 无限期等待（WAITING）\n等待其它线程显式地唤醒。\n阻塞和等待的区别在于，阻塞是被动的，它是在等待获取 monitor lock。而等待是主动的，通过调用 Object.wait() 等方法进入。\n\n\n\n进入方法\n退出方法\n\n\n\n\n没有设置 Timeout 参数的 Object.wait() 方法\nObject.notify() / Object.notifyAll()\n\n\n没有设置 Timeout 参数的 Thread.join() 方法\n被调用的线程执行完毕\n\n\nLockSupport.park() 方法\nLockSupport.unpark(Thread)\n\n\n\n 限期等待（TIMED_WAITING）\n无需等待其它线程显式地唤醒，在一定时间之后会被系统自动唤醒。\n\n\n\n进入方法\n退出方法\n\n\n\n\nThread.sleep() 方法\n时间结束\n\n\n设置了 Timeout 参数的 Object.wait() 方法\n时间结束 / Object.notify() / Object.notifyAll()\n\n\n设置了 Timeout 参数的 Thread.join() 方法\n时间结束 / 被调用的线程执行完毕\n\n\nLockSupport.parkNanos() 方法\nLockSupport.unpark(Thread)\n\n\nLockSupport.parkUntil() 方法\nLockSupport.unpark(Thread)\n\n\n\n调用 Thread.sleep() 方法使线程进入限期等待状态时，常常用“使一个线程睡眠”进行描述。调用 Object.wait() 方法使线程进入限期等待或者无限期等待时，常常用“挂起一个线程”进行描述。睡眠和挂起是用来描述行为，而阻塞和等待用来描述状态。\n 死亡（TERMINATED）\n可以是线程结束任务之后自己结束，或者产生了异常而结束。\n J.U.C - AQS\njava.util.concurrent（J.U.C）大大提高了并发性能，AQS 被认为是 J.U.C 的核心。\n CountDownLatch\n用来控制一个或者多个线程等待多个线程。\n维护了一个计数器 cnt，每次调用 countDown() 方法会让计数器的值减 1，减到 0 的时候，那些因为调用 await() 方法而在等待的线程就会被唤醒。\n\n123456789101112131415161718public class CountdownLatchExample &#123;    public static void main(String[] args) throws InterruptedException &#123;        final int totalThread = 10;        CountDownLatch countDownLatch = new CountDownLatch(totalThread);        ExecutorService executorService = Executors.newCachedThreadPool();        for (int i = 0; i &lt; totalThread; i++) &#123;            executorService.execute(() -&gt; &#123;                System.out.print(\"run..\");                countDownLatch.countDown();            &#125;);        &#125;        countDownLatch.await();        System.out.println(\"end\");        executorService.shutdown();    &#125;&#125;run..run..run..run..run..run..run..run..run..run..end\n CyclicBarrier\n用来控制多个线程互相等待，只有当多个线程都到达时，这些线程才会继续执行。\n和 CountdownLatch 相似，都是通过维护计数器来实现的。线程执行 await() 方法之后计数器会减 1，并进行等待，直到计数器为 0，所有调用 await() 方法而在等待的线程才能继续执行。\nCyclicBarrier 和 CountdownLatch 的一个区别是，CyclicBarrier 的计数器通过调用 reset() 方法可以循环使用，所以它才叫做循环屏障。\nCyclicBarrier 有两个构造函数，其中 parties 指示计数器的初始值，barrierAction 在所有线程都到达屏障的时候会执行一次。\n12345678910public CyclicBarrier(int parties, Runnable barrierAction) &#123;    if (parties &lt;= 0) throw new IllegalArgumentException();    this.parties = parties;    this.count = parties;    this.barrierCommand = barrierAction;&#125;public CyclicBarrier(int parties) &#123;    this(parties, null);&#125;\n\n123456789101112131415161718192021public class CyclicBarrierExample &#123;    public static void main(String[] args) &#123;        final int totalThread = 10;        CyclicBarrier cyclicBarrier = new CyclicBarrier(totalThread);        ExecutorService executorService = Executors.newCachedThreadPool();        for (int i = 0; i &lt; totalThread; i++) &#123;            executorService.execute(() -&gt; &#123;                System.out.print(\"before..\");                try &#123;                    cyclicBarrier.await();                &#125; catch (InterruptedException | BrokenBarrierException e) &#123;                    e.printStackTrace();                &#125;                System.out.print(\"after..\");            &#125;);        &#125;        executorService.shutdown();    &#125;&#125;before..before..before..before..before..before..before..before..before..before..after..after..after..after..after..after..after..after..after..after..\n Semaphore\nSemaphore 类似于操作系统中的信号量，可以控制对互斥资源的访问线程数。\n以下代码模拟了对某个服务的并发请求，每次只能有 3 个客户端同时访问，请求总数为 10。\n1234567891011121314151617181920212223public class SemaphoreExample &#123;    public static void main(String[] args) &#123;        final int clientCount = 3;        final int totalRequestCount = 10;        Semaphore semaphore = new Semaphore(clientCount);        ExecutorService executorService = Executors.newCachedThreadPool();        for (int i = 0; i &lt; totalRequestCount; i++) &#123;            executorService.execute(()-&gt;&#123;                try &#123;                    semaphore.acquire();                    System.out.print(semaphore.availablePermits() + \" \");                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125; finally &#123;                    semaphore.release();                &#125;            &#125;);        &#125;        executorService.shutdown();    &#125;&#125;2 1 2 2 2 2 2 1 2 2\n J.U.C - 其它组件\n FutureTask\n在介绍 Callable 时我们知道它可以有返回值，返回值通过 Future 进行封装。FutureTask 实现了 RunnableFuture 接口，该接口继承自 Runnable 和 Future 接口，这使得 FutureTask 既可以当做一个任务执行，也可以有返回值。\n12public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt;public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt;\nFutureTask 可用于异步获取执行结果或取消执行任务的场景。当一个计算任务需要执行很长时间，那么就可以用 FutureTask 来封装这个任务，主线程在完成自己的任务之后再去获取结果。\n1234567891011121314151617181920212223242526272829303132public class FutureTaskExample &#123;    public static void main(String[] args) throws ExecutionException, InterruptedException &#123;        FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(new Callable&lt;Integer&gt;() &#123;            @Override            public Integer call() throws Exception &#123;                int result = 0;                for (int i = 0; i &lt; 100; i++) &#123;                    Thread.sleep(10);                    result += i;                &#125;                return result;            &#125;        &#125;);        Thread computeThread = new Thread(futureTask);        computeThread.start();        Thread otherThread = new Thread(() -&gt; &#123;            System.out.println(\"other task is running...\");            try &#123;                Thread.sleep(1000);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;);        otherThread.start();        System.out.println(futureTask.get());    &#125;&#125;other task is running...4950\n BlockingQueue\njava.util.concurrent.BlockingQueue 接口有以下阻塞队列的实现：\n\nFIFO 队列 ：LinkedBlockingQueue、ArrayBlockingQueue（固定长度）\n优先级队列 ：PriorityBlockingQueue\n\n提供了阻塞的 take() 和 put() 方法：如果队列为空 take() 将阻塞，直到队列中有内容；如果队列为满 put() 将阻塞，直到队列有空闲位置。\n使用 BlockingQueue 实现生产者消费者问题\n1234567891011121314151617181920212223242526272829303132333435363738394041424344public class ProducerConsumer &#123;    private static BlockingQueue&lt;String&gt; queue = new ArrayBlockingQueue&lt;&gt;(5);    private static class Producer extends Thread &#123;        @Override        public void run() &#123;            try &#123;                queue.put(\"product\");            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            System.out.print(\"produce..\");        &#125;    &#125;    private static class Consumer extends Thread &#123;        @Override        public void run() &#123;            try &#123;                String product = queue.take();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            System.out.print(\"consume..\");        &#125;    &#125;&#125;public static void main(String[] args) &#123;    for (int i = 0; i &lt; 2; i++) &#123;        Producer producer = new Producer();        producer.start();    &#125;    for (int i = 0; i &lt; 5; i++) &#123;        Consumer consumer = new Consumer();        consumer.start();    &#125;    for (int i = 0; i &lt; 3; i++) &#123;        Producer producer = new Producer();        producer.start();    &#125;&#125;produce..produce..consume..consume..produce..consume..produce..consume..produce..consume..\n ForkJoin\n主要用于并行计算中，和 MapReduce 原理类似，都是把大的计算任务拆分成多个小任务并行计算。\n12345678910111213141516171819202122232425262728293031323334353637public class ForkJoinExample extends RecursiveTask&lt;Integer&gt; &#123;    private final int threshold = 5;    private int first;    private int last;    public ForkJoinExample(int first, int last) &#123;        this.first = first;        this.last = last;    &#125;    @Override    protected Integer compute() &#123;        int result = 0;        if (last - first &lt;= threshold) &#123;            // 任务足够小则直接计算            for (int i = first; i &lt;= last; i++) &#123;                result += i;            &#125;        &#125; else &#123;            // 拆分成小任务            int middle = first + (last - first) / 2;            ForkJoinExample leftTask = new ForkJoinExample(first, middle);            ForkJoinExample rightTask = new ForkJoinExample(middle + 1, last);            leftTask.fork();            rightTask.fork();            result = leftTask.join() + rightTask.join();        &#125;        return result;    &#125;&#125;public static void main(String[] args) throws ExecutionException, InterruptedException &#123;    ForkJoinExample example = new ForkJoinExample(1, 10000);    ForkJoinPool forkJoinPool = new ForkJoinPool();    Future result = forkJoinPool.submit(example);    System.out.println(result.get());&#125;\nForkJoin 使用 ForkJoinPool 来启动，它是一个特殊的线程池，线程数量取决于 CPU 核数。\n1public class ForkJoinPool extends AbstractExecutorService\nForkJoinPool 实现了工作窃取算法来提高 CPU 的利用率。每个线程都维护了一个双端队列，用来存储需要执行的任务。工作窃取算法允许空闲的线程从其它线程的双端队列中窃取一个任务来执行。窃取的任务必须是最晚的任务，避免和队列所属线程发生竞争。例如下图中，Thread2 从 Thread1 的队列中拿出最晚的 Task1 任务，Thread1 会拿出 Task2 来执行，这样就避免发生竞争。但是如果队列中只有一个任务时还是会发生竞争。\n\n 线程不安全示例\n如果多个线程对同一个共享数据进行访问而不采取同步操作的话，那么操作的结果是不一致的。\n以下代码演示了 1000 个线程同时对 cnt 执行自增操作，操作结束之后它的值有可能小于 1000。\n12345678910111213141516171819202122232425262728public class ThreadUnsafeExample &#123;    private int cnt = 0;    public void add() &#123;        cnt++;    &#125;    public int get() &#123;        return cnt;    &#125;&#125;public static void main(String[] args) throws InterruptedException &#123;    final int threadSize = 1000;    ThreadUnsafeExample example = new ThreadUnsafeExample();    final CountDownLatch countDownLatch = new CountDownLatch(threadSize);    ExecutorService executorService = Executors.newCachedThreadPool();    for (int i = 0; i &lt; threadSize; i++) &#123;        executorService.execute(() -&gt; &#123;            example.add();            countDownLatch.countDown();        &#125;);    &#125;    countDownLatch.await();    executorService.shutdown();    System.out.println(example.get());&#125;997\n Java 内存模型\nJava 内存模型试图屏蔽各种硬件和操作系统的内存访问差异，以实现让 Java 程序在各种平台下都能达到一致的内存访问效果。\n 主内存与工作内存\n处理器上的寄存器的读写的速度比内存快几个数量级，为了解决这种速度矛盾，在它们之间加入了高速缓存。\n加入高速缓存带来了一个新的问题：缓存一致性。如果多个缓存共享同一块主内存区域，那么多个缓存的数据可能会不一致，需要一些协议来解决这个问题。\n所有的变量都存储在主内存中，每个线程还有自己的工作内存，工作内存存储在高速缓存或者寄存器中，保存了该线程使用的变量的主内存副本拷贝。\n线程只能直接操作工作内存中的变量，不同线程之间的变量值传递需要通过主内存来完成。\n\n 内存间交互操作\nJava 内存模型定义了 8 个操作来完成主内存和工作内存的交互操作。\n\n\nread：把一个变量的值从主内存传输到工作内存中\nload：在 read 之后执行，把 read 得到的值放入工作内存的变量副本中\nuse：把工作内存中一个变量的值传递给执行引擎\nassign：把一个从执行引擎接收到的值赋给工作内存的变量\nstore：把工作内存的一个变量的值传送到主内存中\nwrite：在 store 之后执行，把 store 得到的值放入主内存的变量中\nlock：作用于主内存的变量\nunlock\n\n 内存模型三大特性\n 1. 原子性\nJava 内存模型保证了 read、load、use、assign、store、write、lock 和 unlock 操作具有原子性，例如对一个 int 类型的变量执行 assign 赋值操作，这个操作就是原子性的。但是 Java 内存模型允许虚拟机将没有被 volatile 修饰的 64 位数据（long，double）的读写操作划分为两次 32 位的操作来进行，即 load、store、read 和 write 操作可以不具备原子性。\n有一个错误认识就是，int 等原子性的类型在多线程环境中不会出现线程安全问题。前面的线程不安全示例代码中，cnt 属于 int 类型变量，1000 个线程对它进行自增操作之后，得到的值为 997 而不是 1000。\n为了方便讨论，将内存间的交互操作简化为 3 个：load、assign、store。\n下图演示了两个线程同时对 cnt 进行操作，load、assign、store 这一系列操作整体上看不具备原子性，那么在 T1 修改 cnt 并且还没有将修改后的值写入主内存，T2 依然可以读入旧值。可以看出，这两个线程虽然执行了两次自增运算，但是主内存中 cnt 的值最后为 1 而不是 2。因此对 int 类型读写操作满足原子性只是说明 load、assign、store 这些单个操作具备原子性。\n\nAtomicInteger 能保证多个线程修改的原子性。\n\n使用 AtomicInteger 重写之前线程不安全的代码之后得到以下线程安全实现：\n123456789101112131415161718192021222324252627public class AtomicExample &#123;    private AtomicInteger cnt = new AtomicInteger();    public void add() &#123;        cnt.incrementAndGet();    &#125;    public int get() &#123;        return cnt.get();    &#125;&#125;public static void main(String[] args) throws InterruptedException &#123;    final int threadSize = 1000;    AtomicExample example = new AtomicExample(); // 只修改这条语句    final CountDownLatch countDownLatch = new CountDownLatch(threadSize);    ExecutorService executorService = Executors.newCachedThreadPool();    for (int i = 0; i &lt; threadSize; i++) &#123;        executorService.execute(() -&gt; &#123;            example.add();            countDownLatch.countDown();        &#125;);    &#125;    countDownLatch.await();    executorService.shutdown();    System.out.println(example.get());&#125;1000\n除了使用原子类之外，也可以使用 synchronized 互斥锁来保证操作的原子性。它对应的内存间交互操作为：lock 和 unlock，在虚拟机实现上对应的字节码指令为 monitorenter 和 monitorexit。\n123456789101112131415161718192021222324252627public class AtomicSynchronizedExample &#123;    private int cnt = 0;    public synchronized void add() &#123;        cnt++;    &#125;    public synchronized int get() &#123;        return cnt;    &#125;&#125;public static void main(String[] args) throws InterruptedException &#123;    final int threadSize = 1000;    AtomicSynchronizedExample example = new AtomicSynchronizedExample();    final CountDownLatch countDownLatch = new CountDownLatch(threadSize);    ExecutorService executorService = Executors.newCachedThreadPool();    for (int i = 0; i &lt; threadSize; i++) &#123;        executorService.execute(() -&gt; &#123;            example.add();            countDownLatch.countDown();        &#125;);    &#125;    countDownLatch.await();    executorService.shutdown();    System.out.println(example.get());&#125;1000\n 2. 可见性\n可见性指当一个线程修改了共享变量的值，其它线程能够立即得知这个修改。Java 内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值来实现可见性的。\n主要有三种实现可见性的方式：\n\nvolatile\nsynchronized，对一个变量执行 unlock 操作之前，必须把变量值同步回主内存。\nfinal，被 final 关键字修饰的字段在构造器中一旦初始化完成，并且没有发生 this 逃逸（其它线程通过 this 引用访问到初始化了一半的对象），那么其它线程就能看见 final 字段的值。\n\n对前面的线程不安全示例中的 cnt 变量使用 volatile 修饰，不能解决线程不安全问题，因为 volatile 并不能保证操作的原子性。\n 3. 有序性\n有序性是指：在本线程内观察，所有操作都是有序的。在一个线程观察另一个线程，所有操作都是无序的，无序是因为发生了指令重排序。在 Java 内存模型中，允许编译器和处理器对指令进行重排序，重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。\nvolatile 关键字通过添加内存屏障的方式来禁止指令重排，即重排序时不能把后面的指令放到内存屏障之前。\n也可以通过 synchronized 来保证有序性，它保证每个时刻只有一个线程执行同步代码，相当于是让线程顺序执行同步代码。\n 先行发生原则\n上面提到了可以用 volatile 和 synchronized 来保证有序性。除此之外，JVM 还规定了先行发生原则，让一个操作无需控制就能先于另一个操作完成。\n 1. 单一线程原则\n\nSingle Thread rule\n\n在一个线程内，在程序前面的操作先行发生于后面的操作。\n 2. 管程锁定规则\n\nMonitor Lock Rule\n\n一个 unlock 操作先行发生于后面对同一个锁的 lock 操作。\n 3. volatile 变量规则\n\nVolatile Variable Rule\n\n对一个 volatile 变量的写操作先行发生于后面对这个变量的读操作。\n 4. 线程启动规则\n\nThread Start Rule\n\nThread 对象的 start() 方法调用先行发生于此线程的每一个动作。\n 5. 线程加入规则\n\nThread Join Rule\n\nThread 对象的结束先行发生于 join() 方法返回。\n\n 6. 线程中断规则\n\nThread Interruption Rule\n\n对线程 interrupt() 方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过 interrupted() 方法检测到是否有中断发生。\n 7. 对象终结规则\n\nFinalizer Rule\n\n一个对象的初始化完成（构造函数执行结束）先行发生于它的 finalize() 方法的开始。\n 8. 传递性\n\nTransitivity\n\n如果操作 A 先行发生于操作 B，操作 B 先行发生于操作 C，那么操作 A 先行发生于操作 C。\n 线程安全\n多个线程不管以何种方式访问某个类，并且在主调代码中不需要进行同步，都能表现正确的行为。\n线程安全有以下几种实现方式：\n 不可变\n不可变（Immutable）的对象一定是线程安全的，不需要再采取任何的线程安全保障措施。只要一个不可变的对象被正确地构建出来，永远也不会看到它在多个线程之中处于不一致的状态。多线程环境下，应当尽量使对象成为不可变，来满足线程安全。\n不可变的类型：\n\nfinal 关键字修饰的基本数据类型\nString\n枚举类型\nNumber 部分子类，如 Long 和 Double 等数值包装类型，BigInteger 和 BigDecimal 等大数据类型。但同为 Number 的原子类 AtomicInteger 和 AtomicLong 则是可变的。\n\n对于集合类型，可以使用 Collections.unmodifiableXXX() 方法来获取一个不可变的集合。\n12345678910public class ImmutableExample &#123;    public static void main(String[] args) &#123;        Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;();        Map&lt;String, Integer&gt; unmodifiableMap = Collections.unmodifiableMap(map);        unmodifiableMap.put(\"a\", 1);    &#125;&#125;Exception in thread \"main\" java.lang.UnsupportedOperationException    at java.util.Collections$UnmodifiableMap.put(Collections.java:1457)    at ImmutableExample.main(ImmutableExample.java:9)\nCollections.unmodifiableXXX() 先对原始的集合进行拷贝，需要对集合进行修改的方法都直接抛出异常。\n123public V put(K key, V value) &#123;    throw new UnsupportedOperationException();&#125;\n 互斥同步\nsynchronized 和 ReentrantLock。\n 非阻塞同步\n互斥同步最主要的问题就是线程阻塞和唤醒所带来的性能问题，因此这种同步也称为阻塞同步。\n互斥同步属于一种悲观的并发策略，总是认为只要不去做正确的同步措施，那就肯定会出现问题。无论共享数据是否真的会出现竞争，它都要进行加锁（这里讨论的是概念模型，实际上虚拟机会优化掉很大一部分不必要的加锁）、用户态核心态转换、维护锁计数器和检查是否有被阻塞的线程需要唤醒等操作。\n随着硬件指令集的发展，我们可以使用基于冲突检测的乐观并发策略：先进行操作，如果没有其它线程争用共享数据，那操作就成功了，否则采取补偿措施（不断地重试，直到成功为止）。这种乐观的并发策略的许多实现都不需要将线程阻塞，因此这种同步操作称为非阻塞同步。\n CAS\n乐观锁需要操作和冲突检测这两个步骤具备原子性，这里就不能再使用互斥同步来保证了，只能靠硬件来完成。硬件支持的原子性操作最典型的是：比较并交换（Compare-and-Swap，CAS）。CAS 指令需要有 3 个操作数，分别是内存地址 V、旧的预期值 A 和新值 B。当执行操作时，只有当 V 的值等于 A，才将 V 的值更新为 B。\n AtomicInteger\nJ.U.C 包里面的整数原子类 AtomicInteger 的方法调用了 Unsafe 类的 CAS 操作。\n以下代码使用了 AtomicInteger 执行了自增的操作。\n12345private AtomicInteger cnt = new AtomicInteger();public void add() &#123;    cnt.incrementAndGet();&#125;\n以下代码是 incrementAndGet() 的源码，它调用了 Unsafe 的 getAndAddInt() 。\n123public final int incrementAndGet() &#123;    return unsafe.getAndAddInt(this, valueOffset, 1) + 1;&#125;\n以下代码是 getAndAddInt() 源码，var1 指示对象内存地址，var2 指示该字段相对对象内存地址的偏移，var4 指示操作需要加的数值，这里为 1。通过 getIntVolatile(var1, var2) 得到旧的预期值，通过调用 compareAndSwapInt() 来进行 CAS 比较，如果该字段内存地址中的值等于 var5，那么就更新内存地址为 var1+var2 的变量为 var5+var4。\n可以看到 getAndAddInt() 在一个循环中进行，发生冲突的做法是不断的进行重试。\n12345678public final int getAndAddInt(Object var1, long var2, int var4) &#123;    int var5;    do &#123;        var5 = this.getIntVolatile(var1, var2);    &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));    return var5;&#125;\n ABA\n如果一个变量初次读取的时候是 A 值，它的值被改成了 B，后来又被改回为 A，那 CAS 操作就会误认为它从来没有被改变过。\nJ.U.C 包提供了一个带有标记的原子引用类 AtomicStampedReference 来解决这个问题，它可以通过控制变量值的版本来保证 CAS 的正确性。大部分情况下 ABA 问题不会影响程序并发的正确性，如果需要解决 ABA 问题，改用传统的互斥同步可能会比原子类更高效。\n 无同步方案\n要保证线程安全，并不是一定就要进行同步。如果一个方法本来就不涉及共享数据，那它自然就无须任何同步措施去保证正确性。\n 栈封闭\n多个线程访问同一个方法的局部变量时，不会出现线程安全问题，因为局部变量存储在虚拟机栈中，属于线程私有的。\n123456789101112131415161718public class StackClosedExample &#123;    public void add100() &#123;        int cnt = 0;        for (int i = 0; i &lt; 100; i++) &#123;            cnt++;        &#125;        System.out.println(cnt);    &#125;&#125;public static void main(String[] args) &#123;    StackClosedExample example = new StackClosedExample();    ExecutorService executorService = Executors.newCachedThreadPool();    executorService.execute(() -&gt; example.add100());    executorService.execute(() -&gt; example.add100());    executorService.shutdown();&#125;100100\n 线程本地存储（Thread Local Storage）\n如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行。如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题。\n符合这种特点的应用并不少见，大部分使用消费队列的架构模式（如“生产者-消费者”模式）都会将产品的消费过程尽量在一个线程中消费完。其中最重要的一个应用实例就是经典 Web 交互模型中的“一个请求对应一个服务器线程”（Thread-per-Request）的处理方式，这种处理方式的广泛应用使得很多 Web 服务端应用都可以使用线程本地存储来解决线程安全问题。\n可以使用 java.lang.ThreadLocal 类来实现线程本地存储功能。\n对于以下代码，thread1 中设置 threadLocal 为 1，而 thread2 设置 threadLocal 为 2。过了一段时间之后，thread1 读取 threadLocal 依然是 1，不受 thread2 的影响。\n12345678910111213141516171819202122public class ThreadLocalExample &#123;    public static void main(String[] args) &#123;        ThreadLocal threadLocal = new ThreadLocal();        Thread thread1 = new Thread(() -&gt; &#123;            threadLocal.set(1);            try &#123;                Thread.sleep(1000);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            System.out.println(threadLocal.get());            threadLocal.remove();        &#125;);        Thread thread2 = new Thread(() -&gt; &#123;            threadLocal.set(2);            threadLocal.remove();        &#125;);        thread1.start();        thread2.start();    &#125;&#125;1\n为了理解 ThreadLocal，先看以下代码：\n12345678910111213141516public class ThreadLocalExample1 &#123;    public static void main(String[] args) &#123;        ThreadLocal threadLocal1 = new ThreadLocal();        ThreadLocal threadLocal2 = new ThreadLocal();        Thread thread1 = new Thread(() -&gt; &#123;            threadLocal1.set(1);            threadLocal2.set(1);        &#125;);        Thread thread2 = new Thread(() -&gt; &#123;            threadLocal1.set(2);            threadLocal2.set(2);        &#125;);        thread1.start();        thread2.start();    &#125;&#125;\n它所对应的底层结构图为：\n\n每个 Thread 都有一个 ThreadLocal.ThreadLocalMap 对象。\n123/* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ThreadLocal.ThreadLocalMap threadLocals = null;\n当调用一个 ThreadLocal 的 set(T value) 方法时，先得到当前线程的 ThreadLocalMap 对象，然后将 ThreadLocal-&gt;value 键值对插入到该 Map 中。\n12345678public void set(T value) &#123;    Thread t = Thread.currentThread();    ThreadLocalMap map = getMap(t);    if (map != null)        map.set(this, value);    else        createMap(t, value);&#125;\nget() 方法类似。\n12345678910111213public T get() &#123;    Thread t = Thread.currentThread();    ThreadLocalMap map = getMap(t);    if (map != null) &#123;        ThreadLocalMap.Entry e = map.getEntry(this);        if (e != null) &#123;            @SuppressWarnings(\"unchecked\")            T result = (T)e.value;            return result;        &#125;    &#125;    return setInitialValue();&#125;\nThreadLocal 从理论上讲并不是用来解决多线程并发问题的，因为根本不存在多线程竞争。\n在一些场景 (尤其是使用线程池) 下，由于 ThreadLocal.ThreadLocalMap 的底层数据结构导致 ThreadLocal 有内存泄漏的情况，应该尽可能在每次使用 ThreadLocal 后手动调用 remove()，以避免出现 ThreadLocal 经典的内存泄漏甚至是造成自身业务混乱的风险。\n 可重入代码（Reentrant Code）\n这种代码也叫做纯代码（Pure Code），可以在代码执行的任何时刻中断它，转而去执行另外一段代码（包括递归调用它本身），而在控制权返回后，原来的程序不会出现任何错误。\n可重入代码有一些共同的特征，例如不依赖存储在堆上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非可重入的方法等。\n 锁优化\n这里的锁优化主要是指 JVM 对 synchronized 的优化。\n 自旋锁\n互斥同步进入阻塞状态的开销都很大，应该尽量避免。在许多应用中，共享数据的锁定状态只会持续很短的一段时间。自旋锁的思想是让一个线程在请求一个共享数据的锁时执行忙循环（自旋）一段时间，如果在这段时间内能获得锁，就可以避免进入阻塞状态。\n自旋锁虽然能避免进入阻塞状态从而减少开销，但是它需要进行忙循环操作占用 CPU 时间，它只适用于共享数据的锁定状态很短的场景。\n在 JDK 1.6 中引入了自适应的自旋锁。自适应意味着自旋的次数不再固定了，而是由前一次在同一个锁上的自旋次数及锁的拥有者的状态来决定。\n 锁消除\n锁消除是指对于被检测出不可能存在竞争的共享数据的锁进行消除。\n锁消除主要是通过逃逸分析来支持，如果堆上的共享数据不可能逃逸出去被其它线程访问到，那么就可以把它们当成私有数据对待，也就可以将它们的锁进行消除。\n对于一些看起来没有加锁的代码，其实隐式的加了很多锁。例如下面的字符串拼接代码就隐式加了锁：\n123public static String concatString(String s1, String s2, String s3) &#123;    return s1 + s2 + s3;&#125;\nString 是一个不可变的类，编译器会对 String 的拼接自动优化。在 JDK 1.5 之前，会转化为 StringBuffer 对象的连续 append() 操作：\n1234567public static String concatString(String s1, String s2, String s3) &#123;    StringBuffer sb = new StringBuffer();    sb.append(s1);    sb.append(s2);    sb.append(s3);    return sb.toString();&#125;\n每个 append() 方法中都有一个同步块。虚拟机观察变量 sb，很快就会发现它的动态作用域被限制在 concatString() 方法内部。也就是说，sb 的所有引用永远不会逃逸到 concatString() 方法之外，其他线程无法访问到它，因此可以进行消除。\n 锁粗化\n如果一系列的连续操作都对同一个对象反复加锁和解锁，频繁的加锁操作就会导致性能损耗。\n上一节的示例代码中连续的 append() 方法就属于这类情况。如果虚拟机探测到由这样的一串零碎的操作都对同一个对象加锁，将会把加锁的范围扩展（粗化）到整个操作序列的外部。对于上一节的示例代码就是扩展到第一个 append() 操作之前直至最后一个 append() 操作之后，这样只需要加锁一次就可以了。\n 轻量级锁\nJDK 1.6 引入了偏向锁和轻量级锁，从而让锁拥有了四个状态：无锁状态（unlocked）、偏向锁状态（biasble）、轻量级锁状态（lightweight locked）和重量级锁状态（inflated）。\n以下是 HotSpot 虚拟机对象头的内存布局，这些数据被称为 Mark Word。其中 tag bits 对应了五个状态，这些状态在右侧的 state 表格中给出。除了 marked for gc 状态，其它四个状态已经在前面介绍过了。\n\n下图左侧是一个线程的虚拟机栈，其中有一部分称为 Lock Record 的区域，这是在轻量级锁运行过程创建的，用于存放锁对象的 Mark Word。而右侧就是一个锁对象，包含了 Mark Word 和其它信息。\n\n轻量级锁是相对于传统的重量级锁而言，它使用 CAS 操作来避免重量级锁使用互斥量的开销。对于绝大部分的锁，在整个同步周期内都是不存在竞争的，因此也就不需要都使用互斥量进行同步，可以先采用 CAS 操作进行同步，如果 CAS 失败了再改用互斥量进行同步。\n当尝试获取一个锁对象时，如果锁对象标记为 0 01，说明锁对象的锁未锁定（unlocked）状态。此时虚拟机在当前线程的虚拟机栈中创建 Lock Record，然后使用 CAS 操作将对象的 Mark Word 更新为 Lock Record 指针。如果 CAS 操作成功了，那么线程就获取了该对象上的锁，并且对象的 Mark Word 的锁标记变为 00，表示该对象处于轻量级锁状态。\n\n如果 CAS 操作失败了，虚拟机首先会检查对象的 Mark Word 是否指向当前线程的虚拟机栈，如果是的话说明当前线程已经拥有了这个锁对象，那就可以直接进入同步块继续执行，否则说明这个锁对象已经被其他线程线程抢占了。如果有两条以上的线程争用同一个锁，那轻量级锁就不再有效，要膨胀为重量级锁。\n 偏向锁\n偏向锁的思想是偏向于让第一个获取锁对象的线程，这个线程在之后获取该锁就不再需要进行同步操作，甚至连 CAS 操作也不再需要。\n当锁对象第一次被线程获得的时候，进入偏向状态，标记为 1 01。同时使用 CAS 操作将线程 ID 记录到 Mark Word 中，如果 CAS 操作成功，这个线程以后每次进入这个锁相关的同步块就不需要再进行任何同步操作。\n当有另外一个线程去尝试获取这个锁对象时，偏向状态就宣告结束，此时撤销偏向（Revoke Bias）后恢复到未锁定状态或者轻量级锁状态。\n\n 多线程开发良好的实践\n\n给线程起个有意义的名字，这样可以方便找 Bug。\n缩小同步范围，从而减少锁争用。例如对于 synchronized，应该尽量使用同步块而不是同步方法。\n多用同步工具少用 wait() 和 notify()。首先，CountDownLatch, CyclicBarrier, Semaphore 和 Exchanger 这些同步类简化了编码操作，而用 wait() 和 notify() 很难实现复杂控制流；其次，这些同步类是由最好的企业编写和维护，在后续的 JDK 中还会不断优化和完善。\n使用 BlockingQueue 实现生产者消费者问题。\n多用并发集合少用同步集合，例如应该使用 ConcurrentHashMap 而不是 Hashtable。\n使用本地变量和不可变类来保证线程安全。\n使用线程池而不是直接创建线程，这是因为创建线程代价很高，线程池可以有效地利用有限的线程来启动任务。\n\n","plink":"ilucia.github.io/多线程/"},{"title":"spring&mybatis/Dubbo","date":"2022-04-27T15:24:01.747Z","updated":"2022-04-27T15:24:01.747Z","content":" Dubbo\n 作用\n\n 架构\n\n 节点角色说明\n\n\n\n节点\n角色说明\n\n\n\n\nProvider\n暴露服务的服务提供方\n\n\nConsumer\n调用远程服务的服务消费方\n\n\nRegistry\n服务注册与发现的注册中心\n\n\nMonitor\n统计服务的调用次数和调用时间的监控中心\n\n\nContainer\n服务运行容器\n\n\n\n看了这几个概念后似乎发现，其实 Dubbo 的架构也是很简单的（其实现细节是复杂的），为什么这么说呢，有没有发现，其实很像生产者-消费者模型。只是在这种模型上，加上了注册中心和监控中心，用于管理提供方提供的url，以及管理整个过程。\n那么，整个发布-订阅的过程就非常的简单了。\n\n启动容器，加载，运行服务提供者。\n服务提供者在启动时，在注册中心发布注册自己提供的服务。\n服务消费者在启动时，在注册中心订阅自己所需的服务。\n\n如果考虑失败或变更的情况，就需要考虑下面的过程。\n\n注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。\n服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。\n服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。\n\n Dubbo项目构建\n 基础\n 服务端\n首先，我们先把服务端的接口写好，因为其实 dubbo 的作用简单来说就是给消费端提供接口。\n 接口定义\n1234567/** * xml方式服务提供者接口 */public interface ProviderService &#123;    String SayHello(String word);&#125;\n这个接口非常简单，只是包含一个 SayHello 的方法。\n接着，定义它的实现类。\n123456789/** * xml方式服务提供者实现类 */public class ProviderServiceImpl implements ProviderService&#123;    public String SayHello(String word) &#123;        return word;    &#125;&#125;\n这样我们就把我们的接口写好了，那么我们应该怎么将我们的服务暴露出去呢？\n 导入 maven 依赖\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\"         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;groupId&gt;com.ouyangsihai&lt;/groupId&gt;    &lt;artifactId&gt;dubbo-provider&lt;/artifactId&gt;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;junit&lt;/groupId&gt;            &lt;artifactId&gt;junit&lt;/artifactId&gt;            &lt;version&gt;3.8.1&lt;/version&gt;            &lt;scope&gt;test&lt;/scope&gt;        &lt;/dependency&gt;        &lt;!-- https://mvnrepository.com/artifact/com.alibaba/dubbo --&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.alibaba&lt;/groupId&gt;            &lt;artifactId&gt;dubbo&lt;/artifactId&gt;            &lt;version&gt;2.6.6&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt;            &lt;artifactId&gt;zookeeper&lt;/artifactId&gt;            &lt;version&gt;3.4.10&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.101tec&lt;/groupId&gt;            &lt;artifactId&gt;zkclient&lt;/artifactId&gt;            &lt;version&gt;0.5&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;io.netty&lt;/groupId&gt;            &lt;artifactId&gt;netty-all&lt;/artifactId&gt;            &lt;version&gt;4.1.32.Final&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.curator&lt;/groupId&gt;            &lt;artifactId&gt;curator-framework&lt;/artifactId&gt;            &lt;version&gt;2.8.0&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.curator&lt;/groupId&gt;            &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt;            &lt;version&gt;2.8.0&lt;/version&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;&lt;/project&gt;\n这里使用的 dubbo 的版本是 2.6.6 ，需要注意的是，如果你只导入 dubbo 的包的时候是会报错的，找不到 netty 和 curator 的依赖，所以，在这里我们需要把这两个的依赖加上，就不会报错了。\n另外，这里我们使用 zookeeper 作为注册中心。\n到目前为止，dubbo 需要的环境就已经可以了，下面，我们就把上面刚刚定义的接口暴露出去。\n 暴露接口（xml 配置方法）\n首先，我们在我们项目的 resource 目录下创建 META-INF.spring 包，然后再创建 provider.xml 文件，名字可以任取哦，如下图。\n\n​\n12345678910111213141516171819202122232425262728293031&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\"       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"       xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\"       xsi:schemaLocation=\"http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans.xsd        http://code.alibabatech.com/schema/dubbo        http://code.alibabatech.com/schema/dubbo/dubbo.xsd\"&gt;    &lt;!--当前项目在整个分布式架构里面的唯一名称，计算依赖关系的标签--&gt;    &lt;dubbo:application name=\"provider\" owner=\"sihai\"&gt;        &lt;dubbo:parameter key=\"qos.enable\" value=\"true\"/&gt;        &lt;dubbo:parameter key=\"qos.accept.foreign.ip\" value=\"false\"/&gt;        &lt;dubbo:parameter key=\"qos.port\" value=\"55555\"/&gt;    &lt;/dubbo:application&gt;    &lt;dubbo:monitor protocol=\"registry\"/&gt;    &lt;!--dubbo这个服务所要暴露的服务地址所对应的注册中心--&gt;    &lt;!--&lt;dubbo:registry address=\"N/A\"/&gt;--&gt;    &lt;dubbo:registry address=\"N/A\" /&gt;    &lt;!--当前服务发布所依赖的协议；webserovice、Thrift、Hessain、http--&gt;    &lt;dubbo:protocol name=\"dubbo\" port=\"20880\"/&gt;    &lt;!--服务发布的配置，需要暴露的服务接口--&gt;    &lt;dubbo:service            interface=\"com.sihai.dubbo.provider.service.ProviderService\"            ref=\"providerService\"/&gt;    &lt;!--Bean bean定义--&gt;    &lt;bean id=\"providerService\" class=\"com.sihai.dubbo.provider.service.ProviderServiceImpl\"/&gt;&lt;/beans&gt;\n① 上面的文件其实就是类似 spring 的配置文件，而且，dubbo 底层就是 spring。\n② 节点：dubbo:application\n就是整个项目在分布式架构中的唯一名称，可以在 name 属性中配置，另外还可以配置 owner 字段，表示属于谁。\n下面的参数是可以不配置的，这里配置是因为出现了端口的冲突，所以配置。\n③ 节点：dubbo:monitor\n监控中心配置， 用于配置连接监控中心相关信息，可以不配置，不是必须的参数。\n④ 节点：dubbo:registry\n配置注册中心的信息，比如，这里我们可以配置 zookeeper 作为我们的注册中心。address 是注册中心的地址，这里我们配置的是 N/A 表示由 dubbo 自动分配地址。或者说是一种直连的方式，不通过注册中心。\n⑤ 节点：dubbo:protocol\n服务发布的时候 dubbo 依赖什么协议，可以配置 dubbo、webserovice、Thrift、Hessain、http等协议。\n⑥ 节点：dubbo:service\n这个节点就是我们的重点了，当我们服务发布的时候，我们就是通过这个配置将我们的服务发布出去的。interface 是接口的包路径，ref 是第 ⑦ 点配置的接口的 bean。\n⑦ 最后，我们需要像配置 spring 的接口一样，配置接口的 bean。\n到这一步，关于服务端的配置就完成了，下面我们通过 main 方法将接口发布出去。\n 发布接口\n1234567891011121314151617181920212223242526package com.sihai.dubbo.provider;import com.alibaba.dubbo.config.ApplicationConfig;import com.alibaba.dubbo.config.ProtocolConfig;import com.alibaba.dubbo.config.RegistryConfig;import com.alibaba.dubbo.config.ServiceConfig;import com.alibaba.dubbo.container.Main;import com.sihai.dubbo.provider.service.ProviderService;import com.sihai.dubbo.provider.service.ProviderServiceImpl;import org.springframework.context.support.ClassPathXmlApplicationContext;import java.io.IOException;/** * xml方式启动 * */public class App &#123;    public static void main( String[] args ) throws IOException &#123;        //加载xml配置文件启动        ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"META-INF/spring/provider.xml\");        context.start();        System.in.read(); // 按任意键退出    &#125;&#125;\n发布接口非常简单，因为 dubbo 底层就是依赖 spring 的，所以，我们只需要通过 ClassPathXmlApplicationContext 拿到我们刚刚配置好的 xml ，然后调用 context.start() 方法就启动了。\n看到下面的截图，就算是启动成功了，接口也就发布出去了。\n\n你以为到这里就结束了了，并不是的，我们拿到 dubbo 暴露出去的 url分析分析。\n dubbo 暴露的 url\n1dubbo://192.168.234.1:20880/com.sihai.dubbo.provider.service.ProviderService?anyhost=true&amp;application=provider&amp;bean.name=com.sihai.dubbo.provider.service.ProviderService&amp;bind.ip=192.168.234.1&amp;bind.port=20880&amp;dubbo=2.0.2&amp;generic=false&amp;interface=com.sihai.dubbo.provider.service.ProviderService&amp;methods=SayHello&amp;owner=sihai&amp;pid=8412&amp;qos.accept.foreign.ip=false&amp;qos.enable=true&amp;qos.port=55555&amp;side=provider&amp;timestamp=1562077289380\n 分析\n① 首先，在形式上我们发现，其实这么牛逼的 dubbo 也是用类似于 http 的协议发布自己的服务的，只是这里我们用的是 dubbo 协议。\n② dubbo://192.168.234.1:20880/com.sihai.dubbo.provider.service.ProviderService\n上面这段链接就是 ? 之前的链接，构成：协议://ip:端口/接口。发现是不是也没有什么神秘的。\n③ anyhost=true&amp;application=provider&amp;bean.name=com.sihai.dubbo.provider.service.ProviderService&amp;bind.ip=192.168.234.1&amp;bind.port=20880&amp;dubbo=2.0.2&amp;generic=false&amp;interface=com.sihai.dubbo.provider.service.ProviderService&amp;methods=SayHello&amp;owner=sihai&amp;pid=8412&amp;qos.accept.foreign.ip=false&amp;qos.enable=true&amp;qos.port=55555&amp;side=provider&amp;timestamp=1562077289380\n? 之后的字符串，分析后你发现，这些都是刚刚在 provider.xml 中配置的字段，然后通过 &amp; 拼接而成的，闻到了 http 的香味了吗？\n终于，dubbo 服务端入门了。下面我们看看拿到了 url 后，怎么消费呢？\n 消费端\n上面提到，我们在服务端提供的只是点对点的方式提供服务，并没有使用注册中心，所以，下面的配置也是会有一些不一样的。\n 消费端环境配置\n首先，我们在消费端的 resource 下建立配置文件 consumer.xml。\n\n123456789101112131415161718192021222324&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\"       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"       xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\"       xsi:schemaLocation=\"http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans.xsd        http://code.alibabatech.com/schema/dubbo        http://code.alibabatech.com/schema/dubbo/dubbo.xsd\"&gt;    &lt;!--当前项目在整个分布式架构里面的唯一名称，计算依赖关系的标签--&gt;    &lt;dubbo:application name=\"consumer\" owner=\"sihai\"/&gt;    &lt;!--dubbo这个服务所要暴露的服务地址所对应的注册中心--&gt;    &lt;!--点对点的方式--&gt;    &lt;dubbo:registry address=\"N/A\" /&gt;    &lt;!--&lt;dubbo:registry address=\"zookeeper://localhost:2181\" check=\"false\"/&gt;--&gt;    &lt;!--生成一个远程服务的调用代理--&gt;    &lt;!--点对点方式--&gt;    &lt;dubbo:reference id=\"providerService\"                     interface=\"com.sihai.dubbo.provider.service.ProviderService\"                     url=\"dubbo://192.168.234.1:20880/com.sihai.dubbo.provider.service.ProviderService\"/&gt;    &lt;!--&lt;dubbo:reference id=\"providerService\"                     interface=\"com.sihai.dubbo.provider.service.ProviderService\"/&gt;--&gt;&lt;/beans&gt;\n分析\n① 发现这里的 dubbo:application 和 dubbo:registry 是一致的。\n② dubbo:reference ：我们这里采用点对点的方式，所以，需要配置在服务端暴露的 url 。\n maven 依赖\n和服务端一样\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\"         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;groupId&gt;com.ouyangsihai&lt;/groupId&gt;    &lt;artifactId&gt;dubbo-consumer&lt;/artifactId&gt;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.ouyangsihai&lt;/groupId&gt;            &lt;artifactId&gt;dubbo-provider&lt;/artifactId&gt;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;junit&lt;/groupId&gt;            &lt;artifactId&gt;junit&lt;/artifactId&gt;            &lt;version&gt;3.8.1&lt;/version&gt;            &lt;scope&gt;test&lt;/scope&gt;        &lt;/dependency&gt;        &lt;!-- https://mvnrepository.com/artifact/com.alibaba/dubbo --&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.alibaba&lt;/groupId&gt;            &lt;artifactId&gt;dubbo&lt;/artifactId&gt;            &lt;version&gt;2.6.6&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt;            &lt;artifactId&gt;zookeeper&lt;/artifactId&gt;            &lt;version&gt;3.4.10&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.101tec&lt;/groupId&gt;            &lt;artifactId&gt;zkclient&lt;/artifactId&gt;            &lt;version&gt;0.5&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;io.netty&lt;/groupId&gt;            &lt;artifactId&gt;netty-all&lt;/artifactId&gt;            &lt;version&gt;4.1.32.Final&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.curator&lt;/groupId&gt;            &lt;artifactId&gt;curator-framework&lt;/artifactId&gt;            &lt;version&gt;2.8.0&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.curator&lt;/groupId&gt;            &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt;            &lt;version&gt;2.8.0&lt;/version&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;&lt;/project&gt;\n 调用服务\n123456789101112131415161718192021222324252627package com.sihai.dubbo.consumer;import com.alibaba.dubbo.config.ApplicationConfig;import com.alibaba.dubbo.config.ReferenceConfig;import com.alibaba.dubbo.config.RegistryConfig;import com.sihai.dubbo.provider.service.ProviderService;import org.springframework.context.support.ClassPathXmlApplicationContext;import java.io.IOException;/** * xml的方式调用 * */public class App &#123;    public static void main( String[] args ) throws IOException &#123;        ClassPathXmlApplicationContext context=new ClassPathXmlApplicationContext(\"consumer.xml\");        context.start();        ProviderService providerService = (ProviderService) context.getBean(\"providerService\");        String str = providerService.SayHello(\"hello\");        System.out.println(str);        System.in.read();    &#125;&#125;\n这里和服务端的发布如出一辙。\n\n如此，我们就成功调用接口了。\n 加入 zookeeper 作为注册中心\n在前面的案例中，我们没有使用任何的注册中心，而是用一种直连的方式进行的。但是，实际上很多时候，我们都是使用 dubbo + zookeeper 的方式，使用 zookeeper 作为注册中心，这里，我们就介绍一下 zookeeper 作为注册中心的使用方法。\n这里，我们在前面的入门实例中进行改造。\n 服务端\n在服务端中，我们只需要修改 provider.xml 即可。\n12345678910111213141516171819202122232425262728293031&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\"       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"       xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\"       xsi:schemaLocation=\"http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans.xsd        http://code.alibabatech.com/schema/dubbo        http://code.alibabatech.com/schema/dubbo/dubbo.xsd\"&gt;    &lt;!--当前项目在整个分布式架构里面的唯一名称，计算依赖关系的标签--&gt;    &lt;dubbo:application name=\"provider\" owner=\"sihai\"&gt;        &lt;dubbo:parameter key=\"qos.enable\" value=\"true\"/&gt;        &lt;dubbo:parameter key=\"qos.accept.foreign.ip\" value=\"false\"/&gt;        &lt;dubbo:parameter key=\"qos.port\" value=\"55555\"/&gt;    &lt;/dubbo:application&gt;    &lt;dubbo:monitor protocol=\"registry\"/&gt;    &lt;!--dubbo这个服务所要暴露的服务地址所对应的注册中心--&gt;    &lt;!--&lt;dubbo:registry address=\"N/A\"/&gt;--&gt;    &lt;dubbo:registry address=\"zookeeper://localhost:2181\" check=\"false\"/&gt;    &lt;!--当前服务发布所依赖的协议；webserovice、Thrift、Hessain、http--&gt;    &lt;dubbo:protocol name=\"dubbo\" port=\"20880\"/&gt;    &lt;!--服务发布的配置，需要暴露的服务接口--&gt;    &lt;dubbo:service            interface=\"com.sihai.dubbo.provider.service.ProviderService\"            ref=\"providerService\"/&gt;    &lt;!--Bean bean定义--&gt;    &lt;bean id=\"providerService\" class=\"com.sihai.dubbo.provider.service.ProviderServiceImpl\"/&gt;&lt;/beans&gt;\n重点关注这句话\n1&lt;dubbo:registry address=\"zookeeper://localhost:2181\" /&gt;\n在 address 中，使用我们的 zookeeper 的地址。\n如果是 zookeeper 集群的话，使用下面的方式。\n1&lt;dubbo:registry protocol=\"zookeeper\" address=\"192.168.11.129:2181,192.168.11.137:2181,192.168.11.138:2181\"/&gt;\n服务端的配置就好了，其他的跟 入门案例 一样。\n 消费端\n跟服务端一样，在消费端，我们也只需要修改 consumer.xml 即可。\n123456789101112131415161718192021222324&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\"       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"       xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\"       xsi:schemaLocation=\"http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans.xsd        http://code.alibabatech.com/schema/dubbo        http://code.alibabatech.com/schema/dubbo/dubbo.xsd\"&gt;    &lt;!--当前项目在整个分布式架构里面的唯一名称，计算依赖关系的标签--&gt;    &lt;dubbo:application name=\"consumer\" owner=\"sihai\"/&gt;    &lt;!--dubbo这个服务所要暴露的服务地址所对应的注册中心--&gt;    &lt;!--点对点的方式--&gt;    &lt;!--&lt;dubbo:registry address=\"N/A\" /&gt;--&gt;    &lt;dubbo:registry address=\"zookeeper://localhost:2181\" check=\"false\"/&gt;    &lt;!--生成一个远程服务的调用代理--&gt;    &lt;!--点对点方式--&gt;    &lt;!--&lt;dubbo:reference id=\"providerService\"                     interface=\"com.sihai.dubbo.provider.service.ProviderService\"                     url=\"dubbo://192.168.234.1:20880/com.sihai.dubbo.provider.service.ProviderService\"/&gt;--&gt;    &lt;dubbo:reference id=\"providerService\"                     interface=\"com.sihai.dubbo.provider.service.ProviderService\"/&gt;&lt;/beans&gt;\n① 注册中心配置跟服务端一样。\n1&lt;dubbo:registry address=\"zookeeper://localhost:2181\"/&gt;\n② dubbo:reference\n由于我们这里使用 zookeeper 作为注册中心，所以，跟点对点的方式是不一样的，这里不再需要 dubbo 服务端提供的 url 了，只需要直接引用服务端提供的接口即可。\n12&lt;dubbo:reference id=&quot;providerService&quot;                     interface=&quot;com.sihai.dubbo.provider.service.ProviderService&quot;/&gt;\n好了，消费端也配置好了，这样就可以使用修改的入门案例，重新启动运行了。\n\n同样成功了。\n这时候的区别在于，将 dubbo 发布的 url 注册到了 zookeeper，消费端从 zookeeper 消费，zookeeper 相当于一个中介，给消费者提供服务。\n 注解配置方式\n注解配置方式还是需要了解一下的，现在微服务都倾向于这种方式，这也是以后发展的趋势，0 配置应该是这几年的趋势。\n那么如何对 dubbo 使用注解的方式呢？我们先看服务端。\n 服务端\n\n 第一步：定义接口及实现类，在上面的截图中的 annotation 包下\n12345678package com.sihai.dubbo.provider.service.annotation;/** * 注解方式接口 */public interface ProviderServiceAnnotation &#123;    String SayHelloAnnotation(String word);&#125;\n1234567891011121314package com.sihai.dubbo.provider.service.annotation;import com.alibaba.dubbo.config.annotation.Service;/** * 注解方式实现类 */@Service(timeout = 5000)public class ProviderServiceImplAnnotation implements ProviderServiceAnnotation&#123;    public String SayHelloAnnotation(String word) &#123;        return word;    &#125;&#125;\n@Service\n@Service 用来配置 Dubbo 的服务提供方。\n 第二步：组装服务提供方。\n通过 Spring 中 Java Config 的技术（@Configuration）和 annotation 扫描（@EnableDubbo）来发现、组装、并向外提供 Dubbo 的服务。\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.sihai.dubbo.provider.configuration;import com.alibaba.dubbo.config.ApplicationConfig;import com.alibaba.dubbo.config.ProtocolConfig;import com.alibaba.dubbo.config.ProviderConfig;import com.alibaba.dubbo.config.RegistryConfig;import com.alibaba.dubbo.config.spring.context.annotation.EnableDubbo;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * 注解方式配置 */@Configuration@EnableDubbo(scanBasePackages = \"com.sihai.dubbo.provider.service.annotation\")public class DubboConfiguration &#123;    @Bean // #1 服务提供者信息配置    public ProviderConfig providerConfig() &#123;        ProviderConfig providerConfig = new ProviderConfig();        providerConfig.setTimeout(1000);        return providerConfig;    &#125;    @Bean // #2 分布式应用信息配置    public ApplicationConfig applicationConfig() &#123;        ApplicationConfig applicationConfig = new ApplicationConfig();        applicationConfig.setName(\"dubbo-annotation-provider\");        return applicationConfig;    &#125;    @Bean // #3 注册中心信息配置    public RegistryConfig registryConfig() &#123;        RegistryConfig registryConfig = new RegistryConfig();        registryConfig.setProtocol(\"zookeeper\");        registryConfig.setAddress(\"localhost\");        registryConfig.setPort(2181);        return registryConfig;    &#125;    @Bean // #4 使用协议配置，这里使用 dubbo    public ProtocolConfig protocolConfig() &#123;        ProtocolConfig protocolConfig = new ProtocolConfig();        protocolConfig.setName(\"dubbo\");        protocolConfig.setPort(20880);        return protocolConfig;    &#125;&#125;\n分析\n\n通过 @EnableDubbo 指定在com.sihai.dubbo.provider.service.annotation 下扫描所有标注有 @Service 的类\n通过 @Configuration 将 DubboConfiguration 中所有的 @Bean 通过 Java Config 的方式组装出来并注入给 Dubbo 服务，也就是标注有 @Service 的类。这其中就包括了：\n\nProviderConfig：服务提供方配置\nApplicationConfig：应用配置\nRegistryConfig：注册中心配置\nProtocolConfig：协议配置\n\n\n\n 第三步：启动服务\n1234567891011121314151617181920package com.sihai.dubbo.provider;import com.alibaba.dubbo.config.spring.context.annotation.DubboComponentScan;import com.sihai.dubbo.provider.configuration.DubboConfiguration;import org.springframework.context.annotation.AnnotationConfigApplicationContext;import sun.applet.Main;import java.io.IOException;/** * 注解启动方式 */public class AppAnnotation &#123;    public static void main(String[] args) throws IOException &#123;        AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(DubboConfiguration.class);         context.start();        System.in.read();     &#125;&#125;\n发现输出下面信息就表示 success 了。\n\n 消费端\n同样我们下看看消费端的工程，有一个感性认识。\n\n 第一步：引用服务\n12345678910111213141516171819package com.sihai.dubbo.consumer.Annotation;import com.alibaba.dubbo.config.annotation.Reference;import com.sihai.dubbo.provider.service.annotation.ProviderServiceAnnotation;import org.springframework.stereotype.Component;/** * 注解方式的service */@Component(\"annotatedConsumer\")public class ConsumerAnnotationService &#123;    @Reference    private ProviderServiceAnnotation providerServiceAnnotation;    public String doSayHello(String name) &#123;        return providerServiceAnnotation.SayHelloAnnotation(name);    &#125;&#125;\n在 ConsumerAnnotationService 类中，通过 @Reference 引用服务端提供的类，然后通过方法调用这个类的方式，给消费端提供接口。\n**注意：**如果这里找不到 ProviderServiceAnnotation 类，请在服务端先把服务端工程用 Maven intall 一下，然后将服务端的依赖放到消费端的 pom 中。如下：\n12345&lt;dependency&gt;  &lt;groupId&gt;com.ouyangsihai&lt;/groupId&gt;  &lt;artifactId&gt;dubbo-provider&lt;/artifactId&gt;  &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt;\n 第二步：组装服务消费者\n这一步和服务端是类似的，这里就不在重复了。\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.sihai.dubbo.consumer.configuration;import com.alibaba.dubbo.config.ApplicationConfig;import com.alibaba.dubbo.config.ConsumerConfig;import com.alibaba.dubbo.config.RegistryConfig;import com.alibaba.dubbo.config.spring.context.annotation.EnableDubbo;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.Configuration;import java.util.HashMap;import java.util.Map;/** * 注解配置类 */@Configuration@EnableDubbo(scanBasePackages = \"com.sihai.dubbo.consumer.Annotation\")@ComponentScan(value = &#123;\"com.sihai.dubbo.consumer.Annotation\"&#125;)public class ConsumerConfiguration &#123;    @Bean // 应用配置    public ApplicationConfig applicationConfig() &#123;        ApplicationConfig applicationConfig = new ApplicationConfig();        applicationConfig.setName(\"dubbo-annotation-consumer\");        Map&lt;String, String&gt; stringStringMap = new HashMap&lt;String, String&gt;();        stringStringMap.put(\"qos.enable\",\"true\");        stringStringMap.put(\"qos.accept.foreign.ip\",\"false\");        stringStringMap.put(\"qos.port\",\"33333\");        applicationConfig.setParameters(stringStringMap);        return applicationConfig;    &#125;    @Bean // 服务消费者配置    public ConsumerConfig consumerConfig() &#123;        ConsumerConfig consumerConfig = new ConsumerConfig();        consumerConfig.setTimeout(3000);        return consumerConfig;    &#125;    @Bean // 配置注册中心    public RegistryConfig registryConfig() &#123;        RegistryConfig registryConfig = new RegistryConfig();        registryConfig.setProtocol(\"zookeeper\");        registryConfig.setAddress(\"localhost\");        registryConfig.setPort(2181);        return registryConfig;    &#125;&#125;\n 第三步：发起远程调用\n在 main 方法中通过启动一个 Spring Context，从其中查找到组装好的 Dubbo 的服务消费者，并发起一次远程调用。\n1234567891011121314151617181920212223242526package com.sihai.dubbo.consumer;import com.sihai.dubbo.consumer.Annotation.ConsumerAnnotationService;import com.sihai.dubbo.consumer.configuration.ConsumerConfiguration;import com.sihai.dubbo.provider.service.ProviderService;import org.springframework.context.annotation.AnnotationConfigApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import java.io.IOException;/** * 注解方式启动 * */public class AppAnnotation&#123;    public static void main( String[] args ) throws IOException &#123;        AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(ConsumerConfiguration.class);         context.start(); // 启动        ConsumerAnnotationService consumerAnnotationService = context.getBean(ConsumerAnnotationService.class);         String hello = consumerAnnotationService.doSayHello(&quot;annotation&quot;); // 调用方法        System.out.println(&quot;result: &quot; + hello); // 输出结果    &#125;&#125;\n 结果\n\n 常用场景\n在下面的讲解中，都会是以 xml 配置的方式来讲解的，这也是 dubbo 官方比较推荐的方式。以下的操作都是在服务端的 xml 配置文件和消费端的配置文件来讲解的。\n 启动时检查\nDubbo 缺省会在启动时检查依赖的服务是否可用，不可用时会抛出异常，阻止 Spring 初始化完成，以便上线时，能及早发现问题，默认 `check=“true”。\n但是，有的时候，我们并不是都需要启动时就检查的，比如测试的时候，我们是需要更快速的启动，所以，这种场景的时候，我们是需要关闭这个功能的。\n下面，我们看看如何使用这个功能。\n在服务端注册的时候（客户端注册时同样适用）；\n1&lt;dubbo:registry protocol=&quot;zookeeper&quot; address=&quot;localhost:2181,localhost:2182,localhost:2183&quot; check=&quot;false&quot;/&gt;\n在客户端引用服务端服务的时候；\n12&lt;dubbo:reference check=\"false\" id=\"providerService\"                     interface=\"com.sihai.dubbo.provider.service.ProviderService\"/&gt;\n就是这么简单，就是这么强！\n 集群容错\ndubbo 也是支持集群容错的，同时也有很多可选的方案，其中，默认的方案是 failover，也就是重试机制。\n首先，我们先把所有的容错机制都整理一遍，然后再看看使用。\n\n\n\n集群模式\n说明\n使用方法\n\n\n\n\nFailover Cluster\n失败自动切换，当出现失败，重试其它服务器。通常用于读操作，但重试会带来更长延迟。可通过 retries=“2” 来设置重试次数(不含第一次)。\ncluster=“xxx” xxx：集群模式名称 ，例如cluster=“failover”\n\n\nFailfast Cluster\n快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。\n\n\n\nFailsafe Cluster\n失败安全，出现异常时，直接忽略。\n\n\n\nFailback Cluster\n失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。\n\n\n\nForking Cluster\n并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks=“2” 来设置最大并行数。\n\n\n\nBroadcast Cluster\n广播调用所有提供者，逐个调用，任意一台报错则报错。通常用于通知所有提供者更新缓存或日志等本地资源信息。\n\n\n\n\n 使用实例\n在发布服务或者引用服务的时候设置\n1234&lt;!--服务发布的配置，需要暴露的服务接口--&gt;    &lt;dubbo:service cluster=\"failover\" retries=\"2\"            interface=\"com.sihai.dubbo.provider.service.ProviderService\"            ref=\"providerService\"/&gt;\n12&lt;dubbo:reference cluster=\"failover\" retries=\"2\" check=\"false\" id=\"providerService\"                     interface=\"com.sihai.dubbo.provider.service.ProviderService\"/&gt;\n 负载均衡\n负载均衡想必是一个再熟悉不过的概念了，所以，dubbo 支持也是再正常不过了，这里也总结一下 dubbo 支持的负载均衡的一些方案及使用方法。\n\n\n\n负载均衡模式\n说明\n使用方法\n\n\n\n\nRandom LoadBalance\n随机 按权重设置随机概率\n&lt;dubbo:service loadbalance=“xxx”/&gt; xxx：负载均衡方法\n\n\nRoundRobin LoadBalance\n轮询 按公约后的权重设置轮询比率。\n\n\n\nLeastActive LoadBalance\n最少活跃调用数 相同活跃数的随机，活跃数指调用前后计数差。\n\n\n\nConsistentHash LoadBalance\n一致性 Hash 相同参数的请求总是发到同一提供者。 当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。\n\n\n\n\n 直连提供者\n在开发及测试环境下，经常需要绕过注册中心，只测试指定服务提供者，所以，这种情况下，我们只需要直接连接服务端的地即可，其实，这种方法在前面的讲解已经使用到了，第一种讲解的方式就是这种方式，因为这种方式简单。\n 使用\n123&lt;dubbo:reference id=\"providerService\"                     interface=\"com.sihai.dubbo.provider.service.ProviderService\"                     url=\"dubbo://192.168.234.1:20880/com.sihai.dubbo.provider.service.ProviderService\"/&gt;\n说明：可以看到，只要在消费端在 dubbo:reference 节点使用 url 给出服务端的方法即可。\n 只订阅\n只订阅就是只能够订阅服务端的服务，而不能够注册。\n引用官方的使用场景如下：\n\n为方便开发测试，经常会在线下共用一个所有服务可用的注册中心，这时，如果一个正在开发中的服务提供者注册，可能会影响消费者不能正常运行。\n可以让服务提供者开发方，只订阅服务(开发的服务可能依赖其它服务)，而不注册正在开发的服务，通过直连测试正在开发的服务。\n\n1&lt;dubbo:registry register=\"false\" protocol=\"zookeeper\" address=\"localhost:2181,localhost:2182,localhost:2183\" check=\"false\"/&gt;\n ① 使用只订阅方式\n当在服务提供端使用 register=&quot;false&quot; 的时候，我们使用下面的方式获取服务端的服务；\n12&lt;dubbo:reference cluster=&quot;failover&quot; retries=&quot;2&quot; check=&quot;false&quot; id=&quot;providerService&quot;                     interface=&quot;com.sihai.dubbo.provider.service.ProviderService&quot;/&gt;\n启动信息\n\n发现，这时候并不是向注册中心 zookeeper 注册，而只是做了发布服务和启动netty。\n ② 不使用只订阅方式\n1&lt;dubbo:registry protocol=&quot;zookeeper&quot; address=&quot;localhost:2181,localhost:2182,localhost:2183&quot; check=&quot;false&quot;/&gt;\n启动信息\n\n可以发现，这里就向注册中心 zookeeper 注册了。\n 只注册\n只注册正好跟前面的只订阅相反，这个时候可以向注册中心注册，但是，消费端却不能够读到服务。\n 应用场景\n\n如果有两个镜像环境，两个注册中心，有一个服务只在其中一个注册中心有部署，另一个注册中心还没来得及部署，而两个注册中心的其它应用都需要依赖此服务。这个时候，可以让服务提供者方只注册服务到另一注册中心，而不从另一注册中心订阅服务。\n\n 使用说明\n1&lt;dubbo:registry subscribe=&quot;false&quot; address=&quot;localhost:2181&quot;&gt;&lt;/dubbo:registry&gt;\n在服务端的 dubbo:registry 节点下使用 subscribe=&quot;false&quot; 来声明这个服务是只注册的服务。\n这个时候消费端调用的时候是不能调用的。\n\n 多协议机制\n在前面我们使用的协议都是 dubbo 协议，但是 dubbo 除了支持这种协议外还支持其他的协议，比如，rmi、hessian等，另外，而且还可以用多种协议同时暴露一种服务。\n 使用方法\n一对一，一对多\n ① 一种接口使用一种协议\n先声明多种协议\n123&lt;!--当前服务发布所依赖的协议；webserovice、Thrift、Hessain、http--&gt;   &lt;dubbo:protocol name=\"dubbo\" port=\"20880\"/&gt;   &lt;dubbo:protocol name=\"rmi\" port=\"1099\" /&gt;\n然后在发布接口的时候使用具体协议\n1234567&lt;!--服务发布的配置，需要暴露的服务接口--&gt;    &lt;dubbo:service cluster=\"failover\" retries=\"2\"            interface=\"com.sihai.dubbo.provider.service.ProviderService\"            ref=\"providerService\"/&gt;    &lt;dubbo:service cluster=\"failover\" retries=\"2\"                   interface=\"com.sihai.dubbo.provider.service.ProviderService\"                   ref=\"providerService\" protocol=\"rmi\"/&gt;\n在输出日志中，就可以找到rmi发布的接口。\n1rmi://192.168.234.1:1099/com.sihai.dubbo.provider.service.ProviderService?anyhost=true&amp;application=provider&amp;bean.name=com.sihai.dubbo.provider.service.ProviderService&amp;cluster=failover&amp;dubbo=2.0.2&amp;generic=false&amp;interface=com.sihai.dubbo.provider.service.ProviderService&amp;methods=SayHello&amp;owner=sihai&amp;pid=796&amp;retries=2&amp;side=provider&amp;timestamp=1564281053185, dubbo version: 2.6.6, current host: 192.168.234.1\n ② 一种接口使用多种协议\n声明协议和上面的方式一样，在发布接口的时候有一点不一样。\n123&lt;dubbo:service cluster=&quot;failover&quot; retries=&quot;2&quot;                   interface=&quot;com.sihai.dubbo.provider.service.ProviderService&quot;                   ref=&quot;providerService&quot; protocol=&quot;rmi,dubbo&quot;/&gt;\n**说明：**protocol属性，可以用,隔开，使用多种协议。\n 多注册中心\nDubbo 支持同一服务向多注册中心同时注册，或者不同服务分别注册到不同的注册中心上去，甚至可以同时引用注册在不同注册中心上的同名服务。\n 服务端多注册中心发布服务\n一个服务可以在不同的注册中心注册，当一个注册中心出现问题时，可以用其他的注册中心。\n 注册\n1234&lt;!--多注册中心--&gt;    &lt;dubbo:registry protocol=\"zookeeper\" id=\"reg1\" timeout=\"10000\" address=\"localhost:2181\"/&gt;    &lt;dubbo:registry protocol=\"zookeeper\" id=\"reg2\" timeout=\"10000\" address=\"localhost:2182\"/&gt;    &lt;dubbo:registry protocol=\"zookeeper\" id=\"reg3\" timeout=\"10000\" address=\"localhost:2183\"/&gt;\n 发布服务\n1234567&lt;!--服务发布的配置，需要暴露的服务接口--&gt;    &lt;dubbo:service cluster=\"failover\" retries=\"2\"            interface=\"com.sihai.dubbo.provider.service.ProviderService\"            ref=\"providerService\" registry=\"reg1\"/&gt;    &lt;dubbo:service cluster=\"failover\" retries=\"2\"                   interface=\"com.sihai.dubbo.provider.service.ProviderService\"                   ref=\"providerService\" protocol=\"rmi\" registry=\"reg2\"/&gt;\n**说明：**使用registry=&quot;reg2&quot;指定该接口使用的注册中心，同时也可以使用多个，用，隔开，例如，registry=&quot;reg1,,reg2&quot;。\n 消费端多注册中心引用服务\n首先，先向不同注册中心注册;\n1234&lt;!--多注册中心--&gt;    &lt;dubbo:registry protocol=\"zookeeper\" id=\"reg1\" timeout=\"10000\" address=\"localhost:2181\"/&gt;    &lt;dubbo:registry protocol=\"zookeeper\" id=\"reg2\" timeout=\"10000\" address=\"localhost:2182\"/&gt;    &lt;dubbo:registry protocol=\"zookeeper\" id=\"reg3\" timeout=\"10000\" address=\"localhost:2183\"/&gt;\n其次，不同的消费端服务引用使用不同的注册中心；\n12345!--不同的服务使用不同的注册中心--&gt;    &lt;dubbo:reference cluster=\"failover\" retries=\"2\" check=\"false\" id=\"providerService\"                     interface=\"com.sihai.dubbo.provider.service.ProviderService\" registry=\"reg1\"/&gt;    &lt;dubbo:reference cluster=\"failover\" retries=\"2\" check=\"false\" id=\"providerService2\"                     interface=\"com.sihai.dubbo.provider.service.ProviderService\" registry=\"reg2\"/&gt;\n**说明：**上面分别使用注册中心1和注册中心2。\n 多版本\n不同的服务是有版本不同的，版本可以更新并且升级，同时，不同的版本之间是不可以调用的。\n1234567&lt;!--服务发布的配置，需要暴露的服务接口--&gt;    &lt;dubbo:service cluster=\"failover\" retries=\"2\"            interface=\"com.sihai.dubbo.provider.service.ProviderService\"            ref=\"providerService\" registry=\"reg1\" version=\"1.0.0\"/&gt;    &lt;dubbo:service cluster=\"failover\" retries=\"2\"                   interface=\"com.sihai.dubbo.provider.service.ProviderService\"                   ref=\"providerService\" protocol=\"rmi\" registry=\"reg2\" version=\"1.0.0\"/&gt;\n加入了版本控制。\n 日志管理\ndubbo 也可以将日志信息记录或者保存到文件中的。\n① 使用accesslog输出到log4j\n12&lt;dubbo:protocol accesslog=&quot;true&quot; name=&quot;dubbo&quot; port=&quot;20880&quot;/&gt;    &lt;dubbo:protocol accesslog=&quot;true&quot; name=&quot;rmi&quot; port=&quot;1099&quot; /&gt;\n② 输出到文件\n12&lt;dubbo:protocol accesslog=&quot;http://localhost/log.txt&quot; name=&quot;dubbo&quot; port=&quot;20880&quot;/&gt;    &lt;dubbo:protocol accesslog=&quot;http://localhost/log2.txt&quot; name=&quot;rmi&quot; port=&quot;1099&quot; /&gt;\n","plink":"ilucia.github.io/spring&mybatis/Dubbo/"},{"title":"spring&mybatis/Java Web","date":"2022-04-27T15:24:01.747Z","updated":"2022-04-27T15:24:01.747Z","content":" Servlet\n\n\nServlet其实就是一个遵循Servlet开发的java类\n\n\nServlet是由服务器调用的，运行在服务器端\n\n\nServlet带给我们最大的作用就是能够处理浏览器带来的HTTP请求，并返回一个响应给浏览器，从而实现浏览器和服务器的交互\n\n\n Java Web目录结构\n![Java Web目录结构](/Users/ng/Documents/spring&amp;mybatis/pictures/Java Web目录结构.png)\n\nbbs目录代表一个web应用\nbbs目录下的html,jsp文件可以直接被浏览器访问\nWEB-INF目录下的资源是不能直接被浏览器访问的\nweb.xml文件是web程序的主要配置文件\n所有的classes文件都放在classes目录下\njar文件放在lib目录下\n\n 编写Servlet程序\n\n创建一个自定义类，实现Servlet接口\n我们发现有5个方法需要重写，有init【初始化】，destroy【销毁】,service【服务】,ServletConfig【Servlet配置】,getServletInfo【Servlet信息\n调用ServletResponse对象的方法向浏览器输出HelloWorld\n配置xml文件，光写了Servlet是不行的，Tomcat还要知道浏览器怎么访问这个Servlet\n\n Servlet生命周期\n\n加载Servlet。当Tomcat第一次访问Servlet的时候，Tomcat会负责创建Servlet的实例\n初始化。当Servlet被实例化后，Tomcat会调用init()方法初始化这个对象\n处理服务。当浏览器访问Servlet的时候，Servlet 会调用service()方法处理请求\n销毁。当Tomcat关闭时或者检测到Servlet要从Tomcat删除的时候会自动调用destroy()方法，让该实例释放掉所占的资源。一个Servlet如果长时间不被使用的话，也会被Tomcat自动销毁\n卸载。当Servlet调用完destroy()方法后，等待垃圾回收。如果有需要再次使用这个Servlet，会重新调用init()方法进行初始化操作\n简单总结：只要访问Servlet，service()就会被调用。init()只有第一次访问Servlet的时候才会被调用。destroy()只有在Tomcat关闭的时候才会被调用\n\n\n 继承HttpServlet编写Servlet程序\n\n实现Servlet接口，要实现5个方法\n而HttpServlet类已经实现了Servlet接口的所有方法，编写Servlet时，只需要继承HttpServlet，重写你需要的方法即可，并且它在原有Servlet接口上添加了一些与HTTP协议处理方法，它比Servlet接口的功能更为强大\nidea创建Servlet的时候已经重写好了doGet()和doPost()方法\n\n HTTP协议\n\nHTTP协议是客户端和服务器交互的一种通迅的格式\n当在浏览器中点击这个链接的时候，浏览器会向服务器发送一段文本，**告诉服务器请求打开的是哪一个网页。服务器收到请求后，就返回一段文本给浏览器，浏览器会将该文本解析，然后显示出来。**这段「文本」就是遵循HTTP协议规范的\n\n","plink":"ilucia.github.io/spring&mybatis/Java Web/"},{"title":"spring&mybatis/Mybatis - MybatisPlus","date":"2022-04-27T15:24:01.747Z","updated":"2022-04-27T15:24:01.747Z","content":" Mybatis\n 步骤\n 创建表\n 创建实体\n 创建配置文件\n\n创建mybatis的配置⽂件，配置数据库的信息\n数据库我们可以配置多个，但是默认的只能⽤⼀个\n\n 创建映射文件\n\nSQL语句在映射文件中\n\n CRUD\n\n\ncreate read update delete\n\n\ninsert/update/delete标签只是⼀个模板，在做操作时，其实是以SQL语句为核⼼的\n\n即在做增删改时，insert/update/delete标签可通⽤，\n\n\n\n但做查询时只能⽤select标签\n\n\n我们提倡什么操作就⽤什么标签\n\n\n 创建工具类测试\n\nMybatis中的事务是默认开启的，因此我们在完成操作以后，需要我们⼿动去提交事务\n\n 扩展功能\n 创建DAO\n 分页\n 动态SQL\n 动态查询\n1234567891011121314&lt;!--多条件查询【动态SQL】--&gt;&lt;!--会⾃动组合成⼀个正常的WHERE字句--&gt;&lt;!--name值会从map中寻找--&gt;&lt;select id=\"findByCondition\" resultMap=\"studentMap\" parameterType=\"map\"&gt;  select * from users  &lt;where&gt;    &lt;if test=\"uname!=null\"&gt;    \tand uname=#&#123;uname&#125;  \t&lt;/if&gt;  \t&lt;if test=\"uage!=null\"&gt;  \t\tand uage &lt; #&#123;uage&#125;  \t&lt;/if&gt;  &lt;/where&gt;&lt;/select&gt;\n\n查询名字为name，年龄小于age的人\n\n为null则代表该字段无条件\n\n\n\n123456789101112131415161718192021public static List&lt;User&gt; findByCondition(String name,Integer age) throws Exception &#123;    //得到连接对象    SqlSession sqlSession = MybatisUtil.getSqlSession();    try&#123;        //映射⽂件的命名空间.SQL⽚段的ID，就可以调⽤对应的映射⽂件中的SQL        /**         * 由于我们的参数超过了两个，⽽⽅法中只有⼀个Object参数收集         * 因此我们可以使⽤Map集合来装载我们的参数         */        Map&lt;String, Object&gt; map = new HashMap();        map.put(\"uname\", name);        map.put(\"uage\", age);        return sqlSession.selectList(\"findByCondition\", map);    &#125;catch(Exception e)&#123;        e.printStackTrace();        sqlSession.rollback();        throw e;    &#125;finally&#123;        MybatisUtil.closeSqlSession();    &#125;&#125;\n choose, when, otherwise\n有些时候，我们不想用到所有的条件语句，而只想从中择其一二。针对这种情况，MyBatis 提供了 choose 元素，它有点像 Java 中的 switch 语句。\n还是上面的例子，但是这次变为提供了&quot;title&quot;就按&quot;title&quot;查找，提供了&quot;author&quot;就按&quot;author&quot;查找，若两者都没有提供，就返回所有符合条件的BLOG（实际情况可能是由管理员按一定策略选出BLOG列表，而不是返回大量无意义的随机结果）。\n123456789101112131415&lt;select id=\"findActiveBlogLike\"     resultType=\"Blog\"&gt;  SELECT * FROM BLOG WHERE state = ‘ACTIVE’  &lt;choose&gt;    &lt;when test=\"title != null\"&gt;      AND title like #&#123;title&#125;    &lt;/when&gt;    &lt;when test=\"author != null and author.name != null\"&gt;      AND author_name like #&#123;author.name&#125;    &lt;/when&gt;    &lt;otherwise&gt;      AND featured = 1    &lt;/otherwise&gt;  &lt;/choose&gt;&lt;/select&gt;\n trim, where, set\n前面几个例子已经合宜地解决了一个臭名昭著的动态 SQL 问题。现在考虑回到&quot;if&quot;示例，这次我们将&quot;ACTIVE = 1&quot;也设置成动态的条件，看看会发生什么。\n1234567891011121314&lt;select id=\"findActiveBlogLike\"     resultType=\"Blog\"&gt;  SELECT * FROM BLOG   WHERE   &lt;if test=\"state != null\"&gt;    state = #&#123;state&#125;  &lt;/if&gt;   &lt;if test=\"title != null\"&gt;    AND title like #&#123;title&#125;  &lt;/if&gt;  &lt;if test=\"author != null and author.name != null\"&gt;    AND author_name like #&#123;author.name&#125;  &lt;/if&gt;&lt;/select&gt;\n如果这些条件没有一个能匹配上将会怎样？最终这条 SQL 会变成这样：\n12SELECT * FROM BLOGWHERE\n这会导致查询失败。如果仅仅第二个条件匹配又会怎样？这条 SQL 最终会是这样:\n123SELECT * FROM BLOGWHEREAND title like 'someTitle'\n这个查询也会失败。这个问题不能简单的用条件句式来解决，如果你也曾经被迫这样写过，那么你很可能从此以后都不想再这样去写了。\nMyBatis 有一个简单的处理，这在90%的情况下都会有用。而在不能使用的地方，你可以自定义处理方式来令其正常工作。一处简单的修改就能得到想要的效果：\n123456789101112131415&lt;select id=&quot;findActiveBlogLike&quot;     resultType=&quot;Blog&quot;&gt;  SELECT * FROM BLOG   &lt;where&gt;     &lt;if test=&quot;state != null&quot;&gt;         state = #&#123;state&#125;    &lt;/if&gt;     &lt;if test=&quot;title != null&quot;&gt;        AND title like #&#123;title&#125;    &lt;/if&gt;    &lt;if test=&quot;author != null and author.name != null&quot;&gt;        AND author_name like #&#123;author.name&#125;    &lt;/if&gt;  &lt;/where&gt;&lt;/select&gt;\nwhere 元素知道只有在一个以上的if条件有值的情况下才去插入&quot;WHERE&quot;子句。而且，若最后的内容是&quot;AND&quot;或&quot;OR&quot;开头的，where 元素也知道如何将他们去除。\n如果 where 元素没有按正常套路出牌，我们还是可以通过自定义 trim 元素来定制我们想要的功能。比如，和 where 元素等价的自定义 trim 元素为：\n123&lt;trim prefix=&quot;WHERE&quot; prefixOverrides=&quot;AND |OR &quot;&gt;  ... &lt;/trim&gt;\nprefixOverrides 属性会忽略通过管道分隔的文本序列（注意此例中的空格也是必要的）。它带来的结果就是所有在 prefixOverrides 属性中指定的内容将被移除，并且插入 prefix 属性中指定的内容。\n类似的用于动态更新语句的解决方案叫做 set。set 元素可以被用于动态包含需要更新的列，而舍去其他的。比如：\n12345678910&lt;update id=\"updateAuthorIfNecessary\"&gt;  update Author    &lt;set&gt;      &lt;if test=\"username != null\"&gt;username=#&#123;username&#125;,&lt;/if&gt;      &lt;if test=\"password != null\"&gt;password=#&#123;password&#125;,&lt;/if&gt;      &lt;if test=\"email != null\"&gt;email=#&#123;email&#125;,&lt;/if&gt;      &lt;if test=\"bio != null\"&gt;bio=#&#123;bio&#125;&lt;/if&gt;    &lt;/set&gt;  where id=#&#123;id&#125;&lt;/update&gt;\n这里，set 元素会动态前置 SET 关键字，同时也会消除无关的逗号，因为用了条件语句之后很可能就会在生成的赋值语句的后面留下这些逗号。\n若你对等价的自定义 trim 元素的样子感兴趣，那这就应该是它的真面目：\n123&lt;trim prefix=&quot;SET&quot; suffixOverrides=&quot;,&quot;&gt;  ...&lt;/trim&gt;\n注意这里我们忽略的是后缀中的值，而又一次附加了前缀中的值。\n foreach\n动态 SQL 的另外一个常用的必要操作是需要对一个集合进行遍历，通常是在构建 IN 条件语句的时候。比如：\n123456789&lt;select id=&quot;selectPostIn&quot; resultType=&quot;domain.blog.Post&quot;&gt;  SELECT *  FROM POST P  WHERE ID in  &lt;foreach item=&quot;item&quot; index=&quot;index&quot; collection=&quot;list&quot;      open=&quot;(&quot; separator=&quot;,&quot; close=&quot;)&quot;&gt;        #&#123;item&#125;  &lt;/foreach&gt;&lt;/select&gt;\nforeach 元素的功能是非常强大的，它允许你指定一个集合，声明可以用在元素体内的集合项和索引变量。它也允许你指定开闭匹配的字符串以及在迭代中间放置分隔符。这个元素是很智能的，因此它不会偶然地附加多余的分隔符。\n注意 你可以将一个 List 实例或者数组作为参数对象传给 MyBatis，当你这么做的时候，MyBatis 会自动将它包装在一个 Map 中并以名称为键。List 实例将会以&quot;list&quot;作为键，而数组实例的键将是&quot;array&quot;。\n到此我们已经完成了涉及 XML 配置文件和 XML 映射文件的讨论。下一部分将详细探讨 Java API，这样才能从已创建的映射中获取最大利益。\n bind\nbind 元素可以从 OGNL 表达式中创建一个变量并将其绑定到上下文。比如：\n12345&lt;select id=&quot;selectBlogsLike&quot; resultType=&quot;Blog&quot;&gt;  &lt;bind name=&quot;pattern&quot; value=&quot;&apos;%&apos; + _parameter.getTitle() + &apos;%&apos;&quot; /&gt;  SELECT * FROM BLOG  WHERE title LIKE #&#123;pattern&#125;&lt;/select&gt;\n Multi-db vendor support\n一个配置了&quot;_databaseId&quot;变量的 databaseIdProvider 对于动态代码来说是可用的，这样就可以根据不同的数据库厂商构建特定的语句。比如下面的例子：\n1234567891011&lt;insert id=\"insert\"&gt;  &lt;selectKey keyProperty=\"id\" resultType=\"int\" order=\"BEFORE\"&gt;    &lt;if test=\"_databaseId == 'oracle'\"&gt;      select seq_users.nextval from dual    &lt;/if&gt;    &lt;if test=\"_databaseId == 'db2'\"&gt;      select nextval for seq_users from sysibm.sysdummy1\"    &lt;/if&gt;  &lt;/selectKey&gt;  insert into users values (#&#123;id&#125;, #&#123;name&#125;)&lt;/insert&gt;\n 动态 SQL 中可插拔的脚本语言\nMyBatis 从 3.2 开始支持可插拔的脚本语言，因此你可以在插入一种语言的驱动（language driver）之后来写基于这种语言的动态 SQL 查询。\n可以通过实现下面接口的方式来插入一种语言：\n12345public interface LanguageDriver &#123;  ParameterHandler createParameterHandler(MappedStatement mappedStatement, Object parameterObject, BoundSql boundSql);  SqlSource createSqlSource(Configuration configuration, XNode script, Class parameterType);  SqlSource createSqlSource(Configuration configuration, String script, Class parameterType);&#125;\n一旦有了自定义的语言驱动，你就可以在 mybatis-config.xml 文件中将它设置为默认语言：\n123456&lt;typeAliases&gt;  &lt;typeAlias type=\"org.sample.MyLanguageDriver\" alias=\"myLanguage\"/&gt;&lt;/typeAliases&gt;&lt;settings&gt;  &lt;setting name=\"defaultScriptingLanguage\" value=\"myLanguage\"/&gt;&lt;/settings&gt;\n除了设置默认语言，你也可以针对特殊的语句指定特定语言，这可以通过如下的 lang 属性来完成：\n123&lt;select id=\"selectBlog\" lang=\"myLanguage\"&gt;  SELECT * FROM BLOG&lt;/select&gt;\n或者在你正在使用的映射中加上注解 @Lang 来完成：\n12345public interface Mapper &#123;  @Lang(MyLanguageDriver.class)  @Select(\"SELECT * FROM BLOG\")  List selectBlog();&#125;\n注意 可以将 Apache Velocity 作为动态语言来使用，更多细节请参考 MyBatis-Velocity 项目。\n你前面看到的所有 xml 标签都是默认 MyBatis 语言提供的，它是由别名为 xml 语言驱动器 org.apache.ibatis.scripting.xmltags.XmlLanguageDriver 驱动的。\n 注解\n\n\n\n注解\n目标\n相对应的 XML\n描述\n\n\n\n\n@CacheNamespace\n类\n``\n为给定的命名空间 (比如类) 配置缓存。 属性:implemetation,eviction, flushInterval,size 和 readWrite。\n\n\n@CacheNamespaceRef\n类\n``\n参照另外一个命名空间的缓存来使用。 属性:value,应该是一个名空间的字 符串值(也就是类的完全限定名) 。\n\n\n@ConstructorArgs\nMethod\n``\n收集一组结果传递给一个劫夺对象的 构造方法。属性:value,是形式参数 的数组。\n\n\n@Arg\n方法\n\n单 独 的 构 造 方 法 参 数 , 是 ConstructorArgs 集合的一部分。属性: id,column,javaType,typeHandler。 id 属性是布尔值, 来标识用于比较的属 性,和XML 元素相似。\n\n\n@TypeDiscriminator\n方法\n``\n一组实例值被用来决定结果映射的表 现。 属性: column, javaType, jdbcType, typeHandler,cases。cases 属性就是实 例的数组。\n\n\n@Case\n方法\n``\n单独实例的值和它对应的映射。属性: value,type,results。Results 属性是结 果数组,因此这个注解和实际的 ResultMap 很相似,由下面的 Results 注解指定。\n\n\n@Results\n方法\n``\n结果映射的列表, 包含了一个特别结果 列如何被映射到属性或字段的详情。 属 性:value,是 Result 注解的数组。\n\n\n@Result\n方法\n\n在列和属性或字段之间的单独结果映 射。属 性:id,column, property, javaType ,jdbcType ,type Handler, one,many。id 属性是一个布尔值,表 示了应该被用于比较(和在 XML 映射 中的相似)的属性。one 属性是单 独 的 联 系, 和 相 似 , 而 many 属 性 是 对 集 合 而 言 的 , 和 相似。 它们这样命名是为了 避免名称冲突。\n\n\n@One\n方法\n``\n复杂类型的单独属性值映射。属性: select,已映射语句(也就是映射器方 法)的完全限定名,它可以加载合适类 型的实例。注意:联合映射在注解 API 中是不支持的。这是因为 Java 注解的 限制,不允许循环引用。fetchType, which supersedes the global configuration parameterlazyLoadingEnabled for this mapping.\n\n\n@Many\n方法\n``\nA mapping to a collection property of a complex type. Attributes:select, which is the fully qualified name of a mapped statement (i.e. mapper method) that can load a collection of instances of the appropriate types,fetchType, which supersedes the global configuration parameterlazyLoadingEnabled for this mapping. NOTE You will notice that join mapping is not supported via the Annotations API. This is due to the limitation in Java Annotations that does not allow for circular references.\n\n\n@MapKey\n方法\n\n复 杂 类 型 的 集合 属 性 映射 。 属 性 : select,是映射语句(也就是映射器方 法)的完全限定名,它可以加载合适类 型的一组实例。注意:联合映射在 Java 注解中是不支持的。这是因为 Java 注 解的限制,不允许循环引用。\n\n\n@Options\n方法\n映射语句的属性\n这个注解提供访问交换和配置选项的 宽广范围, 它们通常在映射语句上作为 属性出现。 而不是将每条语句注解变复 杂,Options 注解提供连贯清晰的方式 来访问它们。属性:useCache=true , flushCache=false , resultSetType=FORWARD_ONLY , statementType=PREPARED , fetchSize=-1 , , timeout=-1 useGeneratedKeys=false , keyProperty=“id”。 理解 Java 注解是很 重要的,因为没有办法来指定&quot;null&quot; 作为值。因此,一旦你使用了 Options 注解,语句就受所有默认值的支配。要 注意什么样的默认值来避免不期望的 行为。\n\n\n* @Insert,@Update, @Delete, @Select\n方法\n&lt;insert&gt;,&lt;update&gt;,&lt;delete&gt;,&lt;select&gt;\n这些注解中的每一个代表了执行的真 实 SQL。 它们每一个都使用字符串数组 (或单独的字符串)。如果传递的是字 符串数组, 它们由每个分隔它们的单独 空间串联起来。这就当用 Java 代码构 建 SQL 时避免了“丢失空间”的问题。 然而,如果你喜欢,也欢迎你串联单独 的字符串。属性:value,这是字符串 数组用来组成单独的 SQL 语句。\n\n\n@InsertProvider,@UpdateProvider,@DeleteProvider,@SelectProvider\n方法\n&lt;insert&gt;,&lt;update&gt;,&lt;delete&gt;,&lt;select&gt;\n这些可选的 SQL 注解允许你指定一个 类名和一个方法在执行时来返回运行 允许创建动态 的 SQL。 基于执行的映射语句, MyBatis 会实例化这个类,然后执行由 provider 指定的方法. 这个方法可以选择性的接 受参数对象作为它的唯一参数, 但是必 须只指定该参数或者没有参数。属性: type,method。type 属性是类的完全限 定名。method 是该类中的那个方法名。 注意: 这节之后是对 SelectBuilder 类的 讨论,它可以帮助你以干净,容于阅读 的方式来构建动态 SQL。\n\n\n@Param\nParameter\nN/A\n如果你的映射器的方法需要多个参数, 这个注解可以被应用于映射器的方法 参数来给每个参数一个名字。否则,多 参数将会以它们的顺序位置来被命名 (不包括任何 RowBounds 参数) 比如。 #{param1} , #{param2} 等 , 这 是 默 认 的 。 使 用 @Param(“person”),参数应该被命名为 #{person}。\n\n\n@SelectKey\nMethod\n&lt;selectKey&gt;\nThis annotation duplicates the `` functionality for methods annotated with@Insert,@InsertProvider,@Updateor@UpdateProvider. It is ignored for other methods. If you specify a@SelectKeyannotation, then MyBatis will ignore any generated key properties set via the@Optionsannotation, or configuration properties. Attributes: statement an array of strings which is the SQL statement to execute,keyPropertywhich is the property of the parameter object that will be updated with the new value, before which must be eithertrueorfalseto denote if the SQL statement should be executed before or after the insert,resultTypewhich is the Java type of thekeyProperty, andstatementType=PREPARED.\n\n\n@ResultMap\nMethod\nN/A\nThis annotation is used to provide the id of a `` element in an XML mapper to a@Selector@SelectProviderannotation. This allows annotated selects to reuse resultmaps that are defined in XML. This annotation will override any@Resultsor@ConstructorArgs annotation if both are specified on an annotated select.\n\n\n@ResultType\nMethod\nN/A\nThis annotation is used when using a result handler. In that case, the return type is void so MyBatis must have a way to determine the type of object to construct for each row. If there is an XML result map, use the @ResultMap annotation. If the result type is specified in XML on the ` Night Mode\n\n\n\n 映射申明样例\n这个例子展示了如何使用 @SelectKey 注解来在插入前读取数据库序列的值：\n123@Insert(&quot;insert into table3 (id, name) values(#&#123;nameId&#125;, #&#123;name&#125;)&quot;)@SelectKey(statement=&quot;call next value for TestSequence&quot;, keyProperty=&quot;nameId&quot;, before=true, resultType=int.class)int insertTable3(Name name);\n这个例子展示了如何使用 @SelectKey 注解来在插入后读取数据库识别列的值：\n123@Insert(&quot;insert into table2 (name) values(#&#123;name&#125;)&quot;)@SelectKey(statement=&quot;call identity()&quot;, keyProperty=&quot;nameId&quot;, before=false, resultType=int.class)int insertTable2(Name name);\n MyBatis Plus\n 一、mybatis-plus简介：\nMybatis-Plus（简称MP）是一个 Mybatis 的增强工具，在 Mybatis 的基础上只做增强不做改变，为简化开发、提高效率而生。这是官方给的定义，关于mybatis-plus的更多介绍及特性，可以参考mybatis-plus官网。那么它是怎么增强的呢？其实就是它已经封装好了一些crud方法，我们不需要再写xml了，直接调用这些方法就行，就类似于JPA。\n 二、spring整合mybatis-plus:\n正如官方所说，mybatis-plus在mybatis的基础上只做增强不做改变，因此其与spring的整合亦非常简单。只需把mybatis的依赖换成mybatis-plus的依赖，再把sqlSessionFactory换成mybatis-plus的即可。接下来看具体操作：\n 1、pom.xml:\n核心依赖如下：\n1234567891011121314151617181920212223&lt;!-- spring --&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework&lt;/groupId&gt;    &lt;artifactId&gt;spring-context&lt;/artifactId&gt;    &lt;version&gt;4.3.14.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework&lt;/groupId&gt;    &lt;artifactId&gt;spring-orm&lt;/artifactId&gt;    &lt;version&gt;4.3.14.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework&lt;/groupId&gt;    &lt;artifactId&gt;spring-test&lt;/artifactId&gt;    &lt;version&gt;4.3.14.RELEASE&lt;/version&gt;    &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;!-- mp 依赖 --&gt;&lt;dependency&gt;    &lt;groupId&gt;com.baomidou&lt;/groupId&gt;    &lt;artifactId&gt;mybatis-plus&lt;/artifactId&gt;    &lt;version&gt;2.3&lt;/version&gt;&lt;/dependency&gt;\n**注意：**这些是核心依赖，本项目还用到了mysql驱动、c3p0、日志（slf4j-api，slf4j-log4j2）、lombok。集成mybatis-plus要把mybatis、mybatis-spring去掉，避免冲突；lombok是一个工具，添加了这个依赖，开发工具再安装Lombok插件，就可以使用它了，最常用的用法就是在实体类中使用它的@Data注解，这样实体类就不用写set、get、toString等方法了。关于Lombok的更多用法，请自行百度。\n 2、log4j.xml:\n123456789101112131415161718192021&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"&gt;&lt;log4j:configuration xmlns:log4j=\"http://jakarta.apache.org/log4j/\"&gt;    &lt;appender name=\"STDOUT\" class=\"org.apache.log4j.ConsoleAppender\"&gt;        &lt;param name=\"Encoding\" value=\"UTF-8\" /&gt;        &lt;layout class=\"org.apache.log4j.PatternLayout\"&gt;            &lt;param name=\"ConversionPattern\" value=\"%-5p %d&#123;MM-ddHH:mm:ss,SSS&#125; %m (%F:%L) \\n\" /&gt;        &lt;/layout&gt;    &lt;/appender&gt;    &lt;logger name=\"java.sql\"&gt;        &lt;level value=\"debug\" /&gt;    &lt;/logger&gt;    &lt;logger name=\"org.apache.ibatis\"&gt;        &lt;level value=\"info\" /&gt;    &lt;/logger&gt;    &lt;root&gt;        &lt;level value=\"debug\" /&gt;        &lt;appender-ref ref=\"STDOUT\" /&gt;    &lt;/root&gt;&lt;/log4j:configuration&gt;\n 3、jdbc.properties:\n1234jdbc.driver=com.mysql.jdbc.Driverjdbc.url=jdbc:mysql:///数据库名?useUnicode=true&amp;characterEncoding=utf8jdbc.username=#jdbc.password=#\n 4、mybatis-config.xml:\n123456&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE configurationPUBLIC \"-//mybatis.org//DTD Config 3.0//EN\"\"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt;&lt;/configuration&gt;\n**注：**因为是与spring整合，所有mybatis-plus的大部分都写在spring的配置文件中，这里定义一个空的mybatis-config.xml即可。\n 5、spring-dao.xml:\n1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;    &lt;beans xmlns=\"http://www.springframework.org/schema/beans\"        xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"       xmlns:p=\"http://www.springframework.org/schema/p\"      xmlns:aop=\"http://www.springframework.org/schema/aop\"       xmlns:context=\"http://www.springframework.org/schema/context\"      xmlns:jee=\"http://www.springframework.org/schema/jee\"      xmlns:tx=\"http://www.springframework.org/schema/tx\"      xsi:schemaLocation=\"            http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.0.xsd          http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd          http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd          http://www.springframework.org/schema/jee http://www.springframework.org/schema/jee/spring-jee-4.0.xsd          http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.0.xsd\"&gt;                &lt;!-- 配置整合mybatis-plus过程 --&gt;    &lt;!-- 1、配置数据库相关参数properties的属性：$&#123;url&#125; --&gt;    &lt;context:property-placeholder location=\"classpath:jdbc.properties\" /&gt;    &lt;!-- 2、配置数据库连接池 --&gt;    &lt;bean id=\"dataSource\" class=\"com.mchange.v2.c3p0.ComboPooledDataSource\"&gt;        &lt;property name=\"driverClass\" value=\"$&#123;jdbc.driver&#125;\"/&gt;        &lt;property name=\"jdbcUrl\" value=\"$&#123;jdbc.url&#125;\"/&gt;        &lt;property name=\"user\" value=\"$&#123;jdbc.username&#125;\"/&gt;        &lt;property name=\"password\" value=\"$&#123;jdbc.password&#125;\"/&gt;    &lt;/bean&gt;    &lt;!-- mybatis的sqlsessionFactorybean：org.mybatis.spring.SqlSessionFactoryBean--&gt;    &lt;!-- 3、配置mybatis-plus的sqlSessionFactory --&gt;    &lt;bean id=\"sqlSessionFactory\" class=\"com.baomidou.mybatisplus.spring.MybatisSqlSessionFactoryBean\"&gt;        &lt;property name=\"dataSource\" ref=\"dataSource\" /&gt;        &lt;property name=\"configLocation\" value=\"classpath:mybatis-config.xml\"/&gt;        &lt;property name=\"typeAliasesPackage\" value=\"com.zhu.mybatisplus.entity\"/&gt;    &lt;/bean&gt;    &lt;!-- 4、DAO接口所在包名，Spring会自动查找其下的类 --&gt;    &lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt;        &lt;property name=\"basePackage\" value=\"com.zhu.mybatisplus.dao\" /&gt;        &lt;property name=\"sqlSessionFactoryBeanName\" value=\"sqlSessionFactory\"/&gt;    &lt;/bean&gt; &lt;/beans&gt;\n 6、entity:\n12345678910111213@Data@TableName(value = \"tb_employee\")//指定表名public class Employee &#123;    //value与数据库主键列名一致，若实体类属性名与表主键列名一致可省略value    @TableId(value = \"id\",type = IdType.AUTO)//指定自增策略    private Integer id;    //若没有开启驼峰命名，或者表中列名不符合驼峰规则，可通过该注解指定数据库表中的列名，exist标明数据表中有没有对应列    @TableField(value = \"last_name\",exist = true)    private String lastName;    private String email;    private Integer gender;    private Integer age;&#125;\n 7、mapper:\n12public interface EmplopyeeDao extends BaseMapper&lt;Employee&gt; &#123;&#125;\n这样就完成了mybatis-plus与spring的整合。首先是把mybatis和mybatis-spring依赖换成mybatis-plus的依赖，然后把sqlsessionfactory换成mybatis-plus的，然后实体类中添加@TableName、@TableId等注解，最后mapper继承BaseMapper即可。\n 8、测试：\n12345678910@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(&#123;\"classpath:spring/spring-dao.xml\"&#125;)public class test &#123;    @Autowired    private DataSource dataSource;    @Test    public void testDataSource() throws SQLException &#123;        System.out.println(dataSource.getConnection());    &#125;&#125;\n运行该junit，可输出获取到的连接，说明整合没问题：\n 三、mp的通用crud\n\n需求：\n\n存在一张 tb_employee 表，且已有对应的实体类 Employee，实现tb_employee 表的 CRUD 操作我们需要做什么呢？\n\n\n基于 Mybatis：\n\n需要编写 EmployeeMapper 接口，并在 EmployeeMapper.xml 映射文件中手动编写 CRUD 方法对应的sql语句。\n\n\n基于 MP：\n\n只需要创建 EmployeeMapper 接口, 并继承 BaseMapper 接口\n我们已经有了Employee、tb_employee了，并且EmployeeDao也继承了BaseMapper了，接下来就使用crud方法\n\n\n\n 1、insert操作：\n1234567891011121314151617@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(&#123;\"classpath:spring/spring-dao.xml\"&#125;)public class test &#123;    @Autowired    private EmplopyeeDao emplopyeeDao;    @Test    public void testInsert()&#123;        Employee employee = new Employee();        employee.setLastName(\"东方不败\");        employee.setEmail(\"dfbb@163.com\");        employee.setGender(1);        employee.setAge(20);        emplopyeeDao.insert(employee);        //mybatisplus会自动把当前插入对象在数据库中的id写回到该实体中        System.out.println(employee.getId());    &#125;&#125;\n执行添加操作，直接调用insert方法传入实体即可。\n 2、update操作：\n12345678@Testpublic void testUpdate()&#123;        Employee employee = new Employee();        employee.setId(1);        employee.setLastName(\"更新测试\");        //emplopyeeDao.updateById(employee);//根据id进行更新，没有传值的属性就不会更新        emplopyeeDao.updateAllColumnById(employee);//根据id进行更新，没传值的属性就更新为null&#125;\n**注：**注意这两个update操作的区别，updateById方法，没有传值的字段不会进行更新，比如只传入了lastName，那么age、gender等属性就会保留原来的值；updateAllColumnById方法，顾名思义，会更新所有的列，没有传值的列会更新为null。\n 3、select操作：\n**(1)、**根据id查询：\n1Employee employee = emplopyeeDao.selectById(1);\n**(2)、**根据条件查询一条数据：\n12345Employee employeeCondition = new Employee();employeeCondition.setId(1);employeeCondition.setLastName(\"更新测试\");//若是数据库中符合传入的条件的记录有多条，那就不能用这个方法，会报错Employee employee = emplopyeeDao.selectOne(employeeCondition);\n**注：**这个方法的sql语句就是where id = 1 and last_name = 更新测试，若是符合这个条件的记录不止一条，那么就会报错。\n**(3)、**根据查询条件返回多条数据：\n当符合指定条件的记录数有多条时，上面那个方法就会报错，就应该用这个方法。\n12345Map&lt;String,Object&gt; columnMap = new HashMap&lt;&gt;();columnMap.put(\"last_name\",\"东方不败\");//写表中的列名columnMap.put(\"gender\",\"1\");List&lt;Employee&gt; employees = emplopyeeDao.selectByMap(columnMap);System.out.println(employees.size());\n**注：**查询条件用map集合封装，columnMap，写的是数据表中的列名，而非实体类的属性名。比如属性名为lastName，数据表中字段为last_name，这里应该写的是last_name。selectByMap方法返回值用list集合接收。\n**(4)、**通过id批量查询：\n123456List&lt;Integer&gt; idList = new ArrayList&lt;&gt;();idList.add(1);idList.add(2);idList.add(3);List&lt;Employee&gt; employees = emplopyeeDao.selectBatchIds(idList);System.out.println(employees);\n**注：**把需要查询的id都add到list集合中，然后调用selectBatchIds方法，传入该list集合即可，该方法返回的是对应id的所有记录，所有返回值也是用list接收。\n**(5)、**分页查询：\n12List&lt;Employee&gt; employees = emplopyeeDao.selectPage(new Page&lt;&gt;(1,2),null);System.out.println(employees);\n**注：**selectPage方法就是分页查询，在page中传入分页信息，后者为null的分页条件，这里先让其为null，讲了条件构造器再说其用法。这个分页其实并不是物理分页，而是内存分页。也就是说，查询的时候并没有limit语句。等配置了分页插件后才可以实现真正的分页。\n4、delete操作：\n**(1)、**根据id删除：\n1emplopyeeDao.deleteById(1);\n**(2)、**根据条件删除：\n1234Map&lt;String,Object&gt; columnMap = new HashMap&lt;&gt;();columnMap.put(\"gender\",0);columnMap.put(\"age\",18);emplopyeeDao.deleteByMap(columnMap);\n**注：**该方法与selectByMap类似，将条件封装在columnMap中，然后调用deleteByMap方法，传入columnMap即可，返回值是Integer类型，表示影响的行数。\n**(3)、**根据id批量删除：\n1234List&lt;Integer&gt; idList = new ArrayList&lt;&gt;();idList.add(1);idList.add(2);emplopyeeDao.deleteBatchIds(idList);\n**注：**该方法和selectBatchIds类似，把需要删除的记录的id装进idList，然后调用deleteBatchIds，传入idList即可。\n 四、全局策略配置：\n通过上面的小案例我们可以发现，实体类需要加@TableName注解指定数据库表名，通过@TableId注解指定id的增长策略。实体类少倒也无所谓，实体类一多的话也麻烦。所以可以在spring-dao.xml的文件中进行全局策略配置。\n123456789&lt;!-- 5、mybatisplus的全局策略配置 --&gt;&lt;bean id=\"globalConfiguration\" class=\"com.baomidou.mybatisplus.entity.GlobalConfiguration\"&gt;        &lt;!-- 2.3版本后，驼峰命名默认值就是true，所以可不配置 --&gt;        &lt;!--&lt;property name=\"dbColumnUnderline\" value=\"true\"/&gt;--&gt;        &lt;!-- 全局主键自增策略，0表示auto --&gt;        &lt;property name=\"idType\" value=\"0\"/&gt;        &lt;!-- 全局表前缀配置 --&gt;        &lt;property name=\"tablePrefix\" value=\"tb_\"/&gt;&lt;/bean&gt;\n这里配置了还没用，还需要在sqlSessionFactory中注入配置才会生效。如下：\n12345678&lt;!-- 3、配置mybatisplus的sqlSessionFactory --&gt;&lt;bean id=\"sqlSessionFactory\" class=\"com.baomidou.mybatisplus.spring.MybatisSqlSessionFactoryBean\"&gt;        &lt;property name=\"dataSource\" ref=\"dataSource\" /&gt;        &lt;property name=\"configLocation\" value=\"classpath:mybatis-config.xml\"/&gt;        &lt;property name=\"typeAliasesPackage\" value=\"com.zhu.mybatisplus.entity\"/&gt;        &lt;!-- 注入全局配置 --&gt;        &lt;property name=\"globalConfig\" ref=\"globalConfiguration\"/&gt;&lt;/bean&gt;\n如此一来，实体类中的@TableName注解和@TableId注解就可以去掉了\n 五、条件构造器(EntityWrapper)：\n以上基本的 CRUD 操作，我们仅仅需要继承一个 BaseMapper 即可实现大部分单表 CRUD 操作。BaseMapper 提供了多达 17 个方法供使用, 可以极其方便的实现单一、批量、分页等操作，极大的减少开发负担。但是mybatis-plus的强大不限于此，请看如下需求该如何处理：\n\n需求：\n\n我们需要分页查询 tb_employee 表中，年龄在 18~50 之间性别为男且姓名为 xx 的所有用户，这时候我们该如何实现上述需求呢？\n\n\n使用MyBatis : 需要在 SQL 映射文件中编写带条件查询的 SQL,并用PageHelper 插件完成分页. 实现以上一个简单的需求，往往需要我们做很多重复单调的工作。\n使用MP: 依旧不用编写 SQL 语句，MP 提供了功能强大的条件构造器 ------  EntityWrapper。\n\n接下来就直接看几个案例体会EntityWrapper的使用。\n 1、分页查询年龄在18 - 50且gender为0、姓名为tom的用户：\n123456List&lt;Employee&gt; employees = emplopyeeDao.selectPage(new Page&lt;Employee&gt;(1,3),     new EntityWrapper&lt;Employee&gt;()        .between(\"age\",18,50)        .eq(\"gender\",0)        .eq(\"last_name\",\"tom\"));\n**注：**由此案例可知，分页查询和之前一样，new 一个page对象传入分页信息即可。至于分页条件，new 一个EntityWrapper对象，调用该对象的相关方法即可。between方法三个参数，分别是column、value1、value2，该方法表示column的值要在value1和value2之间；eq是equals的简写，该方法两个参数，column和value，表示column的值和value要相等。注意column是数据表对应的字段，而非实体类属性字段。\n 2、查询gender为0且名字中带有老师、或者邮箱中带有a的用户：\n12345678List&lt;Employee&gt; employees = emplopyeeDao.selectList(                new EntityWrapper&lt;Employee&gt;()               .eq(\"gender\",0)               .like(\"last_name\",\"老师\")                //.or()//和or new 区别不大               .orNew()               .like(\"email\",\"a\"));\n**注：**未说分页查询，所以用selectList即可，用EntityWrapper的like方法进行模糊查询，like方法就是指column的值包含value值，此处like方法就是查询last_name中包含“老师”字样的记录；“或者”用or或者orNew方法表示，这两个方法区别不大，用哪个都可以，可以通过控制台的sql语句自行感受其区别。\n 3、查询gender为0，根据age排序，简单分页：\n123456List&lt;Employee&gt; employees = emplopyeeDao.selectList(                new EntityWrapper&lt;Employee&gt;()                .eq(\"gender\",0)                .orderBy(\"age\")//直接orderby 是升序，asc                .last(\"desc limit 1,3\")//在sql语句后面追加last里面的内容(改为降序，同时分页));\n**注：**简单分页是指不用page对象进行分页。orderBy方法就是根据传入的column进行升序排序，若要降序，可以使用orderByDesc方法，也可以如案例中所示用last方法；last方法就是将last方法里面的value值追加到sql语句的后面，在该案例中，最后的sql语句就变为select ······ order by desc limit 1, 3，追加了desc limit 1,3所以可以进行降序排序和分页。\n 4、分页查询年龄在18 - 50且gender为0、姓名为tom的用户：\n条件构造器除了EntityWrapper，还有Condition。用Condition来处理一下这个需求：\n123456List&lt;Employee&gt; employees = emplopyeeDao.selectPage(               new Page&lt;Employee&gt;(1,2),               Condition.create()                       .between(\"age\",18,50)                       .eq(\"gender\",\"0\"));\n**注：**Condition和EntityWrapper的区别就是，创建条件构造器时，EntityWrapper是new出来的，而Condition是调create方法创建出来。\n 5、根据条件更新：\n123456789101112@Testpublic void testEntityWrapperUpdate()&#123;        Employee employee = new Employee();        employee.setLastName(\"苍老师\");        employee.setEmail(\"cjk@sina.com\");        employee.setGender(0);        emplopyeeDao.update(employee,                new EntityWrapper&lt;Employee&gt;()                .eq(\"last_name\",\"tom\")                .eq(\"age\",25)        );&#125;\n**注：**该案例表示把last_name为tom，age为25的所有用户的信息更新为employee中设置的信息。\n 6、根据条件删除：\n12345emplopyeeDao.delete(        new EntityWrapper&lt;Employee&gt;()        .eq(\"last_name\",\"tom\")        .eq(\"age\",16));\n**注：**该案例表示把last_name为tom、age为16的所有用户删除。\n 代码生成工具\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193package com.zhx.plus_demo2.util;import com.baomidou.mybatisplus.core.exceptions.MybatisPlusException;import com.baomidou.mybatisplus.core.toolkit.StringPool;import com.baomidou.mybatisplus.generator.AutoGenerator;import com.baomidou.mybatisplus.generator.InjectionConfig;import com.baomidou.mybatisplus.generator.config.*;import com.baomidou.mybatisplus.generator.config.po.TableInfo;import com.baomidou.mybatisplus.generator.config.rules.DateType;import com.baomidou.mybatisplus.generator.config.rules.NamingStrategy;import org.apache.commons.lang3.StringUtils;import java.util.ArrayList;import java.util.List;import java.util.Scanner;// 演示例子，执行 main 方法控制台输入模块表名回车自动生成对应项目目录中public class MpGenerator &#123;    public static final String projectPath = System.getProperty(\"user.dir\");    /**     * &lt;p&gt;     * 读取控制台内容     * &lt;/p&gt;     */    public static String scanner(String tip) &#123;        Scanner scanner = new Scanner(System.in);        System.out.println(\"请输入\" + tip + \"：\");        if (scanner.hasNext()) &#123;            String ipt = scanner.next();            if (StringUtils.isNotEmpty(ipt)) &#123;                return ipt;            &#125;        &#125;        throw new MybatisPlusException(\"请输入正确的\" + tip + \"！\");    &#125;    public static void main(String[] args) &#123;        // 全局配置        GlobalConfig globalConfig = generateGlobalConfig();        // 数据源配置        DataSourceConfig dsc = generateDataSourceConfig();        // 包设置        final PackageConfig pc = generatePackageConfig();        // 自定义设置        InjectionConfig injectionConfig = generateInjectConfig(pc);        // 策略配置        StrategyConfig strategy = generateStrategy();        // 配置模板        TemplateConfig templateConfig = new TemplateConfig();        // 配置自定义输出模板        //指定自定义模板路径，注意不要带上.ftl/.vm, 会根据使用的模板引擎自动识别        // templateConfig.setEntity(\"templates/entity2.java\");        // templateConfig.setService();        // templateConfig.setController();        templateConfig.setXml(null);        // 代码生成器        AutoGenerator mpg = new AutoGenerator();        mpg.setGlobalConfig(globalConfig);        mpg.setDataSource(dsc);        mpg.setPackageInfo(pc);        mpg.setStrategy(strategy);        mpg.setCfg(injectionConfig);        mpg.setTemplate(templateConfig);        mpg.execute();    &#125;    private static StrategyConfig generateStrategy() &#123;        // 策略配置        StrategyConfig strategy = new StrategyConfig();        // strategy.setCapitalMode(true);// 全局大写命名 ORACLE 注意        //strategy.setTablePrefix(new String[] &#123; \"tlog_\", \"tsys_\" &#125;);// 此处可以修改为您的表前缀        strategy.setNaming(NamingStrategy.underline_to_camel);// 表名生成策略        strategy.setInclude(scanner(\"表名\").split(\",\")); // 需要生成的表        strategy.setEntityLombokModel(true);        strategy.setEntityBuilderModel(true);        // strategy.setExclude(new String[]&#123;\"test\"&#125;); // 排除生成的表        // 自定义实体父类        // strategy.setSuperEntityClass(\"com.baomidou.demo.TestEntity\");        // 自定义实体，公共字段        // strategy.setSuperEntityColumns(new String[] &#123; \"test_id\", \"age\" &#125;);        // 自定义 mapper 父类        // strategy.setSuperMapperClass(\"com.baomidou.demo.TestMapper\");        // 自定义 service 父类        // strategy.setSuperServiceClass(\"com.baomidou.demo.TestService\");        // 自定义 service 实现类父类        // strategy.setSuperServiceImplClass(\"com.baomidou.demo.TestServiceImpl\");        // 自定义 controller 父类        // strategy.setSuperControllerClass(\"com.baomidou.demo.TestController\");        // 【实体】是否生成字段常量（默认 false）        // public static final String ID = \"test_id\";        // strategy.setEntityColumnConstant(true);        return strategy;    &#125;    private static InjectionConfig generateInjectConfig(PackageConfig pc) &#123;        // 自定义配置        InjectionConfig cfg = new InjectionConfig() &#123;            @Override            public void initMap() &#123;                // to do nothing            &#125;        &#125;;        // 如果模板引擎是 freemarker//        String templatePath = \"/templates/mapper.xml.ftl\";        // 如果模板引擎是 velocity        String templatePath = \"/templates/mapper.xml.vm\";        // 自定义输出配置        List&lt;FileOutConfig&gt; focList = new ArrayList&lt;&gt;();        // 自定义配置会被优先输出        focList.add(new FileOutConfig(templatePath) &#123;            @Override            public String outputFile(TableInfo tableInfo) &#123;                // 自定义输出文件名 ， 如果你 Entity 设置了前后缀、此处注意 xml 的名称会跟着发生变化！！                return projectPath + \"/src/main/resources/mapper/\" +                        \"/\" + tableInfo.getEntityName() + \"Mapper\" + StringPool.DOT_XML;            &#125;        &#125;);        /*        cfg.setFileCreate(new IFileCreate() &#123;            @Override            public boolean isCreate(ConfigBuilder configBuilder, FileType fileType, String filePath) &#123;                // 判断自定义文件夹是否需要创建                checkDir(\"调用默认方法创建的目录\");                return false;            &#125;        &#125;);        */        cfg.setFileOutConfigList(focList);        return cfg;    &#125;    private static PackageConfig generatePackageConfig() &#123;        final PackageConfig pc = new PackageConfig();//        pc.setModuleName(scanner(\"模块名\"));        // 包配置//        final PackageConfig pc = new PackageConfig();//        pc.setModuleName(scanner(\"模块名\"));//        pc.setParent(\"com.nfsq.es.demo.bean\");        pc.setParent(\"cn.ng.springboot\");        pc.setMapper(\"dao.mapper\");//生成mapper接口        pc.setEntity(\"dao.entity\");        pc.setServiceImpl(\"service.impl\");        pc.setService(\"service\");        pc.setXml(null);        return pc;    &#125;    private static DataSourceConfig generateDataSourceConfig() &#123;        DataSourceConfig dataSource = new DataSourceConfig();//        dsc.setDbType(DbType.MYSQL);        dataSource.setDriverName(\"com.mysql.jdbc.Driver\");        dataSource.setUsername(\"root\");        dataSource.setPassword(\"root\");        dataSource.setUrl(\"jdbc:mysql://localhost:3306/hive\");//        // 数据源配置//        DataSourceConfig dsc = new DataSourceConfig();//        dsc.setUrl(\"jdbc:mysql://localhost:3306/es_demo?useUnicode=true&amp;useSSL=false&amp;characterEncoding=utf8\");//        // dsc.setSchemaName(\"public\");//        dsc.setDriverName(\"com.mysql.jdbc.Driver\");//        dsc.setUsername(\"root\");//        dsc.setPassword(\"aptx1230\");        return dataSource;    &#125;    private static GlobalConfig generateGlobalConfig() &#123;        // 全局配置        GlobalConfig gc = new GlobalConfig();        gc.setOutputDir(projectPath + \"/src/main/java\");        gc.setAuthor(\"ng\");        gc.setOpen(false);        gc.setFileOverride(true);        gc.setActiveRecord(true);// 不需要ActiveRecord特性的请改为false        gc.setEnableCache(false);// XML 二级缓存        gc.setBaseResultMap(true);// XML ResultMap        gc.setBaseColumnList(false);// XML columList        gc.setKotlin(false); // 是否生成 kotlin 代码        gc.setDateType(DateType.ONLY_DATE); //时间类型的映射规则        return gc;    &#125;&#125;\n","plink":"ilucia.github.io/spring&mybatis/Mybatis - MybatisPlus/"},{"title":"spring&mybatis/Spring Cloud","date":"2022-04-27T15:24:01.747Z","updated":"2022-04-27T15:24:01.747Z","content":" Spring Cloud\nSpringCloud的基础功能：\n\n服务治理： Spring Cloud Eureka\n客户端负载均衡： Spring Cloud Ribbon\n服务容错保护： Spring Cloud Hystrix\n声明式服务调用： Spring Cloud Feign\nAPI网关服务：Spring Cloud Zuul\n分布式配置中心： Spring Cloud Config\n\n Spring Cloud Eureka\n 使用场景及架构\n从分布式/微服务的角度而言：就是把我们一大的项目，分解成多个小的模块。这些小的模块组合起来，完成功能\n拆分出多个模块以后，就会出现各种各样的问题\n首当其冲的就是子系统之间的通讯问题。子系统与子系统之间不是在同一个环境下，那就需要远程调用。远程调用可能就会想到httpClient，WebService等等这些技术来实现。\n既然是远程调用，就必须知道ip地址，我们可能有以下的场景。\n\n\n功能实现一：A服务需要调用B服务\n\n\n\n在A服务的代码里面调用B服务，显式通过IP地址调用：http://123.123.123.123:8888/java3y/3\n\n\n\n功能实现二：A服务调用B服务，B服务调用C服务，C服务调用D服务\n\n\n\n在A服务的代码里面调用B服务，显式通过IP地址调用：http://123.123.123.123:8888/java3y/3，(同样地)B-&gt;C，C-&gt;D\n\n\n\n功能实现三：D服务调用B服务，B服务调用C服务\n\n\n\n在D服务的代码里面调用B服务，显式通过IP地址调用：http://123.123.123.123:8888/java3y/3，(同样地)B-&gt;C\n\n\n\n…等等等等\n\n\n万一，我们B服务的IP地址变了，想想会出现什么问题：A服务,D服务(等等)需要手动更新B服务的地址\n\n在服务多的情况下，手动来维护这些静态配置就是噩梦！\n\n\n为了解决微服务架构中的服务实例维护问题(ip地址)， 产生了大量的服务治理框架和产品。 这些框架和产品的实现都围绕着服务注册与服务发现机制来完成对微服务应用实例的自动化管理。\n\n在SpringCloud中我们的服务治理框架一般使用的就是Eureka。\n我们的问题：\n\n现在有A、B、C、D四个服务，它们之间会互相调用(而且IP地址很可能会发生变化)，一旦某个服务的IP地址变了，那服务中的代码要跟着变，手动维护这些静态配置(IP)非常麻烦！\n\nEureka是这样解决上面所说的情况的：\n\n创建一个E服务，将A、B、C、D四个服务的信息都注册到E服务上，E服务维护这些已经注册进来的信息\n\n\nA、B、C、D四个服务都可以拿到Eureka(服务E)那份注册清单。A、B、C、D四个服务互相调用不再通过具体的IP地址，而是通过服务名来调用！\n\n拿到注册清单—&gt;注册清单上有服务名—&gt;自然就能够拿到服务具体的位置了(IP)。\n其实简单来说就是：代码中通过服务名找到对应的IP地址(IP地址会变，但服务名一般不会变)\n\n\n Eureka服务治理机制\nEureka专门用于给其他服务注册的称为Eureka Server(服务注册中心)，其余注册到Eureka Server的服务称为Eureka Client\n在Eureka Server一般我们会这样配置：\n12register-with-eureka: false     #false表示不向注册中心注册自己。    fetch-registry: false     #false表示自己端就是注册中心，我的职责就是维护服务实例，并不需要去检索服务\nEureka Client分为服务提供者和服务消费者。\n\n但很可能，某服务既是服务提供者又是服务消费者。\n\n如果在网上看到SpringCloud的某个服务配置没有&quot;注册&quot;到Eureka-Server也不用过于惊讶(但是它是可以获取Eureka服务清单的)\n\n很可能只是作者把该服务认作为单纯的服务消费者，单纯的服务消费者无需对外提供服务，也就无须注册到Eureka中了\n\n12345eureka:  client:    register-with-eureka: false  # 当前微服务不注册到eureka中(消费端)    service-url:       defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/\n下面是Eureka的治理机制：\n\n\n服务提供者\n\n服务注册：启动的时候会通过发送REST请求的方式将自己注册到Eureka Server上，同时带上了自身服务的一些元数据信息。\n**服务续约：**在注册完服务之后，服务提供者会维护一个心跳用来持续告诉Eureka Server: &quot;我还活着 ” 、\n服务下线：当服务实例进行正常的关闭操作时，它会触发一个服务下线的REST请求给Eureka Server, 告诉服务注册中心：“我要下线了 ”。\n\n\n\n服务消费者\n\n获取服务：当我们启动服务消费者的时候，它会发送一个REST请求给服务注册中心，来获取上面注册的服务清单\n服务调用：服务消费者在获取服务清单后，通过服务名可以获得具体提供服务的实例名和该实例的元数据信息。在进行服务调用的时候，优先访问同处一个Zone中的服务提供方。\n\n\n\nEureka Server(服务注册中心)：\n\n**失效剔除：**默认每隔一段时间（默认为60秒） 将当前清单中超时（默认为90秒）没有续约的服务剔除出去。\n自我保护：。EurekaServer 在运行期间，会统计心跳失败的比例在15分钟之内是否低于85%(通常由于网络不稳定导致)。 Eureka Server会将当前的实例注册信息保护起来， 让这些实例不会过期，尽可能保护这些注册信息。\n\n\n\n最后，我们就有了这张图：\n举个例子：\n\n3y跟女朋友去东站的东方宝泰逛街，但不知道东方宝泰有什么好玩的。于是就去物业搜了一下东方宝泰商户清单，发现一楼有优衣库，二楼有星巴克，三楼有麦当劳。\n在优衣库旁边，有新开张的KFC，在墙壁打上了很大的标识“欢迎KFC入驻东方宝泰”。\n商家们需要定时交物业费给物业。\n物业维持东方宝泰的稳定性。如果某个商家不想在东方宝泰运营了，告诉了物业。物业自然就会将其在东方宝泰商户清单去除。\n\n 服务注册与发现\n 创建“服务注册中心”\n创建一个基础的Spring Boot工程，命名为eureka-server，并在pom.xml中引入需要的依赖内容：\n12345678910111213141516171819202122232425&lt;parent&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;    &lt;version&gt;1.5.4.RELEASE&lt;/version&gt;    &lt;relativePath/&gt;&lt;/parent&gt;&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt;    &lt;dependencies&gt;        &lt;dependency&gt;           &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;           &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;           &lt;version&gt;Dalston.SR1&lt;/version&gt;           &lt;type&gt;pom&lt;/type&gt;           &lt;scope&gt;import&lt;/scope&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;&lt;/dependencyManagement&gt;\n通过@EnableEurekaServer注解启动一个服务注册中心提供给其他应用进行对话。这一步非常的简单，只需要在一个普通的Spring Boot应用中添加这个注解就能开启此功能，比如下面的例子：\n123456789@EnableEurekaServer@SpringBootApplicationpublic class Application &#123;    public static void main(String[] args) &#123;        new SpringApplicationBuilder(Application.class)                    .web(true).run(args);    &#125;&#125;\n在默认设置下，该服务注册中心也会将自己作为客户端来尝试注册它自己，所以我们需要禁用它的客户端注册行为，只需要在application.properties配置文件中增加如下信息：\n123456spring.application.name=eureka-serverserver.port=1001eureka.instance.hostname=localhosteureka.client.register-with-eureka=falseeureka.client.fetch-registry=false\n为了与后续要进行注册的服务区分，这里将服务注册中心的端口通过server.port属性设置为1001。启动工程后，访问：http://localhost:1001/，可以看到下面的页面，其中还没有发现任何服务。\n\n 创建“服务提供方”\n下面我们创建提供服务的客户端，并向服务注册中心注册自己。本文我们主要介绍服务的注册与发现，所以我们不妨在服务提供方中尝试着提供一个接口来获取当前所有的服务信息。\n首先，创建一个基本的Spring Boot应用。命名为eureka-client，在pom.xml中，加入如下配置：\n1234567891011121314151617181920212223242526272829&lt;parent&gt;     &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;    &lt;version&gt;1.5.4.RELEASE&lt;/version&gt;    &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt;&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt;    &lt;dependencies&gt;        &lt;dependency&gt;           &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;           &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;           &lt;version&gt;Dalston.SR1&lt;/version&gt;           &lt;type&gt;pom&lt;/type&gt;           &lt;scope&gt;import&lt;/scope&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;&lt;/dependencyManagement&gt;\n其次，实现/dc请求处理接口，通过DiscoveryClient对象，在日志中打印出服务实例的相关内容。\n1234567891011121314@RestControllerpublic class DcController &#123;    @Autowired    DiscoveryClient discoveryClient;    @GetMapping(\"/dc\")    public String dc() &#123;        String services = \"Services: \" + discoveryClient.getServices();        System.out.println(services);        return services;    &#125;&#125;\n最后在应用主类中通过加上@EnableDiscoveryClient注解，该注解能激活Eureka中的DiscoveryClient实现，这样才能实现Controller中对服务信息的输出。\n123456789@EnableDiscoveryClient@SpringBootApplicationpublic class Application &#123;    public static void main(String[] args) &#123;        new SpringApplicationBuilder(            ComputeServiceApplication.class)            .web(true).run(args);    &#125;&#125;\n我们在完成了服务内容的实现之后，再继续对application.properties做一些配置工作，具体如下：\n123spring.application.name=eureka-clientserver.port=2001eureka.client.serviceUrl.defaultZone=http://localhost:1001/eureka/\n通过spring.application.name属性，我们可以指定微服务的名称后续在调用的时候只需要使用该名称就可以进行服务的访问。eureka.client.serviceUrl.defaultZone属性对应服务注册中心的配置内容，指定服务注册中心的位置。为了在本机上测试区分服务提供方和服务注册中心，使用server.port属性设置不同的端口。\n启动该工程后，再次访问：http://localhost:1001/。可以如下图内容，我们定义的服务被成功注册了。\n\n当然，我们也可以通过直接访问eureka-client服务提供的/dc接口来获取当前的服务清单，只需要访问：http://localhost:2001/dc，我们可以得到如下输出返回：\n1Services: [eureka-client]\n其中，方括号中的eureka-client就是通过Spring Cloud定义的DiscoveryClient接口在eureka的实现中获取到的所有服务清单。由于Spring Cloud在服务发现这一层做了非常好的抽象，所以，对于上面的程序，我们可以无缝的从eureka的服务治理体系切换到consul的服务治理体系中区。\n我们已经成功地将服务提供者：eureka-client或consul-client注册到了Eureka服务注册中心或Consul服务端上了，同时我们也通过DiscoveryClient接口的getServices获取了当前客户端缓存的所有服务清单，那么接下来我们要学习的就是：如何去消费服务提供者的接口？\n 使用LoadBalancerClient\n在Spring Cloud Commons中提供了大量的与服务治理相关的抽象接口，包括DiscoveryClient、这里我们即将介绍的LoadBalancerClient等。对于这些接口的定义我们在上一篇介绍服务注册与发现时已经说过，Spring Cloud做这一层抽象，很好的解耦了服务治理体系，使得我们可以轻易的替换不同的服务治理设施。\n从LoadBalancerClient接口的命名中，我们就知道这是一个负载均衡客户端的抽象定义，下面我们就看看如何使用Spring Cloud提供的负载均衡器客户端接口来实现服务的消费。\n下面的例子，我们将利用上一篇中构建的eureka-server作为服务注册中心、eureka-client作为服务提供者作为基础。\n\n我们先来创建一个服务消费者工程，命名为：eureka-consumer。并在pom.xml中引入依赖（这里省略了parent和dependencyManagement的配置）：\n\n1234567891011121314&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;\n\n配置application.properties，指定eureka注册中心的地址：\n\n1234spring.application.name=eureka-consumerserver.port=2101eureka.client.serviceUrl.defaultZone=http://localhost:1001/eureka/\n\n创建应用主类。初始化RestTemplate，用来真正发起REST请求。@EnableDiscoveryClient注解用来将当前应用加入到服务治理体系中。\n\n12345678910111213@EnableDiscoveryClient@SpringBootApplicationpublic class Application &#123;\t@Bean\tpublic RestTemplate restTemplate() &#123;\t\treturn new RestTemplate();\t&#125;\tpublic static void main(String[] args) &#123;\t\tnew SpringApplicationBuilder(Application.class).web(true).run(args);\t&#125;&#125;\n\n创建一个接口用来消费eureka-client提供的接口：\n\n12345678910111213141516@RestControllerpublic class DcController &#123;    @Autowired    LoadBalancerClient loadBalancerClient;    @Autowired    RestTemplate restTemplate;    @GetMapping(\"/consumer\")    public String dc() &#123;        ServiceInstance serviceInstance = loadBalancerClient.choose(\"eureka-client\");        String url = \"http://\" + serviceInstance.getHost() + \":\" + serviceInstance.getPort() + \"/dc\";        System.out.println(url);        return restTemplate.getForObject(url, String.class);    &#125;&#125;\n可以看到这里，我们注入了LoadBalancerClient和RestTemplate，并在/consumer接口的实现中，先通过loadBalancerClient的choose函数来负载均衡的选出一个eureka-client的服务实例，这个服务实例的基本信息存储在ServiceInstance中，然后通过这些对象中的信息拼接出访问/dc接口的详细地址，最后再利用RestTemplate对象实现对服务提供者接口的调用。\n在完成了上面你的代码编写之后，读者可以将eureka-server、eureka-client、eureka-consumer都启动起来，然后访问http://localhost:2101/consumer ，来跟踪观察eureka-consumer服务是如何消费eureka-client服务的/dc接口的\n Spring Cloud Ribbon\nSpring Cloud Ribbon是基于Netflix Ribbon实现的一套客户端负载均衡的工具。它是一个基于HTTP和TCP的客户端负载均衡器。它可以通过在客户端中配置ribbonServerList来设置服务端列表去轮询访问以达到均衡负载的作用。\n当Ribbon与Eureka联合使用时，ribbonServerList会被DiscoveryEnabledNIWSServerList重写，扩展成从Eureka注册中心中获取服务实例列表。同时它也会用NIWSDiscoveryPing来取代IPing，它将职责委托给Eureka来确定服务端是否已经启动。\n而当Ribbon与Consul联合使用时，ribbonServerList会被ConsulServerList来扩展成从Consul获取服务实例列表。同时由ConsulPing来作为IPing接口的实现。\n我们在使用Spring Cloud Ribbon的时候，不论是与Eureka还是Consul结合，都会在引入Spring Cloud Eureka或Spring Cloud Consul依赖的时候通过自动化配置来加载上述所说的配置内容，所以我们可以快速在Spring Cloud中实现服务间调用的负载均衡。\n负载均衡有两种类型：\n\n\n客户端负载均衡(Ribbon)\n\n\n\n服务实例的清单在客户端，客户端进行负载均衡算法分配。\n(从上面的知识我们已经知道了：客户端可以从Eureka Server中得到一份服务清单，在发送请求时通过负载均衡算法，在多个服务器之间选择一个进行访问)\n\n\n\n服务端负载均衡(Nginx)\n\n\n\n服务实例的清单在服务端，服务器进行负载均衡算法分配\n\n\n\n所以，我们的图可以画成这样：\n\nRibbon是支持负载均衡，默认的负载均衡策略是轮询，我们也是可以根据自己实际的需求自定义负载均衡策略的。\n123456789101112@Configurationpublic class MySelfRule&#123;\t@Bean\tpublic IRule myRule()\t&#123;\t\t//return new RandomRule();// Ribbon默认是轮询，我自定义为随机\t\t//return new RoundRobinRule();// Ribbon默认是轮询，我自定义为随机\t\t\t\treturn new RandomRule_ZY();// 我自定义为每台机器5次\t&#125;&#125;\n实现起来也很简单：继承AbstractLoadBalancerRule类，重写public Server choose(ILoadBalancer lb, Object key)即可。\nSpringCloud 在CAP理论是选择了AP的，在Ribbon中还可以配置重试机制的\n下面我们通过具体的例子来看看如何使用Spring Cloud Ribbon来实现服务的调用以及客户端均衡负载。\n 项目修改\n我们将利用之前构建的eureka-server作为服务注册中心、eureka-client作为服务提供者作为基础。而基于Spring Cloud Ribbon实现的消费者，我们可以根据eureka-consumer实现的内容进行简单改在就能完成，具体步骤如下：\n\n根据eureka-consumer复制一个服务消费者工程，命名为：eureka-consumer-ribbon。在pom.xml中增加下面的依赖：\n\n1234567&lt;dependencies&gt;    ...    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;\n\n修改应用主类。为RestTemplate增加@LoadBalanced注解：\n\n1234567891011121314@EnableDiscoveryClient@SpringBootApplicationpublic class Application &#123;\t@Bean\t@LoadBalanced\tpublic RestTemplate restTemplate() &#123;\t\treturn new RestTemplate();\t&#125;\tpublic static void main(String[] args) &#123;\t\tnew SpringApplicationBuilder(Application.class).web(true).run(args);\t&#125;&#125;\n\n修改Controller。去掉原来通过LoadBalancerClient选取实例和拼接URL的步骤，直接通过RestTemplate发起请求。\n\n123456789101112@RestControllerpublic class DcController &#123;    @Autowired    RestTemplate restTemplate;    @GetMapping(\"/consumer\")    public String dc() &#123;        return restTemplate.getForObject(\"http://eureka-client/dc\", String.class);    &#125;&#125;\n可以看到这里，我们除了去掉了原来与LoadBalancerClient相关的逻辑之外，对于RestTemplate的使用，我们的第一个url参数有一些特别。这里请求的host位置并没有使用一个具体的IP地址和端口的形式，而是采用了服务名的方式组成。那么这样的请求为什么可以调用成功呢？因为Spring Cloud Ribbon有一个拦截器，它能够在这里进行实际调用的时候，自动的去选取服务实例，并将实际要请求的IP地址和端口替换这里的服务名，从而完成服务接口的调用。\n将eureka-server、eureka-client、eureka-consumer-ribbon都启动起来，然后访问http://localhost:2101/consumer ，来跟踪观察eureka-consumer-ribbon服务是如何消费eureka-client服务的/dc接口的，并且也可以通过启动多个eureka-client服务来观察其负载均衡的效果。\n Spring Cloud Feign\nSpring Cloud Feign是一套基于Netflix Feign实现的声明式服务调用客户端。它使得编写Web服务客户端变得更加简单。我们只需要通过创建接口并用注解来配置它既可完成对Web服务接口的绑定。它具备可插拔的注解支持，包括Feign注解、JAX-RS注解。它也支持可插拔的编码器和解码器。Spring Cloud Feign还扩展了对Spring MVC注解的支持，同时还整合了Ribbon和Eureka来提供均衡负载的HTTP客户端实现。\n下面，我们通过一个例子来展现Feign如何方便的声明对eureka-client服务的定义和调用。\n 项目修改\n下面的例子，我们将利用之前构建的eureka-server作为服务注册中心、eureka-client作为服务提供者作为基础。而基于Spring Cloud Ribbon实现的消费者，我们可以根据eureka-consumer实现的内容进行简单改在就能完成，具体步骤如下：\n\n根据eureka-consumer复制一个服务消费者工程，命名为：eureka-consumer-feign。在pom.xml中增加下面的依赖：\n\n1234567&lt;dependencies&gt;    ...    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;\n\n修改应用主类。通过@EnableFeignClients注解开启扫描Spring Cloud Feign客户端的功能：\n\n123456789@EnableFeignClients@EnableDiscoveryClient@SpringBootApplicationpublic class Application &#123;\tpublic static void main(String[] args) &#123;\t\tnew SpringApplicationBuilder(Application.class).web(true).run(args);\t&#125;&#125;\n\n创建一个Feign的客户端接口定义。使用@FeignClient注解来指定这个接口所要调用的服务名称，接口中定义的各个函数使用Spring MVC的注解就可以来绑定服务提供方的REST接口，比如下面就是绑定eureka-client服务的/dc接口的例子：\n\n123456789@FeignClient(\"eureka-client\")public interface DcClient &#123;    @GetMapping(\"/1\")    String consumer1();      @GetMapping(\"/2\")    String consumer2();&#125;\n\n修改Controller。通过定义的feign客户端来调用服务提供方的接口：\n\n1234567891011121314151617@RestControllerpublic class DcController &#123;    @Autowired    DcClient dcClient;    @GetMapping(\"/consumer1\")    public String dc() &#123;        return dcClient.consumer1();    &#125;     @GetMapping(\"/consumer2\")    public String dc() &#123;        return dcClient.consumer2();    &#125;&#125;\n通过Spring Cloud Feign来实现服务调用的方式更加简单了，通过@FeignClient定义的接口来统一的声明我们需要依赖的微服务接口。而在具体使用的时候就跟调用本地方法一点的进行调用即可。由于Feign是基于Ribbon实现的，所以它自带了客户端负载均衡功能，也可以通过Ribbon的IRule进行策略扩展。另外，Feign还整合的Hystrix来实现服务的容错保护，在Dalston版本中，Feign的Hystrix默认是关闭的。\n将eureka-server、eureka-client、eureka-consumer-feign都启动起来，然后访问http://localhost:2101/consumer ，来跟踪观察eureka-consumer-feign服务是如何消费eureka-client服务的/dc接口的，并且也可以通过启动多个eureka-client服务来观察其负载均衡的效果。\n Feign 传输文件\n在Spring Cloud封装的Feign中并不直接支持传文件，但可以通过引入Feign的扩展包来实现，本来就来具体说说如何实现。\n 服务提供方（接收文件）\n服务提供方的实现比较简单，就按Spring MVC的正常实现方式即可，比如：\n1234567891011121314151617181920@EnableFeignClients@EnableDiscoveryClient@SpringBootApplicationpublic class Application &#123;    @RestController    public class UploadController &#123;        @PostMapping(value = \"/uploadFile\", consumes = MediaType.MULTIPART_FORM_DATA_VALUE)        public String handleFileUpload(@RequestPart(value = \"file\") MultipartFile file) &#123;            return file.getName();        &#125;    &#125;    public static void main(String[] args) &#123;        new SpringApplicationBuilder(Application.class).web(true).run(args);    &#125;&#125;\n 服务消费方（发送文件）\n在服务消费方由于会使用Feign客户端，所以在这里需要在引入feign对表单提交的依赖，具体如下：\n123456789101112131415&lt;dependency&gt;   &lt;groupId&gt;io.github.openfeign.form&lt;/groupId&gt;   &lt;artifactId&gt;feign-form&lt;/artifactId&gt;   &lt;version&gt;3.0.3&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;   &lt;groupId&gt;io.github.openfeign.form&lt;/groupId&gt;   &lt;artifactId&gt;feign-form-spring&lt;/artifactId&gt;   &lt;version&gt;3.0.3&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;   &lt;groupId&gt;commons-fileupload&lt;/groupId&gt;   &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt;   &lt;version&gt;1.3.3&lt;/version&gt;&lt;/dependency&gt;\n定义文件上传方的应用主类和FeignClient，假设服务提供方的服务名为eureka-feign-upload-server\n1234567891011121314151617181920212223242526@EnableFeignClients@EnableDiscoveryClient@SpringBootApplicationpublic class Application &#123;    public static void main(String[] args) &#123;        new SpringApplicationBuilder(Application.class).web(true).run(args);    &#125;&#125;@FeignClient(value = \"upload-server\", configuration = UploadService.MultipartSupportConfig.class)public interface UploadService &#123;     @PostMapping(value = \"/uploadFile\", consumes = MediaType.MULTIPART_FORM_DATA_VALUE)    String handleFileUpload(@RequestPart(value = \"file\") MultipartFile file);     @Configuration    class MultipartSupportConfig &#123;        @Bean        public Encoder feignFormEncoder() &#123;            return new SpringFormEncoder();        &#125;    &#125; &#125;\n在启动了服务提供方之后，尝试在服务消费方编写测试用例来通过上面定义的Feign客户端来传文件，比如：\n12345678910111213141516171819202122232425262728@Slf4j@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTestpublic class UploadTester &#123;    @Autowired    private UploadService uploadService;    @Test    @SneakyThrows    public void testHandleFileUpload() &#123;        File file = new File(\"upload.txt\");        DiskFileItem fileItem = (DiskFileItem) new DiskFileItemFactory().createItem(\"file\",                MediaType.TEXT_PLAIN_VALUE, true, file.getName());        try (InputStream input = new FileInputStream(file); OutputStream os = fileItem.getOutputStream()) &#123;            IOUtils.copy(input, os);        &#125; catch (Exception e) &#123;            throw new IllegalArgumentException(\"Invalid file: \" + e, e);        &#125;        MultipartFile multi = new CommonsMultipartFile(fileItem);        log.info(uploadService.handleFileUpload(multi));    &#125;&#125;\n Spring Cloud Config\nSpring Cloud Config是Spring Cloud团队创建的一个全新项目，用来为分布式系统中的基础设施和微服务应用提供集中化的外部配置支持，它分为服务端与客户端两个部分。其中服务端也称为分布式配置中心，它是一个独立的微服务应用，用来连接配置仓库并为客户端提供获取配置信息、加密/解密信息等访问接口；而客户端则是微服务架构中的各个微服务应用或基础设施，它们通过指定的配置中心来管理应用资源与业务相关的配置内容，并在启动的时候从配置中心获取和加载配置信息。Spring Cloud Config实现了对服务端和客户端中环境变量和属性配置的抽象映射，所以它除了适用于Spring构建的应用程序之外，也可以在任何其他语言运行的应用程序中使用。由于Spring Cloud Config实现的配置中心默认采用Git来存储配置信息，所以使用Spring Cloud Config构建的配置服务器，天然就支持对微服务应用配置信息的版本管理，并且可以通过Git客户端工具来方便的管理和访问配置内容。当然它也提供了对其他存储方式的支持，比如：SVN仓库、本地化文件系统。\n在本文中，我们将学习如何构建一个基于Git存储的分布式配置中心，并对客户端进行改造，并让其能够从配置中心获取配置信息并绑定到代码中的整个过程。\n 准备配置仓库\n\n准备一个git仓库，可以在码云或Github上创建都可以。\n\nhttps://gitee.com/ilucia/config_demo\n\n\n假设我们读取配置中心的应用名为config-client，那么我们可以在git仓库中创建该项目的默认配置文件config-client.yml：\n\n12info:  profile: default\n\n为了演示加载不同环境的配置，我们可以在git仓库中再创建一个针对dev环境的配置文件config-client-dev.yml：\n\n12info:  profile: dev\n 构建配置中心\n通过Spring Cloud Config来构建一个分布式配置中心非常简单，只需要三步：\n\n创建一个基础的Spring Boot工程，命名为：config-server-git，并在pom.xml中引入下面的依赖（省略了parent和dependencyManagement部分）：\n\n123456&lt;dependencies&gt;\t&lt;dependency&gt;\t\t&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\t\t&lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;\t&lt;/dependency&gt;&lt;/dependencies&gt;\n\n创建Spring Boot的程序主类，并添加@EnableConfigServer注解，开启Spring Cloud Config的服务端功能。\n\n123456789@EnableConfigServer@SpringBootApplicationpublic class Application &#123;\tpublic static void main(String[] args) &#123;\t\tnew SpringApplicationBuilder(Application.class).web(true).run(args);\t&#125;&#125;\n\n在application.yml中添加配置服务的基本信息以及Git仓库的相关信息，例如：\n\n123456789101112spring:   application:    name: config-server  cloud:    config:      server:        git:          uri: https://gitee.com/ilucia/config_demo          username: ilucia          password: 321324543xserver:  port: 1201\n到这里，使用一个通过Spring Cloud Config实现，并使用Git管理配置内容的分布式配置中心就已经完成了。我们可以将该应用先启动起来，确保没有错误产生，然后再尝试下面的内容。\n\n如果我们的Git仓库需要权限访问，那么可以通过配置下面的两个属性来实现；\nspring.cloud.config.server.git.username：访问Git仓库的用户名\nspring.cloud.config.server.git.password：访问Git仓库的用户密码\n\n完成了这些准备工作之后，我们就可以通过浏览器、POSTMAN或CURL等工具直接来访问到我们的配置内容了。访问配置信息的URL与配置文件的映射关系如下：\n\n/{application}/{profile}[/{label}]\n/{application}-{profile}.yml\n/{label}/{application}-{profile}.yml\n/{application}-{profile}.properties\n/{label}/{application}-{profile}.properties\n\n上面的url会映射{application}-{profile}.properties对应的配置文件，其中{label}对应Git上不同的分支，默认为master。我们可以尝试构造不同的url来访问不同的配置内容，比如，要访问master分支，config-client应用的dev环境，就可以访问这个url：http://localhost:1201/config-client/dev/master，并获得如下返回：\n1234567891011121314151617181920212223&#123;    \"name\": \"config-client\",    \"profiles\": [        \"dev\"    ],    \"label\": \"master\",    \"version\": null,    \"state\": null,    \"propertySources\": [        &#123;            \"name\": \"https://gitee.com/ilucia/config_demo/config-client-dev.yml\",            \"source\": &#123;                \"info.profile\": \"dev\"            &#125;        &#125;,        &#123;            \"name\": \"https://gitee.com/ilucia/config_demo/config-client.yml\",            \"source\": &#123;                \"info.profile\": \"default\"            &#125;        &#125;    ]&#125;\n我们可以看到该Json中返回了应用名：config-client，环境名：dev，分支名：master，以及default环境和dev环境的配置内容。\n 构建客户端\n在完成了上述验证之后，确定配置服务中心已经正常运作，下面我们尝试如何在微服务应用中获取上述的配置信息。\n\n创建一个Spring Boot应用，命名为config-client，并在pom.xml中引入下述依赖：\n\n12345678910&lt;dependencies&gt;\t&lt;dependency&gt;\t\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t\t&lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;\t&lt;/dependency&gt;\t&lt;dependency&gt;\t\t&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\t\t&lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;\t&lt;/dependency&gt;&lt;/dependencies&gt;\n\n创建Spring Boot的应用主类，具体如下：\n\n12345678@SpringBootApplicationpublic class Application &#123;\tpublic static void main(String[] args) &#123;\t\tnew SpringApplicationBuilder(Application.class).web(true).run(args);\t&#125;&#125;\n\n创建bootstrap.yml配置，来指定获取配置文件的config-server-git位置，例如：\n\n1234567891011spring:  application:    name: config-client  cloud:    config:      uri: http://localhost:1201/      profile: default      label: masterserver:  port: 2001\n上述配置参数与Git中存储的配置文件中各个部分的对应关系如下：\n\nspring.application.name：对应配置文件规则中的{application}部分\nspring.cloud.config.profile：对应配置文件规则中的{profile}部分\nspring.cloud.config.label：对应配置文件规则中的{label}部分\nspring.cloud.config.uri：配置中心config-server的地址\n\n这里需要格外注意：上面这些属性必须配置在bootstrap.properties中，这样config-server中的配置信息才能被正确加载。\n在完成了上面你的代码编写之后，读者可以将config-server-git、config-client都启动起来，然后访问http://localhost:2001/info ，我们可以看到该端点将会返回从git仓库中获取的配置信息：\n123&#123;    \"profile\": \"default\"&#125;\n另外，我们也可以修改config-client的profile为dev来观察加载配置的变化。\n","plink":"ilucia.github.io/spring&mybatis/Spring Cloud/"},{"title":"spring&mybatis/Spring IoC","date":"2022-04-27T15:24:01.747Z","updated":"2022-04-27T15:24:01.747Z","content":" Spring IoC\n IoC\n IoC的概念\n\n简单点儿说，IoC的理念就是，让别人为你服务！\n通常情况下，被注入对象会直接依赖于被依赖对象。但是，在IoC的场景中，二者之间通过IoC Service Provider来打交道，所有的被注入对象和依赖对象现在由IoC Service Provider统一管理。被注入对象需要什么，直接跟IoC Service Provider招呼一声，后者就会把相应的被依赖对象注入到被注入对象中，从而达到IoC Service Provider为被注入对象服务的目的\nIoC Service Provider在这里就是通常的IoC容器所充当的角色。从被注入对象的角度看，与之前直接寻求依赖对象相比，依赖对象的取得方式发生了反转，控制也从被注入对象转到了IoC Service Provider那里\n原来是需要什么东西自己去拿，现在是需要什么东西就让别人送过来\nIoC是一种可以帮助我们解耦各业务对象间依赖关系的对象绑定方式\n\n\n 依赖注入\n\n接口注入\n\n从注入方式的使用上来说，接口注入是现在不甚提倡的一种方式，基本处于“退役状态”。因为它强制被注入对象实现不必要的接口，带有侵入性。而构造方法注入和setter方法注入则不需要如此\n\n\n构造方法注入\n\n这种注入方式的优点就是，对象在构造完成之后，即已进入就绪状态，可以马上使用\n缺点就是，当依赖对象比较多的时候，构造方法的参数列表会比较长。而通过反射构造对象的时候，对相同类型的参数的处理会比较困难，维护和使用上也比较麻烦。而且在Java中，构造方法无法被继承，无法设置默认值。对于非必须的依赖处理，可能需要引入多个构造方法，而参数数量的变动可能造成维护上的不便\n\n\nsetter方法注入\n\n因为方法可以命名，所以setter方法注入在描述性上要比构造方法注入好一些。另外，setter方法可以被继承，允许设置默认值，而且有良好的IDE支持\n缺点当然就是对象无法在构造完成后马上进入就绪状态\n\n\n\n IoC Service Provider\n 概念\n\n它可以指代任何将IoC场景中的业务对象绑定到一起的实现方式\nSpring的IoC容器就是一个提供依赖注入服务的IoC Service Provider\nIoC Service Provider的职责\n\n业务对象的构建管理\n业务对象间的依赖绑定\n\n\n\n IoC Service Provider 如何管理对象间的依赖关系\n 直接编码方式\n\n\n通过程序编码的方式将被注入对象和依赖对象注册到容器中，并明确它们相互之间的依赖注入关系\n\n\n通过为相应的类指定对应的具体实例，可以告知IoC容器，当我们要这种类型的对象实例时，将容器中注册的、对应的那个具体实例返回给我们\nIoContainer container = ...;\ncontainer.register(FXNewsProvider.class,new FXNewsProvider());\ncontainer.register(IFXNewsListener.class,new DowJonesNewsListener());\n...\nFXNewsProvider newsProvider = (FXNewsProvider)container.get(FXNewsProvider.class);\nnewProvider.getAndPersistNews();\n\n\n 直接编码方式-接口注入\n\n\n除了注册相应对象，还要将“注入标志接口”与相应的依赖对象绑定一下\nIoContainer container = ...;\ncontainer.register(FXNewsProvider.class,new FXNewsProvider());\ncontainer.register(IFXNewsListener.class,new DowJonesNewsListener());\n...\ncontainer.bind(IFXNewsListenerCallable.class, container.get(IFXNewsListener.class));\n...\nFXNewsProvider newsProvider = (FXNewsProvider)container.get(FXNewsProvider.class);\nnewProvider.getAndPersistNews();\n\n\n通过bind方法将“被注入对象”（由IFXNewsListenerCallable接口添加标志）所依赖的对象，绑定为容器中注册过的IFXNewsListener类型的对象实例\n\n\n容器在返回FXNewsProvider对象实例之前，会根据这个绑定信息，将IFXNewsListener注册到容器中的对象实例注入到“被注入对象”——FXNewsProvider中，并最终返回已经组装完毕FXNewsProvider对象\n\n\n 配置文件方式\n\n通过XML文件来管理对象注册和对象间依赖关系\n\n 注解方式\n\n直接在类中使用元数据信息来标注各个对象之间的依赖关系，然后由Guice框架根据这些注解所提供的信息将这些对象组装后，交给客户端对象使用\n通过**@Inject**，我们指明需要IoC Service Provider通过构造方法注入方式，为FXNewsProvider注入其所依赖的对象。至于余下的依赖相关信息，在Guice中是由相应的Module来提供的\n\n通过Module指定进一步的依赖注入相关信息之后，我们就可以直接从Guice那里取得最终已经注入完毕，并直接可用的对象了\n\n\n注解最终也要通过代码处理来确定最终的注入关系，从这点儿来说，注解方式可以算作编码方式的一种特殊情况\n\n BeanFactory\n BeanFactory和ApplicationContext\n\nBeanFactory\n\n基础类型IoC容器，提供完整的IoC服务支持\n默认采用延迟初始化策略（lazy-load）\n\n只有当客户端对象需要访问容器中的某个受管对象的时候，才对该受管对象进行初始化以及依赖注入操作\n容器启动初期速度较快，所需要的资源有限\n\n\n对于资源有限，并且功能要求不是很严格的场景，BeanFactory是比较合适的IoC容器选择\n\n\nApplicationContext\n\n在BeanFactory的基础上构建，拥有BeanFactory的所有支持，还提供了其他高级特性\n\nApplicationContext间接继承自BeanFactory，所以说它是构建于BeanFactory之上的IoC容器\n\n\nApplicationContext所管理的对象，在该类型容器启动之后，默认全部初始化并绑定完成\n\n要求更多的系统资源，同时，因为在启动时就完成所有初始化，容器启动时间较之BeanFactory也会长一些\n\n\n在那些系统资源充足，并且要求更多功能的场景中，ApplicationContext类型的容器是比较合适的选择\n\n\n\n BeanFactory概念\n\nBeanFactory，顾名思义，就是生产Bean的工厂\n\n把每个业务对象看作一个JavaBean对象\nBeanFactory就像一个汽车生产厂。你从其他汽车零件厂商或者自己的零件生产部门取得汽车零件送入这个汽车生产厂，最后，只需要从生产线的终点取得成品汽车就可以了。相似地，将应用所需的所有业务对象交给BeanFactory之后，剩下要做的，就是直接从BeanFactory取得最终组装完成并且可用的对象。至于这个最终业务对象如何组装，你不需要关心，BeanFactory会帮你搞定\nBeanFactory肯定会公开一个取得组装完成的对象的方法接口\n\n\n\n123456789101112131415161718192021public interface BeanFactory &#123;     String FACTORY_BEAN_PREFIX = \"&amp;\";     Object getBean(String name) throws BeansException;    Object getBean(String name, Class requiredType) throws BeansException;     /**     * @since 2.5     */     Object getBean(String name, Object[] args) throws BeansException;     boolean containsBean(String name);     boolean isSingleton(String name) throws NoSuchBeanDefinitionException;     /**     * @since 2.0.3     */     boolean isPrototype(String name) throws NoSuchBeanDefinitionException;     /**     * @since 2.0.1     */     boolean isTypeMatch(String name, Class targetType) throws NoSuchBeanDefinitionException;     Class getType(String name) throws NoSuchBeanDefinitionException;     String[] getAliases(String name);&#125;\n\n\n上面代码中的方法基本上都是查询相关的方法，例如，取得某个对象的方法（getBean）、查询某个对象是否存在于容器中的方法（containsBean），或者取得某个bean的状态或者类型的方法等\n\n因为通常情况下，对于独立的应用程序，只有主入口类才会跟容器的API直接耦合。\n\n\n\n使用BeanFactory前后唯一的不同，就是对象之间依赖关系的解决方式改变了\n\n\n FX新闻应用设计和实现框架代码\n12345678910111213141516171819202122232425//设计FXNewsProvider类用于普遍的新闻处理public class FXNewsProvider &#123; ... &#125; //设计IFXNewsListener接口抽象各个新闻社不同的新闻获取方式public interface IFXNewsListener &#123; ... &#125; //给出相应实现类public class DowJonesNewsListener implements IFXNewsListener&#123; ... &#125; //设计IFXNewsPersister接口抽象不同数据访问方式public interface IFXNewsPersister &#123; ... &#125; //实现相应的实现类public class DowJonesNewsPersister implements IFXNewsPersister &#123; ... &#125;\n\nBeanFactory会通过常用的XML文件来注册并管理各个业务对象之间的依赖关系\n\n BeanFactory的对象注册与依赖绑定方式\n\n为了能够明确管理各个业务对象以及业务对象之间的依赖绑定关系，需要某种途径来记录和管理这些信息\n\n直接编码，配置文件，元数据\n\n\n\n 直接编码\n\nBeanFactory只是一个接口，我们最终需要一个该接口的实现来进行实际的Bean的管理\nBeanFactory接口只定义如何访问容器内管理的Bean的方法，各个BeanFactory的具体实现类负责具体Bean的注册以及管理工作\nBeanDefinitionRegistry接口才是在BeanFactory的实现中担当Bean注册管理的角色\n\n通常情况下，具体的BeanFactory实现类会实现这个接口来管理Bean的注册\n\n\n打个比方说，BeanDefinitionRegistry就像图书馆的书架，所有的书是放在书架上的。虽然你还书或者借书都是跟图书馆（也就是BeanFactory，或许BookFactory可能更好些）打交道，但书架才是存放各类图书的地方\n\n123456789101112131415161718192021222324252627282930313233343536373839public static void main(String[] args) &#123;     DefaultListableBeanFactory beanRegistry = new DefaultListableBeanFactory();     BeanFactory container = (BeanFactory)bindViaCode(beanRegistry);     FXNewsProvider newsProvider = ➥    (FXNewsProvider)container.getBean(\"djNewsProvider\");     newsProvider.getAndPersistNews(); &#125; public static BeanFactory bindViaCode(BeanDefinitionRegistry registry) &#123;     AbstractBeanDefinition newsProvider = ➥    new RootBeanDefinition(FXNewsProvider.class,true);     AbstractBeanDefinition newsListener = ➥    new RootBeanDefinition(DowJonesNewsListener.class,true);     AbstractBeanDefinition newsPersister = ➥    new RootBeanDefinition(DowJonesNewsPersister.class,true);     // 将bean定义注册到容器中    registry.registerBeanDefinition(\"djNewsProvider\", newsProvider);     registry.registerBeanDefinition(\"djListener\", newsListener);     registry.registerBeanDefinition(\"djPersister\", newsPersister);     // 指定依赖关系    // 1. 可以通过构造方法注入方式    ConstructorArgumentValues argValues = new ConstructorArgumentValues();     argValues.addIndexedArgumentValue(0, newsListener);     argValues.addIndexedArgumentValue(1, newsPersister);     newsProvider.setConstructorArgumentValues(argValues);     // 2. 或者通过setter方法注入方式    MutablePropertyValues propertyValues = new MutablePropertyValues();     propertyValues.addPropertyValue(new ropertyValue(\"newsListener\",newsListener));     propertyValues.addPropertyValue(new PropertyValue(\"newPersistener\",newsPersister));     newsProvider.setPropertyValues(propertyValues);     // 绑定完成    /**      因为传入的DefaultListableBeanFactory同时实现了BeanFactory和      BeanDefinitionRegistry接口，所以，这样做强制类型转换不会出现问题。但需要注意的是，单纯      的BeanDefinitionRegistry是无法强制转换到BeanFactory类型的    **/    return (BeanFactory)registry; &#125;\n\n在 main 方法中，首先构造一个 DefaultListableBeanFactory 作 为 BeanDefinition\u0002 Registry，然后将其交给bindViaCode方法进行具体的对象注册和相关依赖管理，然后通过bindViaCode返回的BeanFactory取得需要的对象，最后执行相应逻辑。在我们的实例里，当然就是取得FXNewsProvider进行新闻的处理\n在bindViaCode方法中，首先针对相应的业务对象构造与其相对应的BeanDefinition，使用了 RootBeanDefinition 作 为 BeanDefinition 的实现类。构造完成后，将这些BeanDefinition注册到通过方法参数传进来的BeanDefinitionRegistry中。之后，因为我们的FXNewsProvider是采用的构造方法注入，所以，需要通过ConstructorArgumentValues为其注入相关依赖。在这里为了同时说明setter方法注入，也同时展示了在Spring中如何使用代码实现setter方法注入。如果要运行这段代码，需要把setter方法注入部分的4行代码注释掉。最后，以BeanFactory的形式返回已经注册并绑定了所有相关业务对象的BeanDefini\u0002tionRegistry实例\n\n 配置文件\n\n采用外部配置文件时，Spring的IoC容器有一个统一的处理方式。通常情况下，需要根据不同的外\n部配置文件格式，给出相应的BeanDefinitionReader实现类，由BeanDefinitionReader的相应实\n现类负责将相应的配置文件内容读取并映射到BeanDefinition，然后将映射后的BeanDefinition注\n册到一个BeanDefinitionRegistry，之后，BeanDefinitionRegistry即完成Bean的注册和加载\n\n properties文件\n1234567891011# Properties格式表达的依赖注入配置内容djNewsProvider.(class)=..FXNewsProvider # ----------通过构造方法注入的时候------------- djNewsProvider.$0(ref)=djListener djNewsProvider.$1(ref)=djPersister # ----------通过setter方法注入的时候--------- # djNewsProvider.newsListener(ref)=djListener # djNewsProvider.newPersistener(ref)=djPersister djListener.(class)=..impl.DowJonesNewsListener djPersister.(class)=..impl.DowJonesNewsPersister\n\ndjNewsProvider作为beanName，后面通过.(class)表明对应的实现类是什么，实际上使用djNewsProvider.class=…的形式也是可以的，但Spring 1.2.6之后不再提倡使用，而提倡使用.(class)的形式\n通过在表示beanName的名称后添加.$[number]后缀的形式，来表示当前beanName对应的对象需要通过构造方法注入的方式注入相应依赖对象。在这里，我们分别将构造方法的第一个\n参数和第二个参数对应到djListener和djPersister。需要注意的一点，就是**$0和$1后面的(ref)，(ref)用来表示所依赖的是引用对象，而不是普通的类型**。如果不加(ref)，\nPropertiesBeanDefinitionReader会将djListener和djPersister作为简单的String类型进行注入，异常自然不可避免啦\nFXNewsProvider采用的是构造方法注入，而为了演示setter方法注入在Properties配置文件中又 5\n是一个什么样子，以便于你更全面地了解基于Properties文件的配置方式，我们在下面增加了\nsetter方法注入的例子，不过进行了注释。实际上，与构造方法注入最大的区别就是，它不使用数字顺序来指定注入的位置，而使用相应的属性名称来指定注入。newsListener和\nnewPersistener恰好就是我们的FXNewsProvider类中所声明的属性名称。这印证了之前在\n比较构造方法注入和setter方法注入方式不同时提到的差异，即构造方法注入无法通过参数名称来标识注入的确切位置，而setter方法注入则可以通过属性名称来明确标识注入。与在\nProperties中表达构造方法注入一样，同样需要注意，如果属性名称所依赖的是引用对象，那\n么一定不要忘了(ref)\n\n12345678910111213141516//加载Properties配置的BeanFactory的使用演示public static void main(String[] args) &#123;  DefaultListableBeanFactory beanRegistry = new DefaultListableBeanFactory();   BeanFactory container = (BeanFactory)bindViaPropertiesFile(beanRegistry);   FXNewsProvider newsProvider = (FXNewsProvider)container.getBean(\"djNewsProvider\");  newsProvider.getAndPersistNews(); &#125; public static BeanFactory bindViaPropertiesFile(BeanDefinitionRegistry registry) &#123;   PropertiesBeanDefinitionReader reader =   new PropertiesBeanDefinitionReader(registry);   reader.loadBeanDefinitions(\"classpath:../../binding-config.properties\");   return (BeanFactory)registry; &#125;\n xml文件\n\nProperties配置文件格式提供PropertiesBeanDefinitionReader相对应，Spring同样为XML格式的配置文件提供了现成的BeanDefinitionReader实现，即XmlBeanDefinitionReader。XmlBeanDefinitionReader负责读取Spring指定格式的XML配置文件并解析，之后将解析后的文件内容映射到相应的BeanDefinition，并加载到相应的BeanDefinitionRegistry中（在这里是Default\u0002ListableBeanFactory）。这时，整个BeanFactory就可以放给客户端使用了\nSpring在Default\u0002ListableBeanFactory的基础上构建了简化XML格式配置加载的XmlBeanFactory实现\n\nXmlBeanFactory现已不再使用\n\n\n\n 元数据\n\n@Autowired的存在将告知Spring容器需要为当前对象注入哪些依赖对象。而**@Component则是配合Spring 2.5中新的classpath-scanning功能使用的**。现在我们只要再向Spring的配置文件中增加一个“触发器”，使用@Autowired和@Component标注的类就能获得依赖对象的注入了\n\n12345678910111213&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\"       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"       xmlns:context=\"http://www.springframework.org/schema/context\"       xmlns:tx=\"http://www.springframework.org/schema/tx\"       xsi:schemaLocation=\"http://www.springframework.org/schema/beans       \t\thttp://www.springframework.org/schema/beans/spring-beans-2.5.xsd          http://www.springframework.org/schema/context          http://www.springframework.org/schema/context/spring-context-2.5.xsd          http://www.springframework.org/schema/tx          http://www.springframework.org/schema/tx/spring-tx-2.5.xsd\"&gt;   \t&lt;context:component-scan base-package=\"cn.spring21.project.base.package\"/&gt; &lt;/beans&gt;\n\n&lt;context:component-scan/&gt;会到指定的包（package）下面扫描标注有@Component的类，如果找到，则将它们添加到容器进行管理，并根据它们所标注的@Autowired为这些类注入符合条件的依赖对象\n\n IoC容器的实现\n\n\nSpring的IoC容器会以某种方式加载Configuration Metadata（通常也就是XML格式的配置信息），然后根据这些信息绑定整个系统的对象，最终组装成一个可用的基于轻量级容器的应用系统\n\n\nSpring的IoC容器实现以上功能的过程，基本上可以按照类似的流程划分为两个阶段，即容器启动阶段和Bean实例化阶段\n\n\n\n 容器启动阶段\n\n容器启动伊始，首先会通过某种途径加载Configuration MetaData。除了代码方式比较直接，在大部分情况下，容器需要依赖某些工具类（BeanDefinitionReader）对加载的Configuration MetaData进行解析和分析，并将分析后的信息编组为相应的BeanDefinition，最后把这些保存了bean定义必要信息的BeanDefinition，注册到相应的BeanDefinitionRegistry，这样容器启动工作就完成了\n\n Bean实例化阶段\n\n经过第一阶段，现在所有的bean定义信息都通过BeanDefinition的方式注册到了BeanDefini\u0002tionRegistry中。当某个请求方通过容器的getBean方法明确地请求某个对象，或者因依赖关系容器需要隐式地调用getBean方法时，就会触发第二阶段的活动\n该阶段，容器会首先检查所请求的对象之前是否已经初始化。如果没有，则会根据注册的BeanDefinition所提供的信息实例化被请求对象，并为其注入依赖。如果该对象实现了某些回调接口，也会根据回调接口的要求来装配它。当该对象装配完毕之后，容器会立即将其返回请求方使用。如果说第一阶段只是根据图纸装配生产线的话，那么第二阶段就是使用装配好的生产线来生产具体的产品了\n\n 干预容器启动阶段\n\nSpring提供了一种叫做BeanFactoryPostProcessor的容器扩展机制。该机制允许我们在容器实例化相应对象之前，对注册到容器的BeanDefinition所保存的信息做相应的修改。这就相当于在容器实现的第一阶段最后加入一道工序，让我们对最终的BeanDefinition做一些额外的操作，比如修改其中bean定义的某些属性，为bean定义增加其他信息等\n对于BeanFactory来说，我们需要用手动方式应用所有的BeanFactoryPostProcessor\n对于ApplicationContext来说，因为ApplicationContext会自动识别配置文件中的BeanFactoryPostProcessor并应用它，所以，相对于BeanFactory，在ApplicationContext中加载并应用BeanFactoryPostProcessor，仅需要在XML配置文件中将这些BeanFactoryPost\u0002Processor简单配置一下即可\n\n1234567891011&lt;beans&gt; &lt;bean class=\"org.springframework.beans.factory.config.PropertyPlaceholderConfigurer\"&gt; &lt;property name=\"locations\"&gt; &lt;list&gt; &lt;value&gt;conf/jdbc.properties&lt;/value&gt; &lt;value&gt;conf/mail.properties&lt;/value&gt; &lt;/list&gt;&lt;/property&gt; &lt;/bean&gt; ... &lt;/beans&gt;\n Spring提供的BeanFactoryPostProcessor实现\n PropertyPlaceholderConfigurer\n\nPropertyPlaceholderConfigurer允许我们在XML配置文件中使用占位符（Placeholder），并将这些占位符所代表的资源单独配置到简单的properties文件中来加载\n\n123456789101112&lt;property name=\"url\"&gt; &lt;value&gt;$&#123;jdbc.url&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name=\"driverClassName\"&gt; &lt;value&gt;$&#123;jdbc.driver&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name=\"username\"&gt; &lt;value&gt;$&#123;jdbc.username&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name=\"password\"&gt; &lt;value&gt;$&#123;jdbc.password&#125;&lt;/value&gt; &lt;/property&gt;\n\n当BeanFactory在第一阶段加载完成所有配置信息时，BeanFac\u0002tory中保存的对象的属性信息还只是以占位符的形式存在，如jdbc.url、{jdbc.url}、jdbc.url、{jdbc.driver}。当PropertyPlaceholderConfigurer作为BeanFactoryPostProcessor被应用时，它会使用properties配置文件中的配置信息来替换相应BeanDefinition中占位符所表示的属性值。这样，当进入容器实现的第二阶段实例化bean时，bean定义中的属性值就是最终替换完成的了\nPropertyPlaceholderConfigurer不单会从其配置的properties文件中加载配置项，同时还会检查Java的System类中的Properties，可以通过setSystemPropertiesMode()或者setSystemProper\u0002tiesModeName()来控制是否加载或者覆盖System相应Properties的行为\n\n PropertyOverrideConfigurer\n\n可以通过PropertyOverrideConfigurer对容器中配置的任何你想处理的bean定义的property信息进行覆盖替换\nPropertyOverrideConfigurer的properties文件中的配置项，覆盖掉了原来XML中的bean定义的property信息\nPropertyOverrideConfigurer使用的配置文件示例：\nbeanName.propertyName=Value\n也就是说，properties文件中的键是以XML中配置的bean定义的beanName为标志开始的（通常就是id指定的值），后面跟着相应被覆盖的property的名称\n当容器中配置的多个PropertyOverrideConfigurer对同一个bean定义的同一个property值进\n行处理的时候，最后一个将会生效\n\n CustomEditorConfigure\n\nCustomEditorConfigure只是辅助性地将后期会用到的信息注册到容器，对BeanDefinition没有做任何变动\n不管对象是什么类型，也不管这些对象所声明的依赖对象是什么类型，通常都是通过XML（或者properties）文件格式来配置这些对象类型。但XML所记载的，都是String类型，即容器从XML格式的文件中读取的都是字符串形式，最终应用程序却是由各种类型的对象所构成。要想完成这种由字符串到具体对象的转换，都需要这种转换规则相关的信息，而CustomEditorConfigurer就是帮助我们传达类似信息的\nSpring内部通过JavaBean的PropertyEditor来帮助进行String类型到其他类型的转换工作。只要为每种对象类型提供一个 PropertyEditor ，就可以根据该对象类型取得与其相对应的PropertyEditor来做具体的类型转换。Spring容器内部在做具体的类型转换的时候，会采用JavaBean框架内默认的PropertyEditor搜寻逻辑，从而继承了对原生类型以及java.lang.String.java.awt.Color和java.awt.Font等类型的转换支持。同时，Spring框架还提供了自身实现的一些Property\u0002Editor，这些PropertyEditor大部分都位于org.springframework. beans.propertyeditors包下\n\nStringArrayPropertyEditor。该PropertyEditor会将符合CSV格式的字符串转换成String[]数组的形式，默认是以逗号（,）分隔的字符串，但可以指定自定义的字符串分隔符\nClassEditor。根据String类型的class名称，直接将其转换成相应的Class对象，相当于通\n过Class.forName(String)完成的功效。可以通过String[]数组的形式传入需转换的值，以\n达到与提供的ClassArrayEditor同样的目的\n\nClassEditor，FileEditor，LocaleEditor，PatternEditor等均默认加载使用\n\n\n\n\n\n 给出针对特定对象类型的PropertyEditor实现\n\n假设需要对yyyy/MM/dd形式的日期格式转换提供支持。虽然可以直接让PropertyEditor实现类去实现java.beans.PropertyEditor接口，不过，我们可以直接继承java.beans.Property\u0002EditorSupport类以避免实现java.beans.PropertyEditor接口的所有方法。就好像这次，我们仅仅让DatePropertyEditor完成从 String 到 java.util.Date 的转换，只需要实现setAsText(String)方法，而其他方法一概不管\n\n![image-20201026162419885](/Users/ng/Library/Application Support/typora-user-images/image-20201026162419885.png)\n\n通过CustomEditorConfigurer将刚实现的DatePro\u0002pertyEditor注册到容器，以告知容器按照DatePropertyEditor的形式进行String到java.util.Date类型的转换工作\n如果容器是BeanFactory的实现，比如XmlBeanFactory，则需要通过编码手动应用\n\n12345678XmlBeanFactory beanFactory = new XmlBeanFactory(new ClassPathResource// CustomEditorConfigurer ceConfigurer = new CustomEditorConfigurer(); Map customerEditors = new HashMap(); customerEditors.put(java.util.Date.class, new DatePropertyEditor())；ceConfigurer.setCustomEditors(customerEditors); // ceConfigurer.postProcessBeanFactory(beanFactory);\n\nApplicationContext相应实现，因为ApplicationContext会自动识别BeanFactoryPostProcessor并应用，所以只需要在相应配置文件中配置一下\n\n Bean的生命周期\n\nApplicationContext启动之后会实例化所有的bean定义，但ApplicationContext在实现的过程中依然遵循Spring容器实现流程的两个阶段，只不过它会在启动阶段的活动完成之后，紧接着调用注册到该容器的所有bean定义的实例化方法getBean()。这就是为什么当你得到ApplicationContext类型的容器引用时，容器内所有对象已经被全部实例化完成\n说getBean()方法是有可能触发Bean实例化阶段的活动，是因为只有当对应某个bean定义的getBean()方法第一次被调用时，不管是显式的还是隐式的，Bean实例化阶段的活动才会被触发，第二次被调用则会直接返回容器缓存的第一次实例化完的对象实例（prototype类型bean除外）。当getBean()方法内部发现该bean定义之前还没有被实例化之后，会通过createBean()方法来进行具体的对象实例化\n\n\n\nSpring容器将对其所管理的对象全部给予统一的生命周期管理\n\n Bean的实例化与BeanWrapper\n\n容器在内部实现的时候，采用“策略模式（Strategy Pattern）”来决定采用何种方式初始化bean实例。通常，可以通过反射或者CGLIB动态字节码生成来初始化相应的bean实例或者动态生成其子类。InstantiationStrategy是实例化策略的抽象接口，其直接子类SimpleInstantiationStrategy实现了简单的对象实例化功能，可以通过反射来实例化对象实例，但不支持方法注入方式的对象实例化\nCglibSubclassingInstantiation\u0002Strategy继承了SimpleInstantiationStrategy的以反射方式实例化对象的功能，并且通过CGLIB的动态字节码生成功能，该策略实现类可以动态生成某个类的子类，进而满足了方法注入所需的对象实例化需求。默认情况下，容器内部采用的是CglibSubclassingInstantiationStrategy\n\n 第一步：实例化Bean对象\n\n容器只要根据相应bean定义的BeanDefintion取得实例化信息，结合CglibSubclassingIns\u0002tantiationStrategy以及不同的bean定义类型，就可以返回实例化完成的对象实例。但是，不是直接返回构造完成的对象实例，而是以BeanWrapper对构造完成的对象实例进行包裹，返回相应的BeanWrapper实例\n\n 第二步：设置对象属性\n\n在第一步结束后返回BeanWrapper实例而不是原先的对象实例，就是为了第二步“设置对象属性”\nBeanWrapper定义继承了PropertyAccessor接口，可以以统一的方式对对象属性进行访问；BeanWrapper定义同时又直接或者间接继承了PropertyEditorRegistry和TypeConverter接口。在第一步构造完成对象之后，Spring会根据对象实例构造一个BeanWrapperImpl实例，然后将之前CustomEditor\u0002Configurer注册的PropertyEditor复制一份给BeanWrapperImpl实例（这就是BeanWrapper同时又是PropertyEditorRegistry的原因）。这样，当BeanWrapper转换类型、设置对象属性值时，就不会无从下手了\n使用BeanWrapper对bean实例操作很方便，可以免去直接使用Java反射API操作对象实例的烦琐\n\n123456789101112Object provider = Class.forName(\"package.name.FXNewsProvider\").newInstance(); Object listener = Class.forName(\"package.name.DowJonesNewsListener\").newInstance(); Object persister = Class.forName(\"package.name.DowJonesNewsPersister\").newInstance(); BeanWrapper newsProvider = new BeanWrapperImpl(provider); newsProvider.setPropertyValue(\"newsListener\", listener); newsProvider.setPropertyValue(\"newPersistener\", persister); assertTrue(newsProvider.getWrappedInstance() instanceof FXNewsProvider); assertSame(provider, newsProvider.getWrappedInstance()); assertSame(listener, newsProvider.getPropertyValue(\"newsListener\")); assertSame(persister, newsProvider.getPropertyValue(\"newsPersister\"));\n Aware接口\n\n当对象实例化完成并且相关属性以及依赖设置完成之后，Spring容器会检查当前对象实例是否实现了一系列的以Aware命名结尾的接口定义。如果是，则将这些Aware接口定义中规定的依赖注入给当前对象实例\nBeanFactory的Aware接口\n\nBeanNameAware。如果Spring容器检测到当前对象实例实现了该接口，会将该对象实例的bean定义对应的beanName设置到当前对象实例\nBeanClassLoaderAware。如果容器检测到当前对象实例实现了该接口，会将对应加载当前bean的Classloader注入当前对象实例。默认会使用加载org.springframework.util.ClassUtils类的Classloader\nBeanFactoryAware。在介绍方法注入的时候，我们提到过使用该接口以便每次获取prototype类型bean的不同实例。如果对象声明实现了BeanFactoryAware接口，BeanFactory容器会将自身设置到当前对象实例。这样，当前对象实例就拥有了一个BeanFactory容器的引用，并且可以对这个容器内允许访问的对象按照需要进行访问\n\n\nApplicationContext的Aware接口\n\nResourceLoaderAware。ApplicationContext实现了Spring的ResourceLoader接口。当容器检测到当前对象实例实现了ResourceLoaderAware接口之后，会将当前ApplicationContext自身设置到对象实例，这样当前对象实例就拥有了其所在ApplicationContext容器的一个引用\nApplicationEventPublisherAware。ApplicationContext作为一个容器，同时还实现了ApplicationEventPublisher接口，这样，它就可以作为Appli\u0002cationEventPublisher来使用。所以，当前ApplicationContext容器如果检测到当前实例化的对象实例声明了ApplicationEventPublisherAware接口，则会将自身注入当前对象\nMessageSourceAware。ApplicationContext通过Message\u0002Source接口提供国际化的信息支持，即I18n（Internationalization）。它自身就实现了Message\u0002Source接口，所以当检测到当前对象实例实现了MessageSourceAware接口，则会将自身注入当前对象实例\norg.springframework.context.ApplicationContextAware。 如果ApplicationContext容器检测到当前对象实现了ApplicationContextAware接口，则会将自身注入当前对象实例\n\n\n\n BeanPostProcessor\n\nBean\u0002PostProcessor存在于对象实例化阶段，而BeanFactoryPostProcessor则存在于容器启动阶段\n与BeanFactoryPostProcessor通常会处理容器内所有符合条件的BeanDefinition类似，Bean\u0002PostProcessor会处理容器内所有符合条件的实例化后的对象实例\npostProcessBeforeInitialization()方法是图4-10中BeanPostProcessor前置处理这一步将会执行的方法，postProcessAfterInitialization()则是对应图4-10中BeanPostProcessor后置处理那一步将会执行的方法。BeanPostProcessor的两个方法中都传入了原来的对象实例的引用，这为我们扩展容器的对象实例化过程中的行为提供了极大的便利，我们几乎可以对传入的对象实例执行任何的操作\n通常比较常见的使用BeanPostProcessor的场景，是处理标记接口实现类，或者为当前对象提供代理实现。在图4-10的第三步中，ApplicationContext对应的那些Aware接口实际上就是通过Bean\u0002PostProcessor的方式进行处理的\n\n InitializingBean和init-method\n\nInitializingBean是容器内部广泛使用的一个对象生命周期标识接口\n\n其作用在于，在对象实例化过程调用过“BeanPostProcessor的前置处理”之后，会接着检测当前对象是否实现了InitializingBean接口，如果是，则会调用其afterProper\u0002tiesSet()方法进一步调整对象实例的状态。比如，在有些情况下，某个业务对象实例化完成后，还不能处于可以使用状态。这个时候就可以让该业务对象实现该接口，并在方法afterPropertiesSet()中完成对该业务对象的后续处理\n让业务对象实现这个接口，则显得Spring容器比较具有侵入性\n\n\nSpring还提供了另一种方式来指定自定义的对象初始化操作，那就是在XML配置的时候，使用&lt;bean&gt;的init-method属性\n\n通过init-method，系统中业务对象的自定义初始化操作可以以任何方式命名，而不再受制于InitializingBean的afterPropertiesSet()。如果系统开发过程中规定：所有业务对象的自定义初始化操作都必须以init()命名，为了省去挨个&lt;bean&gt;的设置init-method这样的烦琐，我们还可以通过最顶层的&lt;beans&gt;的default-init-method统一指定这一init()方法名\n一般，我们是在集成第三方库，或者其他特殊的情况下，才会需要使用该特性\n\n\n\n DisposableBean与destroy-method\n\n当所有的一切，该设置的设置，该注入的注入，该调用的调用完成之后，容器将检查singleton类型的bean实例，看其是否实现了DisposableBean接口。或者其对应的bean定义是否通过&lt;bean&gt;的destroy-method属性指定了自定义的对象销毁方法。如果是，就会为该实例注册一个用于对象销毁的回调（Callback），以便在这些singleton类型的对象实例销毁之前，执行销毁逻辑\n与InitializingBean和init-method用于对象的自定义初始化相对应，DisposableBean和destroy-method为对象提供了执行自定义销毁逻辑的机会\n最常见到的该功能的使用场景就是在Spring容器中注册数据库连接池\n不过，这些自定义的对象销毁逻辑，在对象实例初始化完成并注册了相关的回调方法之后，并不会马上执行。回调方法注册后，返回的对象实例即处于使用状态，只有该对象实例不再被使用的时候，才会执行相关的自定义销毁逻辑，此时通常也就是Spring容器关闭的时候。但Spring容器在关闭之前，不会自动调用这些回调方法。所以，需要我们告知容器，在哪个时间点来执行对象的自定义销毁方法\n对于BeanFactory容器来说。我们需要在独立应用程序的主程序退出之前，或者其他被认为是合适的情况下（依照应用场景而定），调用ConfigurableBeanFactory提供的destroySingletons()方法销毁容器中管理的所有singleton类型的对象实例\n对于ApplicationContext容器来说，它为我们提供了registerShutdownHook()方法，该方法底层使用标准的Runtime类的addShutdownHook()方式来调用相应bean对象的销毁逻辑，从而保证在Java虚拟机退出之前，这些singtleton类型的bean对象实例的自定义销毁逻辑会被执行\n\n ApplicationContext\n\n作为Spring提供的较之BeanFactory更为先进的IoC容器实现，ApplicationContext除了拥有BeanFactory支持的所有功能之外，还进一步扩展了基本容器的功能，包括BeanFactoryPostProces\u0002sor、BeanPostProcessor以及其他特殊类型bean的自动识别、容器启动后bean实例的自动初始化、国际化的信息支持、容器内事件发布等\n\n 统一资源加载策略\n 使用原因\n\njava SE提供的URL全名是Uniform Resource Locator（统一资源定位器）。首先，说是统一资源定位，但基本实现却只限于网络形式发布的资源的查找和定位工作，基本上只提供了基于HTTP、FTP、File等协议的资源定位功能\n资源这个词的范围比较广义，资源可以任何形式存在，如以二进制对象形式存在、以字节流形式存在、以文件形式存在等；而且，资源也可以存在于任何场所，如存在于文件系统、存在于Java应用的Classpath中，甚至存在于URL可以定位的地方\n\n Spring中的Resource\n\nSpring框架内部使用Resource接口作为所有资源的抽象和访问接口，我们之前在构造BeanFactory的时候已经接触过它，如下代码：\n\n``BeanFactory beanFactory = new XmlBeanFactory(new ClassPathResource(&quot;…&quot;));`\n其中ClassPathResource就是Resource的一个特定类型的实现，代表的是位于Classpath中的资源\n\n\nResource接口可以根据资源的不同类型，或者资源所处的不同场合，给出相应的具体实现。Spring框架在这个理念的基础上，提供了一些实现类（可以在org.springframework.core.io包下找到这些实现类）\n\nByteArrayResource。将字节（byte）数组提供的数据作为一种资源进行封装，如果通过InputStream形式访问该类型的资源，该实现会根据字节数组的数据，构造相应的ByteArray\u0002InputStream并返回\nClassPathResource。该实现从Java应用程序的ClassPath中加载具体资源并进行封装，可以使用指定的类加载器（ClassLoader）或者给定的类进行资源加载\nFileSystemResource。对java.io.File类型的封装，所以，我们可以以文件或者URL的形式对该类型资源进行访问，只要能跟File打的交道，基本上跟FileSystemResource也可以\nUrlResource。通过java.net.URL进行的具体资源查找定位的实现类，内部委派URL进行具体的资源操作\nInputStreamResource。将给定的InputStream视为一种资源的Resource实现类，较为少用。可能的情况下，以ByteArrayResource以及其他形式资源实现代之\n\n\n想实现自定义的Resource，我们可以继承AbstractResource抽象类，然后根据当前具体资源特征，覆盖相应的方法就可以了\n\n “更广义的URL”——ResourceLoader\n\n\n资源是有了，但如何去查找和定位这些资源，则应该是ResourceLoader的职责所在了\n\n\nResourceLoader接口是资源查找定位策略的统一抽象，具体的资源查找定位策略则由相应的ResourceLoader实现类给出\n\n把ResourceLoader称作统一资源定位器或许才更恰当一些\n\n\n\nResourceLoader定义如下\n12345public interface ResourceLoader &#123;     String CLASSPATH_URL_PREFIX = ResourceUtils.CLASSPATH_URL_PREFIX;     Resource getResource(String location);     ClassLoader getClassLoader(); &#125;\n\n其中最主要的就是Resource getResource(String location)方法，通过它，我们就可以根据指定的资源位置，定位到具体的资源实例\n\n\n\n DefaultResourceLoader\n\nResourceLoader有一个默认的实现类，即DefaultResource\u0002Loader，该类默认的资源查找处理逻辑如下\n\n首先检查资源路径是否以classpath:前缀打头，如果是，则尝试构造ClassPathResource类型资源并返回\n否则尝试通过URL，根据资源路径来定位资源，如果没有抛出MalformedURLException，有则会构造UrlResource类型的资源并返回\n\n如果还是无法根据资源路径定位指定的资源，则委派getResourceByPath(String) 方法来定位， DefaultResourceLoader 的getResourceByPath(String)方法默认实现逻辑是，构造ClassPathResource类型的资源并返回\n\n\n\n\n\n1234567891011121314151617181920Resource fakeFileResource = resourceLoader.getResource(\"D:/spring21site/README\"); assertTrue(fakeFileResource instanceof ClassPathResource); assertFalse(fakeFileResource.exists()); Resource urlResource1 = resourceLoader.getResource(\"file:D:/spring21site/README\"); assertTrue(urlResource1 instanceof UrlResource); Resource urlResource2 = resourceLoader.getResource(\"http://www.spring21.cn\"); assertTrue(urlResource2 instanceof UrlResource); try&#123; fakeFileResource.getFile();fail(\"no such file with path[\"+fakeFileResource.getFilename()+\"] exists in classpath\"); &#125; catch(FileNotFoundException e)&#123; // &#125; try&#123;   urlResource1.getFile();&#125; catch(FileNotFoundException e)&#123;   fail();&#125;\n\nfakeFileResource资源的类型，并不是我们所预期的FileSystemResource类型，而是ClassPathResource类型，这是由DefaultResourceLoader的资源查找逻辑所决定的。如果最终没有找到符合条件的相应资源，getResourceByPath(String)方法就会构造一个实际上并不存在的资源并返回。而指定有协议前缀的资源路径，则通过URL能够定位，所以，返回的都是UrlResource类型\n\n FileSystemResourceLoader\n\n为了避免DefaultResourceLoader在最后getResourceByPath(String)方法上的不恰当处理，我们可以使用FileSystemResourceLoader，它继承自Default\u0002ResourceLoader，但覆写getResourceByPath(String)方法，使之从文件系统加载资源并以FileSystemResource类型返回。这样，我们就可以取得预想的资源类型\n\n123456789public void testResourceTypesWithFileSystemResourceLoader() &#123; ResourceLoader resourceLoader = new FileSystemResourceLoader(); Resource fileResource = resourceLoader.getResource(\"D:/spring21site/README\"); assertTrue(fileResource instanceof FileSystemResource); assertTrue(fileResource.exists()); Resource urlResource = resourceLoader.getResource(\"file:D:/spring21site/README\"); assertTrue(urlResource instanceof UrlResource); &#125;\n\nFileSystemResourceLoader在ResourceLoader家族中的兄弟FileSystemXmlApplication\u0002Context，也是覆写了getResourceByPath(String)方法的逻辑，以改变DefaultResourceLoader的默认资源加载行为，最终从文件系统中加载并返回FileSystemResource类型的资源\n\n ResourcePatternResolver ——批量查找的ResourceLoader\n\nResourcePatternResolver是ResourceLoader的扩展，ResourceLoader每次只能根据资源路径返回确定的单个Resource实例，而ResourcePatternResolver则可以根据指定的资源路径匹配模式，每次返回多个Resource实例。接口ResourcePattern\u0002Resolver定义如下：\n\n1234public interface ResourcePatternResolver extends ResourceLoader &#123;     String CLASSPATH_ALL_URL_PREFIX = \"classpath*:\";     Resource[] getResources(String locationPattern) throws IOException; &#125;\n\nResourcePatternResolver在继承ResourceLoader原有定义的基础上，又引入了Resource[] getResources(String)方法定义，以支持根据路径匹配模式返回多个Resources的功能。它同时还引入了一种新的协议前缀classpath*:，针对这一点的支持，将由相应的子类实现给出\nResourcePatternResolver最常用的一个实现是PathMatchingResourcePatternResolver，该实现类支持ResourceLoader级别的资源加载，支持基于Ant风格的路径匹配模式（类似于**/*.suffix之类的路径形式），支持ResourcePatternResolver新增加的classpath*:前缀等，基本上集所有技能于一身\n在构造PathMatchingResourcePatternResolver实例的时候，可以指定一个ResourceLoader，如果不指定的话，则PathMatchingResourcePatternResolver内部会默认构造一个Default\u0002ResourceLoader实例。PathMatchingResourcePatternResolver内部会将匹配后确定的资源路径，委派给它的ResourceLoader来查找和定位资源。这样，如果不指定任何ResourceLoader的话，Path\u0002MatchingResourcePatternResolver在加载资源的行为上会与DefaultResourceLoader基本相同，只存在返回的Resource数量上的差异。如下代码表明了二者在资源加载行为上的一致性：\n\n12345ResourcePatternResolver resourceResolver = new PathMatchingResourcePatternResolver(); Resource fileResource = resourceResolver.getResource(\"D:/spring21site/README\"); assertTrue(fileResource instanceof ClassPathResource); assertFalse(fileResource.exists()); ...\n\n不过，可以通过传入其他类型的ResourceLoader来替换PathMatchingResourcePatternResolver内部默认使用的DefaultResourceLoader，从而改变其默认行为\n\n使用FileSystemResourceLoader替换默认的DefaultResourceLoader，从而使得PathMatching\u0002ResourcePatternResolver的行为跟使用FileSystemResourceLoader一样\n\n\n\n123456789101112public void testResourceTypesWithPathMatchingResourcePatternResolver() &#123; ResourcePatternResolver resourceResolver = new PathMatchingResourcePatternResolver(); Resource fileResource = resourceResolver.getResource(\"D:/spring21site/README\"); assertTrue(fileResource instanceof ClassPathResource); assertFalse(fileResource.exists()); resourceResolver = new PathMatchingResourcePatternResolver(new ➥FileSystemResourceLoader()); fileResource = resourceResolver.getResource(\"D:/spring21site/README\"); assertTrue(fileResource instanceof FileSystemResource); assertTrue(fileResource.exists()); &#125;\n ApplicationContext与ResourceLoader\n\nApplicationContext继承了ResourcePatternResolver，当然就间接实现了ResourceLoader接口。所以，任何的ApplicationContext实现都可以看作是一个ResourceLoader甚至ResourcePatternResolver。而这就是ApplicationContext支持Spring内统一资源加载策略的真相\n\n![image-20201104112529095](/Users/ng/Library/Application Support/typora-user-images/image-20201104112529095.png)\n 扮演ResourceLoader的角色\n\n既然ApplicationContext可以作为ResourceLoader或者ResourcePatternResolver来使用，那么，很显然，我们可以通过ApplicationContext来加载任何Spring支持的Resource类型\n\n12345678ResourceLoader resourceLoader = new ClassPathXmlApplicationContext(\"配置文件路径\"); // 或者// ResourceLoader resourceLoader = new FileSystemXmlApplicationContext(\"配置文件路径\"); Resource fileResource = resourceLoader.getResource(\"D:/spring21site/README\"); assertTrue(fileResource instanceof ClassPathResource); assertFalse(fileResource.exists()); Resource urlResource2 = resourceLoader.getResource(\"http://www.spring21.cn\"); assertTrue(urlResource2 instanceof UrlResource);\n ResourceLoader类型的注入\n\n在大部分情况下，如果某个bean需要依赖于ResourceLoader来查找定位资源，我们可以为其注入容器中声明的某个具体的ResourceLoader实现，该bean也无需实现任何接口，直接通过构造方法注入或者setter方法注入规则声明依赖即可，这样处理是比较合理的。不过，如果你不介意你的bean定义依赖于Spring的API，那不妨考虑用一下Spring提供的便利\nApplicationContext容器本身就是一个ResourceLoader，我们为了该类还需要单独提供一个resourceLoader实例就有些多于了，直接将当前的ApplicationContext容器作为Resource\u0002Loader注入\n\n123456789101112131415161718192021222324252627public class FooBar implements ResourceLoaderAware&#123; private ResourceLoader resourceLoader; public void foo(String location) &#123; System.out.println(getResourceLoader().getResource(location).getClass()); &#125;public ResourceLoader getResourceLoader() &#123; return resourceLoader;&#125;  public void setResourceLoader(ResourceLoader resourceLoader) &#123; this.resourceLoader = resourceLoader; &#125; &#125; public class FooBar implements ApplicationContextAware&#123; private ResourceLoader resourceLoader; public void foo(String location) &#123; System.out.println(getResourceLoader().getResource(location).getClass()); &#125; public ResourceLoader getResourceLoader() &#123; return resourceLoader; &#125; public void setApplicationContext(ApplicationContext ctx) ➥throws BeansException &#123; this.resourceLoader = ctx; &#125; &#125;\n\n剩下的就是直接将FooBar配置到bean定义文件即可，如下所示\n\n12&lt;bean id=\"fooBar\" class=\"...FooBar\"&gt; &lt;/bean&gt;\n\n现在，容器启动的时候，就会自动将当前ApplicationContext容器本身注入到FooBar中，因为ApplicationContext类型容器可以自动识别Aware接口\n\n Resource类型的注入\n\n我们之前讲过，容器可以将bean定义文件中的字符串形式表达的信息，正确地转换成具体对象定义的依赖类型。对于那些Spring容器提供的默认的PropertyEditors无法识别的对象类型，我们可以提供自定义的PropertyEditor实现并注册到容器中，以供容器做类型转换的时候使用。默认情况下，BeanFactory容器不会为Resource类型提供相应的Property\u0002Editor，所以，如果我们想注入Resource类型的bean定义，就需要注册自定义的PropertyEditor到BeanFactory容器。不过，对于ApplicationContext来说，我们无需这么做，因为Application\u0002Context容器可以正确识别Resource类型并转换后注入相关对象\n直接在配置文件中以String形式指定template所在位置，ApplicatonContext就可以正确地转换类型并注入依赖\n\n1234&lt;bean id=\"mailer\" class=\"...XMailer\"&gt; &lt;property name=\"template\" value=\"..resources.default_template.vm\"/&gt; ... &lt;/bean&gt;\n\n\nApplicationContext启动伊始，会通过一个Resource\u0002EditorRegistrar来注册Spring提供的针对Resource类型的PropertyEditor实现到容器中，这个PropertyEditor叫做 ResourceEditor。这样，Application\u0002Context就可以正确地识别Resource类型的依赖了。ResourceEditor怎么实现：把配置文件中的路径让ApplicationContext作为ResourceLoader定位一下\n\n\n如果应用对象需要依赖一组Resource，与ApplicationContext注册了ResourceEditor类似，Spring提供了ResourceArrayProperty\u0002Editor实现，我们只需要通过CustomEditorConfigurar告知容器即可\n\n\n 在特定情况下，ApplicationContext的Resource加载行为\n\n\n我们下面主要讨论两种类型的ApplicationContext容器，即ClassPathXmlApplicationContext和FileSystemXmlApplicationContext\n\n\n我们知道，对于URL所接受的资源路径来说，通常开始都会有一个协议前缀，比如file:、http:、ftp:等。既然Spring使用UrlResource对URL定位查找的资源进行了抽象，那么，同样也支持这样类型的资源路径，而且，在这个基础上，Spring还扩展了协议前缀的集合。ResourceLoader中增加了一种新的资源路径协议——classpath:，ResourcePatternResolver又增加了一种——classpath*:。这样，我们就可以通过这些资源路径协议前缀，明确地告知Spring容器要classpath中加载资源\n// 代码中使用协议前缀 ResourceLoader resourceLoader = new ➥ FileSystemXmlApplicationContext(&quot;classpath:conf/container-conf.xml&quot;); // 配置中使用协议前缀 &lt;bean id=&quot;...&quot; class=&quot;...&quot;&gt; ean id=&quot;...&quot; class=&quot;.. &lt;value&gt;classpath:resource/template.vm&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt;\n\n\nclasspath:与classpath:的唯一区别就在于，如果能够在classpath中找到多个指定的资源，则返回多个*。我们可以通过这两个前缀改变某些ApplicationContext实现类的默认资源加载行为\n\n\nClassPathXmlApplicationContext和FileSystemXmlApplicationContext在处理资源加载的默认行为上有所不同\n\n\n当ClassPathXmlApplicationContext在实例化的时候，即使没有指明classpath:或者classpath:等前缀，它会默认从classpath中加载bean定义配置文件*\n\n\n而FileSystemXmlApplicationContext则有些不同，它会尝试从文件系统中加载bean定义文件\n\n\n通过在资源路径之前增加classpath:前缀，明确指定\nFileSystemXmlApplicationContext从classpath中加载bean定义的配置文件\nApplicationContext ctx = new FileSystemXmlApplicationContext(&quot;classpath:conf/appContext.xml&quot;);\n\n\n这时，FileSystemXmlApplicationContext就是从Classpath中加载配置，而不是从文件系统中加载。也就是说，它现在对应的是ClassPathResource类型的资源，而不是默认的FileSystem\u0002Resource类型资源。FileSystemXmlApplicationContext之所以如此，是因为它与FileSystemResourceLoader一样，也覆写了DefaultResourceLoader的getRes\u0002ourceByPath(String)方法，逻辑跟 FileSystemResourceLoader一模一样\n\n\n对于ClassPathXmlApplicationContext来说，如果我们不指定路径之前的前缀，它也不会像资源路径所表现的那样，从文件系统加载资源，而是像实例化时候的行为一样，从Classpath中加载这种没有路径前缀的资源\n\n\n\n\n","plink":"ilucia.github.io/spring&mybatis/Spring IoC/"},{"title":"spring&mybatis/Spring MVC","date":"2022-04-27T15:24:01.747Z","updated":"2022-04-27T15:24:01.747Z","content":" Spring MVC\n Spring ioc\n\n 原理\n\n 1. DispatcherServlet\n\nDispatcherServlet 会拦截所有的请求，并且将这些请求发送给 Spring MVC 控制器\n\n 2. HandlerMapping\n\nDispatcherServlet 会查询一个或多个处理器映射来确定请求的下一站在哪里，处理器映射会根据请求所携带的 URL 信息来进行决策\n例如通过配置 simpleUrlHandlerMapping 来将 /hello 地址交给 helloController 处理\n\n12345678910&lt;bean id=\"simpleUrlHandlerMapping\"      class=\"org.springframework.web.servlet.handler.SimpleUrlHandlerMapping\"&gt;    &lt;property name=\"mappings\"&gt;        &lt;props&gt;            &lt;!-- /hello 路径的请求交给 id 为 helloController 的控制器处理--&gt;            &lt;prop key=\"/hello\"&gt;helloController&lt;/prop&gt;        &lt;/props&gt;    &lt;/property&gt;&lt;/bean&gt;&lt;bean id=\"helloController\" class=\"controller.HelloController\"&gt;&lt;/bean&gt;\n 3. 控制器\n\n一旦选择了合适的控制器， DispatcherServlet 会将请求发送给选中的控制器，到了控制器，请求会卸下其负载（用户提交的请求）等待控制器处理完这些信息\n\n1234public ModelAndView handleRequest(javax.servlet.http.HttpServletRequest httpServletRequest, javax.servlet.http.HttpServletResponse httpServletResponse) throws Exception &#123;    // 处理逻辑    ....&#125;\n 4. 返回DispatcherServlet\n\n\u0015当控制器在完成逻辑处理后，通常会产生一些信息，这些信息就是需要返回给用户并在浏览器上显示的信息，它们被称为模型（Model）。仅仅返回原始的信息时不够的——这些信息需要以用户友好的方式进行格式化，一般会是 HTML，所以，信息需要发送给一个视图（view），通常会是 JSP\n控制器所做的最后一件事就是将模型数据打包，并且表示出用于渲染输出的视图名**（逻辑视图名）。它接下来会将请求连同模型和视图名发送回 DispatcherServlet**\n这样以来，控制器就不会和特定的视图相耦合，传递给 DispatcherServlet 的视图名并不直接表示某个特定的 JSP。（实际上，它甚至不能确定视图就是 JSP）相反，它传递的仅仅是一个逻辑名称，这个名称将会用来查找产生结果的真正视图\n\n123456public ModelAndView handleRequest(javax.servlet.http.HttpServletRequest httpServletRequest, javax.servlet.http.HttpServletResponse httpServletResponse) throws Exception &#123;    // 处理逻辑    ....    // 返回给 DispatcherServlet    return mav;&#125;\n 5. 视图解析器\n\nDispatcherServlet 将会使用视图解析器（view resolver）来将逻辑视图名匹配为一个特定的视图实现，它可能是也可能不是 JSP\n\n 6. 视图\n\n既然 DispatcherServlet 已经知道由哪个视图渲染结果了，那请求的任务基本上也就完成了\n它的最后一站是视图的实现，在这里它交付模型数据，请求的任务也就完成了。视图使用模型数据渲染出结果，这个输出结果会通过响应对象传递给客户端\n\n 使用注解配置SpringMVC\n 完整的命名空间\n12345678910&lt;beans xmlns=\"http://www.springframework.org/schema/beans\"       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"       xmlns:context=\"http://www.springframework.org/schema/context\"       xmlns:mvc=\"http://www.springframework.org/schema/mvc\"       xsi:schemaLocation=\"http://www.springframework.org/schema/beans       http://www.springframework.org/schema/beans/spring-beans-4.2.xsd    http://www.springframework.org/schema/mvc    http://www.springframework.org/schema/mvc/spring-mvc-4.2.xsd    http://www.springframework.org/schema/context    http://www.springframework.org/schema/context/spring-context-4.2.xsd\"&gt;\n 主要注解\n\n 配置视图解析器\n视图解析器负责定位视图，它接受一个由 DispaterServlet 传递过来的逻辑视图名来匹配一个特定的视图。\n\n需求： 有一些页面我们不希望用户用户直接访问到，例如有重要数据的页面，例如有模型数据支撑的页面\n造成的问题：\n\n我们可以在【web】根目录下放置一个【test.jsp】模拟一个重要数据的页面，我们什么都不用做，重新启动服务器，网页中输入 localhost/test.jsp 就能够直接访问到了，这会造成数据泄露\n另外我们可以直接输入 localhost/index.jsp 试试，根据我们上面的程序，这会是一个空白的页面，因为并没有获取到 ${message} 参数就直接访问了，这会影响用户体验\n\n\n\n 解决方案\n\n\n我们将我们的 JSP 文件配置在【WEB-INF】文件夹中的【page】文件夹下，【WEB-INF】是 Java Web 中默认的安全目录，是不允许用户直接访问的\n\n也就是你说你通过 localhost/WEB-INF/ 这样的方式是永远访问不到的\n\n\n\n但是我们需要将这告诉给视图解析器，我们在 dispatcher-servlet.xml 文件中做如下配置\n\n\n12345&lt;bean id=\"viewResolver\"      class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"&gt;    &lt;property name=\"prefix\" value=\"/WEB-INF/page/\" /&gt;    &lt;property name=\"suffix\" value=\".jsp\" /&gt;&lt;/bean&gt;\n这里配置了一个 Spring MVC 内置的一个视图解析器，该解析器是遵循着一种约定：会在视图名上添加前缀和后缀，进而确定一个 Web 应用中视图资源的物理路径的\n 修改HelloController\n1234567891011121314151617181920/** * Controller用来声明控制器 */@Controllerpublic class HelloController&#123;    /**     * description: RequestMapping注解用来映射 路径请求和方法     *     * @param httpServletRequest 请求     * @param httpServletResponse 回应     * @return org.springframework.web.servlet.ModelAndView     */    @RequestMapping(\"/hello\")    public ModelAndView handleRequest(javax.servlet.http.HttpServletRequest httpServletRequest, javax.servlet.http.HttpServletResponse httpServletResponse) throws Exception &#123;        ModelAndView mav = new ModelAndView(\"index\");        mav.addObject(\"message\", \"Hello Spring MVC\");        return mav;    &#125;&#125;\n 配置视图解析器\n12345678910111213141516171819202122232425&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\"       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"       xmlns:context=\"http://www.springframework.org/schema/context\"       xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt;    &lt;!--&lt;bean id=\"simpleUrlHandlerMapping\"--&gt;                                        &lt;!--class=\"org.springframework.web.servlet.handler.SimpleUrlHandlerMapping\"&gt;--&gt;    &lt;!--&lt;property name=\"mappings\"&gt;--&gt;            &lt;!--&lt;props&gt;--&gt;                &lt;!--&amp;lt;!&amp;ndash; /hello 路径的请求交给 id 为 helloController 的控制器处理&amp;ndash;&amp;gt;--&gt;                &lt;!--&lt;prop key=\"/hello\"&gt;helloController&lt;/prop&gt;--&gt;            &lt;!--&lt;/props&gt;--&gt;        &lt;!--&lt;/property&gt;--&gt;    &lt;!--&lt;/bean&gt;--&gt;    &lt;!--&lt;bean id=\"helloController\" class=\"controller.HelloController\"&gt;&lt;/bean&gt;--&gt;    &lt;!-- 扫描controller下的组件 --&gt;    &lt;context:component-scan base-package=\"controller\"/&gt;    &lt;bean id=\"viewResolver\"          class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"&gt;        &lt;property name=\"prefix\" value=\"/WEB-INF/page/\" /&gt;        &lt;property name=\"suffix\" value=\".jsp\" /&gt;    &lt;/bean&gt;&lt;/beans&gt;\n 剪切index.jsp文件\n 控制器接收请求数据\n test.jsp\n12345678910111213141516&lt;!DOCTYPE html&gt;&lt;%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\"         pageEncoding=\"UTF-8\" import=\"java.util.*\" isELIgnored=\"false\"%&gt;&lt;html&gt;&lt;head&gt;    &lt;meta charset=\"utf-8\"&gt;    &lt;title&gt;Spring MVC 传参方式&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form action=\"/param\" role=\"form\"&gt;    用户名：&lt;input type=\"text\" name=\"userName\"&gt;&lt;br/&gt;    密码：&lt;input type=\"text\" name=\"password\"&gt;&lt;br/&gt;    &lt;input type=\"submit\" value=\"提  交\"&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt;\n1234@RequestMapping(\"/test\")    public ModelAndView handlePost(javax.servlet.http.HttpServletRequest httpServletRequest, javax.servlet.http.HttpServletResponse httpServletResponse) throws Exception &#123;        return new ModelAndView(\"test\");    &#125;\n 使用Servlet原生API\n12345678910@RequestMapping(\"/param\")public ModelAndView getParam(HttpServletRequest request,                         HttpServletResponse response) &#123;    String userName = request.getParameter(\"userName\");    String password = request.getParameter(\"password\");    System.out.println(userName);    System.out.println(password);    return null;&#125;\n 使用@RequestParam(“前台参数名”)注入\n\n同名匹配原则\n\n123456@RequestMapping(\"/param\")public ModelAndView getParam(@RequestParam(\"userName\") String name, @RequestParam(\"password\") String pwd) &#123;    System.out.println(name);    System.out.println(pwd);    return null;&#125;\n\n\n该注解有三个变量：value、required、defaultvalue\n\n\nvalue ：指定 name 属性的名称是什么，value 属性都可以默认不写\nrequired ：是否必须要有该参数，可以设置为【true】或者【false】\ndefaultvalue ：设置默认值\n\n\n 使用模型传参\n\n要求： 前台参数名字必须和模型中的字段名一样\n\n User模型\n123456789package pojo;public class User &#123;        String userName;    String password;    /* getter and setter */&#125;\n123456@RequestMapping(\"/param\")public ModelAndView getParam(User user) &#123;    System.out.println(user.getUserName());    System.out.println(user.getPassword());    return null;&#125;\n 中文乱码解决\n\n注意： 跟 Servlet 中的一样，该方法只对 POST 方法有效（因为是直接处理的 request）\n\n我们可以通过配置 Spring MVC 字符编码过滤器来完成，在 web.xml 中添加\n12345678910111213&lt;filter&gt;    &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt;    &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt;    &lt;init-param&gt;        &lt;param-name&gt;encoding&lt;/param-name&gt;        &lt;!-- 设置编码格式 --&gt;        &lt;param-value&gt;utf-8&lt;/param-value&gt;    &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt;    &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt;    &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt;\n 控制器回显数据\n\n在page下创建test2.jsp\n\n1234567891011&lt;!DOCTYPE html&gt;&lt;%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\"         pageEncoding=\"UTF-8\" import=\"java.util.*\" isELIgnored=\"false\" %&gt;&lt;html&gt;&lt;head&gt;    &lt;title&gt;Spring MVC 数据回显&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;回显数据：$&#123;message&#125;&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;\n 使用Servlet原生API\n123456@RequestMapping(\"/value\")public ModelAndView showData(HttpServletRequest request,                                  HttpServletResponse response) &#123;    request.setAttribute(\"message\",\"成功！\");    return new ModelAndView(\"test2\");&#125;\n 使用ModelAndView\n1234567@RequestMapping(\"/value\")public ModelAndView showData(HttpServletRequest request,                                  HttpServletResponse response) &#123;    ModelAndView mav = new ModelAndView(\"test2\");  mav.addObject(\"message\",\"成功！\")    return mav;&#125;\n 使用model对象\n123456789@ModelAttributepublic void model(Model model) &#123;    model.addAttribute(\"message\", \"注解成功\");&#125;@RequestMapping(\"/value\")public String showData() &#123;    return \"test2\";&#125;\n 客户端跳转\n\n前面不管是地址 /hello 跳转到 index.jsp 还是 /test 跳转到 test.jsp，这些都是服务端的跳转，也就是 request.getRequestDispatcher(&quot;地址&quot;).forward(request, response);\n那我们如何进行客户端跳转呢？我们继续在 HelloController 中编写\n\n1234567891011121314151617@RequestMapping(\"/hello\")public ModelAndView handleRequest(javax.servlet.http.HttpServletRequest httpServletRequest, javax.servlet.http.HttpServletResponse httpServletResponse) throws Exception &#123;    ModelAndView mav = new ModelAndView(\"index\");    mav.addObject(\"message\", \"Hello Spring MVC\");    return mav;&#125;@RequestMapping(\"/jump\")public ModelAndView jump() &#123;    ModelAndView mav = new ModelAndView(\"redirect:/hello\");    return mav;&#125;//或者@RequestMapping(\"/jump\")public String jump() &#123;    return \"redirect: ./hello\";&#125;\n\n我们使用 redirect:/hello 就表示我们要跳转到 /hello 这个路径，我们重启服务器，在地址栏中输入：localhost/jump ，会自动跳转到 /hello 路径下\n\n 文件上传\n\n需要先导入 commons-io-1.3.2.jar 和 commons-fileupload-1.2.1.jar 两个包\n\n 1. 配置上传解析器\n\n在 dispatcher-servlet.xml 中新增一句\n\n开启对上传功能的支持\n\n\n\n1&lt;bean id=\"multipartResolver\" class=\"org.springframework.web.multipart.commons.CommonsMultipartResolver\"/&gt;\n 2. 编写upload.jsp\n123456789101112&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt;&lt;head&gt;    &lt;title&gt;测试文件上传&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form action=\"/upload\" method=\"post\" enctype=\"multipart/form-data\"&gt;    &lt;input type=\"file\" name=\"picture\"&gt;    &lt;input type=\"submit\" value=\"上 传\"&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt;\n 3. 编写控制器\n\n在 Package【controller】下新建【UploadController】类\n\n123456789101112131415161718192021package controller;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.multipart.MultipartFile;import org.springframework.web.servlet.ModelAndView;@Controllerpublic class UploadController &#123;    @RequestMapping(\"/upload\")    public void upload(@RequestParam(\"picture\") MultipartFile picture) throws Exception &#123;        System.out.println(picture.getOriginalFilename());    &#125;    @RequestMapping(\"/test2\")    public ModelAndView upload() &#123;        return new ModelAndView(\"upload\");    &#125;&#125;\n 4. 测试\n web.xml\n 加载流程\n\n 配置\n\n DispatcherServlet\n\n 特殊bean\n\n applicationContext.xml配置文件标签\n\n 异常处理\n\n 数据处理\n\n\n\n数据类型\n处理所需注解\n\n\n\n\napplication/x-www-form-urlencoded\nHtml表单默认传输编码类型，@RequestParam、@ModelAttribute可以处理，@RequestBody也能处理\n\n\nmultipart/form-data\n是表单上传的非文本的内容，传递的是文件数据，设置该属性再配合post请求方式从而实现文件上传。需要使用解析器，不能直接处理（即使用@RequestBody不能处理这种格式的数据）\n\n\n其他格式\n其他格式包括application/json, application/xml等。这些格式的数据，必须使用@RequestBody来处理\n\n\n\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131@RestController@RequestMapping(\"/test\")public class TestController &#123;    /**     * 普通请求     *     * http://localhost:8089/test/test1     */    @RequestMapping(value = \"/test1\")    public String test1() &#123;        return \"test1\";    &#125;    /**     * 简单get请求     * 组合注解 @GetMapping     * 是@RequestMapping(method = RequestMethod.GET)的缩写     *     * http://localhost:8089/test/test2/sun     */    @GetMapping(value = \"test2/&#123;name&#125;\")    public String test2(@PathVariable String name) &#123;        // \\n不起作用了,那就直接用html中的标签吧        return \"oh you are \" + name + \"&lt;br&gt; nice to meet you\";    &#125;    /**     * 简单get请求2     * 注解 @PathVariable 映射URL绑定的占位符     * 1）带占位符的URL是Spring3.0新增的功能，该功能在SpringMVC向REST目标挺进发展过程中具有里程碑的意义。     * 2）通过@PathVariable可以将URL中占位符参数绑定到控制器处理方法的入参中：     *    URL中的&#123;xxx&#125;占位符可以通过@PathVariable(\"xxx\")绑定到操作方法的入参中     *     * http://localhost:8089/test/test3/admin&amp;admin     */    @GetMapping(value = \"/test3/&#123;name&#125;&amp;&#123;pwd&#125;\")    public String test3(@PathVariable String name, @PathVariable String pwd) &#123;        if (name.equals(\"admin\") &amp;&amp; pwd.equals(\"admin\")) &#123;            return \"hello welcome admin\";        &#125; else &#123;            return \"oh sorry user name or password is wrong\";        &#125;    &#125;    /**     * get请求     * 注解 @RequestParam绑定请求参数值     * 在处理方法入参使用@RequestParam可以把请求参数传递给请求方法，@RequestParam包含的属性值：     * --- value ：参数名称     * --- required ：是否必须，默认为true，表示请求参数中必须包含对应的参数，否则抛出异常。     * --- defaultValue：当请求参数缺少或者有请求参数但值为空时，值采用该设置值     *     * http://localhost:8089/test/test4?name=111&amp;pwd=111     */    @RequestMapping(value = \"/test4\", method = RequestMethod.GET)    public String test4(@RequestParam(value = \"name\", required = true) String name,                             @RequestParam(value = \"pwd\", required = true) String pwd) &#123;        if (name.equals(\"admin\") &amp;&amp; pwd.equals(\"admin\")) &#123;            return JSON.toJSONString(Result.success());        &#125; else &#123;            return JSON.toJSONString(Result.error());        &#125;    &#125;    /**     * 简单post请求     * 组合注解 @PostMapping     * 是@RequestMapping(method = RequestMethod.POST)的缩写。     *     * http://localhost:8089/test/test5     */    @RequestMapping(value = \"/test5\", method = RequestMethod.POST)    public String test5() &#123;        System.out.println(\"hello test5\");        return \"test5\";    &#125;    /**     * post请求     *     * http://localhost:8089/test/test6?name=111&amp;pwd=111     */    @RequestMapping(value = \"/test6\", method = RequestMethod.POST)    public String test6(@RequestParam(value = \"name\", required = true) String name,                              @RequestParam(value = \"pwd\", required = true) String pwd) &#123;        if (name.equals(\"admin\") &amp;&amp; pwd.equals(\"admin\")) &#123;            return JSON.toJSONString(Result.success());        &#125; else &#123;            return JSON.toJSONString(Result.error());        &#125;    &#125;    /**     * 参数为一个bean对象.spring会自动为我们关联映射     *     * get post     * http://localhost:8089/test/test7?id=1     *     * post form-data和 x-www-form-urlencoded     * http://localhost:8089/test/test7     * id  1     */    @RequestMapping(value = \"/test7\", method = &#123; RequestMethod.POST, RequestMethod.GET &#125;)    public String test7(BaseEntity entity) &#123;        if (null != entity &amp;&amp; entity.getId() == 1) &#123;            return JSON.toJSONString(Result.success());        &#125; else &#123;            return JSON.toJSONString(Result.error());        &#125;    &#125;    /**     * 请求内容是一个json串,spring会自动把他和我们的参数bean对应起来     * 不过要加@RequestBody注解     *     * post row(application/json)     * http://localhost:8089/test/test8     * id   1     */    @RequestMapping(value = \"/test8\", method = &#123; RequestMethod.POST, RequestMethod.GET &#125;)    public String test8(@RequestBody BaseEntity entity) &#123;        if (null != entity &amp;&amp; entity.getId() == 1) &#123;            return JSON.toJSONString(Result.success());        &#125; else &#123;            return JSON.toJSONString(Result.error());        &#125;    &#125;&#125;\n 处理multipart/form-data\n\nmultipart格式的数据会将一个表单拆分为多个部分（part），每个部分对应一个输入域。在一般的表单输入域中，它所对应的部分中会放置文本型数据，但是如果上传文件的话，它所对应的部分可以是二进制\n\n\n\n配置一个multipart解析器，通过它来告诉DispatcherServlet该如何读取multipart请求\n\n StandardServletMultipartResolver\n\napplicationContext.xml中添加\n\n1&lt;bean id=\"multipartResolver\" class=\"org.springframework.web.multipart.commons.StandardServletMultipartResolver\"/&gt;\n\n配置类\n\n1234@Bean(name = \"multipartResolver\")public StandardServletMultipartResolver getStandardServletMultipartResolver()&#123;  \treturn new StandardServletMultipartResolver();&#125;\n\nweb.xml配置上传参数\n\n1234567891011121314151617181920212223&lt;servlet&gt;    &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt;    &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;    &lt;init-param&gt;        &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;        &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt;    &lt;/init-param&gt;    &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;    &lt;multipart-config&gt;        &lt;!--上传到/tmp/upload 目录--&gt;      &lt;location&gt;/tmp/upload&lt;/location&gt;        &lt;!--文件大小为2M--&gt;      &lt;max-file-size&gt;2097152&lt;/max-file-size&gt;        &lt;!--整个请求不超过4M--&gt;      &lt;max-request-size&gt;4194304&lt;/max-request-size&gt;        &lt;!--所有文件都要写入磁盘--&gt;      &lt;file-size-threshold&gt;0&lt;/file-size-threshold&gt;    &lt;/multipart-config&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt;  &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt;  &lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;\n\n配置类中配置上传参数\n\n12345@Overrideprotected void customizeRegistration(ServletRegistration.Dynamic registration) &#123;  \t//上传到/tmp/upload 目录，文件大小为2M，整个请求不超过4M，而且所有文件都要写入磁盘  \tregistration.setMultipartConfig(new MultipartConfigElement(\"E:\\\\upload_ftp\",2097152,4194304,0));&#125;\n CommonsMultipartResolver\n\n在applicationContext.xml中设置\n\n123456&lt;bean id=\"multipartResolver\" class=\"org.springframework.web.multipart.commons.CommonsMultipartResolver\"&gt;       &lt;!--设置上传目录/tmp/upload;最大的文件容量设置为2M;最大的内存大小设置为0，表示所有文件都会写入磁盘中;无法设定multipart请求整体的最大容量--&gt;        &lt;property name=\"uploadTempDir\" value=\"/tmp/upload\"/&gt;        &lt;property name=\"maxUploadSize\" value=\"2097152\"/&gt;        &lt;property name=\"maxInMemorySize\" value=\"0\"/&gt;    &lt;/bean&gt;\n\nCommonsMultipartResolver 相比较 StandardServletMultipartResolver 来说 就是无法设定multipart请求整体的最大容量。\nCommonsMultipartResolver不会强制要求设置临时文件路径。默认情况下，这个路径就是Servlet容器的临时目录。 StandardServletMultipartResolver 必须设置临时文件路径才能正常执行。（以上所述上传目录均为临时文件路径）\n\n1234&lt;form action=\"/picture\" method=\"post\" enctype=\"multipart/form-data\"&gt;  &lt;input type=\"file\" name=\"picture\"&gt;  &lt;input type=\"submit\"&gt;&lt;/form&gt;\n12345678@RequestMapping(value = \"/picture\",method = RequestMethod.POST)public String getHome(@RequestPart(\"picture\") MultipartFile picture) throws IOException &#123;\t\tString name = picture.getName();\t\tbyte[] bytes = picture.getBytes();  \tpicture.transferTo(new File(\"/\"+picture.getOriginalFilename()));   \t//这里保存到文件系统的时候要用相对路径，比如这里配置的是 /。以配置的上传目录为基准。即文件路径E:/upload_ftp/ 是保存的目录  \treturn \"home\";&#125;\n\n@RequestPart(“picture”) ：当注册表单提交的时候，picture属性将会给定一个byte数组，这个数组中包含了请求中对应part的数据（通过@RequestPart指定）。如果用户提交表单的时候没有选择文件，那么这个数组会是空（而不是null）\n\n甚至可以用byte[]数组接收Multipart请求而不用 MultipartFile\n\n\n用MultipartFile接收为我们提供了很多的方法以便进行接下来的工作\n\n 下载文件\n123456789101112131415161718192021222324@RequestMapping(\"download/&#123;fileName:.+&#125;\")    public void downloadZipResource(HttpServletRequest request,                                      HttpServletResponse response,                                      @PathVariable(\"fileName\") String fileName)     &#123;        ServletContext context = request.getSession().getServletContext();        String dataDirectory  = context.getRealPath(\"/downloads\") + \"/\" + fileName;        File file = new File(dataDirectory);        if (file.isFile())         &#123;            String mimeType = context.getMimeType(dataDirectory);   //直接根据文件的路径名来获取它的MineType，这样就可以灵活的根据请求的文件类型来返回输出流了            response.setContentType(mimeType);            response.addHeader(\"Content-Disposition\", \"attachment; filename=\"+fileName);            try             &#123;                OutputStream os = response.getOutputStream();;                IOUtils.copy(new FileInputStream(file), os);                os.flush();            &#125;             catch (IOException ex) &#123;                ex.printStackTrace();            &#125;        &#125;    &#125;\n","plink":"ilucia.github.io/spring&mybatis/Spring MVC/"},{"title":"spring&mybatis/Spring基础","date":"2022-04-27T15:24:01.747Z","updated":"2022-04-27T15:24:01.747Z","content":" Spring基础\n Core模块\n 注解方式配置\n⾃从jdk5有了注解这个新特性，我们可以看到Struts2框架、Hibernate框架都⽀持使⽤注解来配置信\n息…\n通过注解来配置信息就是为了简化IOC容器的配置，注解可以把对象添加到IOC容器中、处理对象依赖\n关系，我们来看看怎么⽤吧：\n使⽤注解步骤：\n1）先引⼊context名称空间\nxmlns:context=&quot;http://www.springframework.org/schema/context\n2）开启注解扫描器\n&lt;context:component-scan base-package=&quot;&quot;&gt;&lt;/context:component-scan&gt;\n第⼆种⽅法:也可以通过⾃定义扫描类以@CompoentScan修饰来扫描IOC容器的bean对象。\n如下代码:\n12345678//表明该类是配置类@Configuration//启动扫描器，扫描bb包下的//也可以指定多个基础包//也可以指定类型@ComponentScan(\"bb\")public class AnnotationScan &#123;&#125;\n\n在使⽤@ComponentScan()这个注解的时候，在测试类上需要@ContextConfiguration这个注解来加载配置类\n@ContextConfiguration这个注解⼜在Spring的test包下\n创建对象以及处理对象依赖关系，相关的注解：\n\n@ComponentScan扫描器\n@Configuration表明该类是配置类\n@Component 指定把⼀个对象加⼊IOC容器—&gt;@Name也可以实现相同的效果【⼀般少⽤】\n@Repository 作⽤同@Component； 在持久层使⽤\n@Service 作⽤同@Component； 在业务逻辑层使⽤\n@Controller 作⽤同@Component； 在控制层使⽤\n@Resource 依赖关系\n\n如果@Resource不指定值，那么就根据类型来找，相同的类型在IOC容器中不能有两个\n如果@Resource指定了值，那么就根据名字来找\n\n\n\n\n\n UserDao\n123456789101112package aa;import org.springframework.stereotype.Repository;/*** Created by ozc on 2017/5/10.*///把对象添加到容器中,⾸字⺟会⼩写@Repositorypublic class UserDao &#123;public void save() &#123;System.out.println(&quot;DB:保存⽤户&quot;);&#125;&#125;\n userService\n123456789101112131415import org.springframework.stereotype.Service;import javax.annotation.Resource;//把UserService对象添加到IOC容器中,⾸字⺟会⼩写@Servicepublic class UserService &#123;//如果@Resource不指定值，那么就根据类型来找---&gt;UserDao....当然了，IOC容器不能有两个UserDao类型的对象//@Resource//如果指定了值，那么Spring就在IOC容器找有没有id为userDao的对象。@Resource(name = &quot;userDao&quot;)private UserDao userDao;public void save() &#123;userDao.save();&#125;&#125;\n userAction\n1234567891011*///把对象添加到IOC容器中,⾸字⺟会⼩写@Controllerpublic class UserAction &#123;@Resource(name = &quot;userService&quot;)private UserService userService;public String execute() &#123;userService.save();return null;&#125;&#125;\n 测试\n123456789public class App &#123;public static void main(String[] args) &#123;// 创建容器对象ApplicationContext ac = newClassPathXmlApplicationContext(&quot;aa/applicationContext.xml&quot;);UserAction userAction = (UserAction) ac.getBean(&quot;userAction&quot;);userAction.execute();&#125;&#125;\n Bean创建细节\n\n参数指定\n\n 单例/多例\n\nscope=&quot;singleton&quot; 默认值， 即 默认是单例 【service/dao/⼯具类】\n\n\nscope=&quot;prototype&quot; 多例\n\nAction对象\n\n\n\n 创建时间点\n\nscope=&quot;prototype&quot; 在⽤到对象的时候，才创建对象\n\n\nscope=&quot;singleton&quot; 在启动(容器初始化之前)， 就已经创建了bean，且整个应⽤只有⼀\n个\n\n 是否延迟创建\n\nlazy-init=&quot;false&quot; 默认为false, 不延迟创建，即在启动时候就创建对象\nlazy-init=&quot;true&quot; 延迟初始化, 在⽤到对象的时候才创建对象\n\n只对单例有效\n\n\n\n 创建对象之后的初始化/销毁\n\ninit-method=&quot;init_user&quot; 对应对象的init_user⽅法，在对象创建之后执⾏\n\n\ndestroy-method=&quot;destroy_user&quot; 在调⽤容器对象的destroy⽅法时候执⾏，(容器⽤\n实现类)\n\n 依赖注入\nSpring提供了好⼏种的⽅式来给属性赋值\n\n通过构造函数\n通过set⽅法给属性注⼊值\np名称空间\n⾃动装配(了解)\n注解\n\n 使用注解实现自动装配\n\n@Autowired注解来实现⾃动装配\n\n可以在构造器上修饰，也可以在setter⽅法上修饰\n来⾃java的@Inject的和@AutoWired有相同的功能\n如果没有匹配到bean，为了避免异常的出现，我们可以使⽤required属性上设置为false\n\n\n\nUserService中使⽤userDao变量来维护与Dao层之间的依赖关系，UserAction中使⽤userService变量\n来维护与Service层之间的依赖关系。\n123456789101112131415161718public class UserDao &#123;public void save() &#123;System.out.println(\"DB:保存⽤户\");&#125;&#125;public class UserService &#123;private UserDao userDao;public void save() &#123;userDao.save();&#125;&#125;public class UserAction &#123;private UserService userService;public String execute() &#123;userService.save();return null;&#125;&#125;\n applicationContext.xml配置⽂件\n12345678&lt;!--创建userDao对象--&gt;&lt;bean id=\"userDao\" class=\"UserDao\"/&gt;&lt;!--创建userService对象--&gt;&lt;bean id=\"userService\" class=\"UserService\"&gt;&lt;!--要想在userService层中能够引⽤到userDao，就必须先创建userDao对象--&gt;&lt;constructor-arg index=\"0\" name=\"userDao\" type=\"UserDao\" ref=\"userDao\"&gt;&lt;/constructor-arg&gt;&lt;/bean&gt;\n AOP\n 注解⽅式实现AOP编程\n我们之前⼿动的实现AOP编程是需要⾃⼰来编写代理⼯⼚的，现在有了Spring，就不需要我们⾃⼰写代\n理⼯⼚了。Spring内部会帮我们创建代理⼯⼚。也就是说，不⽤我们⾃⼰写代理对象了\n因此，我们只要关⼼切⾯类、切⼊点、编写切⼊表达式指定拦截什么⽅法就可以了\n 在配置⽂件中开启AOP注解⽅式\n1234567891011121314151617&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\"       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"       xmlns:p=\"http://www.springframework.org/schema/p\"       xmlns:context=\"http://www.springframework.org/schema/context\"       xmlns:aop=\"http://www.springframework.org/schema/aop\"       xsi:schemaLocation=\"http://www.springframework.org/schema/beans                           http://www.springframework.org/schema/beans/spring-beans.xsd                           http://www.springframework.org/schema/context                           http://www.springframework.org/schema/context/spring-context.xsd                           http://www.springframework.org/schema/aop                           http://www.springframework.org/schema/aop/spring-aop.xsd\"&gt;  &lt;context:component-scan base-package=\"aa\"/&gt;    &lt;!-- 开启aop注解⽅式 --&gt;  &lt;aop:aspectj-autoproxy&gt;&lt;/aop:aspectj-autoproxy&gt;&lt;/beans&gt;\n 类代码\n 切⾯类\n12345678910111213@Component@Aspect//指定为切⾯类public class AOP &#123;    //⾥⾯的值为切⼊点表达式    @Before(\"execution(* aa.*.*(..))\")    public void begin() &#123;        System.out.println(\"开始事务\");    &#125;    @After(\"execution(* aa.*.*(..))\")    public void close() &#123;        System.out.println(\"关闭事务\");    &#125;&#125;\n UserDao\n1234567@Componentpublic class UserDao implements IUser &#123;    @Override    public void save() &#123;        System.out.println(\"DB:保存⽤户\");    &#125;&#125;\n IUser接口\n123public interface IUser &#123;    void save();&#125;\n 测试\n123456789public class App &#123;    public static void main(String[] args) &#123;        ApplicationContext ac = new ClassPathXmlApplicationContext(\"aa/applicationContext.xml\");        //这⾥得到的是代理对象....        IUser iUser = (IUser) ac.getBean(\"userDao\");        System.out.println(iUser.getClass());        iUser.save();    &#125;&#125;\n AOP注解API\n\n@Aspect\n\n指定⼀个类为切⾯类\n\n\n@Pointcut(&quot;execution( cn.itcast.e_aop_anno…(…))&quot;)*\n\n指定切⼊点表达式\n\n\n@Before(“pointCut_()”)\n\n前置通知，⽬标⽅法之前执⾏\n\n\n@After(“pointCut_()”)\n\n后置通知，⽬标⽅法之后执⾏（始终执⾏）\n\n\n@AfterReturning(“pointCut_()”)\n\n返回后通知，执⾏⽅法结束前执⾏(异常不执⾏)\n\n\n@AfterThrowing(“pointCut_()”)\n\n异常通知，出现异常时候执⾏\n\n\n@Around(“pointCut_()”)\n\n环绕通知，环绕⽬标⽅法执⾏\n\n\n\n1234567891011121314151617181920212223242526272829303132// 指定切⼊点表达式，拦截哪个类的哪些⽅法@Pointcut(\"execution(* aa.*.*(..))\")//Point签名public void pointCut_() &#123;&#125;// 前置通知 : 在执⾏⽬标⽅法之前执⾏@Before(\"pointCut_()\")public void begin()&#123;  System.out.println(\"开始事务/异常\");&#125;// 后置/最终通知：在执⾏⽬标⽅法之后执⾏，⽆论是否出现异常最终都会执⾏@After(\"pointCut_()\")public void after()&#123;  System.out.println(\"提交事务/关闭\");&#125;// 返回后通知： 在调⽤⽬标⽅法结束后执⾏ 【出现异常不执⾏】@AfterReturning(\"pointCut_()\")public void afterReturning() &#123;  System.out.println(\"afterReturning()\");&#125;// 异常通知： 当⽬标⽅法执⾏异常时候执⾏此关注点代码@AfterThrowing(\"pointCut_()\")public void afterThrowing()&#123;  System.out.println(\"afterThrowing()\");&#125;// 环绕通知：环绕⽬标⽅式执⾏@Around(\"pointCut_()\")public void around(ProceedingJoinPoint pjp) throws Throwable&#123;  System.out.println(\"环绕前....\");  pjp.proceed(); // 执⾏⽬标⽅法  System.out.println(\"环绕后....\");&#125;\n @Pointcut\n在Spring 2.0中，Pointcut的定义包括两个部分：Pointcut表示式(expression)和Pointcut签名(signature)\n1234//Pointcut表示式@Pointcut(\"execution(* com.savage.aop.MessageSender.*(..))\")//Point签名private void log()&#123;&#125;\n然后要使用所定义的Pointcut时，可以指定Pointcut签名\n1@Before(\"og()\")\n这种使用方式等同于以下方式，直接定义execution表达式使用\n1@Before(\"execution(* com.savage.aop.MessageSender.*(..))\")\nPointcut定义时，还可以使用&amp;&amp;、||、! 这三个运算\n12345678@Pointcut(\"execution(* com.savage.aop.MessageSender.*(..))\")private void logSender()&#123;&#125;@Pointcut(\"execution(* com.savage.aop.MessageReceiver.*(..))\")private void logReceiver()&#123;&#125;@Pointcut(\"logSender() || logReceiver()\")private void logMessage()&#123;&#125;\n这个例子中，logMessage()将匹配任何MessageSender和MessageReceiver中的任何方法\n还可以将公用的Pointcut放到一个类中，以供整个应用程序使用，如下：\n1234567891011121314package com.savage.aop;import org.aspectj.lang.annotation.*;public class Pointcuts &#123;@Pointcut(\"execution(* *Message(..))\")public void logMessage()&#123;&#125;@Pointcut(\"execution(* *Attachment(..))\")public void logAttachment()&#123;&#125;@Pointcut(\"execution(* *Service.*(..))\")public void auth()&#123;&#125;&#125;\n在使用上面定义Pointcut时，指定完整的类名加上Pointcut签名就可以了，如：\n123456789101112package com.savage.aop;import org.aspectj.lang.JoinPoint;import org.aspectj.lang.annotation.*;@Aspectpublic class LogBeforeAdvice &#123;@Before(\"com.sagage.aop.Pointcuts.logMessage()\")public void before(JoinPoint joinPoint) &#123;System.out.println(\"Logging before \" + joinPoint.getSignature().getName());&#125;&#125;\n 切入点表达式\n1execution(modifiers-pattern? ret-type-pattern declaring-type-pattern? name-pattern(param-pattern) throws-pattern?)\n\n\n? 号代表0或1，可以不写\n\n\n*** **号代表任意类型，0或多\n\n\n⽅法参数为 … 表示为可变参数\n\n\nmodifiers-pattern?【修饰的类型，可以不写】\n\n\nret-type-pattern【⽅法返回值类型，必写】\n\n\ndeclaring-type-pattern?【⽅法声明的类型，可以不写】\n\n\nname-pattern(param-pattern)【要匹配的名称，括号⾥⾯是⽅法的参数】\n\n\nthrows-pattern?【⽅法抛出的异常类型，可以不写】\n\n\n 例\n\n","plink":"ilucia.github.io/spring&mybatis/Spring基础/"},{"title":"java1.8/集合_容器","date":"2022-04-27T15:24:01.727Z","updated":"2022-04-27T15:24:01.727Z","content":" 容器\n 作用\n\n可以动态增加长度\n存储的元素都是对象(引用地址)，所以集合可以存储不同的数据类型，但如果是需要比较元素来排序的集合，则需要类型一致\n提供了统一的增删改查方法，使用方便\n支持泛型，避免数据不一致和转换异常，还对常用的数据结构进行了封装\n\n 总框架\n\n由Collection、Map(映射关系)和Iterator(迭代器)组成\n\n Collection体系\n\nSet(集)： 元素是无序的且不可重复\nList(列表)：元素是有序的且可重复\nQueue(队列)：封装了数据结构中的队列\n\n Map体系\n\nMap用于保存具有映射关系的数据，即key-value(键值对)。Map集合的key是唯一的，不可重复，而value可以重复。所以一个value可以对应多个key\nMap体系除了常用类之外，还有Properties（属性类）也属于Map体系\n\n Iterator(迭代器)\n 迭代器模式\n\n把访问逻辑从不同类型的集合类中抽取出来，从而避免向外部暴露集合的内部结构\n在java中是一个对象，其目的是遍历并选中其中的每个元素，而使用者（客户端）无需知道里面的具体细节\n要足够“轻量”，即创建代价小\n\n Iterator\n\nCollection集合元素的通用获取方式：在取出元素之前先判断集合中有没有元素。如果有，就把这个元素取出来，继续再判断，如果还有就再取出来，一直把集合中的所有元素全部取出来，这种取出元素的方式专业术语称为迭代\njava.util.Iterator:在Java中Iterator为一个接口，它只提供了迭代的基本规则\nCollection中有一个抽象方法iterator方法，所有的Collection子类都实现了这个方法，该方法返回一个Iterator对象\n\n123456package java.util;public interface Iterator&lt;E&gt; &#123;    boolean hasNext();//判断是否存在下一个对象元素    E next();//获取下一个元素    void remove();//移除元素&#125;\n 异常\n\n在迭代集合中元素的过程中，集合的长度发生改变（进行了add或者remove操作)，会出现修改并发异常ConcurrentModificationException\n\n增强for的底层原理也是迭代器，所以也需要避免这种操作\n\n获取迭代器由jvm完成，不需要我们获取迭代器\n\n\n\n\n在进行集合元素取出的时候，如果集合中没有元素了，还继续使用next()方法的话，将发生NoSuchElementException\n解决上述异常的方法：使用ListIterator\n\n Iterable接口\n\nIterable接口实现后的功能是‘返回’一个迭代器\n该接口的iterator()方法返回一个标准的Iterator实现，实现Iterable接口允许对象成为Foreach语句的目标，就可以通过foreach语句来遍历你的底层序列\n\n for each语法使用\n12List&lt;String&gt; strs = Arrays.asList(\"a\", \"b\", \"c\"); for (String str: strs) &#123; out.println(str); &#125;\n\n代码减少，方便遍历\n没有索引，不能操作容器里的元素\n\n forEach()\n\nforEach方法接收lambda表达式\n\n12List&lt;String&gt; strs = Arrays.asList(\"a\", \"b\", \"c\"); //使用Java 1.8的lambda表达式 strs.forEach(out::println);\n Spliterator迭代器\n\n1.8新增的迭代器\n属于并行迭代器，可以将迭代任务分割交由多个线程来进行\n\n使用Spliterator的时候，将元素分割成多份，分别交于不于的线程去遍历，以提高效率\n\n\n使用 Spliterator 每次可以处理某个元素集合中的一个元素\n\n不是从 Spliterator 中获取元素，而是使用 tryAdvance() 或 forEachRemaining() 方法对元素应用操作\n\n\nSpliterator 还可以用于估计其中保存的元素数量，而且还可以像细胞分裂一样变为一分为二\n\n ListIterator\n\n是一个更强大的Iterator子类型，能用于各种List类访问\n可以双向移动，所以能指出迭代器当前位置的前一个和后一个索引\n可以用set方法替换它访问过的最后一个元素\n调用listIterator方法产生一个指向List开始处的ListIterator\n可以用过重载方法listIterator(n)来创建一个指定列表索引为n的元素的ListIterator\n\n 和Iterator区别\n\n两者都有next()和hasNext()，可以实现向后遍历，但是ListIterator有previous()和hasPrevious()方法，即可以实现向前遍历\nListIterator可以定位当前位置，nextIndex()和previous()可以实现\nListIterator有add()方法，可以向list集合中添加数据\n都可以实现删除操作，但是ListIterator可以通过set方法实现对对象的修改，Iterator仅能遍历，不能修改\n\n Fail-Fast\n\n类中的iterator()方法和listIterator()方法返回的iterators迭代器是fail-fast的\n当某一个线程A通过iterator去遍历某集合的过程中，若该集合的内容被其他线程所改变了；那么线程A访问集合时，就会抛出ConcurrentModificationException异常，产生fail-fast事件\n\n 接口/工具类\n Arrays\n\n数组的工具类,里面都是操作数组的工具\n\n 常用方法\n1、数组的排序:Arrays.sort(a);//实现了对数组从小到大的排序//注：此类中只有升序排序，而无降序排序。\n2、数组元素的定位查找:Arrays.binarySearch(a,8);//二分查找法\n3、数组的打印:Arrays.toString(a);//String 前的a和括号中的a均表示数组名称\n4、 查看数组中是否有特定的值:Arrays.asList(a).contains(1)\n Collections\n 排序操作\n\nCollections提供以下方法对List进行排序操作\n\n123456void reverse(List list)//反转void shuffle(List list)//随机排序void sort(List list)//按自然排序的升序排序void sort(List list, Comparator c)//定制排序，由Comparator控制排序逻辑void swap(List list, int i , int j)//交换两个索引位置的元素void rotate(List list, int distance)//旋转。当distance为正数时，将list后distance个元素整体移到前面。当distance为负数时，将 list的前distance个元素整体移到后面\n 查找/替换操作\n1234567int binarySearch(List list, Object key),//对List进行二分查找，返回索引，注意List必须是有序的int max(Collection coll)//根据元素的自然顺序，返回最大的元素。 类比int min(Collection coll)int max(Collection coll, Comparator c)//根据定制排序，返回最大元素，排序规则由Comparatator类控制。类比int min(Collection coll, Comparator c)void fill(List list, Object obj)//用元素obj填充list中所有元素int frequency(Collection c, Object o)//统计元素出现次数int indexOfSubList(List list, List target)//统计targe在list中第一次出现的索引，找不到则返回-1，类比int lastIndexOfSubList(List source, list target).boolean replaceAll(List list, Object oldVal, Object newVal)//用新元素替换旧元素\n 同步控制\n\nCollections中几乎对每个集合都定义了同步控制方法, 这些方法，来将集合包装成线程安全的集合\n\n123SynchronizedList(List);SynchronizedSet(Set;SynchronizedMap(Map);\n Collection\n\n最基本的集合接口，一个Collection代表一组Object，即Collection的元素\nJava SDK不提供直接继承自Collection的类， Java SDK提供的类都是继承自Collection的“子接口”如List和Set\n所有实现Collection接口的类都必须提供两个标准的构造函数：无参数的构造函数用于创建一个空的Collection，有一个Collection参数的构造函数用于创建一个新的 Collection，这个新的Collection与传入的Collection有相同的元素。后一个构造函数允许用户复制一个Collection\n\n 遍历\n\n不论Collection的实际类型如何，它都支持一个iterator()的方法，该方法返回一个迭代子，使用该迭代子即可逐一访问Collection中每一个元素\n\n1234Iterator it = collection.iterator(); // 获得一个迭代子\twhile(it.hasNext()) &#123;    Object obj = it.next(); // 得到下一个元素  &#125;\n 框架\n\n\nSet(集)：元素是无序的且不可重复\nList(列表)：元素是有序的且可重复\nQueue(队列)：封装了数据结构中的队列\n\n Set\n\nSet利用Map实现，无序(存入和取出顺序有可能不一致)，允许重复元素（Map中的Key值唯一，可为null，最多有一个null元素）\n\n元素无放入顺序，但是元素在set中的位置是有该元素的HashCode决定的，其位置其实是固定的\n加入Set的元素必须定义equals()方法以确保对象的唯一性\n\n\n具有与Collection完全一样的接口，因此没有任何额外的功能,只是行为不同\n\n HashSet\n\n基于哈希表实现，支持快速查找，但不支持有序性操作。并且失去了元素的插入顺序信息，也就是说使用 Iterator 遍历 HashSet 得到的结果是不确定的\n放入的对象必须重写equals和hashCode方法\n\n当元素的 hashCode 值相同时，才继续判断元素的 equals 是否为 true\n如果 hashCode 值不同，那么不判断 equals，从而提高对象比较的速度\n\n\n不是同步的\n存储取出都比较快\n\n TreeSet\n\n基于红黑树/TreeMap实现，支持有序性操作，例如根据一个范围查找元素的操作。但是查找效率不如 HashSet，HashSet 查找的时间复杂度为 O(1)，TreeSet 则为 O(logN)\n不能写入空数据\n排序方式\n\n自然排序：让元素自身具备比较性，需要元素对象实现Comparable接口，覆盖compareTo方法\n\n在默认的compareTo方法中，需要将的两个的类型的对象的转换同一个类型，因此需要将的保证的加入到TreeSet中的数据类型是同一个类型，但是如果自己覆盖compareTo方法时，没有要求两个对象强制转换成同一个对象，是可以成功的添加treeSet中\n\n\n定制排序：让集合自身具备比较性，需要定义一个实现了Comparator接口的比较器，并覆盖compare方法，并将该类对象作为实际参数传递给TreeSet集合的构造函数\n\n\n额外增加的方法\n\n12345first()//返回第一个元素last()//返回最后一个元素lower(Object o)//返回指定元素之前的元素higher(Obect o)//返回指定元素之后的元素subSet(fromElement, toElement)//返回子集合\n LinkedHashSet\n\n\n底层数据结构为LinkedHashMap\n\n\n具有 HashSet 的查找效率，并且内部使用双向链表维护元素的插入顺序\n\nLinkedHashSet在迭代访问Set中的全部元素时，性能比HashSet好，但是插入时性能稍微逊色于HashSet\n\n\n\n没有重写HashSet的方法\n\n\n List\n\n有序(元素存入集合的顺序和取出的顺序一致)\n元素/特有方法都有索引\n元素可以重复\n除了Collection接口必备的iterator()方法外，List还提供一个listIterator()方法\n\n返回一个 ListIterator接口\n和标准的Iterator接口相比，ListIterator多了一些add()之类的方法，允许添加，删除，设定元素，还能向前或向后遍历\n\n\n\n ArrayList\n\n基于动态数组实现，支持随机访问\n\nRandomAccess 接口标识着该类支持快速随机访问\n\n\n数组默认大小为10\n\n 扩容\n\n添加元素时使用 ensureCapacityInternal() 方法来保证容量足够，如果不够时，需要使用 grow() 方法进行扩容\n\n新容量的大小为 oldCapacity + (oldCapacity &gt;&gt; 1)，也就是旧容量的 1.5 倍\n\n\n扩容操作需要调用 Arrays.copyOf() 把原数组整个复制到新数组中，这个操作代价很高，因此最好在创建 ArrayList 对象时就指定大概的容量大小，减少扩容操作的次数\n\n123456789101112131415161718192021222324252627282930public boolean add(E e) &#123;    ensureCapacityInternal(size + 1);  // Increments modCount!!    elementData[size++] = e;    return true;&#125;private void ensureCapacityInternal(int minCapacity) &#123;    if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123;        minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);    &#125;    ensureExplicitCapacity(minCapacity);&#125;private void ensureExplicitCapacity(int minCapacity) &#123;    modCount++;    // overflow-conscious code    if (minCapacity - elementData.length &gt; 0)        grow(minCapacity);&#125;private void grow(int minCapacity) &#123;    // overflow-conscious code    int oldCapacity = elementData.length;    int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);    if (newCapacity - minCapacity &lt; 0)        newCapacity = minCapacity;    if (newCapacity - MAX_ARRAY_SIZE &gt; 0)        newCapacity = hugeCapacity(minCapacity);    // minCapacity is usually close to size, so this is a win:    elementData = Arrays.copyOf(elementData, newCapacity);&#125;\n 删除\n\n需要调用 System.arraycopy() 将 index+1 后面的元素都复制到 index 位置上，该操作的时间复杂度为 O(N)\n\n12345678910public E remove(int index) &#123;    rangeCheck(index);    modCount++;    E oldValue = elementData(index);    int numMoved = size - index - 1;    if (numMoved &gt; 0)        System.arraycopy(elementData, index+1, elementData, index, numMoved);    elementData[--size] = null; // clear to let GC do its work    return oldValue;&#125;\n 序列化\n\nArrayList 基于数组实现，并且具有动态扩容特性，因此保存元素的数组不一定都会被使用，那么就没必要全部进行序列化\n保存元素的数组 elementData 使用 transient 修饰，该关键字声明数组默认不会被序列化\nArrayList 实现了 writeObject() 和 readObject() 来控制只序列化数组中有元素填充那部分内容\n序列化时需要使用 ObjectOutputStream 的 writeObject() 将对象转换为字节流并输出。而 writeObject() 方法在传入的对象存在 writeObject() 的时候会去反射调用该对象的 writeObject() 来实现序列化。反序列化使用的是 ObjectInputStream 的 readObject() 方法，原理类似\n\n123ArrayList list = new ArrayList();ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(file));oos.writeObject(list);\n Fail-Fast机制\n\n参数modCount用来记录 ArrayList 结构发生变化的次数\n\n结构发生变化是指添加或者删除至少一个元素的所有操作，或者是调整内部数组的大小，仅仅只是设置元素的值不算结构发生变化\n\n\n在进行序列化或者迭代等操作时，需要比较操作前后 modCount 是否改变，如果改变了需要抛出 ConcurrentModificationException\n在面对并发的修改时，迭代器很快就会完全失败，而不是冒着在将来某个不确定时间发生任意不确定行为的风险\n\n Vector\n\n和 ArrayList 类似，但它是线程安全的\n\n使用synchronized进行同步\n\n\n\n12345678910111213public synchronized boolean add(E e) &#123;    modCount++;    ensureCapacityHelper(elementCount + 1);    elementData[elementCount++] = e;    return true;&#125;public synchronized E get(int index) &#123;    if (index &gt;= elementCount)        throw new ArrayIndexOutOfBoundsException(index);    return elementData(index);&#125;\n 扩容\n\nVector 的构造函数可以传入 capacityIncrement 参数，它的作用是在扩容时使容量 capacity 增长 capacityIncrement\n如果这个参数的值小于等于 0，扩容时每次都令 capacity 为原来的两倍\n\n调用没有 capacityIncrement 的构造函数时，capacityIncrement 值被设置为 0，也就是说默认情况下 Vector 每次扩容时容量都会翻倍\n\n\n\n 替代方案\n\n可以使用 Collections.synchronizedList(); 得到一个线程安全的 ArrayList\n\n12List&lt;String&gt; list = new ArrayList&lt;&gt;();List&lt;String&gt; synList = Collections.synchronizedList(list);\n CopyOnWriteArrayList\n\n\n在concurrent 并发包下\n\n\n读写分离\n\n写操作在一个复制的数组上进行，读操作还是在原始数组中进行，读写分离，互不影响\n写操作需要加锁，防止并发写入时导致写入数据丢失\n写操作结束之后需要把原始数组指向新的复制数组\n\n\n\n适用场景\n\nCopyOnWriteArrayList 在写操作的同时允许读操作，大大提高了读操作的性能，因此很适合读多写少的应用场景\n\n\n\n缺点\n\n内存占用：在写操作时需要复制一个新的数组，使得内存占用为原来的两倍左右\n数据不一致：读操作不能读取实时性的数据，因为部分写操作的数据还未同步到读数组中\n\n\n\nCopyOnWriteArrayList 不适合内存敏感以及对实时性要求很高的场景\n\n\n LinkedList\n\n\n基于双向链表实现，只能顺序访问，但是可以快速地在链表中间插入和删除元素。不仅如此，LinkedList 还可以用作栈、队列和双向队列\n使用 Node 存储链表节点信息\n\n每个链表存储了 first 和 last 指针\n\n\n线程不安全\n\n可以使用 Collections.synchronizedList(); 得到一个线程安全的 LinkedList\n\n\n可被用作堆栈（stack），队列（queue）或双向队列（deque）\n允许null元素\n使用foreach或迭代器来进行遍历操作\n\n Queue\n\nQueue用于模拟队列这种数据结构，实现“FIFO”等数据结构\n通常，队列不允许随机访问队列中的元素\nQueue 接口并未定义阻塞队列的方法\n\nBlockingQueue 接口定义了那些等待元素出现或等待队列中有可用空间的方法，这些方法扩展了此接口\n\n\nQueue 实现通常不允许插入 null 元素，尽管某些实现（如 LinkedList）并不禁止插入 null\n\n即使在允许 null 的实现中，也不应该将 null 插入到 Queue 中，因为 null 也用作 poll 方法的一个特殊返回值，表明队列不包含元素\n\n\n相对于LinkedList，Queue添加了element、offer、peek、poll、remove方法\noffer：在允许的情况下，将一个元素插入到队尾，或者返回false\n\n自动包装机制，会自动的把random.nextInt转化程Integer，把char转化成Character\n\n\npeek，element：在不移除的情况下返回队头，peek在队列为空返回null，element抛异常NoSuchElementException\npoll,remove：移除并返回队头，poll当队列为空是返回null，remove抛出NoSuchElementException异常\n\n Deque\n\nDeque是Queue的子接口,我们知道Queue是一种队列形式,而Deque则是双向队列,它支持从两个端点方向检索和插入元素,因此Deque既可以支持LIFO形式也可以支持LIFO形式\n\n 添加功能\n12345void push(E) //向队列头部插入一个元素,失败时抛出异常void addFirst(E) //向队列头部插入一个元素,失败时抛出异常void addLast(E) //向队列尾部插入一个元素,失败时抛出异常boolean offerFirst(E) //向队列头部加入一个元素,失败时返回falseboolean offerLast(E) //向队列尾部加入一个元素,失败时返回false\n 获取功能\n1234E getFirst() //获取队列头部元素,队列为空时抛出异常E getLast() //获取队列尾部元素,队列为空时抛出异常E peekFirst() //获取队列头部元素,队列为空时返回nullE peekLast() //获取队列尾部元素,队列为空时返回null\n 删除功能\n12boolean removeFirstOccurrence(Object) //删除第一次出现的指定元素,不存在时返回falseboolean removeLastOccurrence(Object) //删除最后一次出现的指定元素,不存在时返回false\n 弹出功能\n12345E pop() //弹出队列头部元素,队列为空时抛出异常E removeFirst() //弹出队列头部元素,队列为空时抛出异常E removeLast() //弹出队列尾部元素,队列为空时抛出异常E pollFirst() //弹出队列头部元素,队列为空时返回nullE pollLast() //弹出队列尾部元素,队列为空时返回null\n 迭代器\n1Iterator&lt;E&gt; descendingIterator() //返回队列反向迭代器\n ArrayDeque\n\n从效率来看,ArrayDeque要比LinkedList在两端增删元素上更为高效,因为没有在节点创建删除上的开销\n总体ArrayDeque要比LinkedList更优越,在大队列的测试上有3倍与LinkedList的性能,最好的是给ArrayDeque一个较大的初始化大小,以避免底层数组扩容时数据拷贝的开销\n\n LinkedBlockingDeque\n\nLinkedBlockingDeque是Deque的并发实现,在队列为空的时候,它的takeFirst,takeLast会阻塞等待队列处于可用状态\n\n Map\n\n存储健值对，根据键得到值，因此不允许键重复，但允许值重复\n底层是一个哈希表（数组+单向链表）：查询快，增删快, 是一个无序集合\n\n 常用方法\n\nget(key)\n\n根据key值返回对应的value值，key值不存在则返回null\n\n\nput(key , value)\n\n往集合中添加元素（key和value）\n添加的时候，如果key不存在，返回值null\n如果Key已经存在的话，就会新值替换旧值，返回旧值\n\n\nremove(key)\n\n删除key值对应的键值对\n如果key不存在，删除失败，返回值为null\n如果key存在则删除成功，返回值为删除的value\n\n\n可以通过containsKey()和containsValue()来判断集合是否包含某个键或某个值\n\n HashMap\n\n非线程安全，高效，支持null\n\n最多只允许一条记录的键为Null；允许多条记录的值为 Null\n可以用 Collections的synchronizedMap() 方法使HashMap具有同步的能力\n\n\nHashMap里面存入的值在取出的时候是随机的，它根据键的HashCode来存储数据，根据键可以直接获取它的值，具有很快的访问速度。在Map中插入、删除和定位元素，HashMap 是最好的选择\n采用拉链法解决冲突\njdk1.8在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时，将链表转化为红黑树，以减少搜索时间。原本Map.Entry接口的实现类Entry改名为了Node。转化为红黑树时改用另一种实现TreeNode\n\n 拉链法工作原理\n\n\n链表的插入是以头插法方式进行的\n\n put操作\n\n允许插入键为 null 的键值对，但是因为无法调用 null 的 hashCode() 方法，也就无法确定该键值对的桶下标，只能通过强制指定一个桶下标来存放\n\nHashMap 使用第 0 个桶存放键为 null 的键值对\n\n\n头插法\n\n 确定桶下标\n12int hash = hash(key);int i = indexFor(hash, table.length);\n\n位运算的代价比求模运算小的多，因此在进行取模计算时用位运算的话能带来更高的性能\n确定桶下标的最后一步是将 key 的 hash 值对桶个数取模：hash%capacity，如果能保证 capacity 为 2 的 n 次方，那么就可以将这个操作转换为位运算\n\n 扩容\n\n\n设 HashMap 的 table 长度为 M，需要存储的键值对数量为 N，如果哈希函数满足均匀性的要求，那么每条链表的长度大约为 N/M，因此查找的复杂度为 O(N/M)\n\n\n为了让查找的成本降低，应该使 N/M 尽可能小，因此需要保证 M 尽可能大，也就是说 table 要尽可能大。HashMap 采用动态扩容来根据当前的 N 值来调整 M 值，使得空间效率和时间效率都能得到保证\n\n\n和扩容相关的参数主要有：capacity、size、threshold 和 load_factor\n\n\n\n\n\n参数\n含义\n\n\n\n\ncapacity\ntable 的容量大小，默认为 16。需要注意的是 capacity 必须保证为 2 的 n 次方。\n\n\nsize\n键值对数量。\n\n\nthreshold\nsize 的临界值，当 size 大于等于 threshold 就必须进行扩容操作。\n\n\nloadFactor\n装载因子，table 能够使用的比例，threshold = (int)(capacity* loadFactor)。\n\n\n\n\n当需要扩容时，令 capacity 为原来的两倍\n扩容使用 resize() 实现\n\n扩容操作同样需要把 oldTable 的所有键值对重新插入 newTable 中，因此这一步是很费时的\n\n\n\n 扩容后重新计算桶下标\n\nHashMap capacity 为 2 的 n 次方这一特点能够极大降低重新计算桶下标操作的复杂度\n\n假设原数组长度 capacity 为 16，扩容之后 new capacity 为 32：\n12capacity     : 00010000new capacity : 00100000\n对于一个 Key，它的哈希值 hash 在第 5 位：\n\n为 0，那么 hash%00010000 = hash%00100000，桶位置和原来一致\n为 1，hash%00010000 = hash%00100000 + 16，桶位置是原位置 + 16\n\n 与HashTable的比较\n\nHashtable 使用 synchronized 来进行同步。\nHashMap 可以插入键为 null 的 Entry。\nHashMap 的迭代器是 fail-fast 迭代器。\nHashMap 不能保证随着时间的推移 Map 中的元素次序是不变的。\n\n ConcurrentHashMap\n\n\nConcurrentHashMap 和 HashMap 实现上类似，最主要的差别是 ConcurrentHashMap 采用了分段锁（Segment），每个分段锁维护着几个桶（HashEntry），多个线程可以同时访问不同分段锁上的桶，从而使其并发度更高（并发度就是 Segment 的个数）\n\nSegment 继承自 ReentrantLock\n默认的并发级别为 16，也就是说默认创建 16 个 Segment\n\n\n\n size操作\n\n每个 Segment 维护了一个 count 变量来统计该 Segment 中的键值对个数\n在执行 size 操作时，需要遍历所有 Segment 然后把 count 累计起来\nConcurrentHashMap 在执行 size 操作时先尝试不加锁，如果连续两次不加锁操作得到的结果一致，那么可以认为这个结果是正确的\n\n尝试次数使用 RETRIES_BEFORE_LOCK 定义，该值为 2，retries 初始值为 -1，因此尝试次数为 3\n如果尝试的次数超过 3 次，就需要对每个 Segment 加锁\n\n\nJDK1.8使用了CAS操作来支持更高的并发度，在 CAS 操作失败时使用内置锁 synchronized\n\n在链表过长时会转换为红黑树\n\n\n\n LinkedHashMap\n\n继承自 HashMap，因此具有和 HashMap 一样的快速查找特性\n内部维护了一个双向链表，用来维护插入顺序或者 LRU 顺序\n\nhead和tail\n\n\naccessOrder 参数决定了顺序，默认为 false，此时维护的是插入顺序\nLinkedHashMap 最重要的是以下用于维护顺序的函数，它们会在 put、get 等方法中调用\n\n12void afterNodeAccess(Node&lt;K,V&gt; p) &#123; &#125;void afterNodeInsertion(boolean evict) &#123; &#125;\n afterNodeAccess()\n\n当一个节点被访问时，如果 accessOrder 为 true，则会将该节点移到链表尾部\n也就是说指定为 LRU 顺序之后，在每次访问一个节点时，会将这个节点移到链表尾部，保证链表尾部是最近访问的节点，那么链表首部就是最近最久未使用的节点\n\n afterNodeInsertion()\n\n在 put 等操作之后执行，当 removeEldestEntry() 方法返回 true 时会移除最晚的节点，也就是链表首部节点 first\nevict 只有在构建 Map 的时候才为 false，在这里为 true\n\n1234567void afterNodeInsertion(boolean evict) &#123; // possibly remove eldest    LinkedHashMap.Entry&lt;K,V&gt; first;    if (evict &amp;&amp; (first = head) != null &amp;&amp; removeEldestEntry(first)) &#123;        K key = first.key;        removeNode(hash(key), key, null, false, true);    &#125;&#125;\nremoveEldestEntry() 默认为 false，如果需要让它为 true，需要继承 LinkedHashMap 并且覆盖这个方法的实现，这在实现 LRU 的缓存中特别有用，通过移除最近最久未使用的节点，从而保证缓存空间足够，并且缓存的数据都是热点数据\n 实现LRU缓存\n\n设定最大缓存空间 MAX_ENTRIES 为 3\n使用 LinkedHashMap 的构造函数将 accessOrder 设置为 true，开启 LRU 顺序\n覆盖 removeEldestEntry() 方法实现，在节点多于 MAX_ENTRIES 就会将最近最久未使用的数据移除\n\n12345678910111213141516171819202122232425class LRUCache&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt; &#123;    private static final int MAX_ENTRIES = 3;    protected boolean removeEldestEntry(Map.Entry eldest) &#123;        return size() &gt; MAX_ENTRIES;    &#125;    LRUCache() &#123;        super(MAX_ENTRIES, 0.75f, true);    &#125;&#125;public static void main(String[] args) &#123;    LRUCache&lt;Integer, String&gt; cache = new LRUCache&lt;&gt;();    cache.put(1, \"a\");    cache.put(2, \"b\");    cache.put(3, \"c\");    cache.get(1);    cache.put(4, \"d\");    System.out.println(cache.keySet());&#125;/*结果为 [3,1,4]*/\n WeakHashMap\n\nWeakHashMap 的 Entry 继承自 WeakReference，被 WeakReference 关联的对象在下一次垃圾回收时会被回收\nWeakHashMap 主要用来实现缓存，通过使用 WeakHashMap 来引用缓存对象，由 JVM 对这部分缓存进行回收\n\n ConcurrentCache\n\nTomcat 中的 ConcurrentCache 使用了 WeakHashMap 来实现缓存功能。\nConcurrentCache 采取的是分代缓存\n\n 分代缓存\n\n经常使用的对象放入 eden 中，eden 使用 ConcurrentHashMap 实现，不用担心会被回收（伊甸园）；\n不常用的对象放入 longterm，longterm 使用 WeakHashMap 实现，这些老对象会被垃圾收集器回收。\n当调用 get() 方法时，会先从 eden 区获取，如果没有找到的话再到 longterm 获取，当从 longterm 获取到就把对象放入 eden 中，从而保证经常被访问的节点不容易被回收。\n当调用 put() 方法时，如果 eden 的大小超过了 size，那么就将 eden 中的所有对象都放入 longterm 中，利用虚拟机回收掉一部分不经常使用的对象。\n\n","plink":"ilucia.github.io/java1.8/集合_容器/"},{"title":"java1.8/函数式编程","date":"2022-04-27T15:24:01.723Z","updated":"2022-04-27T15:24:01.723Z","content":" 概述\n 函数式编程简介\n我们最常用的面向对象编程（Java）属于命令式编程（Imperative Programming）这种编程范式。常见的编程范式还有逻辑式编程（Logic Programming），函数式编程（Functional Programming）\n函数式编程把计算过程当做是数学函数的求值，而避免更改状态和可变数据\n什么是函数式编程？简单的回答：一切都是数学函数。函数式编程语言里也可以有对象，但通常这些对象都是恒定不变的 —— 要么是函数参数，要什么是函数返回值。函数式编程语言里没有 for/next 循环，因为这些逻辑意味着有状态的改变。相替代的是，这种循环逻辑在函数式编程语言里是通过递归、把函数当成参数传递的方式实现的\n Lambda 表达式简介\nJava 8的最大变化是引入了Lambda（Lambda 是希腊字母 λ 的英文名称）表达式——一种紧凑的、传递行为的方式。\n先看个例子：\n12345button.addActionListener(new ActionListener() &#123;\tpublic void actionPerformed(ActionEvent event) &#123;\t\tSystem.out.println(\"button clicked\");\t&#125;&#125;);\n这段代码使用了匿名类。ActionListener 是一个接口，这里 new 了一个类实现了 ActionListener 接口，然后重写了 actionPerformed 方法。actionPerformed 方法接收 ActionEvent 类型参数，返回空。\n这段代码我们其实只关心中间打印的语句，其他都是多余的。所以使用 Lambda 表达式，我们就可以简写为：\n1button.addActionListener(event -&gt; System.out.println(\"button clicked\"));\n Lambda 表达式\n Lambda 表达式的形式\nJava 中 Lambda 表达式一共有五种基本形式，具体如下：\n 1\n1Runnable noArguments = () -&gt; System.out.println(\"Hello World\");\n\n不包含参数,使用空括号 () 表示没有参数\n该 Lambda 表达式 实现了 Runnable 接口,该接口也只有一个 run 方法,没有参数,且返回类型为 void\n\n 2\n1ActionListener oneArgument = event -&gt; System.out.println(\"button clicked\");\n\n包含且只包含一个参数,可省略参数的括号\n\n 3\n1234Runnable multiStatement = () -&gt; &#123;\tSystem.out.print(\"Hello\");\tSystem.out.println(\" World\");&#125;;\n\nLambda 表达式的主体不仅可以是一个表达式,而且也可以是一段代码块,使用大括号 ({})将代码块括起来\n该代码块和普通方法遵循的规则别无二致,可以用返 回或抛出异常来退出。只有一行代码的 Lambda 表达式也可使用大括号,用以明确 Lambda表达式从何处开始、到哪里结束\n\n 4\n1BinaryOperator&lt;Long&gt; add = (x, y) -&gt; x + y;\n\n表示包含多个参数的方法\n代码阅读方法\n\n这行代码并不是将两个数字相加,而是创建了一个函数,用来计算 两个数字相加的结果\n变量 add 的类型是 BinaryOperator,它不是两个数字的和, 而是将两个数字相加的那行代码\n\n\n\n 5\n1BinaryOperator&lt;Long&gt; addExplicit = (Long x, Long y) -&gt; x + y;\n\n\n到目前为止,所有 Lambda 表达式中的参数类型都是由编译器推断得出的\n\n\n可以显式声明参数类型,此时就需要使用小括号将参数括起来,多个参数的情况也是如此\n\n\nLambda 表达式都可以扩写为原始的“匿名类”形式\n\nLambda 表达式很复杂不容易理解的时候，不妨把它扩写为“匿名类”形式来看\n\n\n\n 闭包\n\n匿名内部类所在方法里的变量，必须声明为 final\n\n123456final String name = getUserName();button.addActionListener(new ActionListener() &#123;\tpublic void actionPerformed(ActionEvent event) &#123;\t\tSystem.out.println(\"hi \" + name);\t&#125;&#125;);\n\nJava 8放松了这一限制，可以不必再把变量声明为 final，但其实该变量实际上仍然是 final 的\n虽然无需将变量声明为 final，但在 Lambda 表达式中，也无法用作非终态变量\n\n如果坚持用作非终态变量（即改变变量的值），编译器就会报错\n\n\n\n 函数接口\n上面例子里提到了 ActionListener 接口，我们看一下它的代码：\n12345678public interface ActionListener extends EventListener &#123;    /**     * Invoked when an action occurs.     */    public void actionPerformed(ActionEvent e);&#125;\n\nActionListener 只有一个抽象方法：actionPerformed，被用来表示行为:接受一个参数，返回空\n由于 actionPerformed 定义在一个接口里，因此 abstract 关键字不是必需的\n该接口也继承自一个不具有任何方法的父接口：EventListener\n\n我们把这种接口就叫做函数接口\n\n\n\n JDK 8 常用核心函数接口\n\n\n\n接口\n参数\n返回类型\n描述\n\n\n\n\nPredicate\nT\nboolean\n用于判别一个对象。比如求一个人是否为男性\n\n\nConsumer\nT\nvoid\n用于接收一个对象进行处理但没有返回，比如接收一个人并打印他的名字\n\n\nFunction&lt;T, R&gt;\nT\nR\n转换一个对象为不同类型的对象\n\n\nSupplier\nNone\nT\n提供一个对象\n\n\nUnaryOperator\nT\nT\n接收对象并返回同类型的对象\n\n\nBinaryOperator\n(T, T)\nT\n接收两个同类型的对象，并返回一个原类型对象\n\n\n\n\nCosumer 与 Supplier 对应，一个是消费者，一个是提供者\nPredicate 用于判断对象是否符合某个条件，经常被用来过滤对象\nFunction 是将一个对象转换为另一个对象，比如说要装箱或者拆箱某个对象\nUnaryOperator 接收和返回同类型对象，一般用于对对象修改属性。BinaryOperator 则可以理解为合并对象\n\n 集合处理\n lambda表达式\n 例 线程\n123456789101112131415161718public static void main(String[] args) &#123;  // Java7  new Thread(new Runnable() &#123;    @Override    public void run() &#123;      for (int i = 0; i &lt; 100; i++) &#123;        System.out.println(i);      &#125;    &#125;  &#125;).start();  // Java8  new Thread(() -&gt; &#123;    for (int i = 0; i &lt; 100; i++) &#123;      System.out.println(i);    &#125;  &#125;).start();&#125;\n 使用场景\n 简化匿名类的编码\n 减少不必要的方法创建\n\n某个方法只会在某处使用且内部逻辑也很简单，在Java8之前我们通常都会创建一个方法，但是事实上我们经常会发现这样写着写着，一个类中的方法可能会变得非常庞杂，严重影响阅读体验，进而影响编码效率。但是如果使用lambda表达式，那么这个问题就可以很容易就解决\n例：多次打印时间\n\n1234567891011121314151617181920212223242526public class FunctionMain &#123;        public static void main(String[] args) &#123;        TimeDemo timeDemo = new TimeDemo();        timeDemo.createTime = System.currentTimeMillis();        timeDemo.updateTime = System.currentTimeMillis() + 10000;        outputTimeDemo(timeDemo);    &#125;    private static void outputTimeDemo(TimeDemo timeDemo) &#123;        Function timestampToDate = timestamp -&gt; &#123;            DateFormat df = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");            return df.format(new Date(timestamp));        &#125;;     System.out.println(timestampToDate.apply(timeDemo.createTime));       System.out.println(timestampToDate.apply(timeDemo.updateTime));    &#125;    interface Function &#123;        String apply(long timestamp);    &#125;&#125;class TimeDemo &#123;    long createTime;    long updateTime;&#125;\n\n在这段代码的outputTimeDemo中我们可以看到，对于时间戳转换的内容，我们并没有额外创建一个方法，而是类似于创建了一个变量来表达\n不过，这个时候出现了另一个问题，虽然我们少创建了一个方法，但是我们却多创建了一个接口Function，总有种因小失大的感觉，不过这个问题，我们在后面的java.util.function包部分可以找到答案\n\n 事件处理(回调)\n12345678910111213public static void main(String[] args) &#123;    execute(\"hello world\", () -&gt; System.out.println(\"callback\"));&#125;private static void execute(String s, Callback callback) &#123;    System.out.println(s);    callback.callback();&#125;@FunctionalInterfaceinterface Callback &#123;    void callback();&#125;\n\nCallback多了一个注解@FunctionalInterface，这个注解主要用于编译期检查，如果我们的接口不符合函数式接口的要求，那编译的时候就会报错\n\n java.util.function包\n\n在之前的例子中，我们发现使用lambda表达式的时候，经常需要定义一些接口用来辅助我们的编码，这样就会使得本应轻量级的lambda表达式又变得重量级\n其实Java8本身已经为我们提供了一些常见的函数式接口，就在java.util.function包下面\n\n\n\n\n接口\n描述\n\n\n\n\nFunction&lt;T,R&gt;\n接受一个输入参数，返回一个结果\n\n\nSupplier\n无参数，返回一个结果\n\n\nConsumer\n接受一个输入参数，并且不返回任何结果\n\n\nBiFunction&lt;T,U,R&gt;\n接受两个输入参数的方法，并且返回一个结果\n\n\nBiConsumer&lt;T,U&gt;\n接受两个输入参数的操作，并且不返回任何结果\n\n\n\n\n此处列出最基本的几个，其他的都是在这些的基础上做了一些简单的封装，例如IntFunction就是对Function&lt;T,R&gt;的封装\n\n如果有更复杂的情况，那就得自己定义接口了\n\n\n在java.util.function下没有无参数无返回结果的接口\n\n自己定义一个接口或者直接使用Runnable接口\n\n\n\n1234567public static void main(String[] args) &#123;    Function&lt;Integer, Integer&gt; f = x -&gt; x + 1;    System.out.println(f.apply(1));    BiFunction&lt;Integer, Integer, Integer&gt; g = (x, y) -&gt; x + y;    System.out.println(g.apply(1, 2));&#125;\n lambda表达式和匿名类的区别\n this指向不同\n\nlambda表达式中使用this指向的是外部的类，而匿名类中使用this则指向的是匿名类本身\n\n1234567891011121314151617181920212223242526272829303132public class FunctionMain &#123;    private String test = \"test-main\";    public static void main(String[] args) &#123;        new FunctionMain().output();    &#125;    private void output() &#123;        Function f = () -&gt; &#123;            System.out.println(\"1:-----------------\");            System.out.println(this);            System.out.println(this.test);        &#125;;        f.outputThis();        new Function() &#123;            @Override            public void outputThis() &#123;                System.out.println(\"2:-----------------\");                System.out.println(this);                System.out.println(this.test);            &#125;        &#125;.outputThis();    &#125;    interface Function &#123;        String test = \"test-function\";        void outputThis();    &#125;&#125;\n\n\n使用lambda表达式的同时去访问原类中的变量、方法的是做不到的\n\n 底层实现不同\n 编译\n\n匿名类会生成额外的class文件，lambda不会\n\nClassMain$1.class\n\n\n\n 字节码\n\n匿名类通过new一个类来实现\nlambda表达式被编译成一个lambda$main$0的静态方法，并通过invokedynamic的方式调用\n\n 替代条件\n\nlambda表达式想要替代匿名类，需要匿名类实现的接口为函数式接口，即只有一个抽象方法\n\n Lambda的延迟执行\n有些场景的代码执行后，结果不一定会被使用，从而造成性能浪费。而Lambda表达式是延迟执行的，这正好可以 作为解决方案，提升性能。\n 性能浪费的日志案例\n1注：日志可以帮助我们快速的定位问题，记录程序运行过程中的情况，以便项目的监控和优化。\n一种典型的场景就是对参数进行有条件使用，例如对日志消息进行拼接后，在满足条件的情况下进行打印输出：\n123456789101112131415public class Demo01Logger &#123;    public static void main(String[] args) &#123;        String msgA = \"Hello \";        String msgB = \"World \";        String msgC = \"Java\";        log(1, msgA + msgB + msgC);    &#125;    private static void log(int level, String mgs) &#123;        if (level == 1) &#123;            System.out.println(mgs);        &#125;    &#125;&#125;\n这段代码存在问题：无论级别 level 是否满足要求，作为 log 方法的第二个参数，三个字符串一定会首先被拼接并传入方法内，然后才会进行级别判断。如果级别不符合要求，那么字符串的拼接操作就白做了，存在性能浪费。\n1234备注：SLF4J是应用非常广泛的日志框架，它在记录日志时为了解决这种性能浪费的问题，并不推荐首先进行 字符串的拼接，而是将字符串的若干部分作为可变参数传入方法中，仅在日志级别满足要求的情况下才会进 行字符串拼接。例如: LOGGER.debug(&quot;变量&#123;&#125;的取值为&#123;&#125;。&quot;, &quot;os&quot;, &quot;macOS&quot;) ，其中的大括号 &#123;&#125; 为占位 符。如果满足日志级别要求，则会将“os”和“macOS”两个字符串依次拼接到大括号的位置;否则不会进行字 符串拼接。这也是一种可行解决方案，但Lambda可以做到更好。\n 体验Lambda的更优写法\n使用Lambda必然需要一个函数式接口：\n12345678@FunctionalInterfacepublic interface MessageBuilder &#123;    /**     * 信息生成器     * @return 生成的信息     */    public abstract String builderMessage();&#125;\n然后对 log 方法进行改造：\n123456789101112131415public class Demo02Logger &#123;    public static void main(String[] args) &#123;        String msgA = \"Hello \";        String msgB = \"World \";        String msgC = \"Java\";        log(1, () -&gt; msgA + msgB + msgC);    &#125;    private static void log(int level, MessageBuilder mb) &#123;        if (level == 1) &#123;            System.out.println(mb.builderMessage());        &#125;    &#125;&#125;\n改造前后的对比：\n\n这样一来，只有当级别满足要求的时候，才会进行三个字符串的拼接;否则三个字符串将不会进行拼接。\n 证明Lambda的延迟\n下面的代码可以通过结果进行验证：\n123456789101112131415161718public class Demo03Logger &#123;    public static void main(String[] args) &#123;        String msgA = \"Hello \";        String msgB = \"World \";        String msgC = \"Java\";        log(2, () -&gt; &#123;            System.out.println(\"Lambada 执行！\");            return msgA + msgB + msgC;        &#125;);    &#125;    private static void log(int level, MessageBuilder mb) &#123;        if (level == 1) &#123;            System.out.println(mb.builderMessage());        &#125;    &#125;&#125;\n这里只是在调用 log 方法的时候，将传入的Lambda稍作修改，\n当传入的 level = 1 的时候，控制台输出：\n12Lambada 执行！Hello World Java\n当传入的 level != 1 的时候，控制台没有输出。\n从结果中可以看出，在不符合级别要求的情况下，Lambda将不会执行。从而达到节省性能的效果。\n1234567891011121314151617181920212223扩展：实际上使用内部类也可以达到同样的效果，只是将代码操作延迟到了另外一个对象当中通过调用方法来完成。而是否调用其所在方法是在条件判断之后才执行的。public class Demo04Logger &#123;    public static void main(String[] args) &#123;        String msgA = \"Hello \";        String msgB = \"World \";        String msgC = \"Java\";        log(1, new MessageBuilder() &#123;            @Override            public String builderMessage() &#123;                System.out.println(\"Lambada 执行！\");                return msgA + msgB + msgC;            &#125;        &#125;);    &#125;    private static void log(int level, MessageBuilder mb) &#123;        if (level == 1) &#123;            System.out.println(mb.builderMessage());        &#125;    &#125;&#125;\n 使用Lambda作为参数和返回值\n如果抛开实现原理不说，Java中的Lambda表达式可以被当作是匿名内部类的替代品。如果方法的参数是一个函数式接口类型，那么就可以使用Lambda表达式进行替代。使用Lambda表达式作为方法参数，其实就是使用函数式 接口作为方法参数。\n Lambda作为参数\n例如 java.lang.Runnable 接口就是一个函数式接口，假设有一个 startThread 方法使用该接口作为参数，那么就可以使用Lambda进行传参。这种情况其实和 Thread 类的构造方法参数为 Runnable 没有本质区别。\n 匿名内部类作为参数，创建新的线程并执行\n123456789101112131415161718public class Demo01Runnable &#123;    public static void main(String[] args) &#123;        startThread(new Runnable() &#123;            @Override            public void run() &#123;                System.out.println(\"线程任务执行!\");            &#125;        &#125;);    &#125;    /**     * 创建一个新的线程，赋予任务，然后开启线程     * @param runnable 传入Thread类的接口，实现创建新线程     */    private static void startThread(Runnable runnable) &#123;        new Thread(runnable).start();    &#125;&#125;\n运行程序，控制台输出：\n1线程任务执行!\n Lambda作为参数，创建新的线程并执行\n123456789101112131415public class Demo02Runnable &#123;    public static void main(String[] args) &#123;        startThread(                () -&gt; System.out.println(\"线程任务执行!\")        );    &#125;    /**     * 创建一个新的线程，赋予任务，然后开启线程     * @param runnable 传入Thread类的接口，实现创建新线程     */    private static void startThread(Runnable runnable) &#123;        new Thread(runnable).start();    &#125;&#125;\n运行程序，控制台输出：\n1线程任务执行!\n Lambda作为返回值\n类似地，如果一个方法的返回值类型是一个函数式接口，那么就可以直接返回一个Lambda表达式。当需要通过一个方法来获取一个 java.util.Comparator 接口类型的对象作为排序器时,就可以调该方法获取。\n Lambda作为返回值，字符串的长短比较\n12345678910111213141516171819202122import java.util.Arrays;import java.util.Comparator;public class DemoComparator &#123;    public static void main(String[] args) &#123;        String[] array = &#123; \"abc\", \"ab\", \"a\" &#125;;        System.out.println(\"使用比较器比较之前：\" + Arrays.toString(array));        Arrays.sort(array, newComparator());        System.out.println(\"使用比较器比较之后：\" + Arrays.toString(array));    &#125;    /**     * 字符串a、b的长短比较，自己定义比较器规则，生序排序，字符串长的排在后面。     * @return 布尔值，     *         a.length() - b.length() &lt; 0 返回 false，     *         a.length() - b.length() &gt; 0 返回 true，     *         a.length() = b.length() 返回 0     */    public static Comparator&lt;String&gt; newComparator() &#123;        return (a, b) -&gt; a.length() - b.length();    &#125;&#125;\n 匿名内部类作为返回值，字符串的长短比较\n1234567891011121314151617181920import java.util.Arrays;import java.util.Comparator;public class DemoComparator &#123;    public static void main(String[] args) &#123;        String[] array = &#123; \"abc\", \"ab\", \"a\" &#125;;        System.out.println(\"使用比较器比较之前：\" + Arrays.toString(array));        Arrays.sort(array, newComparator());        System.out.println(\"使用比较器比较之后：\" + Arrays.toString(array));    &#125;    public static Comparator&lt;String&gt; newComparator1() &#123;        return new Comparator&lt;String&gt;() &#123;            @Override            public int compare(String o1, String o2) &#123;                return o1.length() - o2.length();            &#125;        &#125;;    &#125;&#125;\n运行程序，控制台输出一样：\n12使用比较器比较之前：[abc, ab, a]使用比较器比较之后：[a, ab, abc]","plink":"ilucia.github.io/java1.8/函数式编程/"},{"title":"java1.8/多线程","date":"2022-04-27T15:24:01.723Z","updated":"2022-04-27T15:24:01.727Z","content":" 使用线程\n有三种使用线程的方法：\n\n实现 Runnable 接口；\n实现 Callable 接口；\n继承 Thread 类。\n\n实现 Runnable 和 Callable 接口的类只能当做一个可以在线程中运行的任务，不是真正意义上的线程，因此最后还需要通过 Thread 来调用。可以理解为任务是通过线程驱动从而执行的。\n 实现 Runnable 接口\n需要实现接口中的 run() 方法。\n123456public class MyRunnable implements Runnable &#123;    @Override    public void run() &#123;        // ...    &#125;&#125;\n使用 Runnable 实例再创建一个 Thread 实例，然后调用 Thread 实例的 start() 方法来启动线程。\n12345public static void main(String[] args) &#123;    MyRunnable instance = new MyRunnable();    Thread thread = new Thread(instance);    thread.start();&#125;\n 实现 Callable 接口\n与 Runnable 相比，Callable 可以有返回值，返回值通过 FutureTask 进行封装。\n123456789101112public class MyCallable implements Callable&lt;Integer&gt; &#123;    public Integer call() &#123;        return 123;    &#125;&#125;public static void main(String[] args) throws ExecutionException, InterruptedException &#123;    MyCallable mc = new MyCallable();    FutureTask&lt;Integer&gt; ft = new FutureTask&lt;&gt;(mc);    Thread thread = new Thread(ft);    thread.start();    System.out.println(ft.get());&#125;\n 继承 Thread 类\n同样也是需要实现 run() 方法，因为 Thread 类也实现了 Runable 接口。\n当调用 start() 方法启动一个线程时，虚拟机会将该线程放入就绪队列中等待被调度，当一个线程被调度时会执行该线程的 run() 方法。\n123456789public class MyThread extends Thread &#123;    public void run() &#123;        // ...    &#125;&#125;public static void main(String[] args) &#123;    MyThread mt = new MyThread();    mt.start();&#125;\n 实现接口 VS 继承 Thread\n实现接口会更好一些，因为：\n\nJava 不支持多重继承，因此继承了 Thread 类就无法继承其它类，但是可以实现多个接口；\n类可能只要求可执行就行，继承整个 Thread 类开销过大。\n\n 基础线程机制\n Executor\nExecutor 管理多个异步任务的执行，而无需程序员显式地管理线程的生命周期。这里的异步是指多个任务的执行互不干扰，不需要进行同步操作。\n主要有三种 Executor：\n\nCachedThreadPool：一个任务创建一个线程；\nFixedThreadPool：所有任务只能使用固定大小的线程；\nSingleThreadExecutor：相当于大小为 1 的 FixedThreadPool。\n\n1234567public static void main(String[] args) &#123;    ExecutorService executorService = Executors.newCachedThreadPool();    for (int i = 0; i &lt; 5; i++) &#123;        executorService.execute(new MyRunnable());    &#125;    executorService.shutdown();&#125;\n Daemon\n守护线程是程序运行时在后台提供服务的线程，不属于程序中不可或缺的部分。\n当所有非守护线程结束时，程序也就终止，同时会杀死所有守护线程。\nmain() 属于非守护线程。\n在线程启动之前使用 setDaemon() 方法可以将一个线程设置为守护线程。\n1234public static void main(String[] args) &#123;    Thread thread = new Thread(new MyRunnable());    thread.setDaemon(true);&#125;\n sleep()\nThread.sleep(millisec) 方法会休眠当前正在执行的线程，millisec 单位为毫秒。\nsleep() 可能会抛出 InterruptedException，因为异常不能跨线程传播回 main() 中，因此必须在本地进行处理。线程中抛出的其它异常也同样需要在本地进行处理。\n1234567public void run() &#123;    try &#123;        Thread.sleep(3000);    &#125; catch (InterruptedException e) &#123;        e.printStackTrace();    &#125;&#125;\n yield()\n对静态方法 Thread.yield() 的调用声明了当前线程已经完成了生命周期中最重要的部分，可以切换给其它线程来执行。该方法只是对线程调度器的一个建议，而且也只是建议具有相同优先级的其它线程可以运行。\n123public void run() &#123;    Thread.yield();&#125;\n 中断\n一个线程执行完毕之后会自动结束，如果在运行过程中发生异常也会提前结束。\n InterruptedException\n通过调用一个线程的 interrupt() 来中断该线程，如果该线程处于阻塞、限期等待或者无限期等待状态，那么就会抛出 InterruptedException，从而提前结束该线程。但是不能中断 I/O 阻塞和 synchronized 锁阻塞。\n对于以下代码，在 main() 中启动一个线程之后再中断它，由于线程中调用了 Thread.sleep() 方法，因此会抛出一个 InterruptedException，从而提前结束线程，不执行之后的语句。\n1234567891011121314151617181920212223242526public class InterruptExample &#123;    private static class MyThread1 extends Thread &#123;        @Override        public void run() &#123;            try &#123;                Thread.sleep(2000);                System.out.println(\"Thread run\");            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;&#125;public static void main(String[] args) throws InterruptedException &#123;    Thread thread1 = new MyThread1();    thread1.start();    thread1.interrupt();    System.out.println(\"Main run\");&#125;Main runjava.lang.InterruptedException: sleep interrupted    at java.lang.Thread.sleep(Native Method)    at InterruptExample.lambda$main$0(InterruptExample.java:5)    at InterruptExample$$Lambda$1/713338599.run(Unknown Source)    at java.lang.Thread.run(Thread.java:745)\n interrupted()\n如果一个线程的 run() 方法执行一个无限循环，并且没有执行 sleep() 等会抛出 InterruptedException 的操作，那么调用线程的 interrupt() 方法就无法使线程提前结束。\n但是调用 interrupt() 方法会设置线程的中断标记，此时调用 interrupted() 方法会返回 true。因此可以在循环体中使用 interrupted() 方法来判断线程是否处于中断状态，从而提前结束线程。\n123456789101112131415161718public class InterruptExample &#123;    private static class MyThread2 extends Thread &#123;        @Override        public void run() &#123;            while (!interrupted()) &#123;                // ..            &#125;            System.out.println(\"Thread end\");        &#125;    &#125;&#125;public static void main(String[] args) throws InterruptedException &#123;    Thread thread2 = new MyThread2();    thread2.start();    thread2.interrupt();&#125;Thread end\n Executor 的中断操作\n调用 Executor 的 shutdown() 方法会等待线程都执行完毕之后再关闭，但是如果调用的是 shutdownNow() 方法，则相当于调用每个线程的 interrupt() 方法。\n以下使用 Lambda 创建线程，相当于创建了一个匿名内部线程。\n123456789101112131415161718192021public static void main(String[] args) &#123;    ExecutorService executorService = Executors.newCachedThreadPool();    executorService.execute(() -&gt; &#123;        try &#123;            Thread.sleep(2000);            System.out.println(\"Thread run\");        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;    &#125;);    executorService.shutdownNow();    System.out.println(\"Main run\");&#125;Main runjava.lang.InterruptedException: sleep interrupted    at java.lang.Thread.sleep(Native Method)    at ExecutorInterruptExample.lambda$main$0(ExecutorInterruptExample.java:9)    at ExecutorInterruptExample$$Lambda$1/1160460865.run(Unknown Source)    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)    at java.lang.Thread.run(Thread.java:745)\n如果只想中断 Executor 中的一个线程，可以通过使用 submit() 方法来提交一个线程，它会返回一个 Future&lt;?&gt; 对象，通过调用该对象的 cancel(true) 方法就可以中断线程。\n1234Future&lt;?&gt; future = executorService.submit(() -&gt; &#123;    // ..&#125;);future.cancel(true);\n 互斥同步\nJava 提供了两种锁机制来控制多个线程对共享资源的互斥访问，第一个是 JVM 实现的 synchronized，而另一个是 JDK 实现的 ReentrantLock。\n synchronized\n1. 同步一个代码块\n12345public void func() &#123;    synchronized (this) &#123;        // ...    &#125;&#125;\n它只作用于同一个对象，如果调用两个对象上的同步代码块，就不会进行同步。\n对于以下代码，使用 ExecutorService 执行了两个线程，由于调用的是同一个对象的同步代码块，因此这两个线程会进行同步，当一个线程进入同步语句块时，另一个线程就必须等待。\n1234567891011121314151617public class SynchronizedExample &#123;    public void func1() &#123;        synchronized (this) &#123;            for (int i = 0; i &lt; 10; i++) &#123;                System.out.print(i + \" \");            &#125;        &#125;    &#125;&#125;public static void main(String[] args) &#123;    SynchronizedExample e1 = new SynchronizedExample();    ExecutorService executorService = Executors.newCachedThreadPool();    executorService.execute(() -&gt; e1.func1());    executorService.execute(() -&gt; e1.func1());&#125;0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9\n对于以下代码，两个线程调用了不同对象的同步代码块，因此这两个线程就不需要同步。从输出结果可以看出，两个线程交叉执行。\n12345678public static void main(String[] args) &#123;    SynchronizedExample e1 = new SynchronizedExample();    SynchronizedExample e2 = new SynchronizedExample();    ExecutorService executorService = Executors.newCachedThreadPool();    executorService.execute(() -&gt; e1.func1());    executorService.execute(() -&gt; e2.func1());&#125;0 0 1 1 2 2 3 3 4 4 5 5 6 6 7 7 8 8 9 9\n2. 同步一个方法\n123public synchronized void func () &#123;    // ...&#125;\n它和同步代码块一样，作用于同一个对象。\n3. 同步一个类\n12345public void func() &#123;    synchronized (SynchronizedExample.class) &#123;        // ...    &#125;&#125;\n作用于整个类，也就是说两个线程调用同一个类的不同对象上的这种同步语句，也会进行同步。\n123456789101112131415161718public class SynchronizedExample &#123;    public void func2() &#123;        synchronized (SynchronizedExample.class) &#123;            for (int i = 0; i &lt; 10; i++) &#123;                System.out.print(i + \" \");            &#125;        &#125;    &#125;&#125;public static void main(String[] args) &#123;    SynchronizedExample e1 = new SynchronizedExample();    SynchronizedExample e2 = new SynchronizedExample();    ExecutorService executorService = Executors.newCachedThreadPool();    executorService.execute(() -&gt; e1.func2());    executorService.execute(() -&gt; e2.func2());&#125;0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9\n4. 同步一个静态方法\n123public synchronized static void fun() &#123;    // ...&#125;\n作用于整个类。\n ReentrantLock\nReentrantLock 是 java.util.concurrent（J.U.C）包中的锁。\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106public class LockExample &#123;    private Lock lock = new ReentrantLock();    public void func() &#123;        lock.lock();        try &#123;            for (int i = 0; i &lt; 10; i++) &#123;                System.out.print(i + \" \");            &#125;        &#125; finally &#123;            lock.unlock(); // 确保释放锁，从而避免发生死锁。        &#125;    &#125;&#125;public static void main(String[] args) &#123;    LockExample lockExample = new LockExample();    ExecutorService executorService = Executors.newCachedThreadPool();    executorService.execute(() -&gt; lockExample.func());    executorService.execute(() -&gt; lockExample.func());&#125;0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9​```java## 比较**1. 锁的实现**synchronized 是 JVM 实现的，而 ReentrantLock 是 JDK 实现的。**2. 性能**新版本 Java 对 synchronized 进行了很多优化，例如自旋锁等，synchronized 与 ReentrantLock 大致相同。**3. 等待可中断**当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情。ReentrantLock 可中断，而 synchronized 不行。**4. 公平锁**公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁。synchronized 中的锁是非公平的，ReentrantLock 默认情况下也是非公平的，但是也可以是公平的。**5. 锁绑定多个条件**一个 ReentrantLock 可以同时绑定多个 Condition 对象。## 使用选择除非需要使用 ReentrantLock 的高级功能，否则优先使用 synchronized。这是因为 synchronized 是 JVM 实现的一种锁机制，JVM 原生地支持它，而 ReentrantLock 不是所有的 JDK 版本都支持。并且使用 synchronized 不用担心没有释放锁而导致死锁问题，因为 JVM 会确保锁的释放。# 五、线程之间的协作当多个线程可以一起工作去解决某个问题时，如果某些部分必须在其它部分之前完成，那么就需要对线程进行协调。## join()在线程中调用另一个线程的 join() 方法，会将当前线程挂起，而不是忙等待，直到目标线程结束。对于以下代码，虽然 b 线程先启动，但是因为在 b 线程中调用了 a 线程的 join() 方法，b 线程会等待 a 线程结束才继续执行，因此最后能够保证 a 线程的输出先于 b 线程的输出。​```javapublic class JoinExample &#123;    private class A extends Thread &#123;        @Override        public void run() &#123;            System.out.println(\"A\");        &#125;    &#125;    private class B extends Thread &#123;        private A a;        B(A a) &#123;            this.a = a;        &#125;        @Override        public void run() &#123;            try &#123;                a.join();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            System.out.println(\"B\");        &#125;    &#125;    public void test() &#123;        A a = new A();        B b = new B(a);        b.start();        a.start();    &#125;&#125;public static void main(String[] args) &#123;    JoinExample example = new JoinExample();    example.test();&#125;AB\n wait() notify() notifyAll()\n调用 wait() 使得线程等待某个条件满足，线程在等待时会被挂起，当其他线程的运行使得这个条件满足时，其它线程会调用 notify() 或者 notifyAll() 来唤醒挂起的线程。\n它们都属于 Object 的一部分，而不属于 Thread。\n只能用在同步方法或者同步控制块中使用，否则会在运行时抛出 IllegalMonitorStateException。\n使用 wait() 挂起期间，线程会释放锁。这是因为，如果没有释放锁，那么其它线程就无法进入对象的同步方法或者同步控制块中，那么就无法执行 notify() 或者 notifyAll() 来唤醒挂起的线程，造成死锁。\n123456789101112131415161718192021222324public class WaitNotifyExample &#123;    public synchronized void before() &#123;        System.out.println(\"before\");        notifyAll();    &#125;    public synchronized void after() &#123;        try &#123;            wait();        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        System.out.println(\"after\");    &#125;&#125;public static void main(String[] args) &#123;    ExecutorService executorService = Executors.newCachedThreadPool();    WaitNotifyExample example = new WaitNotifyExample();    executorService.execute(() -&gt; example.after());    executorService.execute(() -&gt; example.before());&#125;beforeafter\nwait() 和 sleep() 的区别\n\nwait() 是 Object 的方法，而 sleep() 是 Thread 的静态方法；\nwait() 会释放锁，sleep() 不会。\n\n await() signal() signalAll()\njava.util.concurrent 类库中提供了 Condition 类来实现线程之间的协调，可以在 Condition 上调用 await() 方法使线程等待，其它线程调用 signal() 或 signalAll() 方法唤醒等待的线程。\n相比于 wait() 这种等待方式，await() 可以指定等待的条件，因此更加灵活。\n使用 Lock 来获取一个 Condition 对象。\n1234567891011121314151617181920212223242526272829303132333435public class AwaitSignalExample &#123;    private Lock lock = new ReentrantLock();    private Condition condition = lock.newCondition();    public void before() &#123;        lock.lock();        try &#123;            System.out.println(\"before\");            condition.signalAll();        &#125; finally &#123;            lock.unlock();        &#125;    &#125;    public void after() &#123;        lock.lock();        try &#123;            condition.await();            System.out.println(\"after\");        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125; finally &#123;            lock.unlock();        &#125;    &#125;&#125;public static void main(String[] args) &#123;    ExecutorService executorService = Executors.newCachedThreadPool();    AwaitSignalExample example = new AwaitSignalExample();    executorService.execute(() -&gt; example.after());    executorService.execute(() -&gt; example.before());&#125;beforeafter\n 线程状态\n一个线程只能处于一种状态，并且这里的线程状态特指 Java 虚拟机的线程状态，不能反映线程在特定操作系统下的状态。\n 新建（NEW）\n创建后尚未启动。\n 可运行（RUNABLE）\n正在 Java 虚拟机中运行。但是在操作系统层面，它可能处于运行状态，也可能等待资源调度（例如处理器资源），资源调度完成就进入运行状态。所以该状态的可运行是指可以被运行，具体有没有运行要看底层操作系统的资源调度。\n 阻塞（BLOCKED）\n请求获取 monitor lock 从而进入 synchronized 函数或者代码块，但是其它线程已经占用了该 monitor lock，所以出于阻塞状态。要结束该状态进入从而 RUNABLE 需要其他线程释放 monitor lock。\n 无限期等待（WAITING）\n等待其它线程显式地唤醒。\n阻塞和等待的区别在于，阻塞是被动的，它是在等待获取 monitor lock。而等待是主动的，通过调用 Object.wait() 等方法进入。\n\n\n\n进入方法\n退出方法\n\n\n\n\n没有设置 Timeout 参数的 Object.wait() 方法\nObject.notify() / Object.notifyAll()\n\n\n没有设置 Timeout 参数的 Thread.join() 方法\n被调用的线程执行完毕\n\n\nLockSupport.park() 方法\nLockSupport.unpark(Thread)\n\n\n\n 限期等待（TIMED_WAITING）\n无需等待其它线程显式地唤醒，在一定时间之后会被系统自动唤醒。\n\n\n\n进入方法\n退出方法\n\n\n\n\nThread.sleep() 方法\n时间结束\n\n\n设置了 Timeout 参数的 Object.wait() 方法\n时间结束 / Object.notify() / Object.notifyAll()\n\n\n设置了 Timeout 参数的 Thread.join() 方法\n时间结束 / 被调用的线程执行完毕\n\n\nLockSupport.parkNanos() 方法\nLockSupport.unpark(Thread)\n\n\nLockSupport.parkUntil() 方法\nLockSupport.unpark(Thread)\n\n\n\n调用 Thread.sleep() 方法使线程进入限期等待状态时，常常用“使一个线程睡眠”进行描述。调用 Object.wait() 方法使线程进入限期等待或者无限期等待时，常常用“挂起一个线程”进行描述。睡眠和挂起是用来描述行为，而阻塞和等待用来描述状态。\n 死亡（TERMINATED）\n可以是线程结束任务之后自己结束，或者产生了异常而结束。\n J.U.C - AQS\njava.util.concurrent（J.U.C）大大提高了并发性能，AQS 被认为是 J.U.C 的核心。\n CountDownLatch\n用来控制一个或者多个线程等待多个线程。\n维护了一个计数器 cnt，每次调用 countDown() 方法会让计数器的值减 1，减到 0 的时候，那些因为调用 await() 方法而在等待的线程就会被唤醒。\n\n123456789101112131415161718public class CountdownLatchExample &#123;    public static void main(String[] args) throws InterruptedException &#123;        final int totalThread = 10;        CountDownLatch countDownLatch = new CountDownLatch(totalThread);        ExecutorService executorService = Executors.newCachedThreadPool();        for (int i = 0; i &lt; totalThread; i++) &#123;            executorService.execute(() -&gt; &#123;                System.out.print(\"run..\");                countDownLatch.countDown();            &#125;);        &#125;        countDownLatch.await();        System.out.println(\"end\");        executorService.shutdown();    &#125;&#125;run..run..run..run..run..run..run..run..run..run..end\n CyclicBarrier\n用来控制多个线程互相等待，只有当多个线程都到达时，这些线程才会继续执行。\n和 CountdownLatch 相似，都是通过维护计数器来实现的。线程执行 await() 方法之后计数器会减 1，并进行等待，直到计数器为 0，所有调用 await() 方法而在等待的线程才能继续执行。\nCyclicBarrier 和 CountdownLatch 的一个区别是，CyclicBarrier 的计数器通过调用 reset() 方法可以循环使用，所以它才叫做循环屏障。\nCyclicBarrier 有两个构造函数，其中 parties 指示计数器的初始值，barrierAction 在所有线程都到达屏障的时候会执行一次。\n12345678910public CyclicBarrier(int parties, Runnable barrierAction) &#123;    if (parties &lt;= 0) throw new IllegalArgumentException();    this.parties = parties;    this.count = parties;    this.barrierCommand = barrierAction;&#125;public CyclicBarrier(int parties) &#123;    this(parties, null);&#125;\n\n123456789101112131415161718192021public class CyclicBarrierExample &#123;    public static void main(String[] args) &#123;        final int totalThread = 10;        CyclicBarrier cyclicBarrier = new CyclicBarrier(totalThread);        ExecutorService executorService = Executors.newCachedThreadPool();        for (int i = 0; i &lt; totalThread; i++) &#123;            executorService.execute(() -&gt; &#123;                System.out.print(\"before..\");                try &#123;                    cyclicBarrier.await();                &#125; catch (InterruptedException | BrokenBarrierException e) &#123;                    e.printStackTrace();                &#125;                System.out.print(\"after..\");            &#125;);        &#125;        executorService.shutdown();    &#125;&#125;before..before..before..before..before..before..before..before..before..before..after..after..after..after..after..after..after..after..after..after..\n Semaphore\nSemaphore 类似于操作系统中的信号量，可以控制对互斥资源的访问线程数。\n以下代码模拟了对某个服务的并发请求，每次只能有 3 个客户端同时访问，请求总数为 10。\n1234567891011121314151617181920212223public class SemaphoreExample &#123;    public static void main(String[] args) &#123;        final int clientCount = 3;        final int totalRequestCount = 10;        Semaphore semaphore = new Semaphore(clientCount);        ExecutorService executorService = Executors.newCachedThreadPool();        for (int i = 0; i &lt; totalRequestCount; i++) &#123;            executorService.execute(()-&gt;&#123;                try &#123;                    semaphore.acquire();                    System.out.print(semaphore.availablePermits() + \" \");                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125; finally &#123;                    semaphore.release();                &#125;            &#125;);        &#125;        executorService.shutdown();    &#125;&#125;2 1 2 2 2 2 2 1 2 2\n J.U.C - 其它组件\n FutureTask\n在介绍 Callable 时我们知道它可以有返回值，返回值通过 Future 进行封装。FutureTask 实现了 RunnableFuture 接口，该接口继承自 Runnable 和 Future 接口，这使得 FutureTask 既可以当做一个任务执行，也可以有返回值。\n12public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt;public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt;\nFutureTask 可用于异步获取执行结果或取消执行任务的场景。当一个计算任务需要执行很长时间，那么就可以用 FutureTask 来封装这个任务，主线程在完成自己的任务之后再去获取结果。\n1234567891011121314151617181920212223242526272829303132public class FutureTaskExample &#123;    public static void main(String[] args) throws ExecutionException, InterruptedException &#123;        FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(new Callable&lt;Integer&gt;() &#123;            @Override            public Integer call() throws Exception &#123;                int result = 0;                for (int i = 0; i &lt; 100; i++) &#123;                    Thread.sleep(10);                    result += i;                &#125;                return result;            &#125;        &#125;);        Thread computeThread = new Thread(futureTask);        computeThread.start();        Thread otherThread = new Thread(() -&gt; &#123;            System.out.println(\"other task is running...\");            try &#123;                Thread.sleep(1000);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;);        otherThread.start();        System.out.println(futureTask.get());    &#125;&#125;other task is running...4950\n BlockingQueue\njava.util.concurrent.BlockingQueue 接口有以下阻塞队列的实现：\n\nFIFO 队列 ：LinkedBlockingQueue、ArrayBlockingQueue（固定长度）\n优先级队列 ：PriorityBlockingQueue\n\n提供了阻塞的 take() 和 put() 方法：如果队列为空 take() 将阻塞，直到队列中有内容；如果队列为满 put() 将阻塞，直到队列有空闲位置。\n使用 BlockingQueue 实现生产者消费者问题\n1234567891011121314151617181920212223242526272829303132333435363738394041424344public class ProducerConsumer &#123;    private static BlockingQueue&lt;String&gt; queue = new ArrayBlockingQueue&lt;&gt;(5);    private static class Producer extends Thread &#123;        @Override        public void run() &#123;            try &#123;                queue.put(\"product\");            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            System.out.print(\"produce..\");        &#125;    &#125;    private static class Consumer extends Thread &#123;        @Override        public void run() &#123;            try &#123;                String product = queue.take();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            System.out.print(\"consume..\");        &#125;    &#125;&#125;public static void main(String[] args) &#123;    for (int i = 0; i &lt; 2; i++) &#123;        Producer producer = new Producer();        producer.start();    &#125;    for (int i = 0; i &lt; 5; i++) &#123;        Consumer consumer = new Consumer();        consumer.start();    &#125;    for (int i = 0; i &lt; 3; i++) &#123;        Producer producer = new Producer();        producer.start();    &#125;&#125;produce..produce..consume..consume..produce..consume..produce..consume..produce..consume..\n ForkJoin\n主要用于并行计算中，和 MapReduce 原理类似，都是把大的计算任务拆分成多个小任务并行计算。\n12345678910111213141516171819202122232425262728293031323334353637public class ForkJoinExample extends RecursiveTask&lt;Integer&gt; &#123;    private final int threshold = 5;    private int first;    private int last;    public ForkJoinExample(int first, int last) &#123;        this.first = first;        this.last = last;    &#125;    @Override    protected Integer compute() &#123;        int result = 0;        if (last - first &lt;= threshold) &#123;            // 任务足够小则直接计算            for (int i = first; i &lt;= last; i++) &#123;                result += i;            &#125;        &#125; else &#123;            // 拆分成小任务            int middle = first + (last - first) / 2;            ForkJoinExample leftTask = new ForkJoinExample(first, middle);            ForkJoinExample rightTask = new ForkJoinExample(middle + 1, last);            leftTask.fork();            rightTask.fork();            result = leftTask.join() + rightTask.join();        &#125;        return result;    &#125;&#125;public static void main(String[] args) throws ExecutionException, InterruptedException &#123;    ForkJoinExample example = new ForkJoinExample(1, 10000);    ForkJoinPool forkJoinPool = new ForkJoinPool();    Future result = forkJoinPool.submit(example);    System.out.println(result.get());&#125;\nForkJoin 使用 ForkJoinPool 来启动，它是一个特殊的线程池，线程数量取决于 CPU 核数。\n1public class ForkJoinPool extends AbstractExecutorService\nForkJoinPool 实现了工作窃取算法来提高 CPU 的利用率。每个线程都维护了一个双端队列，用来存储需要执行的任务。工作窃取算法允许空闲的线程从其它线程的双端队列中窃取一个任务来执行。窃取的任务必须是最晚的任务，避免和队列所属线程发生竞争。例如下图中，Thread2 从 Thread1 的队列中拿出最晚的 Task1 任务，Thread1 会拿出 Task2 来执行，这样就避免发生竞争。但是如果队列中只有一个任务时还是会发生竞争。\n\n 线程不安全示例\n如果多个线程对同一个共享数据进行访问而不采取同步操作的话，那么操作的结果是不一致的。\n以下代码演示了 1000 个线程同时对 cnt 执行自增操作，操作结束之后它的值有可能小于 1000。\n12345678910111213141516171819202122232425262728public class ThreadUnsafeExample &#123;    private int cnt = 0;    public void add() &#123;        cnt++;    &#125;    public int get() &#123;        return cnt;    &#125;&#125;public static void main(String[] args) throws InterruptedException &#123;    final int threadSize = 1000;    ThreadUnsafeExample example = new ThreadUnsafeExample();    final CountDownLatch countDownLatch = new CountDownLatch(threadSize);    ExecutorService executorService = Executors.newCachedThreadPool();    for (int i = 0; i &lt; threadSize; i++) &#123;        executorService.execute(() -&gt; &#123;            example.add();            countDownLatch.countDown();        &#125;);    &#125;    countDownLatch.await();    executorService.shutdown();    System.out.println(example.get());&#125;997\n Java 内存模型\nJava 内存模型试图屏蔽各种硬件和操作系统的内存访问差异，以实现让 Java 程序在各种平台下都能达到一致的内存访问效果。\n 主内存与工作内存\n处理器上的寄存器的读写的速度比内存快几个数量级，为了解决这种速度矛盾，在它们之间加入了高速缓存。\n加入高速缓存带来了一个新的问题：缓存一致性。如果多个缓存共享同一块主内存区域，那么多个缓存的数据可能会不一致，需要一些协议来解决这个问题。\n所有的变量都存储在主内存中，每个线程还有自己的工作内存，工作内存存储在高速缓存或者寄存器中，保存了该线程使用的变量的主内存副本拷贝。\n线程只能直接操作工作内存中的变量，不同线程之间的变量值传递需要通过主内存来完成。\n\n 内存间交互操作\nJava 内存模型定义了 8 个操作来完成主内存和工作内存的交互操作。\n\n\nread：把一个变量的值从主内存传输到工作内存中\nload：在 read 之后执行，把 read 得到的值放入工作内存的变量副本中\nuse：把工作内存中一个变量的值传递给执行引擎\nassign：把一个从执行引擎接收到的值赋给工作内存的变量\nstore：把工作内存的一个变量的值传送到主内存中\nwrite：在 store 之后执行，把 store 得到的值放入主内存的变量中\nlock：作用于主内存的变量\nunlock\n\n 内存模型三大特性\n 1. 原子性\nJava 内存模型保证了 read、load、use、assign、store、write、lock 和 unlock 操作具有原子性，例如对一个 int 类型的变量执行 assign 赋值操作，这个操作就是原子性的。但是 Java 内存模型允许虚拟机将没有被 volatile 修饰的 64 位数据（long，double）的读写操作划分为两次 32 位的操作来进行，即 load、store、read 和 write 操作可以不具备原子性。\n有一个错误认识就是，int 等原子性的类型在多线程环境中不会出现线程安全问题。前面的线程不安全示例代码中，cnt 属于 int 类型变量，1000 个线程对它进行自增操作之后，得到的值为 997 而不是 1000。\n为了方便讨论，将内存间的交互操作简化为 3 个：load、assign、store。\n下图演示了两个线程同时对 cnt 进行操作，load、assign、store 这一系列操作整体上看不具备原子性，那么在 T1 修改 cnt 并且还没有将修改后的值写入主内存，T2 依然可以读入旧值。可以看出，这两个线程虽然执行了两次自增运算，但是主内存中 cnt 的值最后为 1 而不是 2。因此对 int 类型读写操作满足原子性只是说明 load、assign、store 这些单个操作具备原子性。\n\nAtomicInteger 能保证多个线程修改的原子性。\n\n使用 AtomicInteger 重写之前线程不安全的代码之后得到以下线程安全实现：\n123456789101112131415161718192021222324252627public class AtomicExample &#123;    private AtomicInteger cnt = new AtomicInteger();    public void add() &#123;        cnt.incrementAndGet();    &#125;    public int get() &#123;        return cnt.get();    &#125;&#125;public static void main(String[] args) throws InterruptedException &#123;    final int threadSize = 1000;    AtomicExample example = new AtomicExample(); // 只修改这条语句    final CountDownLatch countDownLatch = new CountDownLatch(threadSize);    ExecutorService executorService = Executors.newCachedThreadPool();    for (int i = 0; i &lt; threadSize; i++) &#123;        executorService.execute(() -&gt; &#123;            example.add();            countDownLatch.countDown();        &#125;);    &#125;    countDownLatch.await();    executorService.shutdown();    System.out.println(example.get());&#125;1000\n除了使用原子类之外，也可以使用 synchronized 互斥锁来保证操作的原子性。它对应的内存间交互操作为：lock 和 unlock，在虚拟机实现上对应的字节码指令为 monitorenter 和 monitorexit。\n123456789101112131415161718192021222324252627public class AtomicSynchronizedExample &#123;    private int cnt = 0;    public synchronized void add() &#123;        cnt++;    &#125;    public synchronized int get() &#123;        return cnt;    &#125;&#125;public static void main(String[] args) throws InterruptedException &#123;    final int threadSize = 1000;    AtomicSynchronizedExample example = new AtomicSynchronizedExample();    final CountDownLatch countDownLatch = new CountDownLatch(threadSize);    ExecutorService executorService = Executors.newCachedThreadPool();    for (int i = 0; i &lt; threadSize; i++) &#123;        executorService.execute(() -&gt; &#123;            example.add();            countDownLatch.countDown();        &#125;);    &#125;    countDownLatch.await();    executorService.shutdown();    System.out.println(example.get());&#125;1000\n 2. 可见性\n可见性指当一个线程修改了共享变量的值，其它线程能够立即得知这个修改。Java 内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值来实现可见性的。\n主要有三种实现可见性的方式：\n\nvolatile\nsynchronized，对一个变量执行 unlock 操作之前，必须把变量值同步回主内存。\nfinal，被 final 关键字修饰的字段在构造器中一旦初始化完成，并且没有发生 this 逃逸（其它线程通过 this 引用访问到初始化了一半的对象），那么其它线程就能看见 final 字段的值。\n\n对前面的线程不安全示例中的 cnt 变量使用 volatile 修饰，不能解决线程不安全问题，因为 volatile 并不能保证操作的原子性。\n 3. 有序性\n有序性是指：在本线程内观察，所有操作都是有序的。在一个线程观察另一个线程，所有操作都是无序的，无序是因为发生了指令重排序。在 Java 内存模型中，允许编译器和处理器对指令进行重排序，重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。\nvolatile 关键字通过添加内存屏障的方式来禁止指令重排，即重排序时不能把后面的指令放到内存屏障之前。\n也可以通过 synchronized 来保证有序性，它保证每个时刻只有一个线程执行同步代码，相当于是让线程顺序执行同步代码。\n 先行发生原则\n上面提到了可以用 volatile 和 synchronized 来保证有序性。除此之外，JVM 还规定了先行发生原则，让一个操作无需控制就能先于另一个操作完成。\n 1. 单一线程原则\n\nSingle Thread rule\n\n在一个线程内，在程序前面的操作先行发生于后面的操作。\n 2. 管程锁定规则\n\nMonitor Lock Rule\n\n一个 unlock 操作先行发生于后面对同一个锁的 lock 操作。\n 3. volatile 变量规则\n\nVolatile Variable Rule\n\n对一个 volatile 变量的写操作先行发生于后面对这个变量的读操作。\n 4. 线程启动规则\n\nThread Start Rule\n\nThread 对象的 start() 方法调用先行发生于此线程的每一个动作。\n 5. 线程加入规则\n\nThread Join Rule\n\nThread 对象的结束先行发生于 join() 方法返回。\n\n 6. 线程中断规则\n\nThread Interruption Rule\n\n对线程 interrupt() 方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过 interrupted() 方法检测到是否有中断发生。\n 7. 对象终结规则\n\nFinalizer Rule\n\n一个对象的初始化完成（构造函数执行结束）先行发生于它的 finalize() 方法的开始。\n 8. 传递性\n\nTransitivity\n\n如果操作 A 先行发生于操作 B，操作 B 先行发生于操作 C，那么操作 A 先行发生于操作 C。\n 线程安全\n多个线程不管以何种方式访问某个类，并且在主调代码中不需要进行同步，都能表现正确的行为。\n线程安全有以下几种实现方式：\n 不可变\n不可变（Immutable）的对象一定是线程安全的，不需要再采取任何的线程安全保障措施。只要一个不可变的对象被正确地构建出来，永远也不会看到它在多个线程之中处于不一致的状态。多线程环境下，应当尽量使对象成为不可变，来满足线程安全。\n不可变的类型：\n\nfinal 关键字修饰的基本数据类型\nString\n枚举类型\nNumber 部分子类，如 Long 和 Double 等数值包装类型，BigInteger 和 BigDecimal 等大数据类型。但同为 Number 的原子类 AtomicInteger 和 AtomicLong 则是可变的。\n\n对于集合类型，可以使用 Collections.unmodifiableXXX() 方法来获取一个不可变的集合。\n12345678910public class ImmutableExample &#123;    public static void main(String[] args) &#123;        Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;();        Map&lt;String, Integer&gt; unmodifiableMap = Collections.unmodifiableMap(map);        unmodifiableMap.put(\"a\", 1);    &#125;&#125;Exception in thread \"main\" java.lang.UnsupportedOperationException    at java.util.Collections$UnmodifiableMap.put(Collections.java:1457)    at ImmutableExample.main(ImmutableExample.java:9)\nCollections.unmodifiableXXX() 先对原始的集合进行拷贝，需要对集合进行修改的方法都直接抛出异常。\n123public V put(K key, V value) &#123;    throw new UnsupportedOperationException();&#125;\n 互斥同步\nsynchronized 和 ReentrantLock。\n 非阻塞同步\n互斥同步最主要的问题就是线程阻塞和唤醒所带来的性能问题，因此这种同步也称为阻塞同步。\n互斥同步属于一种悲观的并发策略，总是认为只要不去做正确的同步措施，那就肯定会出现问题。无论共享数据是否真的会出现竞争，它都要进行加锁（这里讨论的是概念模型，实际上虚拟机会优化掉很大一部分不必要的加锁）、用户态核心态转换、维护锁计数器和检查是否有被阻塞的线程需要唤醒等操作。\n随着硬件指令集的发展，我们可以使用基于冲突检测的乐观并发策略：先进行操作，如果没有其它线程争用共享数据，那操作就成功了，否则采取补偿措施（不断地重试，直到成功为止）。这种乐观的并发策略的许多实现都不需要将线程阻塞，因此这种同步操作称为非阻塞同步。\n CAS\n乐观锁需要操作和冲突检测这两个步骤具备原子性，这里就不能再使用互斥同步来保证了，只能靠硬件来完成。硬件支持的原子性操作最典型的是：比较并交换（Compare-and-Swap，CAS）。CAS 指令需要有 3 个操作数，分别是内存地址 V、旧的预期值 A 和新值 B。当执行操作时，只有当 V 的值等于 A，才将 V 的值更新为 B。\n AtomicInteger\nJ.U.C 包里面的整数原子类 AtomicInteger 的方法调用了 Unsafe 类的 CAS 操作。\n以下代码使用了 AtomicInteger 执行了自增的操作。\n12345private AtomicInteger cnt = new AtomicInteger();public void add() &#123;    cnt.incrementAndGet();&#125;\n以下代码是 incrementAndGet() 的源码，它调用了 Unsafe 的 getAndAddInt() 。\n123public final int incrementAndGet() &#123;    return unsafe.getAndAddInt(this, valueOffset, 1) + 1;&#125;\n以下代码是 getAndAddInt() 源码，var1 指示对象内存地址，var2 指示该字段相对对象内存地址的偏移，var4 指示操作需要加的数值，这里为 1。通过 getIntVolatile(var1, var2) 得到旧的预期值，通过调用 compareAndSwapInt() 来进行 CAS 比较，如果该字段内存地址中的值等于 var5，那么就更新内存地址为 var1+var2 的变量为 var5+var4。\n可以看到 getAndAddInt() 在一个循环中进行，发生冲突的做法是不断的进行重试。\n12345678public final int getAndAddInt(Object var1, long var2, int var4) &#123;    int var5;    do &#123;        var5 = this.getIntVolatile(var1, var2);    &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));    return var5;&#125;\n ABA\n如果一个变量初次读取的时候是 A 值，它的值被改成了 B，后来又被改回为 A，那 CAS 操作就会误认为它从来没有被改变过。\nJ.U.C 包提供了一个带有标记的原子引用类 AtomicStampedReference 来解决这个问题，它可以通过控制变量值的版本来保证 CAS 的正确性。大部分情况下 ABA 问题不会影响程序并发的正确性，如果需要解决 ABA 问题，改用传统的互斥同步可能会比原子类更高效。\n 无同步方案\n要保证线程安全，并不是一定就要进行同步。如果一个方法本来就不涉及共享数据，那它自然就无须任何同步措施去保证正确性。\n 栈封闭\n多个线程访问同一个方法的局部变量时，不会出现线程安全问题，因为局部变量存储在虚拟机栈中，属于线程私有的。\n123456789101112131415161718public class StackClosedExample &#123;    public void add100() &#123;        int cnt = 0;        for (int i = 0; i &lt; 100; i++) &#123;            cnt++;        &#125;        System.out.println(cnt);    &#125;&#125;public static void main(String[] args) &#123;    StackClosedExample example = new StackClosedExample();    ExecutorService executorService = Executors.newCachedThreadPool();    executorService.execute(() -&gt; example.add100());    executorService.execute(() -&gt; example.add100());    executorService.shutdown();&#125;100100\n 线程本地存储（Thread Local Storage）\n如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行。如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题。\n符合这种特点的应用并不少见，大部分使用消费队列的架构模式（如“生产者-消费者”模式）都会将产品的消费过程尽量在一个线程中消费完。其中最重要的一个应用实例就是经典 Web 交互模型中的“一个请求对应一个服务器线程”（Thread-per-Request）的处理方式，这种处理方式的广泛应用使得很多 Web 服务端应用都可以使用线程本地存储来解决线程安全问题。\n可以使用 java.lang.ThreadLocal 类来实现线程本地存储功能。\n对于以下代码，thread1 中设置 threadLocal 为 1，而 thread2 设置 threadLocal 为 2。过了一段时间之后，thread1 读取 threadLocal 依然是 1，不受 thread2 的影响。\n12345678910111213141516171819202122public class ThreadLocalExample &#123;    public static void main(String[] args) &#123;        ThreadLocal threadLocal = new ThreadLocal();        Thread thread1 = new Thread(() -&gt; &#123;            threadLocal.set(1);            try &#123;                Thread.sleep(1000);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            System.out.println(threadLocal.get());            threadLocal.remove();        &#125;);        Thread thread2 = new Thread(() -&gt; &#123;            threadLocal.set(2);            threadLocal.remove();        &#125;);        thread1.start();        thread2.start();    &#125;&#125;1\n为了理解 ThreadLocal，先看以下代码：\n12345678910111213141516public class ThreadLocalExample1 &#123;    public static void main(String[] args) &#123;        ThreadLocal threadLocal1 = new ThreadLocal();        ThreadLocal threadLocal2 = new ThreadLocal();        Thread thread1 = new Thread(() -&gt; &#123;            threadLocal1.set(1);            threadLocal2.set(1);        &#125;);        Thread thread2 = new Thread(() -&gt; &#123;            threadLocal1.set(2);            threadLocal2.set(2);        &#125;);        thread1.start();        thread2.start();    &#125;&#125;\n它所对应的底层结构图为：\n\n每个 Thread 都有一个 ThreadLocal.ThreadLocalMap 对象。\n123/* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ThreadLocal.ThreadLocalMap threadLocals = null;\n当调用一个 ThreadLocal 的 set(T value) 方法时，先得到当前线程的 ThreadLocalMap 对象，然后将 ThreadLocal-&gt;value 键值对插入到该 Map 中。\n12345678public void set(T value) &#123;    Thread t = Thread.currentThread();    ThreadLocalMap map = getMap(t);    if (map != null)        map.set(this, value);    else        createMap(t, value);&#125;\nget() 方法类似。\n12345678910111213public T get() &#123;    Thread t = Thread.currentThread();    ThreadLocalMap map = getMap(t);    if (map != null) &#123;        ThreadLocalMap.Entry e = map.getEntry(this);        if (e != null) &#123;            @SuppressWarnings(\"unchecked\")            T result = (T)e.value;            return result;        &#125;    &#125;    return setInitialValue();&#125;\nThreadLocal 从理论上讲并不是用来解决多线程并发问题的，因为根本不存在多线程竞争。\n在一些场景 (尤其是使用线程池) 下，由于 ThreadLocal.ThreadLocalMap 的底层数据结构导致 ThreadLocal 有内存泄漏的情况，应该尽可能在每次使用 ThreadLocal 后手动调用 remove()，以避免出现 ThreadLocal 经典的内存泄漏甚至是造成自身业务混乱的风险。\n 可重入代码（Reentrant Code）\n这种代码也叫做纯代码（Pure Code），可以在代码执行的任何时刻中断它，转而去执行另外一段代码（包括递归调用它本身），而在控制权返回后，原来的程序不会出现任何错误。\n可重入代码有一些共同的特征，例如不依赖存储在堆上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非可重入的方法等。\n 锁优化\n这里的锁优化主要是指 JVM 对 synchronized 的优化。\n 自旋锁\n互斥同步进入阻塞状态的开销都很大，应该尽量避免。在许多应用中，共享数据的锁定状态只会持续很短的一段时间。自旋锁的思想是让一个线程在请求一个共享数据的锁时执行忙循环（自旋）一段时间，如果在这段时间内能获得锁，就可以避免进入阻塞状态。\n自旋锁虽然能避免进入阻塞状态从而减少开销，但是它需要进行忙循环操作占用 CPU 时间，它只适用于共享数据的锁定状态很短的场景。\n在 JDK 1.6 中引入了自适应的自旋锁。自适应意味着自旋的次数不再固定了，而是由前一次在同一个锁上的自旋次数及锁的拥有者的状态来决定。\n 锁消除\n锁消除是指对于被检测出不可能存在竞争的共享数据的锁进行消除。\n锁消除主要是通过逃逸分析来支持，如果堆上的共享数据不可能逃逸出去被其它线程访问到，那么就可以把它们当成私有数据对待，也就可以将它们的锁进行消除。\n对于一些看起来没有加锁的代码，其实隐式的加了很多锁。例如下面的字符串拼接代码就隐式加了锁：\n123public static String concatString(String s1, String s2, String s3) &#123;    return s1 + s2 + s3;&#125;\nString 是一个不可变的类，编译器会对 String 的拼接自动优化。在 JDK 1.5 之前，会转化为 StringBuffer 对象的连续 append() 操作：\n1234567public static String concatString(String s1, String s2, String s3) &#123;    StringBuffer sb = new StringBuffer();    sb.append(s1);    sb.append(s2);    sb.append(s3);    return sb.toString();&#125;\n每个 append() 方法中都有一个同步块。虚拟机观察变量 sb，很快就会发现它的动态作用域被限制在 concatString() 方法内部。也就是说，sb 的所有引用永远不会逃逸到 concatString() 方法之外，其他线程无法访问到它，因此可以进行消除。\n 锁粗化\n如果一系列的连续操作都对同一个对象反复加锁和解锁，频繁的加锁操作就会导致性能损耗。\n上一节的示例代码中连续的 append() 方法就属于这类情况。如果虚拟机探测到由这样的一串零碎的操作都对同一个对象加锁，将会把加锁的范围扩展（粗化）到整个操作序列的外部。对于上一节的示例代码就是扩展到第一个 append() 操作之前直至最后一个 append() 操作之后，这样只需要加锁一次就可以了。\n 轻量级锁\nJDK 1.6 引入了偏向锁和轻量级锁，从而让锁拥有了四个状态：无锁状态（unlocked）、偏向锁状态（biasble）、轻量级锁状态（lightweight locked）和重量级锁状态（inflated）。\n以下是 HotSpot 虚拟机对象头的内存布局，这些数据被称为 Mark Word。其中 tag bits 对应了五个状态，这些状态在右侧的 state 表格中给出。除了 marked for gc 状态，其它四个状态已经在前面介绍过了。\n\n下图左侧是一个线程的虚拟机栈，其中有一部分称为 Lock Record 的区域，这是在轻量级锁运行过程创建的，用于存放锁对象的 Mark Word。而右侧就是一个锁对象，包含了 Mark Word 和其它信息。\n\n轻量级锁是相对于传统的重量级锁而言，它使用 CAS 操作来避免重量级锁使用互斥量的开销。对于绝大部分的锁，在整个同步周期内都是不存在竞争的，因此也就不需要都使用互斥量进行同步，可以先采用 CAS 操作进行同步，如果 CAS 失败了再改用互斥量进行同步。\n当尝试获取一个锁对象时，如果锁对象标记为 0 01，说明锁对象的锁未锁定（unlocked）状态。此时虚拟机在当前线程的虚拟机栈中创建 Lock Record，然后使用 CAS 操作将对象的 Mark Word 更新为 Lock Record 指针。如果 CAS 操作成功了，那么线程就获取了该对象上的锁，并且对象的 Mark Word 的锁标记变为 00，表示该对象处于轻量级锁状态。\n\n如果 CAS 操作失败了，虚拟机首先会检查对象的 Mark Word 是否指向当前线程的虚拟机栈，如果是的话说明当前线程已经拥有了这个锁对象，那就可以直接进入同步块继续执行，否则说明这个锁对象已经被其他线程线程抢占了。如果有两条以上的线程争用同一个锁，那轻量级锁就不再有效，要膨胀为重量级锁。\n 偏向锁\n偏向锁的思想是偏向于让第一个获取锁对象的线程，这个线程在之后获取该锁就不再需要进行同步操作，甚至连 CAS 操作也不再需要。\n当锁对象第一次被线程获得的时候，进入偏向状态，标记为 1 01。同时使用 CAS 操作将线程 ID 记录到 Mark Word 中，如果 CAS 操作成功，这个线程以后每次进入这个锁相关的同步块就不需要再进行任何同步操作。\n当有另外一个线程去尝试获取这个锁对象时，偏向状态就宣告结束，此时撤销偏向（Revoke Bias）后恢复到未锁定状态或者轻量级锁状态。\n\n 多线程开发良好的实践\n\n给线程起个有意义的名字，这样可以方便找 Bug。\n缩小同步范围，从而减少锁争用。例如对于 synchronized，应该尽量使用同步块而不是同步方法。\n多用同步工具少用 wait() 和 notify()。首先，CountDownLatch, CyclicBarrier, Semaphore 和 Exchanger 这些同步类简化了编码操作，而用 wait() 和 notify() 很难实现复杂控制流；其次，这些同步类是由最好的企业编写和维护，在后续的 JDK 中还会不断优化和完善。\n使用 BlockingQueue 实现生产者消费者问题。\n多用并发集合少用同步集合，例如应该使用 ConcurrentHashMap 而不是 Hashtable。\n使用本地变量和不可变类来保证线程安全。\n使用线程池而不是直接创建线程，这是因为创建线程代价很高，线程池可以有效地利用有限的线程来启动任务。\n\n","plink":"ilucia.github.io/java1.8/多线程/"},{"title":"java1.8/pictures/周会","date":"2022-04-27T15:24:01.723Z","updated":"2022-04-27T15:24:01.723Z","content":"周会\n方案-&gt;评审-&gt;代码\n终端和后端同步\nPDA套用自贩机\n自动化测试\n后端报告风险/工作\n拼团开发阶段\n提交代码按功能提交\n","plink":"ilucia.github.io/java1.8/pictures/周会/"},{"title":"java1.8/ATM修改方案","date":"2022-04-27T15:24:01.719Z","updated":"2022-04-27T15:24:01.719Z","content":" ATM修改方案\n\n使用NIO进行连接，构造主线程\n使用线程池进行读写\n数组改为其他集合类\n按钮监听器改为函数式编程方式实现\n\n","plink":"ilucia.github.io/java1.8/ATM修改方案/"},{"title":"java1.8/IO-NIO","date":"2022-04-27T15:24:01.719Z","updated":"2022-04-27T15:24:01.719Z","content":" I/O\n![Java IO](/Users/ng/Documents/java1.8/pictures/Java IO.jpg)\n\nJava 的 I/O 大概可以分成以下几类：\n\n磁盘操作：File\n字节操作：InputStream 和 OutputStream\n字符操作：Reader 和 Writer\n对象操作：Serializable\n网络操作：Socket\nNIO\n\n\n\n 磁盘操作\nFile 类可以用于表示文件和目录的信息，但是它不表示文件的内容。\n递归地列出一个目录下所有文件：\n123456789101112public static void listAllFiles(File dir) &#123;    if (dir == null || !dir.exists()) &#123;        return;    &#125;    if (dir.isFile()) &#123;        System.out.println(dir.getName());        return;    &#125;    for (File file : dir.listFiles()) &#123;        listAllFiles(file);    &#125;&#125;\n从 Java7 开始，可以使用 Paths 和 Files 代替 File。\n 字节操作\n 实现文件复制\n1234567891011121314151617public static void copyFile(String src, String dist) throws IOException &#123;    FileInputStream in = new FileInputStream(src);    FileOutputStream out = new FileOutputStream(dist);    byte[] buffer = new byte[20 * 1024];    int cnt;    // read() 最多读取 buffer.length 个字节    // 返回的是实际读取的个数    // 返回 -1 的时候表示读到 eof，即文件尾    while ((cnt = in.read(buffer, 0, buffer.length)) != -1) &#123;        out.write(buffer, 0, cnt);    &#125;    in.close();    out.close();&#125;\n 装饰者模式\nJava I/O 使用了装饰者模式来实现。以 InputStream 为例，\n\nInputStream 是抽象组件；\nFileInputStream 是 InputStream 的子类，属于具体组件，提供了字节流的输入操作；\nFilterInputStream 属于抽象装饰者，装饰者用于装饰组件，为组件提供额外的功能。例如 BufferedInputStream 为 FileInputStream 提供缓存的功能。\n\n\n实例化一个具有缓存功能的字节流对象时，只需要在 FileInputStream 对象上再套一层 BufferedInputStream 对象即可。\n12FileInputStream fileInputStream = new FileInputStream(filePath);BufferedInputStream bufferedInputStream = new BufferedInputStream(fileInputStream);\nDataInputStream 装饰者提供了对更多数据类型进行输入的操作，比如 int、double 等基本类型。\n 字符操作\n 编码与解码\n编码就是把字符转换为字节，而解码是把字节重新组合成字符。\n如果编码和解码过程使用不同的编码方式那么就出现了乱码。\n\nGBK 编码中，中文字符占 2 个字节，英文字符占 1 个字节；\nUTF-8 编码中，中文字符占 3 个字节，英文字符占 1 个字节；\nUTF-16be 编码中，中文字符和英文字符都占 2 个字节。\n\nUTF-16be 中的 be 指的是 Big Endian，也就是大端。相应地也有 UTF-16le，le 指的是 Little Endian，也就是小端。\nJava 的内存编码使用双字节编码 UTF-16be，这不是指 Java 只支持这一种编码方式，而是说 char 这种类型使用 UTF-16be 进行编码。char 类型占 16 位，也就是两个字节，Java 使用这种双字节编码是为了让一个中文或者一个英文都能使用一个 char 来存储。\n String 的编码方式\nString 可以看成一个字符序列，可以指定一个编码方式将它编码为字节序列，也可以指定一个编码方式将一个字节序列解码为 String。\n1234String str1 = \"中文\";byte[] bytes = str1.getBytes(\"UTF-8\");String str2 = new String(bytes, \"UTF-8\");System.out.println(str2);\n在调用无参数 getBytes() 方法时，默认的编码方式不是 UTF-16be。双字节编码的好处是可以使用一个 char 存储中文和英文，而将 String 转为 bytes[] 字节数组就不再需要这个好处，因此也就不再需要双字节编码。getBytes() 的默认编码方式与平台有关，一般为 UTF-8。\n1byte[] bytes = str1.getBytes();\n Reader 与 Writer\n不管是磁盘还是网络传输，最小的存储单元都是字节，而不是字符。但是在程序中操作的通常是字符形式的数据，因此需要提供对字符进行操作的方法。\n\nInputStreamReader 实现从字节流解码成字符流；\nOutputStreamWriter 实现字符流编码成为字节流。\n\n 实现逐行输出文本文件的内容\n123456789101112131415public static void readFileContent(String filePath) throws IOException &#123;    FileReader fileReader = new FileReader(filePath);    BufferedReader bufferedReader = new BufferedReader(fileReader);    String line;    while ((line = bufferedReader.readLine()) != null) &#123;        System.out.println(line);    &#125;    // 装饰者模式使得 BufferedReader 组合了一个 Reader 对象    // 在调用 BufferedReader 的 close() 方法时会去调用 Reader 的 close() 方法    // 因此只要一个 close() 调用即可    bufferedReader.close();&#125;\n 对象操作\n 序列化\n序列化就是将一个对象转换成字节序列，方便存储和传输。\n\n序列化：ObjectOutputStream.writeObject()\n反序列化：ObjectInputStream.readObject()\n\n不会对静态变量进行序列化，因为序列化只是保存对象的状态，静态变量属于类的状态。\n Serializable\n序列化的类需要实现 Serializable 接口，它只是一个标准，没有任何方法需要实现，但是如果不去实现它的话而进行序列化，会抛出异常。\n123456789101112131415161718192021222324252627282930public static void main(String[] args) throws IOException, ClassNotFoundException &#123;    A a1 = new A(123, \"abc\");    String objectFile = \"file/a1\";    ObjectOutputStream objectOutputStream = new ObjectOutputStream(new FileOutputStream(objectFile));    objectOutputStream.writeObject(a1);    objectOutputStream.close();    ObjectInputStream objectInputStream = new ObjectInputStream(new FileInputStream(objectFile));    A a2 = (A) objectInputStream.readObject();    objectInputStream.close();    System.out.println(a2);&#125;private static class A implements Serializable &#123;    private int x;    private String y;    A(int x, String y) &#123;        this.x = x;        this.y = y;    &#125;    @Override    public String toString() &#123;        return \"x = \" + x + \"  \" + \"y = \" + y;    &#125;&#125;\n transient\ntransient 关键字可以使一些属性不会被序列化。\nArrayList 中存储数据的数组 elementData 是用 transient 修饰的，因为这个数组是动态扩展的，并不是所有的空间都被使用，因此就不需要所有的内容都被序列化。通过重写序列化和反序列化方法，使得可以只序列化数组中有内容的那部分数据。\n1private transient Object[] elementData;\n 网络操作\nJava 中的网络支持：\n\nInetAddress：用于表示网络上的硬件资源，即 IP 地址；\nURL：统一资源定位符；\nSockets：使用 TCP 协议实现网络通信；\nDatagram：使用 UDP 协议实现网络通信。\n\n InetAddress\n没有公有的构造函数，只能通过静态方法来创建实例。\n12InetAddress.getByName(String host);InetAddress.getByAddress(byte[] address);\n URL\n可以直接从 URL 中读取字节流数据。\n1234567891011121314151617181920public static void main(String[] args) throws IOException &#123;    URL url = new URL(\"http://www.baidu.com\");    /* 字节流 */    InputStream is = url.openStream();    /* 字符流 */    InputStreamReader isr = new InputStreamReader(is, \"utf-8\");    /* 提供缓存功能 */    BufferedReader br = new BufferedReader(isr);    String line;    while ((line = br.readLine()) != null) &#123;        System.out.println(line);    &#125;    br.close();&#125;\n Sockets\n\nServerSocket：服务器端类\nSocket：客户端类\n服务器和客户端通过 InputStream 和 OutputStream 进行输入输出。\n\n\n Datagram\n\nDatagramSocket：通信类\nDatagramPacket：数据包类\n\n NIO\n新的输入/输出 (NIO) 库是在 JDK 1.4 中引入的，弥补了原来的 I/O 的不足，提供了高速的、面向块的 I/O。\n 流与块\nI/O 与 NIO 最重要的区别是数据打包和传输的方式，I/O 以流的方式处理数据，而 NIO 以块的方式处理数据。\n面向流的 I/O 一次处理一个字节数据：一个输入流产生一个字节数据，一个输出流消费一个字节数据。为流式数据创建过滤器非常容易，链接几个过滤器，以便每个过滤器只负责复杂处理机制的一部分。不利的一面是，面向流的 I/O 通常相当慢。\n面向块的 I/O 一次处理一个数据块，按块处理数据比按流处理数据要快得多。但是面向块的 I/O 缺少一些面向流的 I/O 所具有的优雅性和简单性。\nI/O 包和 NIO 已经很好地集成了，java.io.* 已经以 NIO 为基础重新实现了，所以现在它可以利用 NIO 的一些特性。例如，java.io.* 包中的一些类包含以块的形式读写数据的方法，这使得即使在面向流的系统中，处理速度也会更快。\n 通道与缓冲区\n 通道\n通道 Channel 是对原 I/O 包中的流的模拟，可以通过它读取和写入数据。\n通道与流的不同之处在于，流只能在一个方向上移动(一个流必须是 InputStream 或者 OutputStream 的子类)，而通道是双向的，可以用于读、写或者同时用于读写。\n通道包括以下类型：\n\nFileChannel：从文件中读写数据；\nDatagramChannel：通过 UDP 读写网络中数据；\nSocketChannel：通过 TCP 读写网络中数据；\nServerSocketChannel：可以监听新进来的 TCP 连接，对每一个新进来的连接都会创建一个 SocketChannel。\n\n 缓冲区\n发送给一个通道的所有数据都必须首先放到缓冲区中，同样地，从通道中读取的任何数据都要先读到缓冲区中。也就是说，不会直接对通道进行读写数据，而是要先经过缓冲区。\n缓冲区实质上是一个数组，但它不仅仅是一个数组。缓冲区提供了对数据的结构化访问，而且还可以跟踪系统的读/写进程。\n缓冲区包括以下类型：\n\nByteBuffer\nCharBuffer\nShortBuffer\nIntBuffer\nLongBuffer\nFloatBuffer\nDoubleBuffer\n\n 缓冲区状态变量\n\ncapacity：最大容量；\nposition：当前已经读写的字节数；\nlimit：还可以读写的字节数。\n\n状态变量的改变过程举例：\n① 新建一个大小为 8 个字节的缓冲区，此时 position 为 0，而 limit = capacity = 8。capacity 变量不会改变，下面的讨论会忽略它。\n\n② 从输入通道中读取 5 个字节数据写入缓冲区中，此时 position 为 5，limit 保持不变。\n\n③ 在将缓冲区的数据写到输出通道之前，需要先调用 flip() 方法，这个方法将 limit 设置为当前 position，并将 position 设置为 0。\n\n④ 从缓冲区中取 4 个字节到输出缓冲中，此时 position 设为 4。\n\n⑤ 最后需要调用 clear() 方法来清空缓冲区，此时 position 和 limit 都被设置为最初位置。\n\n 文件 NIO 实例\n以下展示了使用 NIO 快速复制文件的实例：\n12345678910111213141516171819202122232425262728293031323334353637public static void fastCopy(String src, String dist) throws IOException &#123;    /* 获得源文件的输入字节流 */    FileInputStream fin = new FileInputStream(src);    /* 获取输入字节流的文件通道 */    FileChannel fcin = fin.getChannel();    /* 获取目标文件的输出字节流 */    FileOutputStream fout = new FileOutputStream(dist);    /* 获取输出字节流的文件通道 */    FileChannel fcout = fout.getChannel();    /* 为缓冲区分配 1024 个字节 */    ByteBuffer buffer = ByteBuffer.allocateDirect(1024);    while (true) &#123;        /* 从输入通道中读取数据到缓冲区中 */        int r = fcin.read(buffer);        /* read() 返回 -1 表示 EOF */        if (r == -1) &#123;            break;        &#125;        /* 切换读写 */        buffer.flip();        /* 把缓冲区的内容写入输出文件中 */        fcout.write(buffer);        /* 清空缓冲区 */        buffer.clear();    &#125;&#125;\n 选择器\nNIO 常常被叫做非阻塞 IO，主要是因为 NIO 在网络通信中的非阻塞特性被广泛使用。\nNIO 实现了 IO 多路复用中的 Reactor 模型，一个线程 Thread 使用一个选择器 Selector 通过轮询的方式去监听多个通道 Channel 上的事件，从而让一个线程就可以处理多个事件。\n通过配置监听的通道 Channel 为非阻塞，那么当 Channel 上的 IO 事件还未到达时，就不会进入阻塞状态一直等待，而是继续轮询其它 Channel，找到 IO 事件已经到达的 Channel 执行。\n因为创建和切换线程的开销很大，因此使用一个线程来处理多个事件而不是一个线程处理一个事件，对于 IO 密集型的应用具有很好地性能。\n应该注意的是，只有套接字 Channel 才能配置为非阻塞，而 FileChannel 不能，为 FileChannel 配置非阻塞也没有意义。\n\n 1. 创建选择器\n1Selector selector = Selector.open();\n 2. 将通道注册到选择器上\n123ServerSocketChannel ssChannel = ServerSocketChannel.open();ssChannel.configureBlocking(false);ssChannel.register(selector, SelectionKey.OP_ACCEPT);\n通道必须配置为非阻塞模式，否则使用选择器就没有任何意义了，因为如果通道在某个事件上被阻塞，那么服务器就不能响应其它事件，必须等待这个事件处理完毕才能去处理其它事件，显然这和选择器的作用背道而驰。\n在将通道注册到选择器上时，还需要指定要注册的具体事件，主要有以下几类：\n\nSelectionKey.OP_CONNECT\nSelectionKey.OP_ACCEPT\nSelectionKey.OP_READ\nSelectionKey.OP_WRITE\n\n它们在 SelectionKey 的定义如下：\n1234public static final int OP_READ = 1 &lt;&lt; 0;public static final int OP_WRITE = 1 &lt;&lt; 2;public static final int OP_CONNECT = 1 &lt;&lt; 3;public static final int OP_ACCEPT = 1 &lt;&lt; 4;\n可以看出每个事件可以被当成一个位域，从而组成事件集整数。例如：\n1int interestSet = SelectionKey.OP_READ | SelectionKey.OP_WRITE;\n 3. 监听事件\n1int num = selector.select();\n使用 select() 来监听到达的事件，它会一直阻塞直到有至少一个事件到达。\n 4. 获取到达的事件\n1234567891011Set&lt;SelectionKey&gt; keys = selector.selectedKeys();Iterator&lt;SelectionKey&gt; keyIterator = keys.iterator();while (keyIterator.hasNext()) &#123;    SelectionKey key = keyIterator.next();    if (key.isAcceptable()) &#123;        // ...    &#125; else if (key.isReadable()) &#123;        // ...    &#125;    keyIterator.remove();&#125;\n 5. 事件循环\n因为一次 select() 调用不能处理完所有的事件，并且服务器端有可能需要一直监听事件，因此服务器端处理事件的代码一般会放在一个死循环内。\n1234567891011121314while (true) &#123;    int num = selector.select();    Set&lt;SelectionKey&gt; keys = selector.selectedKeys();    Iterator&lt;SelectionKey&gt; keyIterator = keys.iterator();    while (keyIterator.hasNext()) &#123;        SelectionKey key = keyIterator.next();        if (key.isAcceptable()) &#123;            // ...        &#125; else if (key.isReadable()) &#123;            // ...        &#125;        keyIterator.remove();    &#125;&#125;\n 套接字 NIO 实例\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778public class NIOServer &#123;    public static void main(String[] args) throws IOException \t\t&#123;        Selector selector = Selector.open();        ServerSocketChannel ssChannel = ServerSocketChannel.open();        ssChannel.configureBlocking(false);        ssChannel.register(selector, SelectionKey.OP_ACCEPT);        ServerSocket serverSocket = ssChannel.socket();        InetSocketAddress address = new InetSocketAddress(\"127.0.0.1\", 8888);        serverSocket.bind(address);        while (true) &#123;            selector.select();            Set&lt;SelectionKey&gt; keys = selector.selectedKeys();            Iterator&lt;SelectionKey&gt; keyIterator = keys.iterator();            while (keyIterator.hasNext()) &#123;                SelectionKey key = keyIterator.next();                if (key.isAcceptable()) &#123;                    ServerSocketChannel ssChannel1 = (ServerSocketChannel) key.channel();                    // 服务器会为每个新连接创建一个 SocketChannel                    SocketChannel sChannel = ssChannel1.accept();                    sChannel.configureBlocking(false);                    // 这个新连接主要用于从客户端读取数据                    sChannel.register(selector, SelectionKey.OP_READ);                &#125; else if (key.isReadable()) &#123;                    SocketChannel sChannel = (SocketChannel) key.channel();                    System.out.println(readDataFromSocketChannel(sChannel));                    sChannel.close();                &#125;                keyIterator.remove();            &#125;        &#125;    &#125;    private static String readDataFromSocketChannel(SocketChannel sChannel) throws IOException &#123;        ByteBuffer buffer = ByteBuffer.allocate(1024);        StringBuilder data = new StringBuilder();        while (true) &#123;            buffer.clear();            int n = sChannel.read(buffer);            if (n == -1) &#123;                break;            &#125;            buffer.flip();            int limit = buffer.limit();            char[] dst = new char[limit];            for (int i = 0; i &lt; limit; i++) &#123;                dst[i] = (char) buffer.get(i);            &#125;            data.append(dst);            buffer.clear();        &#125;        return data.toString();    &#125;&#125;public class NIOClient &#123;    public static void main(String[] args) throws IOException \t\t&#123;        Socket socket = new Socket(\"127.0.0.1\", 8888);        OutputStream out = socket.getOutputStream();        String s = \"hello world\";        out.write(s.getBytes());        out.close();    &#125;&#125;\n 内存映射文件\n内存映射文件 I/O 是一种读和写文件数据的方法，它可以比常规的基于流或者基于通道的 I/O 快得多。\n向内存映射文件写入可能是危险的，只是改变数组的单个元素这样的简单操作，就可能会直接修改磁盘上的文件。修改数据与将数据保存到磁盘是没有分开的。\n下面代码行将文件的前 1024 个字节映射到内存中，map() 方法返回一个 MappedByteBuffer，它是 ByteBuffer 的子类。因此，可以像使用其他任何 ByteBuffer 一样使用新映射的缓冲区，操作系统会在需要时负责执行映射。\n1MappedByteBuffer mbb = fc.map(FileChannel.MapMode.READ_WRITE, 0, 1024);\n 对比\nNIO 与普通 I/O 的区别主要有以下两点：\n\nNIO 是非阻塞的；\nNIO 面向块，I/O 面向流。\n\n","plink":"ilucia.github.io/java1.8/IO-NIO/"},{"title":"java1.8/Stream","date":"2022-04-27T15:24:01.719Z","updated":"2022-04-27T15:24:01.719Z","content":" Stream 简介\n\nJava 8 中，引入了流（Stream）的概念，这个流和以前我们使用的 IO 中的流并不太相同\n所有继承自 Collection 的接口都可以转换为 Stream\n\n 例\n假设我们有一个 List 包含一系列的 Person，Person 有姓名 name 和年龄 age 连个字段。现要求这个列表中年龄大于 20 的人数\n通常按照以前我们可能会这么写：\n123456long count = 0;for (Person p : persons) &#123;\tif (p.getAge() &gt; 20) &#123;\t\tcount ++;\t&#125;&#125;\n但如果使用 stream 的话，则会简单很多:\n123long count = persons.stream()\t\t\t\t\t.filter(person -&gt; person.getAge() &gt; 20) \t\t\t\t\t.count();\n这只是 stream 的很简单的一个用法。现在链式调用方法算是一个主流，这样写也更利于阅读和理解编写者的意图，一步方法做一件事\n Stream 常用操作\n\nStream 的方法分为两类。一类叫惰性求值，一类叫及早求值。\n如果返回值是 Stream，那么是惰性求值\n\n如果调用惰性求值方法，Stream 只是记录下了这个惰性求值方法的过程，并没有去计算，等到调用及早求值方法后，就连同前面的一系列惰性求值方法顺序进行计算，返回结果\n\n\n\n通用形式为：\n1Stream.惰性求值.惰性求值. ... .惰性求值.及早求值\n整个过程和建造者模式有共通之处。建造者模式使用一系列操作设置属性和配置，最后调 用一个 build 方法，这时，对象才被真正创建\n collect(toList())\ncollect(toList()) 方法由 Stream 里的值生成一个列表，是一个及早求值操作，可以理解为 Stream 向 Collection 的转换\n\n注意这边的 toList() 其实是 Collectors.toList()，因为采用了静态倒入，看起来显得简洁。\n\n123List&lt;String&gt; collected = Stream.of(\"a\", \"b\", \"c\")\t\t\t\t\t\t\t   .collect(Collectors.toList());assertEquals(Arrays.asList(\"a\", \"b\", \"c\"), collected);\n map\n如果有一个函数可以将一种类型的值转换成另外一种类型，map 操作就可以使用该函数，将一个流中的值转换成一个新的流。\n\n1234List&lt;String&gt; collected = Stream.of(\"a\", \"b\", \"hello\")\t\t\t\t\t\t\t   .map(string -&gt; string.toUpperCase())\t\t\t\t\t\t\t   .collect(toList());assertEquals(asList(\"A\", \"B\", \"HELLO\"), collected);\nmap 方法就是接受的一个 Function 的匿名函数类，进行的转换。\n\n filter\n遍历数据并检查其中的元素时，可尝试使用 Stream 中提供的新方法 filter。\n\n12345List&lt;String&gt; beginningWithNumbers = \t\tStream.of(\"a\", \"1abc\", \"abc1\")\t\t\t  .filter(value -&gt; isDigit(value.charAt(0)))\t\t\t  .collect(toList());assertEquals(asList(\"1abc\"), beginningWithNumbers);\nfilter 方法就是接受的一个 Predicate 的匿名函数类，判断对象是否符合条件，符合条件的才保留下来。\n\n flatMap\nflatMap 方法可用 Stream 替换值，然后将多个 Stream 连接成一个 Stream。\n\n1234List&lt;Integer&gt; together = Stream.of(asList(1, 2), asList(3, 4))\t\t\t\t\t\t\t   .flatMap(numbers -&gt; numbers.stream())\t\t\t\t\t\t\t   .collect(toList());assertEquals(asList(1, 2, 3, 4), together);\nflatMap 最常用的操作就是合并多个 Collection。\n max和min\nStream 上常用的操作之一是求最大值和最小值。Stream API 中的 max 和 min 操作足以解决这一问题。\n123456789List&lt;Integer&gt; list = Lists.newArrayList(3, 5, 2, 9, 1);int maxInt = list.stream()\t\t\t\t .max(Integer::compareTo)\t\t\t\t .get();int minInt = list.stream()\t\t\t\t .min(Integer::compareTo)\t\t\t\t .get();assertEquals(maxInt, 9);assertEquals(minInt, 1);\n这里有 2 个要点需要注意：\n\nmax 和 min 方法返回的是一个 Optional 对象（和 Google Guava 里的 Optional 对象是一样的）。Optional 对象封装的就是实际的值，可能为空，所以保险起见，可以先用 isPresent() 方法判断一下。Optional 的引入就是为了解决方法返回 null 的问题。\nInteger::compareTo 也是属于 Java 8 引入的新特性，叫做 方法引用（Method References）。在这边，其实就是 (int1, int2) -&gt; int1.compareTo(int2) 的简写，可以自己查阅了解，这里不再多做赘述。\n\n reduce\nreduce 操作可以实现从一组值中生成一个值。在上述例子中用到的 count、min 和 max 方法,因为常用而被纳入标准库中。事实上，这些方法都是 reduce 操作。\n\n上图展示了 reduce 进行累加的一个过程。具体的代码如下：\n123int result = Stream.of(1, 2, 3, 4)\t\t\t\t   .reduce(0, (acc, element) -&gt; acc + element);assertEquals(10, result);\n注意 reduce 的第一个参数，这是一个初始值。0 + 1 + 2 + 3 + 4 = 10。\n如果是累乘，则为：\n123int result = Stream.of(1, 2, 3, 4)\t\t\t\t   .reduce(1, (acc, element) -&gt; acc * element);assertEquals(24, result);\n 数据并行化操作\nStream 的并行化也是 Java 8 的一大亮点。数据并行化是指将数据分成块，为每块数据分配单独的处理单元。这样可以充分利用多核 CPU 的优势。\n并行化操作流只需改变一个方法调用。如果已经有一个 Stream 对象，调用它的 parallel() 方法就能让其拥有并行操作的能力。如果想从一个集合类创建一个流，调用 parallelStream() 就能立即获得一个拥有并行能力的流。\n123456int sumSize = Stream.of(\"Apple\", \"Banana\", \"Orange\", \"Pear\")\t\t\t\t\t.parallel()\t\t\t\t\t.map(s -&gt; s.length())\t\t\t\t\t.reduce(Integer::sum)\t\t\t\t\t.get();assertEquals(sumSize, 21);\n这里求的是一个字符串列表中各个字符串长度总和。\n\n如果你去计算这段代码所花的时间，很可能比不加上 parallel() 方法花的时间更长。这是因为数据并行化会先对数据进行分块，然后对每块数据开辟线程进行运算，这些地方会花费额外的时间。并行化操作只有在 数据规模比较大 或者 数据的处理时间比较长 的时候才能体现出有事，所以并不是每个地方都需要让数据并行化，应该具体问题具体分析。\n 其他\n 收集器\nStream 转换为 List 是很常用的操作，其他 Collectors 还有很多方法，可以将 Stream 转换为 Set, 或者将数据分组并转换为 Map，并对数据进行处理。也可以指定转换为具体类型，如 ArrayList, LinkedList 或者 HashMap。甚至可以自定义 Collectors，编写自己的收集器。\n 元素顺序\n另外一个尚未提及的关于集合类的内容是流中的元素以何种顺序排列。一些集合类型中的元素是按顺序排列的，比如 List；而另一些则是无序的，比如 HashSet。增加了流操作后，顺序问题变得更加复杂。\n总之记住。如果集合本身就是无序的，由此生成的流也是无序的。一些中间操作会产生顺序，比如对值做映射时，映射后的值是有序的，这种顺序就会保留 下来。如果进来的流是无序的，出去的流也是无序的。\n如果我们需要对流中的数据进行排序，可以调用 sorted 方法：\n12345List&lt;Integer&gt; list = Lists.newArrayList(3, 5, 1, 10, 8);List&lt;Integer&gt; sortedList = list.stream()\t\t\t\t\t\t\t   .sorted(Integer::compareTo)\t\t\t\t\t\t\t   .collect(Collectors.toList());assertEquals(sortedList, Lists.newArrayList(1, 3, 5, 8, 10));\n @FunctionalInterface\n我们讨论过函数接口定义的标准，但未提及 @FunctionalInterface 注释。事实上，每个用作函数接口的接口都应该添加这个注释。\n但 Java 中有一些接口，虽然只含一个方法，但并不是为了使用 Lambda 表达式来实现的。比如，有些对象内部可能保存着某种状态，使用带有一个方法的接口可能纯属巧合。\n该注释会强制 javac 检查一个接口是否符合函数接口的标准。如果该注释添加给一个枚举类型、类或另一个注释，或者接口包含不止一个抽象方法，javac 就会报错。重构代码时，使用它能很容易发现问题。\n","plink":"ilucia.github.io/java1.8/Stream/"},{"title":"Redis","date":"2022-04-27T15:24:01.595Z","updated":"2022-04-27T15:24:01.595Z","content":" Redis\n Redis特性\n注意：Redis支持多个数据库，并且每个数据库的数据是隔离的不能共享，并且基于单机才有，如果是集群就没有数据库的概念。\nRedis是一个字典结构的存储服务器，而实际上一个Redis实例提供了多个用来存储数据的字典，客户端可以指定将数据存储在哪个字典中。这与我们熟知的在一个关系数据库实例中可以创建多个数据库类似，所以可以将其中的每个字典都理解成一个独立的数据库。\n每个数据库对外都是一个从0开始的递增数字命名，Redis默认支持16个数据库（可以通过配置文件支持更多，无上限），可以通过配置databases来修改这一数字。客户端与Redis建立连接后会自动选择0号数据库，不过可以随时使用SELECT命令更换数据库，如要选择1号数据库：\n1234redis&gt; SELECT 1OKredis [1] &gt; GET foo(nil)\n然而这些以数字命名的数据库又与我们理解的数据库有所区别。首先Redis不支持自定义数据库的名字，每个数据库都以编号命名，开发者必须自己记录哪些数据库存储了哪些数据。另外Redis也不支持为每个数据库设置不同的访问密码，所以一个客户端要么可以访问全部数据库，要么连一个数据库也没有权限访问。最重要的一点是多个数据库之间并不是完全隔离的，比如FLUSHALL命令可以清空一个Redis实例中所有数据库中的数据。综上所述，这些数据库更像是一种命名空间，而不适宜存储不同应用程序的数据。比如可以使用0号数据库存储某个应用生产环境中的数据，使用1号数据库存储测试环境中的数据，但不适宜使用0号数据库存储A应用的数据而使用1号数据库B应用的数据，不同的应用应该使用不同的Redis实例存储数据。由于Redis非常轻量级，一个空Redis实例占用的内存只有1M左右，所以不用担心多个Redis实例会额外占用很多内存。\n Redis配置\n 查看配置\n 语法\nRedis CONFIG 命令格式如下：redis 127.0.0.1:6379&gt; CONFIG GET CONFIG_SETTING_NAME\n 实例\n1234redis 127.0.0.1:6379&gt; CONFIG GET loglevel1) &quot;loglevel&quot;2) &quot;notice&quot;\n使用 ***** 号获取所有配置项\n 编辑配置\n你可以通过修改 redis.conf 文件或使用 CONFIG set 命令来修改配置。\n 语法\nCONFIG SET 命令基本语法：\n1redis 127.0.0.1:6379&gt; CONFIG SET CONFIG_SETTING_NAME NEW_CONFIG_VALUE\n 实例\n123456redis 127.0.0.1:6379&gt; CONFIG SET loglevel &quot;notice&quot;OKredis 127.0.0.1:6379&gt; CONFIG GET loglevel1) &quot;loglevel&quot;2) &quot;notice&quot;\n 参数说明\nredis.conf 配置项说明如下：\n\n\n\n序号\n配置项\n说明\n\n\n\n\n1\ndaemonize no\nRedis 默认不是以守护进程的方式运行，可以通过该配置项修改，使用 yes 启用守护进程（Windows 不支持守护线程的配置为 no ）\n\n\n2\npidfile /var/run/redis.pid\n当 Redis 以守护进程方式运行时，Redis 默认会把 pid 写入 /var/run/redis.pid 文件，可以通过 pidfile 指定\n\n\n3\nport 6379\n指定 Redis 监听端口，默认端口为 6379，作者在自己的一篇博文中解释了为什么选用 6379 作为默认端口，因为 6379 在手机按键上 MERZ 对应的号码，而 MERZ 取自意大利歌女 Alessia Merz 的名字\n\n\n4\nbind 127.0.0.1\n绑定的主机地址\n\n\n5\ntimeout 300\n当客户端闲置多长秒后关闭连接，如果指定为 0 ，表示关闭该功能\n\n\n6\nloglevel notice\n指定日志记录级别，Redis 总共支持四个级别：debug、verbose、notice、warning，默认为 notice\n\n\n7\nlogfile stdout\n日志记录方式，默认为标准输出，如果配置 Redis 为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给 /dev/null\n\n\n8\ndatabases 16\n设置数据库的数量，默认数据库为0，可以使用SELECT 命令在连接上指定数据库id\n\n\n9\nsave &lt;seconds&gt; &lt;changes&gt;Redis 默认配置文件中提供了三个条件：save 900 1   save 300 10   save 60 10000分别表示 900 秒（15 分钟）内有 1 个更改，300ß 秒（5 分钟）内有 10 个更改以及 60 秒内有 10000 个更改。\n指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合\n\n\n10\nrdbcompression yes\n指定存储至本地数据库时是否压缩数据，默认为 yes，Redis 采用 LZF 压缩，如果为了节省 CPU 时间，可以关闭该选项，但会导致数据库文件变的巨大\n\n\n11\ndbfilename dump.rdb\n指定本地数据库文件名，默认值为 dump.rdb\n\n\n12\ndir ./\n指定本地数据库存放目录\n\n\n13\nslaveof &lt;masterip&gt; &lt;masterport&gt;\n设置当本机为 slave 服务时，设置 master 服务的 IP 地址及端口，在 Redis 启动时，它会自动从 master 进行数据同步\n\n\n14\nmasterauth &lt;master-password&gt;\n当 master 服务设置了密码保护时，slav 服务连接 master 的密码\n\n\n15\nrequirepass foobared\n设置 Redis 连接密码，如果配置了连接密码，客户端在连接 Redis 时需要通过 AUTH  命令提供密码，默认关闭\n\n\n16\nmaxclients 128\n设置同一时间最大客户端连接数，默认无限制，Redis 可以同时打开的客户端连接数为 Redis 进程可以打开的最大文件描述符数，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis 会关闭新的连接并向客户端返回 max number of clients reached 错误信息\n\n\n17\nmaxmemory &lt;bytes&gt;\n指定 Redis 最大内存限制，Redis 在启动时会把数据加载到内存中，达到最大内存后，Redis 会先尝试清除已到期或即将到期的 Key，当此方法处理 后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis 新的 vm 机制，会把 Key 存放内存，Value 会存放在 swap 区\n\n\n18\nappendonly no\n指定是否在每次更新操作后进行日志记录，Redis 在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为 redis 本身同步数据文件是按上面 save 条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为 no\n\n\n19\nappendfilename appendonly.aof\n指定更新日志文件名，默认为 appendonly.aof\n\n\n20\nappendfsync everysec\n指定更新日志条件，共有 3 个可选值：no：表示等操作系统进行数据缓存同步到磁盘（快）always：表示每次更新操作后手动调用 fsync() 将数据写到磁盘（慢，安全）everysec：表示每秒同步一次（折中，默认值）\n\n\n21\nvm-enabled no\n指定是否启用虚拟内存机制，默认值为 no，简单的介绍一下，VM 机制将数据分页存放，由 Redis 将访问量较少的页即冷数据 swap 到磁盘上，访问多的页面由磁盘自动换出到内存中（在后面的文章我会仔细分析 Redis 的 VM 机制）\n\n\n22\nvm-swap-file /tmp/redis.swap\n虚拟内存文件路径，默认值为 /tmp/redis.swap，不可多个 Redis 实例共享\n\n\n23\nvm-max-memory 0\n将所有大于 vm-max-memory 的数据存入虚拟内存，无论 vm-max-memory 设置多小，所有索引数据都是内存存储的(Redis 的索引数据 就是 keys)，也就是说，当 vm-max-memory 设置为 0 的时候，其实是所有 value 都存在于磁盘。默认值为 0\n\n\n24\nvm-page-size 32\nRedis swap 文件分成了很多的 page，一个对象可以保存在多个 page 上面，但一个 page 上不能被多个对象共享，vm-page-size 是要根据存储的 数据大小来设定的，作者建议如果存储很多小对象，page 大小最好设置为 32 或者 64bytes；如果存储很大大对象，则可以使用更大的 page，如果不确定，就使用默认值\n\n\n25\nvm-pages 134217728\n设置 swap 文件中的 page 数量，由于页表（一种表示页面空闲或使用的 bitmap）是在放在内存中的，，在磁盘上每 8 个 pages 将消耗 1byte 的内存。\n\n\n26\nvm-max-threads 4\n设置访问swap文件的线程数,最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为4\n\n\n27\nglueoutputbuf yes\n设置在向客户端应答时，是否把较小的包合并为一个包发送，默认为开启\n\n\n28\nhash-max-zipmap-entries 64 hash-max-zipmap-value 512\n指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法\n\n\n29\nactiverehashing yes\n指定是否激活重置哈希，默认为开启（后面在介绍 Redis 的哈希算法时具体介绍）\n\n\n30\ninclude /path/to/local.conf\n指定包含其它的配置文件，可以在同一主机上多个Redis实例之间使用同一份配置文件，而同时各个实例又拥有自己的特定配置文件\n\n\n\n Redis 数据类型\nRedis支持五种数据类型：string（字符串），hash（哈希），list（列表），set（集合）及zset(sorted set：有序集合)。\n String（字符串）\nstring 是 redis 最基本的类型，你可以理解成与 Memcached 一模一样的类型，一个 key 对应一个 value。\nstring 类型是二进制安全的。意思是 redis 的 string 可以包含任何数据。比如jpg图片或者序列化的对象。\nstring 类型是 Redis 最基本的数据类型，string 类型的值最大能存储 512MB。\n 实例\n1234redis 127.0.0.1:6379&gt; SET runoob &quot;菜鸟教程&quot;OKredis 127.0.0.1:6379&gt; GET runoob&quot;菜鸟教程&quot;\n在以上实例中我们使用了 Redis 的 SET 和 GET 命令。键为 runoob，对应的值为 菜鸟教程。\n**注意：**一个键最大能存储 512MB。\n Hash（哈希）\nRedis hash 是一个键值(key=&gt;value)对集合。\nRedis hash 是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象。\n 实例\nDEL runoob 用于删除前面测试用过的 key，不然会报错：(error) WRONGTYPE Operation against a key holding the wrong kind of value\n\n1234567redis 127.0.0.1:6379&gt; DEL runoobredis 127.0.0.1:6379&gt; HMSET runoob field1 &quot;Hello&quot; field2 &quot;World&quot;&quot;OK&quot;redis 127.0.0.1:6379&gt; HGET runoob field1&quot;Hello&quot;redis 127.0.0.1:6379&gt; HGET runoob field2&quot;World&quot;\n实例中我们使用了 Redis HMSET, HGET 命令，HMSET 设置了两个 field=&gt;value 对, HGET 获取对应 field 对应的 value。\n每个 hash 可以存储 2^32 -1 键值对（40多亿）。\n List（列表）\nRedis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。\n 实例\n123456789101112redis 127.0.0.1:6379&gt; DEL runoobredis 127.0.0.1:6379&gt; lpush runoob redis(integer) 1redis 127.0.0.1:6379&gt; lpush runoob mongodb(integer) 2redis 127.0.0.1:6379&gt; lpush runoob rabitmq(integer) 3redis 127.0.0.1:6379&gt; lrange runoob 0 101) &quot;rabitmq&quot;2) &quot;mongodb&quot;3) &quot;redis&quot;redis 127.0.0.1:6379&gt;\n列表最多可存储 2^32 - 1 元素 (4294967295, 每个列表可存储40多亿)。\n Set（集合）\nRedis 的 Set 是 string 类型的无序集合。\n集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。\n sadd 命令\n添加一个 string 元素到 key 对应的 set 集合中，成功返回 1，如果元素已经在集合中返回 0。\n1sadd key member\n 实例\n1234567891011121314redis 127.0.0.1:6379&gt; DEL runoobredis 127.0.0.1:6379&gt; sadd runoob redis(integer) 1redis 127.0.0.1:6379&gt; sadd runoob mongodb(integer) 1redis 127.0.0.1:6379&gt; sadd runoob rabitmq(integer) 1redis 127.0.0.1:6379&gt; sadd runoob rabitmq(integer) 0redis 127.0.0.1:6379&gt; smembers runoob1) &quot;redis&quot;2) &quot;rabitmq&quot;3) &quot;mongodb&quot;\n**注意：**以上实例中 rabitmq 添加了两次，但根据集合内元素的唯一性，第二次插入的元素将被忽略。\n集合中最大的成员数为 232 - 1(4294967295, 每个集合可存储40多亿个成员)。\n zset(sorted set：有序集合)\nRedis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。\n不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。\nzset的成员是唯一的,但分数(score)却可以重复。\n zadd 命令\n添加元素到集合，元素在集合中存在则更新对应score\n1zadd key score member\n 实例\n12345678910111213redis 127.0.0.1:6379&gt; DEL runoobredis 127.0.0.1:6379&gt; zadd runoob 0 redis(integer) 1redis 127.0.0.1:6379&gt; zadd runoob 0 mongodb(integer) 1redis 127.0.0.1:6379&gt; zadd runoob 0 rabitmq(integer) 1redis 127.0.0.1:6379&gt; zadd runoob 0 rabitmq(integer) 0redis 127.0.0.1:6379&gt; &gt; ZRANGEBYSCORE runoob 0 10001) &quot;mongodb&quot;2) &quot;rabitmq&quot;3) &quot;redis&quot;\n 各个数据类型应用场景\n\n\n\n类型\n简介\n特性\n场景\n\n\n\n\nString(字符串)\n二进制安全\n可以包含任何数据,比如jpg图片或者序列化的对象,一个键最大能存储512M\n—\n\n\nHash(字典)\n键值对集合,即编程语言中的Map类型\n适合存储对象,并且可以像数据库中update一个属性一样只修改某一项属性值(Memcached中需要取出整个字符串反序列化成对象修改完再序列化存回去)\n存储、读取、修改用户属性\n\n\nList(列表)\n链表(双向链表)\n增删快,提供了操作某一段元素的API\n1,最新消息排行等功能(比如朋友圈的时间线) 2,消息队列\n\n\nSet(集合)\n哈希表实现,元素不重复\n1、添加、删除,查找的复杂度都是O(1) 2、为集合提供了求交集、并集、差集等操作\n1、共同好友 2、利用唯一性,统计访问网站的所有独立ip 3、好友推荐时,根据tag求交集,大于某个阈值就可以推荐\n\n\nSorted Set(有序集合)\n将Set中的元素增加一个权重参数score,元素按score有序排列\n数据插入集合时,已经进行天然排序\n1、排行榜 2、带权重的消息队列\n\n\n\n Redis命令\n 客户端命令\n\n启动客户端redis-cli --raw\n\n--raw用于防止中文乱码\n\n\n\n 远程服务\n\nredis-cli -h host -p port -a password\n\n 键命令\n 语法\nRedis 键命令的基本语法如下：\n1redis 127.0.0.1:6379&gt; COMMAND KEY_NAME\n 实例\n1234redis 127.0.0.1:6379&gt; SET runoobkey redisOKredis 127.0.0.1:6379&gt; DEL runoobkey(integer) 1\n在以上实例中 DEL 是一个命令， runoobkey 是一个键。 如果键被删除成功，命令执行后输出 (integer) 1，否则将输出 (integer) 0\n下表给出了与 Redis 键相关的基本命令：\n\n\n\n序号\n命令及描述\n\n\n\n\n1\nDEL key 该命令用于在 key 存在时删除 key。\n\n\n2\nDUMP key 序列化给定 key ，并返回被序列化的值。\n\n\n3\nEXISTS key 检查给定 key 是否存在。\n\n\n4\nEXPIRE key seconds 为给定 key 设置过期时间，以秒计。\n\n\n5\nEXPIREAT key timestamp EXPIREAT 的作用和 EXPIRE 类似，都用于为 key 设置过期时间。 不同在于 EXPIREAT 命令接受的时间参数是 UNIX 时间戳(unix timestamp)。\n\n\n6\nPEXPIRE key milliseconds 设置 key 的过期时间以毫秒计。\n\n\n7\nPEXPIREAT key milliseconds-timestamp 设置 key 过期时间的时间戳(unix timestamp) 以毫秒计\n\n\n8\nKEYS pattern 查找所有符合给定模式( pattern)的 key 。\n\n\n9\nMOVE key db 将当前数据库的 key 移动到给定的数据库 db 当中。\n\n\n\n 字符串命令\nRedis 字符串数据类型的相关命令用于管理 redis 字符串值，基本语法如下：\n 语法\n1redis 127.0.0.1:6379&gt; COMMAND KEY_NAME\n 实例\n1234redis 127.0.0.1:6379&gt; SET runoobkey redisOKredis 127.0.0.1:6379&gt; GET runoobkey&quot;redis&quot;\n在以上实例中我们使用了 SET 和 GET 命令，键为 runoobkey。\n下表列出了常用的 redis 字符串命令：\n\n\n\n序号\n命令及描述\n\n\n\n\n1\nSET key value 设置指定 key 的值\n\n\n2\nGET key 获取指定 key 的值。\n\n\n3\nGETRANGE key start end 返回 key 中字符串值的子字符\n\n\n4\nGETSET key value 将给定 key 的值设为 value ，并返回 key 的旧值(old value)。\n\n\n5\nGETBIT key offset 对 key 所储存的字符串值，获取指定偏移量上的位(bit)。\n\n\n6\n[MGET key1 key2…] 获取所有(一个或多个)给定 key 的值。\n\n\n7\nSETBIT key offset value 对 key 所储存的字符串值，设置或清除指定偏移量上的位(bit)。\n\n\n8\nSETEX key seconds value 将值 value 关联到 key ，并将 key 的过期时间设为 seconds (以秒为单位)。\n\n\n9\nSETNX key value 只有在 key 不存在时设置 key 的值。\n\n\n10\nSETRANGE key offset value 用 value 参数覆写给定 key 所储存的字符串值，从偏移量 offset 开始。\n\n\n11\nSTRLEN key 返回 key 所储存的字符串值的长度。\n\n\n12\n[MSET key value key value …] 同时设置一个或多个 key-value 对。\n\n\n13\nMSETNX key value \\[key value ...\\]同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在。\n\n\n14\nPSETEX key milliseconds value 这个命令和 SETEX 命令相似，但它以毫秒为单位设置 key 的生存时间，而不是像 SETEX 命令那样，以秒为单位。\n\n\n15\nINCR key 将 key 中储存的数字值增一。\n\n\n16\nINCRBY key increment 将 key 所储存的值加上给定的增量值（increment） 。\n\n\n17\nINCRBYFLOAT key increment 将 key 所储存的值加上给定的浮点增量值（increment） 。\n\n\n18\nDECR key 将 key 中储存的数字值减一。\n\n\n19\nDECRBY key decrement key 所储存的值减去给定的减量值（decrement） 。\n\n\n20\nAPPEND key value 如果 key 已经存在并且是一个字符串， APPEND 命令将指定的 value 追加到该 key 原来值（value）的末尾。\n\n\n\n 哈希命令\nRedis hash 是一个 string 类型的 field（字段） 和 value（值） 的映射表，hash 特别适合用于存储对象。\nRedis 中每个 hash 可以存储 232 - 1 键值对（40多亿）。\n 实例\n1234567891011127.0.0.1:6379&gt;  HMSET runoobkey name &quot;redis tutorial&quot; description &quot;redis basic commands for caching&quot; likes 20 visitors 23000OK127.0.0.1:6379&gt;  HGETALL runoobkey1) &quot;name&quot;2) &quot;redis tutorial&quot;3) &quot;description&quot;4) &quot;redis basic commands for caching&quot;5) &quot;likes&quot;6) &quot;20&quot;7) &quot;visitors&quot;8) &quot;23000&quot;\n在以上实例中，我们设置了 redis 的一些描述信息(name, description, likes, visitors) 到哈希表的 runoobkey 中。\n下表列出了 redis hash 基本的相关命令：\n\n\n\n序号\n命令及描述\n\n\n\n\n1\n[HDEL key field1 field2] 删除一个或多个哈希表字段\n\n\n2\nHEXISTS key field 查看哈希表 key 中，指定的字段是否存在。\n\n\n3\nHGET key field 获取存储在哈希表中指定字段的值。\n\n\n4\nHGETALL key 获取在哈希表中指定 key 的所有字段和值\n\n\n5\nHINCRBY key field increment 为哈希表 key 中的指定字段的整数值加上增量 increment 。\n\n\n6\nHINCRBYFLOAT key field increment 为哈希表 key 中的指定字段的浮点数值加上增量 increment 。\n\n\n7\nHKEYS key 获取所有哈希表中的字段\n\n\n8\nHLEN key 获取哈希表中字段的数量\n\n\n9\n[HMGET key field1 field2] 获取所有给定字段的值\n\n\n10\n[HMSET key field1 value1 field2 value2 ] 同时将多个 field-value (域-值)对设置到哈希表 key 中。\n\n\n11\nHSET key field value 将哈希表 key 中的字段 field 的值设为 value 。\n\n\n12\nHSETNX key field value 只有在字段 field 不存在时，设置哈希表字段的值。\n\n\n13\nHVALS key 获取哈希表中所有值。\n\n\n14\n[HSCAN key cursor MATCH pattern] [COUNT count] 迭代哈希表中的键值对。\n\n\n\n 列表命令\nRedis列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）\n一个列表最多可以包含 232 - 1 个元素 (4294967295, 每个列表超过40亿个元素)。\n 实例\n1234567891011redis 127.0.0.1:6379&gt; LPUSH runoobkey redis(integer) 1redis 127.0.0.1:6379&gt; LPUSH runoobkey mongodb(integer) 2redis 127.0.0.1:6379&gt; LPUSH runoobkey mysql(integer) 3redis 127.0.0.1:6379&gt; LRANGE runoobkey 0 101) &quot;mysql&quot;2) &quot;mongodb&quot;3) &quot;redis&quot;\n在以上实例中我们使用了 LPUSH 将三个值插入了名为 runoobkey 的列表当中。\n下表列出了列表相关的基本命令：\n\n\n\n序号\n命令及描述\n\n\n\n\n1\n[BLPOP key1 key2 ] timeout 移出并获取列表的第一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。\n\n\n2\n[BRPOP key1 key2 ] timeout 移出并获取列表的最后一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。\n\n\n3\nBRPOPLPUSH source destination timeout 从列表中弹出一个值，将弹出的元素插入到另外一个列表中并返回它； 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。\n\n\n4\nLINDEX key index 通过索引获取列表中的元素\n\n\n5\nLINSERT key BEFORE|AFTER pivot value 在列表的元素前或者后插入元素\n\n\n6\nLLEN key 获取列表长度\n\n\n7\nLPOP key 移出并获取列表的第一个元素\n\n\n8\nLPUSH key value1 value2] 将一个或多个值插入到列表头部\n\n\n9\nLPUSHX key value 将一个值插入到已存在的列表头部\n\n\n10\nLRANGE key start stop 获取列表指定范围内的元素\n\n\n11\nLREM key count value 移除列表元素\n\n\n12\nLSET key index value 通过索引设置列表元素的值\n\n\n13\nLTRIM key start stop 对一个列表进行修剪(trim)，就是说，让列表只保留指定区间内的元素，不在指定区间之内的元素都将被删除。\n\n\n14\nRPOP key 移除列表的最后一个元素，返回值为移除的元素。\n\n\n15\nRPOPLPUSH source destination 移除列表的最后一个元素，并将该元素添加到另一个列表并返回\n\n\n16\n[RPUSH key value1 value2] 在列表中添加一个或多个值\n\n\n17\nRPUSHX key value 为已存在的列表添加值\n\n\n\n 集合命令\nRedis 的 Set 是 String 类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据。\nRedis 中集合是通过哈希表实现的\n集合中最大的成员数为 232 - 1 (4294967295, 每个集合可存储40多亿个成员)。\n 实例\n12345678910111213redis 127.0.0.1:6379&gt; SADD runoobkey redis(integer) 1redis 127.0.0.1:6379&gt; SADD runoobkey mongodb(integer) 1redis 127.0.0.1:6379&gt; SADD runoobkey mysql(integer) 1redis 127.0.0.1:6379&gt; SADD runoobkey mysql(integer) 0redis 127.0.0.1:6379&gt; SMEMBERS runoobkey1) \"mysql\"2) \"mongodb\"3) \"redis\"\n在以上实例中我们通过 SADD 命令向名为 runoobkey 的集合插入的三个元素。\n下表列出了 Redis 集合基本命令：\n\n\n\n序号\n命令及描述\n\n\n\n\n1\n[SADD key member1 member2] 向集合添加一个或多个成员\n\n\n2\nSCARD key 获取集合的成员数\n\n\n3\n[SDIFF key1 key2] 返回给定所有集合的差集\n\n\n4\n[SDIFFSTORE destination key1 key2] 返回给定所有集合的差集并存储在 destination 中\n\n\n5\n[SINTER key1 key2] 返回给定所有集合的交集\n\n\n6\n[SINTERSTORE destination key1 key2] 返回给定所有集合的交集并存储在 destination 中\n\n\n7\nSISMEMBER key member 判断 member 元素是否是集合 key 的成员\n\n\n8\nSMEMBERS key 返回集合中的所有成员\n\n\n9\nSMOVE source destination member 将 member 元素从 source 集合移动到 destination 集合\n\n\n10\nSPOP key 移除并返回集合中的一个随机元素\n\n\n11\n[SRANDMEMBER key count] 返回集合中一个或多个随机数\n\n\n12\n[SREM key member1 member2] 移除集合中一个或多个成员\n\n\n13\n[SUNION key1 key2] 返回所有给定集合的并集\n\n\n14\n[SUNIONSTORE destination key1 key2] 所有给定集合的并集存储在 destination 集合中\n\n\n15\n[SSCAN key cursor MATCH pattern] [COUNT count] 迭代集合中的元素\n\n\n\n 有序集合\nRedis 有序集合和集合一样也是string类型元素的集合,且不允许重复的成员。\n不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。\n有序集合的成员是唯一的,但分数(score)却可以重复。\n tips\n在redis sorted sets里面当items内容大于64的时候同时使用了hash和skiplist两种设计实现。这也会为了排序和查找性能做的优化。所以如上可知：\n\n添加和删除都需要修改skiplist，所以复杂度为O(log(n))。\n但是如果仅仅是查找元素的话可以直接使用hash，其复杂度为O(1)\n其他的range操作复杂度一般为O(log(n))\n当然如果是小于64的时候，因为是采用了ziplist的设计，其时间复杂度为O(n)\n\n 实例\n123456789101112131415161718redis 127.0.0.1:6379&gt; ZADD runoobkey 1 redis(integer) 1redis 127.0.0.1:6379&gt; ZADD runoobkey 2 mongodb(integer) 1redis 127.0.0.1:6379&gt; ZADD runoobkey 3 mysql(integer) 1redis 127.0.0.1:6379&gt; ZADD runoobkey 3 mysql(integer) 0redis 127.0.0.1:6379&gt; ZADD runoobkey 4 mysql(integer) 0redis 127.0.0.1:6379&gt; ZRANGE runoobkey 0 10 WITHSCORES1) &quot;redis&quot;2) &quot;1&quot;3) &quot;mongodb&quot;4) &quot;2&quot;5) &quot;mysql&quot;6) &quot;4&quot;\n在以上实例中我们通过命令 ZADD 向 redis 的有序集合中添加了三个值并关联上分数。\n下表列出了 redis 有序集合的基本命令:\n\n\n\n序号\n命令及描述\n\n\n\n\n1\n[ZADD key score1 member1 score2 member2] 向有序集合添加一个或多个成员，或者更新已存在成员的分数\n\n\n2\nZCARD key 获取有序集合的成员数\n\n\n3\nZCOUNT key min max 计算在有序集合中指定区间分数的成员数\n\n\n4\nZINCRBY key increment member 有序集合中对指定成员的分数加上增量 increment\n\n\n5\n[ZINTERSTORE destination numkeys key key …] 计算给定的一个或多个有序集的交集并将结果集存储在新的有序集合 key 中\n\n\n6\nZLEXCOUNT key min max 在有序集合中计算指定字典区间内成员数量\n\n\n7\n[ZRANGE key start stop WITHSCORES] 通过索引区间返回有序集合指定区间内的成员\n\n\n8\n[ZRANGEBYLEX key min max LIMIT offset count] 通过字典区间返回有序集合的成员\n\n\n9\n[ZRANGEBYSCORE key min max WITHSCORES] [LIMIT] 通过分数返回有序集合指定区间内的成员\n\n\n10\nZRANK key member 返回有序集合中指定成员的索引\n\n\n11\n[ZREM key member member …] 移除有序集合中的一个或多个成员\n\n\n12\nZREMRANGEBYLEX key min max 移除有序集合中给定的字典区间的所有成员\n\n\n13\nZREMRANGEBYRANK key start stop 移除有序集合中给定的排名区间的所有成员\n\n\n14\nZREMRANGEBYSCORE key min max 移除有序集合中给定的分数区间的所有成员\n\n\n15\n[ZREVRANGE key start stop WITHSCORES] 返回有序集中指定区间内的成员，通过索引，分数从高到低\n\n\n16\nZREVRANGEBYSCORE key max min \\[WITHSCORES\\]返回有序集中指定分数区间内的成员，分数从高到低排序\n\n\n17\nZREVRANK key member 返回有序集合中指定成员的排名，有序集成员按分数值递减(从大到小)排序\n\n\n18\nZSCORE key member 返回有序集中，成员的分数值\n\n\n19\nZUNIONSTORE destination numkeys key \\[key ...\\]计算给定的一个或多个有序集的并集，并存储在新的 key 中\n\n\n20\n[ZSCAN key cursor MATCH pattern] [COUNT count] 迭代有序集合中的元素（包括元素成员和元素分值）\n\n\n\n HyperLogLog\nRedis 在 2.8.9 版本添加了 HyperLogLog 结构。\nRedis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的。\n在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基 数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。\n但是，因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。\n 什么是基数?\n比如数据集 {1, 3, 5, 7, 5, 7, 8}， 那么这个数据集的基数集为 {1, 3, 5 ,7, 8}, 基数(不重复元素)为5。 基数估计就是在误差可接受的范围内，快速计算基数。\n 实例\n以下实例演示了 HyperLogLog 的工作过程：\n1234567891011redis 127.0.0.1:6379&gt; PFADD runoobkey \"redis\"1) (integer) 1redis 127.0.0.1:6379&gt; PFADD runoobkey \"mongodb\"1) (integer) 1redis 127.0.0.1:6379&gt; PFADD runoobkey \"mysql\"1) (integer) 1redis 127.0.0.1:6379&gt; PFCOUNT runoobkey(integer) 3\n下表列出了 redis HyperLogLog 的基本命令：\n\n\n\n序号\n命令及描述\n\n\n\n\n1\nPFADD key element element … 添加指定元素到 HyperLogLog 中。\n\n\n2\n[PFCOUNT key key …] 返回给定 HyperLogLog 的基数估算值。\n\n\n3\n[PFMERGE destkey sourcekey sourcekey …] 将多个 HyperLogLog 合并为一个 HyperLogLog\n\n\n\n 发布订阅\nRedis 发布订阅(pub/sub)是一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息。\nRedis 客户端可以订阅任意数量的频道。\n下图展示了频道 channel1 ， 以及订阅这个频道的三个客户端 —— client2 、 client5 和 client1 之间的关系：\n\n当有新消息通过 PUBLISH 命令发送给频道 channel1 时， 这个消息就会被发送给订阅它的三个客户端：\n\n 实例\n以下实例演示了发布订阅是如何工作的。在我们实例中我们创建了订阅频道名为 redisChat:\n123456redis 127.0.0.1:6379&gt; SUBSCRIBE redisChatReading messages... (press Ctrl-C to quit)1) \"subscribe\"2) \"redisChat\"3) (integer) 1\n现在，我们先重新开启个 redis 客户端，然后在同一个频道 redisChat 发布两次消息，订阅者就能接收到消息。\n123456789101112131415redis 127.0.0.1:6379&gt; PUBLISH redisChat \"Redis is a great caching technique\"(integer) 1redis 127.0.0.1:6379&gt; PUBLISH redisChat \"Learn redis by runoob.com\"(integer) 1# 订阅者的客户端会显示如下消息1) \"message\"2) \"redisChat\"3) \"Redis is a great caching technique\"1) \"message\"2) \"redisChat\"3) \"Learn redis by runoob.com\"\n下表列出了 redis 发布订阅常用命令：\n\n\n\n序号\n命令及描述\n\n\n\n\n1\nPSUBSCRIBE pattern [pattern …]订阅一个或多个符合给定模式的频道。\n\n\n2\n[PUBSUB subcommand argument [argument …]] 查看订阅与发布系统状态。\n\n\n3\nPUBLISH channel message 将信息发送到指定的频道。\n\n\n4\n[PUNSUBSCRIBE pattern [pattern …]] 退订所有给定模式的频道。\n\n\n5\nSUBSCRIBE channel [channel …]订阅给定的一个或多个频道的信息。\n\n\n6\n[UNSUBSCRIBE channel [channel …]] 退订给定的频道。\n\n\n\n 事务\nRedis 事务可以一次执行多个命令， 并且带有以下三个重要的保证：\n\n批量操作在发送 EXEC 命令前被放入队列缓存。\n收到 EXEC 命令后进入事务执行，事务中任意命令执行失败，其余的命令依然被执行。\n在事务执行过程，其他客户端提交的命令请求不会插入到事务执行命令序列中。\n\n一个事务从开始到执行会经历以下三个阶段：\n\n开始事务。\n命令入队。\n执行事务。\n\n 实例\n以下是一个事务的例子， 它先以 MULTI 开始一个事务， 然后将多个命令入队到事务中， 最后由 EXEC 命令触发事务， 一并执行事务中的所有命令：\n12345678910111213141516171819202122redis 127.0.0.1:6379&gt; MULTIOKredis 127.0.0.1:6379&gt; SET book-name &quot;Mastering C++ in 21 days&quot;QUEUEDredis 127.0.0.1:6379&gt; GET book-nameQUEUEDredis 127.0.0.1:6379&gt; SADD tag &quot;C++&quot; &quot;Programming&quot; &quot;Mastering Series&quot;QUEUEDredis 127.0.0.1:6379&gt; SMEMBERS tagQUEUEDredis 127.0.0.1:6379&gt; EXEC1) OK2) &quot;Mastering C++ in 21 days&quot;3) (integer) 34) 1) &quot;Mastering Series&quot;   2) &quot;C++&quot;   3) &quot;Programming&quot;\n单个 Redis 命令的执行是原子性的，但 Redis 没有在事务上增加任何维持原子性的机制，所以 Redis 事务的执行并不是原子性的。\n事务可以理解为一个打包的批量执行脚本，但批量指令并非原子化的操作，中间某条指令的失败不会导致前面已做指令的回滚，也不会造成后续的指令不做。\n\n这是官网上的说明 From redis docs on transactions:\nIt’s important to note that even when a command fails, all the other commands in the queue are processed – Redis will not stop the processing of commands.\n\n比如：\n123456789101112redis 127.0.0.1:7000&gt; multiOKredis 127.0.0.1:7000&gt; set a aaaQUEUEDredis 127.0.0.1:7000&gt; set b bbbQUEUEDredis 127.0.0.1:7000&gt; set c cccQUEUEDredis 127.0.0.1:7000&gt; exec1) OK2) OK3) OK\n如果在 set b bbb 处失败，set a 已成功不会回滚，set c 还会继续执行。\n Redis 事务命令\n下表列出了 redis 事务的相关命令：\n\n\n\n序号\n命令及描述\n\n\n\n\n1\nDISCARD 取消事务，放弃执行事务块内的所有命令。\n\n\n2\nEXEC 执行所有事务块内的命令。\n\n\n3\nMULTI 标记一个事务块的开始。\n\n\n4\nUNWATCH 取消 WATCH 命令对所有 key 的监视。\n\n\n5\nWATCH key \\[key ...\\] 监视一个(或多个) key ，如果在事务执行之前这个(或这些) key 被其他命令所改动，那么事务将被打断。\n\n\n\n 脚本\nRedis 脚本使用 Lua 解释器来执行脚本。 Redis 2.6 版本通过内嵌支持 Lua 环境。执行脚本的常用命令为 EVAL。\n 语法\nEval 命令的基本语法如下：\n1redis 127.0.0.1:6379&gt; EVAL script numkeys key [key ...] arg [arg ...]\n 实例\n以下实例演示了 redis 脚本工作过程：\n123456redis 127.0.0.1:6379&gt; EVAL &quot;return &#123;KEYS[1],KEYS[2],ARGV[1],ARGV[2]&#125;&quot; 2 key1 key2 first second1) &quot;key1&quot;2) &quot;key2&quot;3) &quot;first&quot;4) &quot;second&quot;\n Redis 脚本命令\n下表列出了 redis 脚本常用命令：\n\n\n\n序号\n命令及描述\n\n\n\n\n1\n[EVAL script numkeys key key …] arg [arg …] 执行 Lua 脚本。\n\n\n2\n[EVALSHA sha1 numkeys key key …] arg [arg …] 执行 Lua 脚本。\n\n\n3\nSCRIPT EXISTS script \\[script ...\\]查看指定的脚本是否已经被保存在缓存当中。\n\n\n4\nSCRIPT FLUSH 从脚本缓存中移除所有脚本。\n\n\n5\nSCRIPT KILL 杀死当前正在运行的 Lua 脚本。\n\n\n6\nSCRIPT LOAD script 将脚本 script 添加到脚本缓存中，但并不立即执行这个脚本。\n\n\n\n 连接\nRedis 连接命令主要是用于连接 redis 服务。\n 实例\n以下实例演示了客户端如何通过密码验证连接到 redis 服务，并检测服务是否在运行：\n1234redis 127.0.0.1:6379&gt; AUTH &quot;password&quot;OKredis 127.0.0.1:6379&gt; PINGPONG\n Redis 连接命令\n下表列出了 redis 连接的基本命令：\n\n\n\n序号\n命令及描述\n\n\n\n\n1\nAUTH password 验证密码是否正确\n\n\n2\nECHO message 打印字符串\n\n\n3\nPING 查看服务是否运行\n\n\n4\nQUIT 关闭当前连接\n\n\n5\nSELECT index 切换到指定的数据库\n\n\n\n 服务器\nRedis 服务器命令主要是用于管理 redis 服务。\n 实例\n以下实例演示了如何获取 redis 服务器的统计信息：\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788redis 127.0.0.1:6379&gt; INFO# Serverredis_version:2.8.13redis_git_sha1:00000000redis_git_dirty:0redis_build_id:c2238b38b1edb0e2redis_mode:standaloneos:Linux 3.5.0-48-generic x86_64arch_bits:64multiplexing_api:epollgcc_version:4.7.2process_id:3856run_id:0e61abd297771de3fe812a3c21027732ac9f41fetcp_port:6379uptime_in_seconds:11554uptime_in_days:0hz:10lru_clock:16651447config_file:# Clientsconnected_clients:1client-longest_output_list:0client-biggest_input_buf:0blocked_clients:0# Memoryused_memory:589016used_memory_human:575.21Kused_memory_rss:2461696used_memory_peak:667312used_memory_peak_human:651.67Kused_memory_lua:33792mem_fragmentation_ratio:4.18mem_allocator:jemalloc-3.6.0# Persistenceloading:0rdb_changes_since_last_save:3rdb_bgsave_in_progress:0rdb_last_save_time:1409158561rdb_last_bgsave_status:okrdb_last_bgsave_time_sec:0rdb_current_bgsave_time_sec:-1aof_enabled:0aof_rewrite_in_progress:0aof_rewrite_scheduled:0aof_last_rewrite_time_sec:-1aof_current_rewrite_time_sec:-1aof_last_bgrewrite_status:okaof_last_write_status:ok# Statstotal_connections_received:24total_commands_processed:294instantaneous_ops_per_sec:0rejected_connections:0sync_full:0sync_partial_ok:0sync_partial_err:0expired_keys:0evicted_keys:0keyspace_hits:41keyspace_misses:82pubsub_channels:0pubsub_patterns:0latest_fork_usec:264# Replicationrole:masterconnected_slaves:0master_repl_offset:0repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0# CPUused_cpu_sys:10.49used_cpu_user:4.96used_cpu_sys_children:0.00used_cpu_user_children:0.01# Keyspacedb0:keys=94,expires=1,avg_ttl=41638810db1:keys=1,expires=0,avg_ttl=0db3:keys=1,expires=0,avg_ttl=0\n Redis 服务器命令\n下表列出了 redis 服务器的相关命令:\n\n\n\n序号\n命令及描述\n\n\n\n\n1\nBGREWRITEAOF 异步执行一个 AOF（AppendOnly File） 文件重写操作\n\n\n2\nBGSAVE 在后台异步保存当前数据库的数据到磁盘\n\n\n3\n[CLIENT KILL ip:port] [ID client-id] 关闭客户端连接\n\n\n4\nCLIENT LIST 获取连接到服务器的客户端连接列表\n\n\n5\nCLIENT GETNAME 获取连接的名称\n\n\n6\nCLIENT PAUSE timeout 在指定时间内终止运行来自客户端的命令\n\n\n7\nCLIENT SETNAME connection-name 设置当前连接的名称\n\n\n8\nCLUSTER SLOTS 获取集群节点的映射数组\n\n\n9\nCOMMAND 获取 Redis 命令详情数组\n\n\n10\nCOMMAND COUNT 获取 Redis 命令总数\n\n\n11\nCOMMAND GETKEYS 获取给定命令的所有键\n\n\n12\nTIME 返回当前服务器时间\n\n\n13\nCOMMAND INFO command-name \\[command-name ...\\]获取指定 Redis 命令描述的数组\n\n\n14\nCONFIG GET parameter 获取指定配置参数的值\n\n\n15\nCONFIG REWRITE 对启动 Redis 服务器时所指定的 redis.conf 配置文件进行改写\n\n\n16\nCONFIG SET parameter value 修改 redis 配置参数，无需重启\n\n\n17\nCONFIG RESETSTAT 重置 INFO 命令中的某些统计数据\n\n\n18\nDBSIZE 返回当前数据库的 key 的数量\n\n\n19\nDEBUG OBJECT key 获取 key 的调试信息\n\n\n20\nDEBUG SEGFAULT 让 Redis 服务崩溃\n\n\n21\nFLUSHALL 删除所有数据库的所有key\n\n\n22\nFLUSHDB 删除当前数据库的所有key\n\n\n23\nINFO \\[section\\]获取 Redis 服务器的各种信息和统计数值\n\n\n24\nLASTSAVE 返回最近一次 Redis 成功将数据保存到磁盘上的时间，以 UNIX 时间戳格式表示\n\n\n25\nMONITOR 实时打印出 Redis 服务器接收到的命令，调试用\n\n\n26\nROLE 返回主从实例所属的角色\n\n\n27\nSAVE 同步保存数据到硬盘\n\n\n28\n[SHUTDOWN NOSAVE] [SAVE] 异步保存数据到硬盘，并关闭服务器\n\n\n29\nSLAVEOF host port 将当前服务器转变为指定服务器的从属服务器(slave server)\n\n\n30\nSLOWLOG subcommand \\[argument\\] 管理 redis 的慢日志\n\n\n31\nSYNC 用于复制功能(replication)的内部命令\n\n\n\n GEO\nRedis GEO 主要用于存储地理位置信息，并对存储的信息进行操作，该功能在 Redis 3.2 版本新增。\nRedis GEO 操作方法有：\n\ngeoadd：添加地理位置的坐标。\ngeopos：获取地理位置的坐标。\ngeodist：计算两个位置之间的距离。\ngeoradius：根据用户给定的经纬度坐标来获取指定范围内的地理位置集合。\ngeoradiusbymember：根据储存在位置集合里面的某个地点获取指定范围内的地理位置集合。\ngeohash：返回一个或多个位置对象的 geohash 值。\n\n geoadd\ngeoadd 用于存储指定的地理空间位置，可以将一个或多个经度(longitude)、纬度(latitude)、位置名称(member)添加到指定的 key 中。\ngeoadd 语法格式如下：\n1GEOADD key longitude latitude member [longitude latitude member ...]\n以下实例中 key 为 Sicily、Catania 为位置名称 ：\n 实例\nredis**&gt;** GEOADD Sicily 13.361389 38.115556 “Palermo” 15.087269 37.502669 “Catania”\n(integer) 2\nredis**&gt;** GEODIST Sicily Palermo Catania\n“166274.1516”\nredis**&gt;** GEORADIUS Sicily 15 37 100 km\n1**)** “Catania”\nredis**&gt;** GEORADIUS Sicily 15 37 200 km\n1**)** “Palermo”\n2**)** “Catania”\nredis**&gt;**\n geopos\ngeopos 用于从给定的 key 里返回所有指定名称(member)的位置（经度和纬度），不存在的返回 nil。\ngeopos 语法格式如下：\n 实例\nredis**&gt;** GEOADD Sicily 13.361389 38.115556 “Palermo” 15.087269 37.502669 “Catania”\n(integer) 2\nredis**&gt;** GEOPOS Sicily Palermo Catania NonExisting\n1**)** 1**)** “13.36138933897018433”\n2**)** “38.11555639549629859”\n2**)** 1**)** “15.08726745843887329”\n2**)** “37.50266842333162032”\n3**)** (nil)\nredis**&gt;**\n geodist\ngeodist 用于返回两个给定位置之间的距离。\ngeodist 语法格式如下：\n1GEODIST key member1 member2 [m|km|ft|mi]\nmember1 member2 为两个地理位置。\n最后一个距离单位参数说明：\n\n\nm ：米，默认单位。\n\n\nkm ：千米。\n\n\nmi ：英里。\n\n\nft ：英尺。\n\n\n&gt; 计算 Palermo 与 Catania 之间的距离：实例\n\n\nredis**&gt;** GEOADD Sicily 13.361389 38.115556 “Palermo” 15.087269 37.502669 “Catania”\n(integer) 2\nredis**&gt;** GEODIST Sicily Palermo Catania\n“166274.1516”\nredis**&gt;** GEODIST Sicily Palermo Catania km\n“166.2742”\nredis**&gt;** GEODIST Sicily Palermo Catania mi\n“103.3182”\nredis**&gt;** GEODIST Sicily Foo Bar\n(nil)\nredis**&gt;**\n\n\n georadius、georadiusbymember\ngeoradius 以给定的经纬度为中心， 返回键包含的位置元素当中， 与中心的距离不超过给定最大距离的所有位置元素。\ngeoradiusbymember 和 GEORADIUS 命令一样， 都可以找出位于指定范围内的元素， 但是 georadiusbymember 的中心点是由给定的位置元素决定的， 而不是使用经度和纬度来决定中心点。\ngeoradius 与 georadiusbymember 语法格式如下：\n12GEORADIUS key longitude latitude radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count] [ASC|DESC] [STORE key] [STOREDIST key]GEORADIUSBYMEMBER key member radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count] [ASC|DESC] [STORE key] [STOREDIST key]\n参数说明：\n\nm ：米，默认单位。\n\nkm ：千米。\nmi ：英里。\nft ：英尺。\nWITHDIST: 在返回位置元素的同时， 将位置元素与中心之间的距离也一并返回。\nWITHCOORD: 将位置元素的经度和维度也一并返回。\nWITHHASH: 以 52 位有符号整数的形式， 返回位置元素经过原始 geohash 编码的有序集合分值。 这个选项主要用于底层应用或者调试， 实际中的作用并不大。\n\n\nCOUNT 限定返回的记录数。\n\nASC: 查找结果根据距离从近到远排序。\nDESC: 查找结果根据从远到近排序。\n\n\n\n georadius 实例\nredis**&gt;** GEOADD Sicily 13.361389 38.115556 “Palermo” 15.087269 37.502669 “Catania”\n(integer) 2\nredis**&gt;** GEORADIUS Sicily 15 37 200 km WITHDIST\n1**)** 1**)** “Palermo”\n2**)** “190.4424”\n2**)** 1**)** “Catania”\n2**)** “56.4413”\nredis**&gt;** GEORADIUS Sicily 15 37 200 km WITHCOORD\n1**)** 1**)** “Palermo”\n2**)** 1**)** “13.36138933897018433”\n2**)** “38.11555639549629859”\n2**)** 1**)** “Catania”\n2**)** 1**)** “15.08726745843887329”\n2**)** “37.50266842333162032”\nredis**&gt;** GEORADIUS Sicily 15 37 200 km WITHDIST WITHCOORD\n1**)** 1**)** “Palermo”\n2**)** “190.4424”\n3**)** 1**)** “13.36138933897018433”\n2**)** “38.11555639549629859”\n2**)** 1**)** “Catania”\n2**)** “56.4413”\n3**)** 1**)** “15.08726745843887329”\n2**)** “37.50266842333162032”\nredis**&gt;**\n georadiusbymember 实例\n\nredis**&gt;** GEOADD Sicily 13.583333 37.316667 “Agrigento”\n(integer) 1\nredis**&gt;** GEOADD Sicily 13.361389 38.115556 “Palermo” 15.087269 37.502669 “Catania”\n(integer) 2\nredis**&gt;** GEORADIUSBYMEMBER Sicily Agrigento 100 km\n1**)** “Agrigento”\n2**)** “Palermo”\nredis**&gt;**\n\n geohash\n\n\nRedis GEO 使用 geohash 来保存地理位置的坐标。\n\n\ngeohash 用于获取一个或多个位置元素的 geohash 值。\n\n\ngeohash 语法格式如下：\n\n\n1GEOHASH key member [member ...]\n 实例\nredis**&gt;** GEOADD Sicily 13.361389 38.115556 “Palermo” 15.087269 37.502669 “Catania”\n(integer) 2\nredis**&gt;** GEOHASH Sicily Palermo Catania\n1**)** “sqc8b49rny0”\n2**)** “sqdtr74hyu0”\nredis**&gt;**\n RedisTemplate\n 引入依赖\nSpring Boot提供的数据访问框架Spring Data Redis基于Jedis。可以通过引入spring-boot-starter-redis来配置依赖关系。\n1234&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-redis&lt;/artifactId&gt;&lt;/dependency&gt;\n\n注意不同版本的spring boot下，redis的starter依赖名略有不同，如果上面的不行，可以尝试spring-boot-starter-data-redis（养生堂使用的是这个）\n\n 参数配置\n按照惯例在application.properties中加入Redis服务端的相关配置，具体说明如下：\n12345678910111213141516171819# REDIS (RedisProperties)# Redis数据库索引（默认为0）spring.redis.database=0# Redis服务器地址spring.redis.host=localhost# Redis服务器连接端口spring.redis.port=6379# Redis服务器连接密码（默认为空）spring.redis.password=# 连接池最大连接数（使用负值表示没有限制）spring.redis.pool.max-active=8# 连接池最大阻塞等待时间（使用负值表示没有限制）spring.redis.pool.max-wait=-1# 连接池中的最大空闲连接spring.redis.pool.max-idle=8# 连接池中的最小空闲连接spring.redis.pool.min-idle=0# 连接超时时间（毫秒）spring.redis.timeout=0\n其中spring.redis.database的配置通常使用0即可，Redis在配置的时候可以设置数据库数量，默认为16，可以理解为数据库的schema\n12345678910111213141516171819spring:  redis:    database: 0      timeout: 0      # Redis服务器地址      host: 127.0.0.1      # Redis服务器连接端口      port: 6379      # Redis服务器连接密码（默认为空）      password: root      # 连接池最大连接数（使用负值表示没有限制）      pool:      max-active: 8        # 连接池最大阻塞等待时间（使用负值表示没有限制）        max-wait: -1        # 连接池中的最大空闲连接        max-idle: 8        # 连接池中的最小空闲连接        min-idle: 0\n redis-server设置\n\nprotected 改为 no\ndaemonize 改为 no\n\n 测试访问\n通过编写测试用例，举例说明如何访问Redis。\n123456789101112131415161718192021222324import ng.redis.entity.User;import org.junit.Assert;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;import javax.annotation.Resource;@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTestpublic class RedisApplicationTests &#123;\t@Autowired\tprivate StringRedisTemplate stringRedisTemplate;\t@Test\tpublic void test() throws Exception &#123;\t\t// 保存字符串\t\tstringRedisTemplate.opsForValue().set(\"aaa\", \"111\");\t\tAssert.assertEquals(\"111\", stringRedisTemplate.opsForValue().get(\"aaa\"));    &#125;&#125;\n通过上面这段极为简单的测试案例演示了如何通过自动配置的StringRedisTemplate对象进行Redis的读写操作，该对象从命名中就可注意到支持的是String类型。如果有使用过spring-data-redis的开发者一定熟悉RedisTemplate&lt;K, V&gt;接口，StringRedisTemplate就相当于RedisTemplate&lt;String, String&gt;的实现。\n除了String类型，实战中我们还经常会在Redis中存储对象，这时候我们就会想是否可以使用类似RedisTemplate&lt;String, User&gt;来初始化并进行操作。但是Spring Boot并不支持直接使用，需要我们自己实现RedisSerializer&lt;T&gt;接口来对传入对象进行序列化和反序列化，下面我们通过一个实例来完成对象的读写操作。\n\n创建要存储的对象：User\n\n123456789101112131415161718192021import lombok.Data;import java.io.Serializable;/** * @author niu * @date 2020/7/28 上午9:48 */@Datapublic class User implements Serializable &#123;    private static final long serialVersionUID = -1L;    private String username;    private Integer age;    public User(String username, Integer age) &#123;        this.username = username;        this.age = age;    &#125;&#125;\n\n实现对象的序列化接口\n\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package ng.redis.util;import org.springframework.core.convert.converter.Converter;import org.springframework.core.serializer.support.DeserializingConverter;import org.springframework.core.serializer.support.SerializingConverter;import org.springframework.data.redis.serializer.RedisSerializer;import org.springframework.data.redis.serializer.SerializationException;/** * @author niu * @date 2020/7/28 上午9:50 */public class RedisObjectSerializer implements RedisSerializer&lt;Object&gt; &#123;    private Converter&lt;Object, byte[]&gt; serializer = new SerializingConverter();    private Converter&lt;byte[], Object&gt; deserializer = new DeserializingConverter();    static final byte[] EMPTY_ARRAY = new byte[0];    @Override    public Object deserialize(byte[] bytes) &#123;        if (isEmpty(bytes)) &#123;            return null;        &#125;        try &#123;            return deserializer.convert(bytes);        &#125; catch (Exception ex) &#123;            throw new SerializationException(\"Cannot deserialize\", ex);        &#125;    &#125;    @Override    public byte[] serialize(Object object) &#123;        if (object == null) &#123;            return EMPTY_ARRAY;        &#125;        try &#123;            return serializer.convert(object);        &#125; catch (Exception ex) &#123;            return EMPTY_ARRAY;        &#125;    &#125;    private boolean isEmpty(byte[] data) &#123;        return (data == null || data.length == 0);    &#125;&#125;\n\n配置针对User的RedisTemplate实例\n\n123456789101112131415161718192021222324252627282930313233343536373839404142434445import ng.redis.entity.User;import ng.redis.util.RedisObjectSerializer;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.connection.jedis.JedisConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.serializer.RedisSerializer;import org.springframework.data.redis.serializer.StringRedisSerializer;/** * @author niu * @date 2020/7/28 上午9:51 */@Configuration@ConditionalOnClass(RedisOperations.class)@EnableConfigurationProperties(RedisProperties.class)public class RedisConfig &#123;//  @Bean//  JedisConnectionFactory jedisConnectionFactory() &#123;//      return new JedisConnectionFactory();//  &#125;  @Bean  @ConditionalOnMissingBean(StringRedisTemplate.class)  public StringRedisTemplate stringRedisTemplate(    RedisConnectionFactory redisConnectionFactory) &#123;    StringRedisTemplate template = new StringRedisTemplate();    template.setConnectionFactory(redisConnectionFactory);    return template;  &#125;  @Bean(\"redisTemplate\")  public RedisTemplate&lt;Object, Object&gt; redisTemplate() &#123;        RedisTemplate&lt;Object, Object&gt; template = new RedisTemplate&lt;&gt;();        JedisConnectionFactory jedisConnectionFactory = new JedisConnectionFactory();        jedisConnectionFactory.afterPropertiesSet();        template.setConnectionFactory(jedisConnectionFactory);        template.setKeySerializer(new StringRedisSerializer());    \t\ttemplate.setHashKeySerializer(new StringRedisSerializer());        template.setValueSerializer(new RedisObjectSerializer());    \t\ttemplate.setHashValueSerializer(new RedisObjectSerializer());        return template;  &#125;&#125;\n\n完成了配置工作后，编写测试用例实验效果\n\n RedisUtil工具类\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554@Componentpublic final class RedisUtil &#123;    @Resource    private RedisTemplate&lt;String, Object&gt; redisTemplate;    public Set&lt;String&gt; keys(String keys) &#123;        try &#123;            return redisTemplate.keys(keys);        &#125; catch (Exception e) &#123;            e.printStackTrace();            return null;        &#125;    &#125;    /**     * 指定缓存失效时间     *     * @param key  键     * @param time 时间(秒)     * @return     */    public boolean expire(String key, long time) &#123;        try &#123;            if (time &gt; 0) &#123;                redisTemplate.expire(key, time, TimeUnit.SECONDS);            &#125;            return true;        &#125; catch (Exception e) &#123;            e.printStackTrace();            return false;        &#125;    &#125;    /**     * 根据key 获取过期时间     *     * @param key 键 不能为null     * @return 时间(秒) 返回0代表为永久有效     */    public long getExpire(String key) &#123;        return redisTemplate.getExpire(key, TimeUnit.SECONDS);    &#125;    /**     * 判断key是否存在     *     * @param key 键     * @return true 存在 false不存在     */    public boolean hasKey(String key) &#123;        try &#123;            return redisTemplate.hasKey(key);        &#125; catch (Exception e) &#123;            e.printStackTrace();            return false;        &#125;    &#125;    /**     * 删除缓存     *     * @param key 可以传一个值 或多个     */    @SuppressWarnings(\"unchecked\")    public void del(String... key) &#123;        if (key != null &amp;&amp; key.length &gt; 0) &#123;            if (key.length == 1) &#123;                redisTemplate.delete(key[0]);            &#125; else &#123;                redisTemplate.delete(CollectionUtils.arrayToList(key));            &#125;        &#125;    &#125;    /**     * 普通缓存获取     *     * @param key 键     * @return 值     */    public Object get(String key) &#123;        return key == null ? null : redisTemplate.opsForValue().get(key);    &#125;    /**     * 普通缓存放入     *     * @param key   键     * @param value 值     * @return true成功 false失败     */    public boolean set(String key, Object value) &#123;        try &#123;            redisTemplate.opsForValue().set(key, value);            return true;        &#125; catch (Exception e) &#123;            e.printStackTrace();            return false;        &#125;    &#125;    /**     * 普通缓存放入并设置时间     *     * @param key   键     * @param value 值     * @param time  时间(秒) time要大于0 如果time小于等于0 将设置无限期     * @return true成功 false 失败     */    public boolean set(String key, Object value, long time) &#123;        try &#123;            if (time &gt; 0) &#123;                redisTemplate.opsForValue().set(key, value, time, TimeUnit.SECONDS);            &#125; else &#123;                set(key, value);            &#125;            return true;        &#125; catch (Exception e) &#123;            e.printStackTrace();            return false;        &#125;    &#125;    /**     * 递增     *     * @param key   键     * @param delta 要增加几(大于0)     * @return     */    public long incr(String key, long delta) &#123;        if (delta &lt; 0) &#123;            throw new RuntimeException(\"递增因子必须大于0\");        &#125;        return redisTemplate.opsForValue().increment(key, delta);    &#125;    /**     * 递减     *     * @param key   键     * @param delta 要减少几(小于0)     * @return     */    public long decr(String key, long delta) &#123;        if (delta &lt; 0) &#123;            throw new RuntimeException(\"递减因子必须大于0\");        &#125;        return redisTemplate.opsForValue().increment(key, -delta);    &#125;    /**     * HashGet     *     * @param key  键 不能为null     * @param item 项 不能为null     * @return 值     */    public Object hget(String key, String item) &#123;        return redisTemplate.opsForHash().get(key, item);    &#125;    /**     * 获取hashKey对应的所有键值     *     * @param key 键     * @return 对应的多个键值     */    public Map&lt;Object, Object&gt; hmget(String key) &#123;        return redisTemplate.opsForHash().entries(key);    &#125;    /**     * HashSet     *     * @param key 键     * @param map 对应多个键值     * @return true 成功 false 失败     */    public boolean hmset(String key, Map&lt;String, Object&gt; map) &#123;        try &#123;            redisTemplate.opsForHash().putAll(key, map);            return true;        &#125; catch (Exception e) &#123;            e.printStackTrace();            return false;        &#125;    &#125;    /**     * HashSet 并设置时间     *     * @param key  键     * @param map  对应多个键值     * @param time 时间(秒)     * @return true成功 false失败     */    public boolean hmset(String key, Map&lt;String, Object&gt; map, long time) &#123;        try &#123;            redisTemplate.opsForHash().putAll(key, map);            if (time &gt; 0) &#123;                expire(key, time);            &#125;            return true;        &#125; catch (Exception e) &#123;            e.printStackTrace();            return false;        &#125;    &#125;    /**     * 向一张hash表中放入数据,如果不存在将创建     *     * @param key   键     * @param item  项     * @param value 值     * @return true 成功 false失败     */    public boolean hset(String key, String item, Object value) &#123;        try &#123;            redisTemplate.opsForHash().put(key, item, value);            return true;        &#125; catch (Exception e) &#123;            e.printStackTrace();            return false;        &#125;    &#125;    /**     * 向一张hash表中放入数据,如果不存在将创建     *     * @param key   键     * @param item  项     * @param value 值     * @param time  时间(秒) 注意:如果已存在的hash表有时间,这里将会替换原有的时间     * @return true 成功 false失败     */    public boolean hset(String key, String item, Object value, long time) &#123;        try &#123;            redisTemplate.opsForHash().put(key, item, value);            if (time &gt; 0) &#123;                expire(key, time);            &#125;            return true;        &#125; catch (Exception e) &#123;            e.printStackTrace();            return false;        &#125;    &#125;    /**     * 删除hash表中的值     *     * @param key  键 不能为null     * @param item 项 可以使多个 不能为null     */    public void hdel(String key, Object... item) &#123;        redisTemplate.opsForHash().delete(key, item);    &#125;    /**     * 判断hash表中是否有该项的值     *     * @param key  键 不能为null     * @param item 项 不能为null     * @return true 存在 false不存在     */    public boolean hHasKey(String key, String item) &#123;        return redisTemplate.opsForHash().hasKey(key, item);    &#125;    /**     * hash递增 如果不存在,就会创建一个 并把新增后的值返回     *     * @param key  键     * @param item 项     * @param by   要增加几(大于0)     * @return     */    public double hincr(String key, String item, double by) &#123;        return redisTemplate.opsForHash().increment(key, item, by);    &#125;    /**     * hash递减     *     * @param key  键     * @param item 项     * @param by   要减少记(小于0)     * @return     */    public double hdecr(String key, String item, double by) &#123;        return redisTemplate.opsForHash().increment(key, item, -by);    &#125;    /**     * 根据key获取Set中的所有值     *     * @param key 键     * @return     */    public Set&lt;Object&gt; sGet(String key) &#123;        try &#123;            return redisTemplate.opsForSet().members(key);        &#125; catch (Exception e) &#123;            e.printStackTrace();            return null;        &#125;    &#125;    /**     * 根据value从一个set中查询,是否存在     *     * @param key   键     * @param value 值     * @return true 存在 false不存在     */    public boolean sHasKey(String key, Object value) &#123;        try &#123;            return redisTemplate.opsForSet().isMember(key, value);        &#125; catch (Exception e) &#123;            e.printStackTrace();            return false;        &#125;    &#125;    /**     * 将数据放入set缓存     *     * @param key    键     * @param values 值 可以是多个     * @return 成功个数     */    public long sSet(String key, Object... values) &#123;        try &#123;            return redisTemplate.opsForSet().add(key, values);        &#125; catch (Exception e) &#123;            e.printStackTrace();            return 0;        &#125;    &#125;    /**     * 将set数据放入缓存     *     * @param key    键     * @param time   时间(秒)     * @param values 值 可以是多个     * @return 成功个数     */    public long sSetAndTime(String key, long time, Object... values) &#123;        try &#123;            Long count = redisTemplate.opsForSet().add(key, values);            if (time &gt; 0)                expire(key, time);            return count;        &#125; catch (Exception e) &#123;            e.printStackTrace();            return 0;        &#125;    &#125;    /**     * 获取set缓存的长度     *     * @param key 键     * @return     */    public long sGetSetSize(String key) &#123;        try &#123;            return redisTemplate.opsForSet().size(key);        &#125; catch (Exception e) &#123;            e.printStackTrace();            return 0;        &#125;    &#125;    /**     * 移除值为value的     *     * @param key    键     * @param values 值 可以是多个     * @return 移除的个数     */    public long setRemove(String key, Object... values) &#123;        try &#123;            Long count = redisTemplate.opsForSet().remove(key, values);            return count;        &#125; catch (Exception e) &#123;            e.printStackTrace();            return 0;        &#125;    &#125;    // ===============================list=================================    /**     * 获取list缓存的内容     *     * @param key   键     * @param start 开始     * @param end   结束 0 到 -1代表所有值     * @return     */    public List&lt;Object&gt; lGet(String key, long start, long end) &#123;        try &#123;            return redisTemplate.opsForList().range(key, start, end);        &#125; catch (Exception e) &#123;            e.printStackTrace();            return null;        &#125;    &#125;    /**     * 获取list缓存的长度     *     * @param key 键     * @return     */    public long lGetListSize(String key) &#123;        try &#123;            return redisTemplate.opsForList().size(key);        &#125; catch (Exception e) &#123;            e.printStackTrace();            return 0;        &#125;    &#125;    /**     * 通过索引 获取list中的值     *     * @param key   键     * @param index 索引 index&gt;=0时， 0 表头，1 第二个元素，依次类推；index&lt;0时，-1，表尾，-2倒数第二个元素，依次类推     * @return     */    public Object lGetIndex(String key, long index) &#123;        try &#123;            return redisTemplate.opsForList().index(key, index);        &#125; catch (Exception e) &#123;            e.printStackTrace();            return null;        &#125;    &#125;    /**     * 将list放入缓存     *     * @param key   键     * @param value 值     * @return     */    public boolean lSet(String key, Object value) &#123;        try &#123;            redisTemplate.opsForList().rightPush(key, value);            return true;        &#125; catch (Exception e) &#123;            e.printStackTrace();            return false;        &#125;    &#125;    /**     * 将list放入缓存     *     * @param key   键     * @param value 值     * @param time  时间(秒)     * @return     */    public boolean lSet(String key, Object value, long time) &#123;        try &#123;            redisTemplate.opsForList().rightPush(key, value);            if (time &gt; 0)                expire(key, time);            return true;        &#125; catch (Exception e) &#123;            e.printStackTrace();            return false;        &#125;    &#125;    /**     * 将list放入缓存     *     * @param key   键     * @param value 值     * @return     */    public boolean lSet(String key, List&lt;Object&gt; value) &#123;        try &#123;            redisTemplate.opsForList().rightPushAll(key, value);            return true;        &#125; catch (Exception e) &#123;            e.printStackTrace();            return false;        &#125;    &#125;    /**     * 将list放入缓存     *     * @param key   键     * @param value 值     * @param time  时间(秒)     * @return     */    public boolean lSet(String key, List&lt;Object&gt; value, long time) &#123;        try &#123;            redisTemplate.opsForList().rightPushAll(key, value);            if (time &gt; 0)                expire(key, time);            return true;        &#125; catch (Exception e) &#123;            e.printStackTrace();            return false;        &#125;    &#125;    /**     * 根据索引修改list中的某条数据     *     * @param key   键     * @param index 索引     * @param value 值     * @return     */    public boolean lUpdateIndex(String key, long index, Object value) &#123;        try &#123;            redisTemplate.opsForList().set(key, index, value);            return true;        &#125; catch (Exception e) &#123;            e.printStackTrace();            return false;        &#125;    &#125;    /**     * 移除N个值为value     *     * @param key   键     * @param count 移除多少个     * @param value 值     * @return 移除的个数     */    public long lRemove(String key, long count, Object value) &#123;        try &#123;            Long remove = redisTemplate.opsForList().remove(key, count, value);            return remove;        &#125; catch (Exception e) &#123;            e.printStackTrace();            return 0;        &#125;    &#125;&#125;\n 测试\n1234567891011121314151617181920212223242526272829303132333435import ng.redis.entity.User;import org.junit.Assert;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;import javax.annotation.Resource;@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTestpublic class RedisApplicationTests &#123;    @Resource    private RedisTemplate&lt;String, User&gt; redisTemplate;    @Test    public void test() throws Exception &#123;        // 保存对象        User user = new User(\"super\", 20);        redisTemplate.opsForValue().set(user.getUsername(), user);        user = new User(\"bat\", 30);        redisTemplate.opsForValue().set(user.getUsername(), user);        user = new User(\"spider\", 40);        redisTemplate.opsForValue().set(user.getUsername(), user);        System.out.println(redisTemplate.opsForValue().get(\"super\").getAge().longValue());//        Assert.assertEquals(30, redisTemplate.opsForValue().get(\"蝙蝠侠\").getAge().longValue());//        Assert.assertEquals(40, redisTemplate.opsForValue().get(\"蜘蛛侠\").getAge().longValue());    &#125;&#125;\n Json\n12345678910111213141516@Bean@ConditionalOnMissingBean(name = \"redisTemplate\")public RedisTemplate&lt;Object, Object&gt; redisTemplate(    RedisConnectionFactory redisConnectionFactory) &#123;    RedisTemplate&lt;Object, Object&gt; template = new RedisTemplate&lt;&gt;();    //使用fastjson序列化    FastJsonRedisSerializer fastJsonRedisSerializer = new FastJsonRedisSerializer(Object.class);    // value值的序列化采用fastJsonRedisSerializer    template.setValueSerializer(fastJsonRedisSerializer);    template.setHashValueSerializer(fastJsonRedisSerializer);    // key的序列化采用StringRedisSerializer    template.setKeySerializer(new StringRedisSerializer());    template.setHashKeySerializer(new StringRedisSerializer());    template.setConnectionFactory(redisConnectionFactory);    return template;&#125;\n\njson使用\n\n1System.out.println(((JSONObject) redisTemplate.opsForValue().get(\"zhx\")).getInteger(\"age\"));\n\n所需依赖\n\n12345&lt;dependency&gt;  &lt;groupId&gt;com.alibaba&lt;/groupId&gt;  &lt;artifactId&gt;fastjson&lt;/artifactId&gt;  &lt;version&gt;1.2.48&lt;/version&gt;&lt;/dependency&gt;\n","plink":"ilucia.github.io/Redis/"},{"title":"Excel生成工具类","date":"2022-04-27T15:24:01.559Z","updated":"2022-04-27T15:24:01.559Z","content":" 一次性excel导出\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public void exportProductExcel() throws IOException &#123;    File file = new File(\"product.txt\");    StringBuilder resultString = new StringBuilder();    try&#123;        BufferedReader br = new BufferedReader(new FileReader(file));//构造一个BufferedReader类来读取文件        String s = null;        while((s = br.readLine())!=null)&#123;//使用readLine方法，一次读一行            resultString.append(System.lineSeparator()+s);        &#125;        br.close();    &#125;catch(Exception e)&#123;        e.printStackTrace();    &#125;    JSONObject result = JSONObject.parseObject(resultString.toString());    System.out.println(resultString);    JSONArray productList = result.getJSONArray(\"data\");    HSSFWorkbook workbook = new HSSFWorkbook();    //创建excel文档    HSSFSheet sheet = workbook.createSheet(\"商品表\");    //定义列的宽度    sheet.setColumnWidth(0, 20 * 256);    sheet.setColumnWidth(1, 15 * 256);    sheet.setColumnWidth(2, 20 * 256);    sheet.setColumnWidth(3, 10 * 256);    sheet.setColumnWidth(4, 10 * 256);    sheet.setColumnWidth(5, 10 * 256);    sheet.setColumnWidth(6, 20 * 256);    sheet.setColumnWidth(7, 30 * 256);    sheet.setColumnWidth(8, 30 * 256);    //设置表头    HSSFRow headerRow = sheet.createRow(0);    headerRow.createCell(0).setCellValue(\"商品编码\");    headerRow.createCell(1).setCellValue(\"外部商品编码\");    headerRow.createCell(2).setCellValue(\"商品名称\");    headerRow.createCell(3).setCellValue(\"大类\");    headerRow.createCell(4).setCellValue(\"中类\");    headerRow.createCell(5).setCellValue(\"小类\");    headerRow.createCell(6).setCellValue(\"品牌\");    headerRow.createCell(7).setCellValue(\"售卖机型\");    headerRow.createCell(8).setCellValue(\"标签\");    for (int i = 0;i &lt; productList.size();i++)&#123;        JSONObject product = productList.getJSONObject(i);        HSSFRow row = sheet.createRow(i+1);        row.createCell(0).setCellValue(product.getString(\"skuCode\"));        row.createCell(1).setCellValue(product.getString(\"externalSkuId\"));        row.createCell(2).setCellValue(product.getString(\"name\"));        row.createCell(3).setCellValue(product.getString(\"bigLevelSpuName\"));        row.createCell(4).setCellValue(product.getString(\"mediumLevelSpuName\"));        row.createCell(5).setCellValue(product.getString(\"productSpuName\"));        row.createCell(6).setCellValue(product.getString(\"product_brand_cn\"));        row.createCell(7).setCellValue(product.getString(\"machine_type_names\"));        JSONArray productTagList = product.getJSONArray(\"productTagVOList\");        StringBuilder tags = new StringBuilder();        if(productTagList != null &amp;&amp; !productTagList.isEmpty())&#123;            for(int j = 0;j &lt; productTagList.size();j++) &#123;                JSONObject tag = productTagList.getJSONObject(j);                tags.append(\" \").append(tag.getString(\"tagName\"));            &#125;        &#125;        if(tags.length() &gt; 0)&#123;            row.createCell(8).setCellValue(tags.substring(1));        &#125;else&#123;            row.createCell(8).setCellValue(\"\");        &#125;    &#125;    //将excel写入到ByteArrayOutStream中    FileOutputStream out = new FileOutputStream(\"商品列表.xls\");    workbook.write(out);&#125;\n excel导出\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687public void exportProductExcel() throws IOException &#123;    PageResultVO result = productSkuController.getProductSkuByPage(null, null, null, null, null, null, 1, 900, null);    List&lt;VemProductSkuResultMap&gt; productList = (List&lt;VemProductSkuResultMap&gt;) result.getData();    HSSFWorkbook workbook = new HSSFWorkbook();    //创建excel文档    HSSFSheet sheet = workbook.createSheet(\"商品表\");    //定义列的宽度    sheet.setColumnWidth(0, 5 * 256);    sheet.setColumnWidth(1, 5 * 256);    sheet.setColumnWidth(2, 10 * 256);    sheet.setColumnWidth(3, 10 * 256);    sheet.setColumnWidth(4, 10 * 256);    sheet.setColumnWidth(5, 10 * 256);    sheet.setColumnWidth(6, 10 * 256);    sheet.setColumnWidth(7, 10 * 256);    sheet.setColumnWidth(8, 10 * 256);    //设置表头    HSSFRow headerRow = sheet.createRow(0);    headerRow.createCell(0).setCellValue(\"商品编码\");    headerRow.createCell(1).setCellValue(\"外部商品编码\");    headerRow.createCell(2).setCellValue(\"商品名称\");    headerRow.createCell(3).setCellValue(\"大类\");    headerRow.createCell(4).setCellValue(\"中类\");    headerRow.createCell(5).setCellValue(\"小类\");    headerRow.createCell(6).setCellValue(\"品牌\");    headerRow.createCell(7).setCellValue(\"售卖机型\");    headerRow.createCell(8).setCellValue(\"标签\");    for (int i = 0;i &lt; productList.size();i++)&#123;        VemProductSkuResultMap product = productList.get(i);        HSSFRow row = sheet.createRow(i+1);        row.createCell(0).setCellValue(product.getId());        row.createCell(1).setCellValue(product.getExternalSkuId());        row.createCell(2).setCellValue(product.getName());        row.createCell(3).setCellValue(product.getBigLevelSpuName());        row.createCell(4).setCellValue(product.getMediumLevelSpuName());        row.createCell(5).setCellValue(product.getProductSpuName());        String cn = DictConsts.UNMATCH_VALUE;        SkuBrandFacade skuBrandFacade = SpringContextUtil.getBean(\"skuBrandFacade\");        VemSkuBrand skuBrand = skuBrandFacade.getSkuBrand(product.getBrandCode());        if(!Objects.isNull(skuBrand))&#123;            cn = skuBrand.getName();        &#125;        row.createCell(6).setCellValue(cn);        List&lt;VemProductSkuMachineType&gt; skuMachineTypes = product.getMachineTypeList();        StringBuilder typeNames = new StringBuilder();        if(CollectionUtils.isNotEmpty(skuMachineTypes))&#123;            DictService dictService= SpringContextUtil.getBean(\"dictServiceImpl\");            List&lt;VemDict&gt; dictList=dictService.listVemDictByDictGroupId(DictConsts.MACHINE_TYPE);            if(CollectionUtils.isNotEmpty(dictList))&#123;                for(VemDict dict : dictList)&#123;                    String value = String.valueOf(dict.getDictCode());                    for(VemProductSkuMachineType type : skuMachineTypes)&#123;                        if(value.equals(type.getMachineType()))&#123;                            typeNames.append(\",\").append(dict.getDictName());                            break;                        &#125;                    &#125;                &#125;            &#125;        &#125;        if(typeNames.length() &gt; 0)&#123;            row.createCell(7).setCellValue(typeNames.substring(1));        &#125;else&#123;            row.createCell(7).setCellValue(DictConsts.UNMATCH_VALUE);        &#125;        List&lt;ProductTagVO&gt; productTagList = product.getProductTagVOList();        StringBuilder tags = new StringBuilder();        if(CollectionUtils.isNotEmpty(productTagList))&#123;            for (ProductTagVO tag : productTagList) &#123;                tags.append(\" \").append(tag.getTagName());            &#125;        &#125;        if(tags.length() &gt; 0)&#123;            row.createCell(8).setCellValue(tags.substring(1));        &#125;else&#123;            row.createCell(8).setCellValue(\"\");        &#125;    &#125;    //将excel写入到ByteArrayOutStream中    FileOutputStream out = new FileOutputStream(\"商品列表.xls\");    workbook.write(out);&#125;\n1&#123;\"商品编码\", \"商品Id\", \"商品名称\", \"商品别名\", \"外部商品编码\", \"市场指导价(元)\", \"类目\", \"品牌\", \"建议售价(元)\", \"计量单位\", \"规格\", \"厚度(mm)\", \"重量(g)\", \"图片\", \"保质期(天)\", \"售卖机型\", \"标签\", \"是否原材料\", \"是否组合商品\", \"是否返信用\", \"是否非专卖\", \"批次来源\", \"定时折扣\", \"折扣模板\", \"修改时间\", \"修改人\"&#125;\n1234567891011121314151617181920212223242526272829303132333435363738394041package com.nfsq.vem.admin.entity.dto;import lombok.Getter;import lombok.Setter;import java.math.BigDecimal;import java.util.Date;/** * @author niu * @date 2020/11/24 下午5:13 */@Setter@Getterpublic class ProductExcelModel &#123;    private String skuCode;    private Integer id;    private String name;    private String nameAlias;    private String externalSkuId;    private BigDecimal marketPrice;    private String productSpuLevelName;    private String productBrand;    private BigDecimal guidePrice;    private String measurementUnit;    private String specification;    private Integer thickness;    private Integer weight;    private String imageUrl;    private Integer guaranteePeriod;    private String machineTypeNames;    private String tags;    private String description;    private String isOrigin;    private String isGroupSkuCnName;    private String isReturnCreditCnName;    private String ifNonMonopolyCnName;    private String ifBatchNoCnName;    private Date updateDate;    private String updatePerson;&#125;\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106/** * 导出商品品项列表 * * @param productName * @return */@ResponseBody@RequestMapping(value = \"/exportProductSkuExcel\", method = RequestMethod.GET)public void exportProductExcel(@RequestParam(required = false) String brandCode,                               @RequestParam(required = false) String spuId,                               @RequestParam(required = false) String productName,                               @RequestParam(required = false) String nameAlias,                               @RequestParam(required = false) Integer tagId,                               @RequestParam(required = false) String machineType,                               @RequestParam(required = false) Boolean isMaterialProduct,                               HttpServletResponse response) throws IOException &#123;    PageResultVO result = getProductSkuByPage(brandCode, spuId, productName, nameAlias, tagId, machineType, null, null, isMaterialProduct);    List&lt;VemProductSkuResultMap&gt; productList = (List&lt;VemProductSkuResultMap&gt;) result.getData();    PoiExcelExport poiExcelExport = new PoiExcelExport(response, \"商品品项\", \"商品品项\");    // 列名    String[] columnNames = &#123;\"商品编码\", \"商品Id\", \"商品名称\", \"商品别名\", \"外部商品编码\", \"市场指导价(元)\", \"类目\", \"品牌\", \"建议售价(元)\", \"计量单位\", \"规格\", \"厚度(mm)\", \"重量(g)\", \"图片\", \"保质期(天)\", \"售卖机型\", \"标签\", \"描述\", \"是否原材料\", \"是否组合商品\", \"是否返信用\", \"是否非专卖\", \"批次来源\", \"修改时间\", \"修改人\"&#125;;    // map中的key    String[] keys = &#123; \"skuCode\", \"id\", \"name\", \"nameAlias\", \"externalSkuId\",            \"marketPrice\", \"productSpuLevelName\", \"productBrand\", \"guidePrice\", \"measurementUnit\",            \"specification\", \"thickness\", \"weight\", \"imageUrl\", \"guaranteePeriod\",            \"machineTypeNames\", \"tags\", \"description\", \"isOrigin\", \"isGroupSkuCnName\",            \"isReturnCreditCnName\", \"ifNonMonopolyCnName\", \"ifBatchNoCnName\", \"updateDate\", \"updatePerson\"&#125;;    int[] titleSize = &#123; 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15&#125;;    List&lt;ProductExcelModel&gt; models = constructProductExcelModel(productList);    poiExcelExport.writeExcelBaseMethod(\"商品品项\", keys, columnNames, titleSize, models);    poiExcelExport.writeExcelMultiSheet();&#125;private List&lt;ProductExcelModel&gt; constructProductExcelModel(List&lt;VemProductSkuResultMap&gt; productSkuResultMaps) &#123;    List&lt;ProductExcelModel&gt; models = new ArrayList&lt;&gt;();    for (VemProductSkuResultMap product : productSkuResultMaps) &#123;        ProductExcelModel model = new ProductExcelModel();        model.setSkuCode(product.getSkuCode());        model.setId(product.getId());        model.setName(product.getName());        model.setNameAlias(product.getNameAlias());        model.setExternalSkuId(product.getExternalSkuId());        model.setMarketPrice(product.getMarketPrice());        model.setProductSpuLevelName(product.getProductSpuLevelName());        String cn = DictConsts.UNMATCH_VALUE;        SkuBrandFacade skuBrandFacade = SpringContextUtil.getBean(\"skuBrandFacade\");        VemSkuBrand skuBrand = skuBrandFacade.getSkuBrand(product.getBrandCode());        if(!Objects.isNull(skuBrand))&#123;            cn = skuBrand.getName();        &#125;        model.setProductBrand(cn);        model.setGuidePrice(product.getGuidePrice());        model.setMeasurementUnit(product.getMeasurementUnit());        model.setSpecification(product.getSpecification());        model.setThickness(product.getThickness());        model.setWeight(product.getWeight());        model.setImageUrl(product.getImageUrl());        model.setGuaranteePeriod(product.getGuaranteePeriod());        List&lt;VemProductSkuMachineType&gt; skuMachineTypes = product.getMachineTypeList();        StringBuilder typeNames = new StringBuilder();        if(CollectionUtils.isNotEmpty(skuMachineTypes))&#123;            DictService dictService= SpringContextUtil.getBean(\"dictServiceImpl\");            List&lt;VemDict&gt; dictList=dictService.listVemDictByDictGroupId(DictConsts.MACHINE_TYPE);            if(CollectionUtils.isNotEmpty(dictList))&#123;                for(VemDict dict : dictList)&#123;                    String value = String.valueOf(dict.getDictCode());                    for(VemProductSkuMachineType type : skuMachineTypes)&#123;                        if(value.equals(type.getMachineType()))&#123;                            typeNames.append(\",\").append(dict.getDictName());                            break;                        &#125;                    &#125;                &#125;            &#125;        &#125;        if(typeNames.length() &gt; 0)&#123;            model.setMachineTypeNames(typeNames.substring(1));        &#125;else&#123;            model.setMachineTypeNames(DictConsts.UNMATCH_VALUE);        &#125;        List&lt;ProductTagVO&gt; productTagList = product.getProductTagVOList();        StringBuilder tags = new StringBuilder();        if(CollectionUtils.isNotEmpty(productTagList))&#123;            for (ProductTagVO tag : productTagList) &#123;                tags.append(\" \").append(tag.getTagName());            &#125;        &#125;        if(tags.length() &gt; 0)&#123;            model.setTags(tags.substring(1));        &#125;else&#123;            model.setTags(\"\");        &#125;        model.setDescription(product.getDescription());        model.setIsOrigin((\"2\".equals(product.getProductType())) ? \"是\" : \"否\");        model.setIsGroupSkuCnName(product.getIsGroupSkuCnName());        model.setIsReturnCreditCnName(product.getIsReturnCreditCnName());        model.setIfNonMonopolyCnName(product.getIfNonMonopolyCnName());        model.setIfBatchNoCnName(product.getIfBatchNoCnName());        model.setUpdateDate(product.getUpdateDate());        model.setUpdatePerson(product.getUpdatePerson());        models.add(model);    &#125;    return models;&#125;\n12345678@Overridepublic List&lt;VemProductSkuResultMap&gt; listVemProductSkuResultMapByPage(List&lt;String&gt; spuIds, String brandCode,String productSkuName, String nameAlias, boolean isMaterialProduct, String machineType, Integer pageNum, Integer pageSize) &#123;    if (pageNum != null &amp;&amp; pageSize != null) &#123;        PageHelper.startPage(pageNum,pageSize);    &#125;    List&lt;VemProductSkuResultMap&gt; vemProductSkuList = manualVemProductSkuMapper.selectVemProductSkuResultMapBySkuNameAndSpuIds(null, productSkuName, nameAlias, spuIds, brandCode,isMaterialProduct,machineType);    return vemProductSkuList;&#125;\n1ALTER TABLE vem_machine ADD WAREHOUSE_ADDRESS CHAR(1) AFTER STATUS;\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112/** * 导出商品品项列表 * * @param productName * @return */@ResponseBody@RequestMapping(value = \"/exportProductSkuExcel\", method = RequestMethod.GET)public void exportProductExcel(@RequestParam(required = false) String brandCode,                               @RequestParam(required = false) String spuId,                               @RequestParam(required = false) String productName,                               @RequestParam(required = false) String nameAlias,                               @RequestParam(required = false) Integer tagId,                               @RequestParam(required = false) String machineType,                               @RequestParam(required = false) Boolean isMaterialProduct,                               HttpServletResponse response) &#123;    PageResultVO result = getProductSkuByPage(brandCode, spuId, productName, nameAlias, tagId, machineType, null, null, isMaterialProduct);    List&lt;VemProductSkuResultMap&gt; productList = (List&lt;VemProductSkuResultMap&gt;) result.getData();    PoiExcelExport poiExcelExport = new PoiExcelExport(response, \"商品品项\", \"商品品项\");    // 列名    String[] columnNames = &#123;\"商品编码\", \"商品Id\", \"商品名称\", \"商品别名\", \"外部商品编码\",            \"市场指导价(元)\", \"类目\", \"品牌\", \"建议售价(元)\", \"计量单位\",            \"规格\", \"厚度(mm)\", \"重量(g)\", \"图片\", \"保质期(天)\",            \"售卖机型\", \"标签\", \"描述\", \"是否原材料\", \"是否组合商品\",            \"是否返信用\", \"是否非专卖\", \"批次来源\", \"修改时间\", \"修改人\"&#125;;    // map中的key    String[] keys = &#123; \"skuCode\", \"id\", \"name\", \"nameAlias\", \"externalSkuId\",            \"marketPrice\", \"productSpuLevelName\", \"productBrand\", \"guidePrice\", \"measurementUnit\",            \"specification\", \"thickness\", \"weight\", \"imageUrl\", \"guaranteePeriod\",            \"machineTypeNames\", \"tags\", \"description\", \"isOrigin\", \"isGroupSkuCnName\",            \"isReturnCreditCnName\", \"ifNonMonopolyCnName\", \"ifBatchNoCnName\", \"updateDate\", \"updatePerson\"&#125;;    int[] titleSize = &#123; 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15&#125;;    List&lt;ProductExcelModel&gt; models = constructProductExcelModel(productList);    poiExcelExport.writeExcelBaseMethod(\"商品品项\", keys, columnNames, titleSize, models);    poiExcelExport.writeExcelMultiSheet();&#125;private List&lt;ProductExcelModel&gt; constructProductExcelModel(List&lt;VemProductSkuResultMap&gt; productSkuResultMaps) &#123;    List&lt;ProductExcelModel&gt; models = new ArrayList&lt;&gt;();    SkuBrandFacade skuBrandFacade = SpringContextUtil.getBean(\"skuBrandFacade\");    Map&lt;String, String&gt; brandMap = skuBrandFacade.findSkuBrands();    DictService dictService= SpringContextUtil.getBean(\"dictServiceImpl\");    List&lt;VemDict&gt; dictList=dictService.listVemDictByDictGroupId(DictConsts.MACHINE_TYPE);    for (VemProductSkuResultMap product : productSkuResultMaps) &#123;        ProductExcelModel model = new ProductExcelModel();        model.setSkuCode(product.getSkuCode());        model.setId(product.getId());        model.setName(product.getName());        model.setNameAlias(product.getNameAlias());        model.setExternalSkuId(product.getExternalSkuId());        model.setMarketPrice(product.getMarketPrice());        model.setProductSpuLevelName(product.getProductSpuLevelName());        String cn = DictConsts.UNMATCH_VALUE;        String skuBrand = brandMap.get(product.getBrandCode());        if(StringUtil.isNotBlank(skuBrand)) &#123;            cn = skuBrand;        &#125;        model.setProductBrand(cn);        model.setGuidePrice(product.getGuidePrice());        model.setMeasurementUnit(product.getMeasurementUnit());        model.setSpecification(product.getSpecification());        model.setThickness(product.getThickness());        model.setWeight(product.getWeight());        model.setImageUrl(product.getImageUrl());        model.setGuaranteePeriod(product.getGuaranteePeriod());        List&lt;VemProductSkuMachineType&gt; skuMachineTypes = product.getMachineTypeList();        StringBuilder typeNames = new StringBuilder();        if(CollectionUtils.isNotEmpty(skuMachineTypes))&#123;            if(CollectionUtils.isNotEmpty(dictList))&#123;                for(VemDict dict : dictList)&#123;                    String value = String.valueOf(dict.getDictCode());                    for(VemProductSkuMachineType type : skuMachineTypes)&#123;                        if(value.equals(type.getMachineType()))&#123;                            typeNames.append(\",\").append(dict.getDictName());                            break;                        &#125;                    &#125;                &#125;            &#125;        &#125;        if(typeNames.length() &gt; 0)&#123;            model.setMachineTypeNames(typeNames.substring(1));        &#125;else&#123;            model.setMachineTypeNames(DictConsts.UNMATCH_VALUE);        &#125;        List&lt;ProductTagVO&gt; productTagList = product.getProductTagVOList();        StringBuilder tags = new StringBuilder();        if(CollectionUtils.isNotEmpty(productTagList))&#123;            for (ProductTagVO tag : productTagList) &#123;                tags.append(\" \").append(tag.getTagName());            &#125;        &#125;        if(tags.length() &gt; 0)&#123;            model.setTags(tags.substring(1));        &#125;else&#123;            model.setTags(\"\");        &#125;        model.setDescription(product.getDescription());        model.setIsOrigin((\"2\".equals(product.getProductType())) ? \"是\" : \"否\");        model.setIsGroupSkuCnName(product.getIsGroupSkuCnName());        model.setIsReturnCreditCnName(product.getIsReturnCreditCnName());        model.setIfNonMonopolyCnName(product.getIfNonMonopolyCnName());        model.setIfBatchNoCnName(product.getIfBatchNoCnName());        model.setUpdateDate(product.getUpdateDate());        model.setUpdatePerson(product.getUpdatePerson());        models.add(model);    &#125;    return models;&#125;\n 提交信息\n1【Fix】ID1107326 商品信息导出功能】 https://www.tapd.cn/52268405/prong/stories/view/1152268405001107326   1.导出文件并下载初步完成\n","plink":"ilucia.github.io/Excel生成工具类/"},{"title":"Maven/基础&POM","date":"2022-04-27T15:24:01.559Z","updated":"2022-04-27T15:24:01.559Z","content":" 基础\n 功能\n\n\n构建\n\n\n文档生成\n\n\n报告\n\n\n依赖\n\n\nSCMs\n\n\n发布\n\n\n分发\n\n\n邮件列表\n\n\n 约定配置\n\n提倡使用一个共同的标准目录结构\n使用约定优于配置的原则\n\n\n\n\n目录\n目的\n\n\n\n\n${basedir}\n存放pom.xml和所有的子目录\n\n\n${basedir}/src/main/java\n项目的java源代码\n\n\n${basedir}/src/main/resources\n项目的资源，比如说property文件，springmvc.xml\n\n\n${basedir}/src/test/java\n项目的测试类，比如说Junit代码\n\n\n${basedir}/src/test/resources\n测试用的资源\n\n\n${basedir}/src/main/webapp/WEB-INF\nweb应用文件目录，web项目的信息，比如存放web.xml、本地图片、jsp视图页面\n\n\n${basedir}/target\n打包输出目录\n\n\n${basedir}/target/classes\n编译输出目录\n\n\n${basedir}/target/test-classes\n测试编译输出目录\n\n\nTest.java\nMaven只会自动运行符合该命名规则的测试类\n\n\n~/.m2/repository\nMaven默认的本地仓库目录位置\n\n\n\n 特点\n\n\n基于模型的构建\n\n将任意数量的项目构建到预定义的输出类型中，如JAR,WAR\n\n\n\n项目信息的一致性站点\n\n能够生成一个网站或PDF，包括要添加的任何文档，并添加到关于项目开发状态的标准报告中\n\n\n\n发布管理和发布单独的输出\n\n可直接和Git集成，管理项目发布\n可将代码发布到分发位置供其他项目使用\n能发布单独的输出，包括JAR,包含其他依赖和文档的归档，或源代码\n\n\n\n向后兼容\n\n\n并行构建\n\n\n错误报告\n\n提供了wiki界面的链接，可以查看错误的完整描述\n\n\n\n Maven POM\n\nPOM是maven工程的基本工作单元\n是一个XML文件\n\n包含项目基本信息\n用于描述项目如何创建，声明依赖等\n\n\n执行任务/目标时，Maven会在当前目录中查找POM，读取并获取所需配置信息，然后执行目标\n\n POM中指定的配置\n\n\n项目依赖\n\n\n插件\n\n\n执行目标\n\n\n项目构建 profile\n\n\n项目版本\n\n\n项目开发者列表\n\n\n相关邮件列表信息\n\n\n 项目组\n\n项目的唯一ID\n\n12345678910111213141516&lt;project xmlns = \"http://maven.apache.org/POM/4.0.0\"    xmlns:xsi = \"http://www.w3.org/2001/XMLSchema-instance\"    xsi:schemaLocation = \"http://maven.apache.org/POM/4.0.0    http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt;     &lt;!-- 模型版本 --&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;!-- 公司或者组织的唯一标志，并且配置时生成的路径也是由此生成， 如com.companyname.project-group，maven会将该项目打成的jar包放本地路径：/com/companyname/project-group --&gt;    &lt;groupId&gt;com.companyname.project-group&lt;/groupId&gt;     &lt;!-- 项目的唯一ID，一个groupId下面可能多个项目，就是靠artifactId来区分的 --&gt;    &lt;artifactId&gt;project&lt;/artifactId&gt;     &lt;!-- 版本号 --&gt;    &lt;version&gt;1.0&lt;/version&gt;&lt;/project&gt;\n\n所有 POM 文件都需要 project 元素和三个必需字段：groupId，artifactId，version\n\n\n\n\n节点\n描述\n\n\n\n\nproject\n工程的根标签。\n\n\nmodelVersion\n模型版本需要设置为 4.0。\n\n\ngroupId\n这是工程组的标识。它在一个组织或者项目中通常是唯一的。例如，一个银行组织 com.companyname.project-group 拥有所有的和银行相关的项目。\n\n\nartifactId\n这是工程的标识。它通常是工程的名称。例如，消费者银行。groupId 和 artifactId 一起定义了 artifact 在仓库中的位置。\n\n\nversion\n这是工程的版本号。在 artifact 的仓库中，它用来区分不同的版本。例如：com.company.bank:consumer-banking:1.0 com.company.bank:consumer-banking:1.1\n\n\n\n 父POM(Super POM)\n\nMaven 默认的 POM\n所有的 POM 都继承自一个父 POM\n\n无论是否显式定义了这个父 POM\n\n\n包含了一些可以被继承的默认设置\n\n当 Maven 发现需要下载 POM 中的 依赖时，它会到 Super POM 中配置的默认仓库 http://repo1.maven.org/maven2 去下载\n\n\nMaven 使用 effective pom（Super pom 加上工程自己的配置）来执行相关的目标\n\n帮助开发者在 pom.xml 中做尽可能少的配置\n这些配置可以被重写\n\n\n\n 查看Super POM默认配置\n\nmvn help:effective-pom\nEffective POM 的结果\n\n经过继承、插值之后，使配置生效\n\n\n\n POM 标签\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"    xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0http://maven.apache.org/maven-v4_0_0.xsd\"&gt;    &lt;!--父项目的坐标。如果项目中没有规定某个元素的值，那么父项目中的对应值即为项目的默认值。 坐标包括group ID，artifact ID和         version。 --&gt;    &lt;parent&gt;        &lt;!--被继承的父项目的构件标识符 --&gt;        &lt;artifactId /&gt;        &lt;!--被继承的父项目的全球唯一标识符 --&gt;        &lt;groupId /&gt;        &lt;!--被继承的父项目的版本 --&gt;        &lt;version /&gt;        &lt;!-- 父项目的pom.xml文件的相对路径。相对路径允许你选择一个不同的路径。默认值是../pom.xml。Maven首先在构建当前项目的地方寻找父项             目的pom，其次在文件系统的这个位置（relativePath位置），然后在本地仓库，最后在远程仓库寻找父项目的pom。 --&gt;        &lt;relativePath /&gt;    &lt;/parent&gt;    &lt;!--声明项目描述符遵循哪一个POM模型版本。模型本身的版本很少改变，虽然如此，但它仍然是必不可少的，这是为了当Maven引入了新的特性或者其他模型变更的时候，确保稳定性。 --&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;!--项目的全球唯一标识符，通常使用全限定的包名区分该项目和其他项目。并且构建时生成的路径也是由此生成， 如com.mycompany.app生成的相对路径为：/com/mycompany/app --&gt;    &lt;groupId&gt;asia.banseon&lt;/groupId&gt;    &lt;!-- 构件的标识符，它和group ID一起唯一标识一个构件。换句话说，你不能有两个不同的项目拥有同样的artifact ID和groupID；在某个         特定的group ID下，artifact ID也必须是唯一的。构件是项目产生的或使用的一个东西，Maven为项目产生的构件包括：JARs，源 码，二进制发布和WARs等。 --&gt;    &lt;artifactId&gt;banseon-maven2&lt;/artifactId&gt;    &lt;!--项目产生的构件类型，例如jar、war、ear、pom。插件可以创建他们自己的构件类型，所以前面列的不是全部构件类型 --&gt;    &lt;packaging&gt;jar&lt;/packaging&gt;    &lt;!--项目当前版本，格式为:主版本.次版本.增量版本-限定版本号 --&gt;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;!--项目的名称, Maven产生的文档用 --&gt;    &lt;name&gt;banseon-maven&lt;/name&gt;    &lt;!--项目主页的URL, Maven产生的文档用 --&gt;    &lt;url&gt;http://www.baidu.com/banseon&lt;/url&gt;    &lt;!-- 项目的详细描述, Maven 产生的文档用。 当这个元素能够用HTML格式描述时（例如，CDATA中的文本会被解析器忽略，就可以包含HTML标         签）， 不鼓励使用纯文本描述。如果你需要修改产生的web站点的索引页面，你应该修改你自己的索引页文件，而不是调整这里的文档。 --&gt;    &lt;description&gt;A maven project to study maven.&lt;/description&gt;    &lt;!--描述了这个项目构建环境中的前提条件。 --&gt;    &lt;prerequisites&gt;        &lt;!--构建该项目或使用该插件所需要的Maven的最低版本 --&gt;        &lt;maven /&gt;    &lt;/prerequisites&gt;    &lt;!--项目的问题管理系统(Bugzilla, Jira, Scarab,或任何你喜欢的问题管理系统)的名称和URL，本例为 jira --&gt;    &lt;issueManagement&gt;        &lt;!--问题管理系统（例如jira）的名字， --&gt;        &lt;system&gt;jira&lt;/system&gt;        &lt;!--该项目使用的问题管理系统的URL --&gt;        &lt;url&gt;http://jira.baidu.com/banseon&lt;/url&gt;    &lt;/issueManagement&gt;    &lt;!--项目持续集成信息 --&gt;    &lt;ciManagement&gt;        &lt;!--持续集成系统的名字，例如continuum --&gt;        &lt;system /&gt;        &lt;!--该项目使用的持续集成系统的URL（如果持续集成系统有web接口的话）。 --&gt;        &lt;url /&gt;        &lt;!--构建完成时，需要通知的开发者/用户的配置项。包括被通知者信息和通知条件（错误，失败，成功，警告） --&gt;        &lt;notifiers&gt;            &lt;!--配置一种方式，当构建中断时，以该方式通知用户/开发者 --&gt;            &lt;notifier&gt;                &lt;!--传送通知的途径 --&gt;                &lt;type /&gt;                &lt;!--发生错误时是否通知 --&gt;                &lt;sendOnError /&gt;                &lt;!--构建失败时是否通知 --&gt;                &lt;sendOnFailure /&gt;                &lt;!--构建成功时是否通知 --&gt;                &lt;sendOnSuccess /&gt;                &lt;!--发生警告时是否通知 --&gt;                &lt;sendOnWarning /&gt;                &lt;!--不赞成使用。通知发送到哪里 --&gt;                &lt;address /&gt;                &lt;!--扩展配置项 --&gt;                &lt;configuration /&gt;            &lt;/notifier&gt;        &lt;/notifiers&gt;    &lt;/ciManagement&gt;    &lt;!--项目创建年份，4位数字。当产生版权信息时需要使用这个值。 --&gt;    &lt;inceptionYear /&gt;    &lt;!--项目相关邮件列表信息 --&gt;    &lt;mailingLists&gt;        &lt;!--该元素描述了项目相关的所有邮件列表。自动产生的网站引用这些信息。 --&gt;        &lt;mailingList&gt;            &lt;!--邮件的名称 --&gt;            &lt;name&gt;Demo&lt;/name&gt;            &lt;!--发送邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建 --&gt;            &lt;post&gt;banseon@126.com&lt;/post&gt;            &lt;!--订阅邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建 --&gt;            &lt;subscribe&gt;banseon@126.com&lt;/subscribe&gt;            &lt;!--取消订阅邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建 --&gt;            &lt;unsubscribe&gt;banseon@126.com&lt;/unsubscribe&gt;            &lt;!--你可以浏览邮件信息的URL --&gt;            &lt;archive&gt;http:/hi.baidu.com/banseon/demo/dev/&lt;/archive&gt;        &lt;/mailingList&gt;    &lt;/mailingLists&gt;    &lt;!--项目开发者列表 --&gt;    &lt;developers&gt;        &lt;!--某个项目开发者的信息 --&gt;        &lt;developer&gt;            &lt;!--SCM里项目开发者的唯一标识符 --&gt;            &lt;id&gt;HELLO WORLD&lt;/id&gt;            &lt;!--项目开发者的全名 --&gt;            &lt;name&gt;banseon&lt;/name&gt;            &lt;!--项目开发者的email --&gt;            &lt;email&gt;banseon@126.com&lt;/email&gt;            &lt;!--项目开发者的主页的URL --&gt;            &lt;url /&gt;            &lt;!--项目开发者在项目中扮演的角色，角色元素描述了各种角色 --&gt;            &lt;roles&gt;                &lt;role&gt;Project Manager&lt;/role&gt;                &lt;role&gt;Architect&lt;/role&gt;            &lt;/roles&gt;            &lt;!--项目开发者所属组织 --&gt;            &lt;organization&gt;demo&lt;/organization&gt;            &lt;!--项目开发者所属组织的URL --&gt;            &lt;organizationUrl&gt;http://hi.baidu.com/banseon&lt;/organizationUrl&gt;            &lt;!--项目开发者属性，如即时消息如何处理等 --&gt;            &lt;properties&gt;                &lt;dept&gt;No&lt;/dept&gt;            &lt;/properties&gt;            &lt;!--项目开发者所在时区， -11到12范围内的整数。 --&gt;            &lt;timezone&gt;-5&lt;/timezone&gt;        &lt;/developer&gt;    &lt;/developers&gt;    &lt;!--项目的其他贡献者列表 --&gt;    &lt;contributors&gt;        &lt;!--项目的其他贡献者。参见developers/developer元素 --&gt;        &lt;contributor&gt;            &lt;name /&gt;            &lt;email /&gt;            &lt;url /&gt;            &lt;organization /&gt;            &lt;organizationUrl /&gt;            &lt;roles /&gt;            &lt;timezone /&gt;            &lt;properties /&gt;        &lt;/contributor&gt;    &lt;/contributors&gt;    &lt;!--该元素描述了项目所有License列表。 应该只列出该项目的license列表，不要列出依赖项目的 license列表。如果列出多个license，用户可以选择它们中的一个而不是接受所有license。 --&gt;    &lt;licenses&gt;        &lt;!--描述了项目的license，用于生成项目的web站点的license页面，其他一些报表和validation也会用到该元素。 --&gt;        &lt;license&gt;            &lt;!--license用于法律上的名称 --&gt;            &lt;name&gt;Apache 2&lt;/name&gt;            &lt;!--官方的license正文页面的URL --&gt;            &lt;url&gt;http://www.baidu.com/banseon/LICENSE-2.0.txt&lt;/url&gt;            &lt;!--项目分发的主要方式： repo，可以从Maven库下载 manual， 用户必须手动下载和安装依赖 --&gt;            &lt;distribution&gt;repo&lt;/distribution&gt;            &lt;!--关于license的补充信息 --&gt;            &lt;comments&gt;A business-friendly OSS license&lt;/comments&gt;        &lt;/license&gt;    &lt;/licenses&gt;    &lt;!--SCM(Source Control Management)标签允许你配置你的代码库，供Maven web站点和其它插件使用。 --&gt;    &lt;scm&gt;        &lt;!--SCM的URL,该URL描述了版本库和如何连接到版本库。欲知详情，请看SCMs提供的URL格式和列表。该连接只读。 --&gt;        &lt;connection&gt;            scm:svn:http://svn.baidu.com/banseon/maven/banseon/banseon-maven2-trunk(dao-trunk)        &lt;/connection&gt;        &lt;!--给开发者使用的，类似connection元素。即该连接不仅仅只读 --&gt;        &lt;developerConnection&gt;            scm:svn:http://svn.baidu.com/banseon/maven/banseon/dao-trunk        &lt;/developerConnection&gt;        &lt;!--当前代码的标签，在开发阶段默认为HEAD --&gt;        &lt;tag /&gt;        &lt;!--指向项目的可浏览SCM库（例如ViewVC或者Fisheye）的URL。 --&gt;        &lt;url&gt;http://svn.baidu.com/banseon&lt;/url&gt;    &lt;/scm&gt;    &lt;!--描述项目所属组织的各种属性。Maven产生的文档用 --&gt;    &lt;organization&gt;        &lt;!--组织的全名 --&gt;        &lt;name&gt;demo&lt;/name&gt;        &lt;!--组织主页的URL --&gt;        &lt;url&gt;http://www.baidu.com/banseon&lt;/url&gt;    &lt;/organization&gt;    &lt;!--构建项目需要的信息 --&gt;    &lt;build&gt;        &lt;!--该元素设置了项目源码目录，当构建项目的时候，构建系统会编译目录里的源码。该路径是相对于pom.xml的相对路径。 --&gt;        &lt;sourceDirectory /&gt;        &lt;!--该元素设置了项目脚本源码目录，该目录和源码目录不同：绝大多数情况下，该目录下的内容 会被拷贝到输出目录(因为脚本是被解释的，而不是被编译的)。 --&gt;        &lt;scriptSourceDirectory /&gt;        &lt;!--该元素设置了项目单元测试使用的源码目录，当测试项目的时候，构建系统会编译目录里的源码。该路径是相对于pom.xml的相对路径。 --&gt;        &lt;testSourceDirectory /&gt;        &lt;!--被编译过的应用程序class文件存放的目录。 --&gt;        &lt;outputDirectory /&gt;        &lt;!--被编译过的测试class文件存放的目录。 --&gt;        &lt;testOutputDirectory /&gt;        &lt;!--使用来自该项目的一系列构建扩展 --&gt;        &lt;extensions&gt;            &lt;!--描述使用到的构建扩展。 --&gt;            &lt;extension&gt;                &lt;!--构建扩展的groupId --&gt;                &lt;groupId /&gt;                &lt;!--构建扩展的artifactId --&gt;                &lt;artifactId /&gt;                &lt;!--构建扩展的版本 --&gt;                &lt;version /&gt;            &lt;/extension&gt;        &lt;/extensions&gt;        &lt;!--当项目没有规定目标（Maven2 叫做阶段）时的默认值 --&gt;        &lt;defaultGoal /&gt;        &lt;!--这个元素描述了项目相关的所有资源路径列表，例如和项目相关的属性文件，这些资源被包含在最终的打包文件里。 --&gt;        &lt;resources&gt;            &lt;!--这个元素描述了项目相关或测试相关的所有资源路径 --&gt;            &lt;resource&gt;                &lt;!-- 描述了资源的目标路径。该路径相对target/classes目录（例如$&#123;project.build.outputDirectory&#125;）。举个例                     子，如果你想资源在特定的包里(org.apache.maven.messages)，你就必须该元素设置为org/apache/maven /messages。然而，如果你只是想把资源放到源码目录结构里，就不需要该配置。 --&gt;                &lt;targetPath /&gt;                &lt;!--是否使用参数值代替参数名。参数值取自properties元素或者文件里配置的属性，文件在filters元素里列出。 --&gt;                &lt;filtering /&gt;                &lt;!--描述存放资源的目录，该路径相对POM路径 --&gt;                &lt;directory /&gt;                &lt;!--包含的模式列表，例如**/*.xml. --&gt;                &lt;includes /&gt;                &lt;!--排除的模式列表，例如**/*.xml --&gt;                &lt;excludes /&gt;            &lt;/resource&gt;        &lt;/resources&gt;        &lt;!--这个元素描述了单元测试相关的所有资源路径，例如和单元测试相关的属性文件。 --&gt;        &lt;testResources&gt;            &lt;!--这个元素描述了测试相关的所有资源路径，参见build/resources/resource元素的说明 --&gt;            &lt;testResource&gt;                &lt;targetPath /&gt;                &lt;filtering /&gt;                &lt;directory /&gt;                &lt;includes /&gt;                &lt;excludes /&gt;            &lt;/testResource&gt;        &lt;/testResources&gt;        &lt;!--构建产生的所有文件存放的目录 --&gt;        &lt;directory /&gt;        &lt;!--产生的构件的文件名，默认值是$&#123;artifactId&#125;-$&#123;version&#125;。 --&gt;        &lt;finalName /&gt;        &lt;!--当filtering开关打开时，使用到的过滤器属性文件列表 --&gt;        &lt;filters /&gt;        &lt;!--子项目可以引用的默认插件信息。该插件配置项直到被引用时才会被解析或绑定到生命周期。给定插件的任何本地配置都会覆盖这里的配置 --&gt;        &lt;pluginManagement&gt;            &lt;!--使用的插件列表 。 --&gt;            &lt;plugins&gt;                &lt;!--plugin元素包含描述插件所需要的信息。 --&gt;                &lt;plugin&gt;                    &lt;!--插件在仓库里的group ID --&gt;                    &lt;groupId /&gt;                    &lt;!--插件在仓库里的artifact ID --&gt;                    &lt;artifactId /&gt;                    &lt;!--被使用的插件的版本（或版本范围） --&gt;                    &lt;version /&gt;                    &lt;!--是否从该插件下载Maven扩展（例如打包和类型处理器），由于性能原因，只有在真需要下载时，该元素才被设置成enabled。 --&gt;                    &lt;extensions /&gt;                    &lt;!--在构建生命周期中执行一组目标的配置。每个目标可能有不同的配置。 --&gt;                    &lt;executions&gt;                        &lt;!--execution元素包含了插件执行需要的信息 --&gt;                        &lt;execution&gt;                            &lt;!--执行目标的标识符，用于标识构建过程中的目标，或者匹配继承过程中需要合并的执行目标 --&gt;                            &lt;id /&gt;                            &lt;!--绑定了目标的构建生命周期阶段，如果省略，目标会被绑定到源数据里配置的默认阶段 --&gt;                            &lt;phase /&gt;                            &lt;!--配置的执行目标 --&gt;                            &lt;goals /&gt;                            &lt;!--配置是否被传播到子POM --&gt;                            &lt;inherited /&gt;                            &lt;!--作为DOM对象的配置 --&gt;                            &lt;configuration /&gt;                        &lt;/execution&gt;                    &lt;/executions&gt;                    &lt;!--项目引入插件所需要的额外依赖 --&gt;                    &lt;dependencies&gt;                        &lt;!--参见dependencies/dependency元素 --&gt;                        &lt;dependency&gt;                            ......                        &lt;/dependency&gt;                    &lt;/dependencies&gt;                    &lt;!--任何配置是否被传播到子项目 --&gt;                    &lt;inherited /&gt;                    &lt;!--作为DOM对象的配置 --&gt;                    &lt;configuration /&gt;                &lt;/plugin&gt;            &lt;/plugins&gt;        &lt;/pluginManagement&gt;        &lt;!--使用的插件列表 --&gt;        &lt;plugins&gt;            &lt;!--参见build/pluginManagement/plugins/plugin元素 --&gt;            &lt;plugin&gt;                &lt;groupId /&gt;                &lt;artifactId /&gt;                &lt;version /&gt;                &lt;extensions /&gt;                &lt;executions&gt;                    &lt;execution&gt;                        &lt;id /&gt;                        &lt;phase /&gt;                        &lt;goals /&gt;                        &lt;inherited /&gt;                        &lt;configuration /&gt;                    &lt;/execution&gt;                &lt;/executions&gt;                &lt;dependencies&gt;                    &lt;!--参见dependencies/dependency元素 --&gt;                    &lt;dependency&gt;                        ......                    &lt;/dependency&gt;                &lt;/dependencies&gt;                &lt;goals /&gt;                &lt;inherited /&gt;                &lt;configuration /&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;    &lt;!--在列的项目构建profile，如果被激活，会修改构建处理 --&gt;    &lt;profiles&gt;        &lt;!--根据环境参数或命令行参数激活某个构建处理 --&gt;        &lt;profile&gt;            &lt;!--构建配置的唯一标识符。即用于命令行激活，也用于在继承时合并具有相同标识符的profile。 --&gt;            &lt;id /&gt;            &lt;!--自动触发profile的条件逻辑。Activation是profile的开启钥匙。profile的力量来自于它 能够在某些特定的环境中自动使用某些特定的值；这些环境通过activation元素指定。activation元素并不是激活profile的唯一方式。 --&gt;            &lt;activation&gt;                &lt;!--profile默认是否激活的标志 --&gt;                &lt;activeByDefault /&gt;                &lt;!--当匹配的jdk被检测到，profile被激活。例如，1.4激活JDK1.4，1.4.0_2，而!1.4激活所有版本不是以1.4开头的JDK。 --&gt;                &lt;jdk /&gt;                &lt;!--当匹配的操作系统属性被检测到，profile被激活。os元素可以定义一些操作系统相关的属性。 --&gt;                &lt;os&gt;                    &lt;!--激活profile的操作系统的名字 --&gt;                    &lt;name&gt;Windows XP&lt;/name&gt;                    &lt;!--激活profile的操作系统所属家族(如 'windows') --&gt;                    &lt;family&gt;Windows&lt;/family&gt;                    &lt;!--激活profile的操作系统体系结构 --&gt;                    &lt;arch&gt;x86&lt;/arch&gt;                    &lt;!--激活profile的操作系统版本 --&gt;                    &lt;version&gt;5.1.2600&lt;/version&gt;                &lt;/os&gt;                &lt;!--如果Maven检测到某一个属性（其值可以在POM中通过$&#123;名称&#125;引用），其拥有对应的名称和值，Profile就会被激活。如果值 字段是空的，那么存在属性名称字段就会激活profile，否则按区分大小写方式匹配属性值字段 --&gt;                &lt;property&gt;                    &lt;!--激活profile的属性的名称 --&gt;                    &lt;name&gt;mavenVersion&lt;/name&gt;                    &lt;!--激活profile的属性的值 --&gt;                    &lt;value&gt;2.0.3&lt;/value&gt;                &lt;/property&gt;                &lt;!--提供一个文件名，通过检测该文件的存在或不存在来激活profile。missing检查文件是否存在，如果不存在则激活 profile。另一方面，exists则会检查文件是否存在，如果存在则激活profile。 --&gt;                &lt;file&gt;                    &lt;!--如果指定的文件存在，则激活profile。 --&gt;                    &lt;exists&gt;/usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/                    &lt;/exists&gt;                    &lt;!--如果指定的文件不存在，则激活profile。 --&gt;                    &lt;missing&gt;/usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/                    &lt;/missing&gt;                &lt;/file&gt;            &lt;/activation&gt;            &lt;!--构建项目所需要的信息。参见build元素 --&gt;            &lt;build&gt;                &lt;defaultGoal /&gt;                &lt;resources&gt;                    &lt;resource&gt;                        &lt;targetPath /&gt;                        &lt;filtering /&gt;                        &lt;directory /&gt;                        &lt;includes /&gt;                        &lt;excludes /&gt;                    &lt;/resource&gt;                &lt;/resources&gt;                &lt;testResources&gt;                    &lt;testResource&gt;                        &lt;targetPath /&gt;                        &lt;filtering /&gt;                        &lt;directory /&gt;                        &lt;includes /&gt;                        &lt;excludes /&gt;                    &lt;/testResource&gt;                &lt;/testResources&gt;                &lt;directory /&gt;                &lt;finalName /&gt;                &lt;filters /&gt;                &lt;pluginManagement&gt;                    &lt;plugins&gt;                        &lt;!--参见build/pluginManagement/plugins/plugin元素 --&gt;                        &lt;plugin&gt;                            &lt;groupId /&gt;                            &lt;artifactId /&gt;                            &lt;version /&gt;                            &lt;extensions /&gt;                            &lt;executions&gt;                                &lt;execution&gt;                                    &lt;id /&gt;                                    &lt;phase /&gt;                                    &lt;goals /&gt;                                    &lt;inherited /&gt;                                    &lt;configuration /&gt;                                &lt;/execution&gt;                            &lt;/executions&gt;                            &lt;dependencies&gt;                                &lt;!--参见dependencies/dependency元素 --&gt;                                &lt;dependency&gt;                                    ......                                &lt;/dependency&gt;                            &lt;/dependencies&gt;                            &lt;goals /&gt;                            &lt;inherited /&gt;                            &lt;configuration /&gt;                        &lt;/plugin&gt;                    &lt;/plugins&gt;                &lt;/pluginManagement&gt;                &lt;plugins&gt;                    &lt;!--参见build/pluginManagement/plugins/plugin元素 --&gt;                    &lt;plugin&gt;                        &lt;groupId /&gt;                        &lt;artifactId /&gt;                        &lt;version /&gt;                        &lt;extensions /&gt;                        &lt;executions&gt;                            &lt;execution&gt;                                &lt;id /&gt;                                &lt;phase /&gt;                                &lt;goals /&gt;                                &lt;inherited /&gt;                                &lt;configuration /&gt;                            &lt;/execution&gt;                        &lt;/executions&gt;                        &lt;dependencies&gt;                            &lt;!--参见dependencies/dependency元素 --&gt;                            &lt;dependency&gt;                                ......                            &lt;/dependency&gt;                        &lt;/dependencies&gt;                        &lt;goals /&gt;                        &lt;inherited /&gt;                        &lt;configuration /&gt;                    &lt;/plugin&gt;                &lt;/plugins&gt;            &lt;/build&gt;            &lt;!--模块（有时称作子项目） 被构建成项目的一部分。列出的每个模块元素是指向该模块的目录的相对路径 --&gt;            &lt;modules /&gt;            &lt;!--发现依赖和扩展的远程仓库列表。 --&gt;            &lt;repositories&gt;                &lt;!--参见repositories/repository元素 --&gt;                &lt;repository&gt;                    &lt;releases&gt;                        &lt;enabled /&gt;                        &lt;updatePolicy /&gt;                        &lt;checksumPolicy /&gt;                    &lt;/releases&gt;                    &lt;snapshots&gt;                        &lt;enabled /&gt;                        &lt;updatePolicy /&gt;                        &lt;checksumPolicy /&gt;                    &lt;/snapshots&gt;                    &lt;id /&gt;                    &lt;name /&gt;                    &lt;url /&gt;                    &lt;layout /&gt;                &lt;/repository&gt;            &lt;/repositories&gt;            &lt;!--发现插件的远程仓库列表，这些插件用于构建和报表 --&gt;            &lt;pluginRepositories&gt;                &lt;!--包含需要连接到远程插件仓库的信息.参见repositories/repository元素 --&gt;                &lt;pluginRepository&gt;                    &lt;releases&gt;                        &lt;enabled /&gt;                        &lt;updatePolicy /&gt;                        &lt;checksumPolicy /&gt;                    &lt;/releases&gt;                    &lt;snapshots&gt;                        &lt;enabled /&gt;                        &lt;updatePolicy /&gt;                        &lt;checksumPolicy /&gt;                    &lt;/snapshots&gt;                    &lt;id /&gt;                    &lt;name /&gt;                    &lt;url /&gt;                    &lt;layout /&gt;                &lt;/pluginRepository&gt;            &lt;/pluginRepositories&gt;            &lt;!--该元素描述了项目相关的所有依赖。 这些依赖组成了项目构建过程中的一个个环节。它们自动从项目定义的仓库中下载。要获取更多信息，请看项目依赖机制。 --&gt;            &lt;dependencies&gt;                &lt;!--参见dependencies/dependency元素 --&gt;                &lt;dependency&gt;                    ......                &lt;/dependency&gt;            &lt;/dependencies&gt;            &lt;!--不赞成使用. 现在Maven忽略该元素. --&gt;            &lt;reports /&gt;            &lt;!--该元素包括使用报表插件产生报表的规范。当用户执行\"mvn site\"，这些报表就会运行。 在页面导航栏能看到所有报表的链接。参见reporting元素 --&gt;            &lt;reporting&gt;                ......            &lt;/reporting&gt;            &lt;!--参见dependencyManagement元素 --&gt;            &lt;dependencyManagement&gt;                &lt;dependencies&gt;                    &lt;!--参见dependencies/dependency元素 --&gt;                    &lt;dependency&gt;                        ......                    &lt;/dependency&gt;                &lt;/dependencies&gt;            &lt;/dependencyManagement&gt;            &lt;!--参见distributionManagement元素 --&gt;            &lt;distributionManagement&gt;                ......            &lt;/distributionManagement&gt;            &lt;!--参见properties元素 --&gt;            &lt;properties /&gt;        &lt;/profile&gt;    &lt;/profiles&gt;    &lt;!--模块（有时称作子项目） 被构建成项目的一部分。列出的每个模块元素是指向该模块的目录的相对路径 --&gt;    &lt;modules /&gt;    &lt;!--发现依赖和扩展的远程仓库列表。 --&gt;    &lt;repositories&gt;        &lt;!--包含需要连接到远程仓库的信息 --&gt;        &lt;repository&gt;            &lt;!--如何处理远程仓库里发布版本的下载 --&gt;            &lt;releases&gt;                &lt;!--true或者false表示该仓库是否为下载某种类型构件（发布版，快照版）开启。 --&gt;                &lt;enabled /&gt;                &lt;!--该元素指定更新发生的频率。Maven会比较本地POM和远程POM的时间戳。这里的选项是：always（一直），daily（默认，每日），interval：X（这里X是以分钟为单位的时间间隔），或者never（从不）。 --&gt;                &lt;updatePolicy /&gt;                &lt;!--当Maven验证构件校验文件失败时该怎么做：ignore（忽略），fail（失败），或者warn（警告）。 --&gt;                &lt;checksumPolicy /&gt;            &lt;/releases&gt;            &lt;!-- 如何处理远程仓库里快照版本的下载。有了releases和snapshots这两组配置，POM就可以在每个单独的仓库中，为每种类型的构件采取不同的                 策略。例如，可能有人会决定只为开发目的开启对快照版本下载的支持。参见repositories/repository/releases元素 --&gt;            &lt;snapshots&gt;                &lt;enabled /&gt;                &lt;updatePolicy /&gt;                &lt;checksumPolicy /&gt;            &lt;/snapshots&gt;            &lt;!--远程仓库唯一标识符。可以用来匹配在settings.xml文件里配置的远程仓库 --&gt;            &lt;id&gt;banseon-repository-proxy&lt;/id&gt;            &lt;!--远程仓库名称 --&gt;            &lt;name&gt;banseon-repository-proxy&lt;/name&gt;            &lt;!--远程仓库URL，按protocol://hostname/path形式 --&gt;            &lt;url&gt;http://192.168.1.169:9999/repository/&lt;/url&gt;            &lt;!-- 用于定位和排序构件的仓库布局类型-可以是default（默认）或者legacy（遗留）。Maven 2为其仓库提供了一个默认的布局；然                 而，Maven 1.x有一种不同的布局。我们可以使用该元素指定布局是default（默认）还是legacy（遗留）。 --&gt;            &lt;layout&gt;default&lt;/layout&gt;        &lt;/repository&gt;    &lt;/repositories&gt;    &lt;!--发现插件的远程仓库列表，这些插件用于构建和报表 --&gt;    &lt;pluginRepositories&gt;        &lt;!--包含需要连接到远程插件仓库的信息.参见repositories/repository元素 --&gt;        &lt;pluginRepository&gt;            ......        &lt;/pluginRepository&gt;    &lt;/pluginRepositories&gt;      &lt;!--该元素描述了项目相关的所有依赖。 这些依赖组成了项目构建过程中的一个个环节。它们自动从项目定义的仓库中下载。要获取更多信息，请看项目依赖机制。 --&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;!--依赖的group ID --&gt;            &lt;groupId&gt;org.apache.maven&lt;/groupId&gt;            &lt;!--依赖的artifact ID --&gt;            &lt;artifactId&gt;maven-artifact&lt;/artifactId&gt;            &lt;!--依赖的版本号。 在Maven 2里, 也可以配置成版本号的范围。 --&gt;            &lt;version&gt;3.8.1&lt;/version&gt;            &lt;!-- 依赖类型，默认类型是jar。它通常表示依赖的文件的扩展名，但也有例外。一个类型可以被映射成另外一个扩展名或分类器。类型经常和使用的打包方式对应，                 尽管这也有例外。一些类型的例子：jar，war，ejb-client和test-jar。如果设置extensions为 true，就可以在 plugin里定义新的类型。所以前面的类型的例子不完整。 --&gt;            &lt;type&gt;jar&lt;/type&gt;            &lt;!-- 依赖的分类器。分类器可以区分属于同一个POM，但不同构建方式的构件。分类器名被附加到文件名的版本号后面。例如，如果你想要构建两个单独的构件成                 JAR，一个使用Java 1.4编译器，另一个使用Java 6编译器，你就可以使用分类器来生成两个单独的JAR构件。 --&gt;            &lt;classifier&gt;&lt;/classifier&gt;            &lt;!--依赖范围。在项目发布过程中，帮助决定哪些构件被包括进来。欲知详情请参考依赖机制。 - compile ：默认范围，用于编译 - provided：类似于编译，但支持你期待jdk或者容器提供，类似于classpath                 - runtime: 在执行时需要使用 - test: 用于test任务时使用 - system: 需要外在提供相应的元素。通过systemPath来取得                 - systemPath: 仅用于范围为system。提供相应的路径 - optional: 当项目自身被依赖时，标注依赖是否传递。用于连续依赖时使用 --&gt;            &lt;scope&gt;test&lt;/scope&gt;            &lt;!--仅供system范围使用。注意，不鼓励使用这个元素，并且在新的版本中该元素可能被覆盖掉。该元素为依赖规定了文件系统上的路径。需要绝对路径而不是相对路径。推荐使用属性匹配绝对路径，例如$&#123;java.home&#125;。 --&gt;            &lt;systemPath&gt;&lt;/systemPath&gt;            &lt;!--当计算传递依赖时， 从依赖构件列表里，列出被排除的依赖构件集。即告诉maven你只依赖指定的项目，不依赖项目的依赖。此元素主要用于解决版本冲突问题 --&gt;            &lt;exclusions&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;spring-core&lt;/artifactId&gt;                    &lt;groupId&gt;org.springframework&lt;/groupId&gt;                &lt;/exclusion&gt;            &lt;/exclusions&gt;            &lt;!--可选依赖，如果你在项目B中把C依赖声明为可选，你就需要在依赖于B的项目（例如项目A）中显式的引用对C的依赖。可选依赖阻断依赖的传递性。 --&gt;            &lt;optional&gt;true&lt;/optional&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;    &lt;!--不赞成使用. 现在Maven忽略该元素. --&gt;    &lt;reports&gt;&lt;/reports&gt;    &lt;!--该元素描述使用报表插件产生报表的规范。当用户执行\"mvn site\"，这些报表就会运行。 在页面导航栏能看到所有报表的链接。 --&gt;    &lt;reporting&gt;        &lt;!--true，则，网站不包括默认的报表。这包括\"项目信息\"菜单中的报表。 --&gt;        &lt;excludeDefaults /&gt;        &lt;!--所有产生的报表存放到哪里。默认值是$&#123;project.build.directory&#125;/site。 --&gt;        &lt;outputDirectory /&gt;        &lt;!--使用的报表插件和他们的配置。 --&gt;        &lt;plugins&gt;            &lt;!--plugin元素包含描述报表插件需要的信息 --&gt;            &lt;plugin&gt;                &lt;!--报表插件在仓库里的group ID --&gt;                &lt;groupId /&gt;                &lt;!--报表插件在仓库里的artifact ID --&gt;                &lt;artifactId /&gt;                &lt;!--被使用的报表插件的版本（或版本范围） --&gt;                &lt;version /&gt;                &lt;!--任何配置是否被传播到子项目 --&gt;                &lt;inherited /&gt;                &lt;!--报表插件的配置 --&gt;                &lt;configuration /&gt;                &lt;!--一组报表的多重规范，每个规范可能有不同的配置。一个规范（报表集）对应一个执行目标 。例如，有1，2，3，4，5，6，7，8，9个报表。1，2，5构成A报表集，对应一个执行目标。2，5，8构成B报表集，对应另一个执行目标 --&gt;                &lt;reportSets&gt;                    &lt;!--表示报表的一个集合，以及产生该集合的配置 --&gt;                    &lt;reportSet&gt;                        &lt;!--报表集合的唯一标识符，POM继承时用到 --&gt;                        &lt;id /&gt;                        &lt;!--产生报表集合时，被使用的报表的配置 --&gt;                        &lt;configuration /&gt;                        &lt;!--配置是否被继承到子POMs --&gt;                        &lt;inherited /&gt;                        &lt;!--这个集合里使用到哪些报表 --&gt;                        &lt;reports /&gt;                    &lt;/reportSet&gt;                &lt;/reportSets&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/reporting&gt;    &lt;!-- 继承自该项目的所有子项目的默认依赖信息。这部分的依赖信息不会被立即解析,而是当子项目声明一个依赖（必须描述group ID和 artifact         ID信息），如果group ID和artifact ID以外的一些信息没有描述，则通过group ID和artifact ID 匹配到这里的依赖，并使用这里的依赖信息。 --&gt;    &lt;dependencyManagement&gt;        &lt;dependencies&gt;            &lt;!--参见dependencies/dependency元素 --&gt;            &lt;dependency&gt;                ......            &lt;/dependency&gt;        &lt;/dependencies&gt;    &lt;/dependencyManagement&gt;    &lt;!--项目分发信息，在执行mvn deploy后表示要发布的位置。有了这些信息就可以把网站部署到远程服务器或者把构件部署到远程仓库。 --&gt;    &lt;distributionManagement&gt;        &lt;!--部署项目产生的构件到远程仓库需要的信息 --&gt;        &lt;repository&gt;            &lt;!--是分配给快照一个唯一的版本号（由时间戳和构建流水号）？还是每次都使用相同的版本号？参见repositories/repository元素 --&gt;            &lt;uniqueVersion /&gt;            &lt;id&gt;banseon-maven2&lt;/id&gt;            &lt;name&gt;banseon maven2&lt;/name&gt;            &lt;url&gt;file://$&#123;basedir&#125;/target/deploy&lt;/url&gt;            &lt;layout /&gt;        &lt;/repository&gt;        &lt;!--构件的快照部署到哪里？如果没有配置该元素，默认部署到repository元素配置的仓库，参见distributionManagement/repository元素 --&gt;        &lt;snapshotRepository&gt;            &lt;uniqueVersion /&gt;            &lt;id&gt;banseon-maven2&lt;/id&gt;            &lt;name&gt;Banseon-maven2 Snapshot Repository&lt;/name&gt;            &lt;url&gt;scp://svn.baidu.com/banseon:/usr/local/maven-snapshot&lt;/url&gt;            &lt;layout /&gt;        &lt;/snapshotRepository&gt;        &lt;!--部署项目的网站需要的信息 --&gt;        &lt;site&gt;            &lt;!--部署位置的唯一标识符，用来匹配站点和settings.xml文件里的配置 --&gt;            &lt;id&gt;banseon-site&lt;/id&gt;            &lt;!--部署位置的名称 --&gt;            &lt;name&gt;business api website&lt;/name&gt;            &lt;!--部署位置的URL，按protocol://hostname/path形式 --&gt;            &lt;url&gt;                scp://svn.baidu.com/banseon:/var/www/localhost/banseon-web            &lt;/url&gt;        &lt;/site&gt;        &lt;!--项目下载页面的URL。如果没有该元素，用户应该参考主页。使用该元素的原因是：帮助定位那些不在仓库里的构件（由于license限制）。 --&gt;        &lt;downloadUrl /&gt;        &lt;!--如果构件有了新的group ID和artifact ID（构件移到了新的位置），这里列出构件的重定位信息。 --&gt;        &lt;relocation&gt;            &lt;!--构件新的group ID --&gt;            &lt;groupId /&gt;            &lt;!--构件新的artifact ID --&gt;            &lt;artifactId /&gt;            &lt;!--构件新的版本号 --&gt;            &lt;version /&gt;            &lt;!--显示给用户的，关于移动的额外信息，例如原因。 --&gt;            &lt;message /&gt;        &lt;/relocation&gt;        &lt;!-- 给出该构件在远程仓库的状态。不得在本地项目中设置该元素，因为这是工具自动更新的。有效的值有：none（默认），converted（仓库管理员从             Maven 1 POM转换过来），partner（直接从伙伴Maven 2仓库同步过来），deployed（从Maven 2实例部 署），verified（被核实时正确的和最终的）。 --&gt;        &lt;status /&gt;    &lt;/distributionManagement&gt;    &lt;!--以值替代名称，Properties可以在整个POM中使用，也可以作为触发条件（见settings.xml配置文件里activation元素的说明）。格式是&lt;name&gt;value&lt;/name&gt;。 --&gt;    &lt;properties /&gt;&lt;/project&gt;\n","plink":"ilucia.github.io/Maven/基础&POM/"},{"title":"Maven/生命周期","date":"2022-04-27T15:24:01.559Z","updated":"2022-04-27T15:24:01.559Z","content":" Maven 生命周期\n\n项目构建和发布的过程\nMaven有三个标准的生命周期\n\nclean：项目清理的处理\ndefault(build)：项目部署的处理\nsite：项目站点文档创建的处理\n\n\n在一个生命周期中，运行某个阶段的时候，它之前的所有阶段都会被运行\n\n如果执行 mvn clean 将运行pre-clean clean两个生命周期\n\n\n\n 构建生命周期(default/build)\n\n\n下面的阶段将顺序执行以完成default生命周期\n\n\n\n\n生命周期阶段\n描述\n\n\n\n\nvalidate（校验）\n校验项目是否正确并且所有必要的信息可以完成项目的构建过程。\n\n\ninitialize（初始化）\n初始化构建状态，比如设置属性值。\n\n\ngenerate-sources（生成源代码）\n生成包含在编译阶段中的任何源代码。\n\n\nprocess-sources（处理源代码）\n处理源代码，比如说，过滤任意值。\n\n\ngenerate-resources（生成资源文件）\n生成将会包含在项目包中的资源文件。\n\n\nprocess-resources （处理资源文件）\n复制和处理资源到目标目录，为打包阶段最好准备。\n\n\ncompile（编译）\n编译项目的源代码。\n\n\nprocess-classes（处理类文件）\n处理编译生成的文件，比如说对Java class文件做字节码改善优化。\n\n\ngenerate-test-sources（生成测试源代码）\n生成包含在编译阶段中的任何测试源代码。\n\n\nprocess-test-sources（处理测试源代码）\n处理测试源代码，比如说，过滤任意值。\n\n\ngenerate-test-resources（生成测试资源文件）\n为测试创建资源文件。\n\n\nprocess-test-resources（处理测试资源文件）\n复制和处理测试资源到目标目录。\n\n\ntest-compile（编译测试源码）\n编译测试源代码到测试目标目录.\n\n\nprocess-test-classes（处理测试类文件）\n处理测试源码编译生成的文件。\n\n\ntest（测试）\n使用合适的单元测试框架运行测试（Juint是其中之一）。\n\n\nprepare-package（准备打包）\n在实际打包之前，执行任何的必要的操作为打包做准备。\n\n\npackage（打包）\n将编译后的代码打包成可分发格式的文件，比如JAR、WAR或者EAR文件。\n\n\npre-integration-test（集成测试前）\n在执行集成测试前进行必要的动作。比如说，搭建需要的环境。\n\n\nintegration-test（集成测试）\n处理和部署项目到可以运行集成测试环境中。\n\n\npost-integration-test（集成测试后）\n在执行集成测试完成后进行必要的动作。比如说，清理集成测试环境。\n\n\nverify （验证）\n运行任意的检查来验证项目包有效且达到质量标准。\n\n\ninstall（安装）\n安装项目包到本地仓库，这样项目包可以用作其他本地项目的依赖。\n\n\ndeploy（部署）\n将最终的项目包复制到远程仓库中与其他开发者和项目共享。\n\n\n\n 构建阶段\n\n由插件目标构成\n\n一个插件目标代表一个特定的任务（比构建阶段更为精细）\n这些目标可能被绑定到多个阶段或者无绑定\n\n不同的 maven 目标将根据打包的类型（JAR / WAR / EAR），被绑定到不同的 Maven 生命周期阶段\n不绑定到任何构建阶段的目标可以在构建生命周期之外通过直接调用执行\n\n\n这些目标的执行顺序取决于调用目标和构建阶段的顺序\n\n\n\n 例 执行顺序\n1mvn clean dependency:copy-dependencies package\n\nclean 和 pakage 是构建阶段，dependency:copy-dependencies 是目标\nclean 阶段将会被首先执行，然后 dependency:copy-dependencies 目标会被执行，最终 package 阶段被执行\n\n Build 生命周期信息显示\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\"  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0  http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;groupId&gt;com.companyname.projectgroup&lt;/groupId&gt;&lt;artifactId&gt;project&lt;/artifactId&gt;&lt;version&gt;1.0&lt;/version&gt;&lt;build&gt;&lt;plugins&gt;&lt;plugin&gt;&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;&lt;artifactId&gt;maven-antrun-plugin&lt;/artifactId&gt;&lt;version&gt;1.1&lt;/version&gt;&lt;executions&gt;   &lt;execution&gt;      &lt;id&gt;id.validate&lt;/id&gt;      &lt;phase&gt;validate&lt;/phase&gt;      &lt;goals&gt;         &lt;goal&gt;run&lt;/goal&gt;      &lt;/goals&gt;      &lt;configuration&gt;         &lt;tasks&gt;            &lt;echo&gt;validate phase&lt;/echo&gt;         &lt;/tasks&gt;      &lt;/configuration&gt;   &lt;/execution&gt;   &lt;execution&gt;      &lt;id&gt;id.compile&lt;/id&gt;      &lt;phase&gt;compile&lt;/phase&gt;      &lt;goals&gt;         &lt;goal&gt;run&lt;/goal&gt;      &lt;/goals&gt;      &lt;configuration&gt;         &lt;tasks&gt;            &lt;echo&gt;compile phase&lt;/echo&gt;         &lt;/tasks&gt;      &lt;/configuration&gt;   &lt;/execution&gt;   &lt;execution&gt;      &lt;id&gt;id.test&lt;/id&gt;      &lt;phase&gt;test&lt;/phase&gt;      &lt;goals&gt;         &lt;goal&gt;run&lt;/goal&gt;      &lt;/goals&gt;      &lt;configuration&gt;         &lt;tasks&gt;            &lt;echo&gt;test phase&lt;/echo&gt;         &lt;/tasks&gt;      &lt;/configuration&gt;   &lt;/execution&gt;   &lt;execution&gt;         &lt;id&gt;id.package&lt;/id&gt;         &lt;phase&gt;package&lt;/phase&gt;         &lt;goals&gt;            &lt;goal&gt;run&lt;/goal&gt;         &lt;/goals&gt;         &lt;configuration&gt;         &lt;tasks&gt;            &lt;echo&gt;package phase&lt;/echo&gt;         &lt;/tasks&gt;      &lt;/configuration&gt;   &lt;/execution&gt;   &lt;execution&gt;      &lt;id&gt;id.deploy&lt;/id&gt;      &lt;phase&gt;deploy&lt;/phase&gt;      &lt;goals&gt;         &lt;goal&gt;run&lt;/goal&gt;      &lt;/goals&gt;      &lt;configuration&gt;      &lt;tasks&gt;         &lt;echo&gt;deploy phase&lt;/echo&gt;      &lt;/tasks&gt;      &lt;/configuration&gt;   &lt;/execution&gt;&lt;/executions&gt;&lt;/plugin&gt;&lt;/plugins&gt;&lt;/build&gt;&lt;/project&gt;\n 命令行调用\n mvn install\n\n使用 mvn install 命令去构建/安装工程到本地仓库\n在执行install阶段之前，按顺序执行了default生命周期的阶段\n\n只需调用最后一个阶段\n\n\n\n mvn clean deploy\n\n纯净地构建和部署项目到共享仓库中\n也可以用于多模块的情况下，即包含多个子项目的项目，Maven 会在每一个子项目执行 clean 命令，然后再执行 deploy 命令\n\n Clean 生命周期\n\nmvn post-clean 命令时，Maven 调用 clean 生命周期\n包含阶段\n\npre-clean：执行一些需要在clean之前完成的工作\nclean：移除所有上一次构建生成的文件\npost-clean：执行一些需要在clean之后立刻完成的工作\n\n\n\n 修改各阶段操作行为\n\n通过这clean生命周期的任何阶段定义目标\n将 maven-antrun-plugin:run 目标添加到三个阶段中\n\n这clean生命周期的各个阶段显示文本信息\n\n\n执行 mvn post-clean\n\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\"   xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"   xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0   http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;groupId&gt;com.companyname.projectgroup&lt;/groupId&gt;&lt;artifactId&gt;project&lt;/artifactId&gt;&lt;version&gt;1.0&lt;/version&gt;&lt;build&gt;&lt;plugins&gt;   &lt;plugin&gt;   &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;   &lt;artifactId&gt;maven-antrun-plugin&lt;/artifactId&gt;   &lt;version&gt;1.1&lt;/version&gt;   &lt;executions&gt;      &lt;execution&gt;         &lt;id&gt;id.pre-clean&lt;/id&gt;         &lt;phase&gt;pre-clean&lt;/phase&gt;         &lt;goals&gt;            &lt;goal&gt;run&lt;/goal&gt;         &lt;/goals&gt;         &lt;configuration&gt;            &lt;tasks&gt;               &lt;echo&gt;pre-clean phase&lt;/echo&gt;            &lt;/tasks&gt;         &lt;/configuration&gt;      &lt;/execution&gt;      &lt;execution&gt;         &lt;id&gt;id.clean&lt;/id&gt;         &lt;phase&gt;clean&lt;/phase&gt;         &lt;goals&gt;          &lt;goal&gt;run&lt;/goal&gt;         &lt;/goals&gt;         &lt;configuration&gt;            &lt;tasks&gt;               &lt;echo&gt;clean phase&lt;/echo&gt;            &lt;/tasks&gt;         &lt;/configuration&gt;      &lt;/execution&gt;      &lt;execution&gt;         &lt;id&gt;id.post-clean&lt;/id&gt;         &lt;phase&gt;post-clean&lt;/phase&gt;         &lt;goals&gt;            &lt;goal&gt;run&lt;/goal&gt;         &lt;/goals&gt;         &lt;configuration&gt;            &lt;tasks&gt;               &lt;echo&gt;post-clean phase&lt;/echo&gt;            &lt;/tasks&gt;         &lt;/configuration&gt;      &lt;/execution&gt;   &lt;/executions&gt;   &lt;/plugin&gt;&lt;/plugins&gt;&lt;/build&gt;&lt;/project&gt;\n 扩展 显示pre-clean和clean post-clean不执行操作\n Site 生命周期\n\nMaven Site 插件一般用来创建新的报告文档、部署站点等\n包含阶段\n\npre-site：执行一些需要在生成站点文档之前完成的工作\nsite：生成项目的站点文档\npost-site： 执行一些需要在生成站点文档之后完成的工作，并且为部署做准备\nsite-deploy：将生成的站点文档部署到特定的服务器上\n\n\nsite阶段和site-deploy阶段，用以生成和发布Maven站点\n将 maven-antrun-plugin:run 目标添加到 Site 生命周期的所有阶段中\n\n执行命令 mvn site\n\n\n\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\"  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0  http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;groupId&gt;com.companyname.projectgroup&lt;/groupId&gt;&lt;artifactId&gt;project&lt;/artifactId&gt;&lt;version&gt;1.0&lt;/version&gt;&lt;build&gt;&lt;plugins&gt;&lt;plugin&gt;&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;&lt;artifactId&gt;maven-antrun-plugin&lt;/artifactId&gt;&lt;version&gt;1.1&lt;/version&gt;   &lt;executions&gt;      &lt;execution&gt;         &lt;id&gt;id.pre-site&lt;/id&gt;         &lt;phase&gt;pre-site&lt;/phase&gt;         &lt;goals&gt;            &lt;goal&gt;run&lt;/goal&gt;         &lt;/goals&gt;         &lt;configuration&gt;            &lt;tasks&gt;               &lt;echo&gt;pre-site phase&lt;/echo&gt;            &lt;/tasks&gt;         &lt;/configuration&gt;      &lt;/execution&gt;      &lt;execution&gt;         &lt;id&gt;id.site&lt;/id&gt;         &lt;phase&gt;site&lt;/phase&gt;         &lt;goals&gt;         &lt;goal&gt;run&lt;/goal&gt;         &lt;/goals&gt;         &lt;configuration&gt;            &lt;tasks&gt;               &lt;echo&gt;site phase&lt;/echo&gt;            &lt;/tasks&gt;         &lt;/configuration&gt;      &lt;/execution&gt;      &lt;execution&gt;         &lt;id&gt;id.post-site&lt;/id&gt;         &lt;phase&gt;post-site&lt;/phase&gt;         &lt;goals&gt;            &lt;goal&gt;run&lt;/goal&gt;         &lt;/goals&gt;         &lt;configuration&gt;            &lt;tasks&gt;               &lt;echo&gt;post-site phase&lt;/echo&gt;            &lt;/tasks&gt;         &lt;/configuration&gt;      &lt;/execution&gt;      &lt;execution&gt;         &lt;id&gt;id.site-deploy&lt;/id&gt;         &lt;phase&gt;site-deploy&lt;/phase&gt;         &lt;goals&gt;            &lt;goal&gt;run&lt;/goal&gt;         &lt;/goals&gt;         &lt;configuration&gt;            &lt;tasks&gt;               &lt;echo&gt;site-deploy phase&lt;/echo&gt;            &lt;/tasks&gt;         &lt;/configuration&gt;      &lt;/execution&gt;   &lt;/executions&gt;&lt;/plugin&gt;&lt;/plugins&gt;&lt;/build&gt;&lt;/project&gt;\n","plink":"ilucia.github.io/Maven/生命周期/"},{"title":"Python进程池、线程池和进程间通信实践参考","date":"2021-08-21T00:00:00.000Z","updated":"2022-04-27T15:24:01.715Z","content":" 业务需求\n业务中有一个计算量比较大的、可以并行执行的操作，为了提升资源利用率，故考虑多进程分配。\n性能：多线程&lt;线程池&lt;多进程&lt;进程池\n\n在Windows中创建一个进程耗费的时间以秒计算，故要避免频繁的进程创建销毁\n\n 业务流程\n\n一个数据产生源，串行产生数据，速度快\n数据源产生的数据需要比较长的时间进行计算才能得到结果\n所有结果要汇总起来进行过滤和处理最终发放下游服务器\n\n 结构设计\n\n每个核心分配一个处理进程、附加两个低资源占用低工作进程负责产生数据和发送数据\n使用阻塞式的多进程间队列\n\n当任务队列满时数据产生进程阻塞暂时不产生数据（处理不及时）\n当结果队列满时数据处理队列阻塞不产生数据（网络问题或故障）\n\n网络请求使用多线程发送，避免过多资源占用低同时保证请求异步不阻塞\n\n\n\n\n抽离业务代码的进程池和多线程设计代码如下\n\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364import osimport multiprocessingimport threadingimport timeimport json# 发送请求地址CONNECTION_URL = 'url:'# CPU核心数CPU_COUNT = os.cpu_count()# 工作进程数PROC_COUNT = CPU_COUNT + 2# 发送更新数据请求def upload(msg: dict):    r = requests.post(CONNECTION_URL, json=msg)# 多进程任务def process(i, frameQueue, resQueue):     print(f\"[proc &#123;i&#125;] pid &#123;os.getpid()&#125;\")    # fetch frame and push to work queqe    if i == 0:\t\t\twhile True:        #.do some work        frame =.work()      \tframeQueue.put(frame)    # fetch result from resQueue and post it to server by multthreading    elif i == 1:        while True:            res = resQueue.get()            # do some work            data = work2(res)            # 多线程发送请求            threading.Thread(target=upload, args=(data,)).start()   # data processer process, cost many resources and require multprocessing to speed up    else:        while True:            frame = frameQueue.get()            res = work3(frame)            resQueue.put(res)def client():    print(f\"Process :&#123;PROC_COUNT&#125;\")    # 进程池创建    pool = multiprocessing.Pool(PROC_COUNT)    # 任务队列    frameQueue = multiprocessing.Manager().Queue(PROC_COUNT)    # 结果队列    resQueue = multiprocessing.Manager().Queue(PROC_COUNT)    # 给进程池分配函数    for i in range(PROC_COUNT):        pool.apply_async(            process, (i, frameQueue, resQueue))    # 关闭进程池不再接受新进程    pool.close()    # 阻塞主进程    pool.join()    print(\"finish\")if __name__ == '__main__':    client()\n","plink":"ilucia.github.io/Template/"},{"title":"Spring生态学习笔记","date":"2020-07-13T00:00:00.000Z","updated":"2022-04-27T15:24:01.763Z","content":"[toc]\n 概览\n 体系结构\n\n 核心容器\n核心容器由核心，Bean，上下文和表达式语言模块组成，它们的细节如下：\n\n核心模块提供了框架的基本组成部分，包括 IoC 和依赖注入功能。\nBean 模块提供 BeanFactory，它是一个工厂模式的复杂实现。\n上下文模块建立在由核心和 Bean 模块提供的坚实基础上，它是访问定义和配置的任何对象的媒介。ApplicationContext 接口是上下文模块的重点。\n表达式语言模块在运行时提供了查询和操作一个对象图的强大的表达式语言。\n\n 数据访问/集成\n数据访问/集成层包括 JDBC，ORM，OXM，JMS 和事务处理模块，它们的细节如下：\n\nJDBC 模块提供了删除冗余的 JDBC 相关编码的 JDBC 抽象层。\nORM 模块为流行的对象关系映射 API，包括 JPA，JDO，Hibernate 和 iBatis，提供了集成层。\nOXM 模块提供了抽象层，它支持对 JAXB，Castor，XMLBeans，JiBX 和 XStream 的对象/XML 映射实现。\nJava 消息服务 JMS 模块包含生产和消费的信息的功能。\n事务模块为实现特殊接口的类及所有的 POJO 支持编程式和声明式事务管理。\n\n Web\nWeb 层由 Web，Web-MVC，Web-Socket 和 Web-Portlet 组成，它们的细节如下：\n\nWeb 模块提供了基本的面向 web 的集成功能，例如多个文件上传的功能和使用 servlet 监听器和面向 web 应用程序的上下文来初始化 IoC 容器。\nWeb-MVC 模块包含 Spring 的模型-视图-控制器（MVC），实现了 web 应用程序。\nWeb-Socket 模块为 WebSocket-based 提供了支持，而且在 web 应用程序中提供了客户端和服务器端之间通信的两种方式。\nWeb-Portlet 模块提供了在 portlet 环境中实现 MVC，并且反映了 Web-Servlet 模块的功能。\n\n 其他\n还有其他一些重要的模块，像 AOP，Aspects，Instrumentation，Web 和测试模块，它们的细节如下：\n\nAOP 模块提供了面向方面的编程实现，允许你定义方法拦截器和切入点对代码进行干净地解耦，它实现了应该分离的功能。\nAspects 模块提供了与 AspectJ 的集成，这是一个功能强大且成熟的面向切面编程（AOP）框架。\nInstrumentation 模块在一定的应用服务器中提供了类 instrumentation 的支持和类加载器的实现。\nMessaging 模块为 STOMP 提供了支持作为在应用程序中 WebSocket 子协议的使用。它也支持一个注解编程模型，它是为了选路和处理来自 WebSocket 客户端的 STOMP 信息。\n测试模块支持对具有 JUnit 或 TestNG 框架的 Spring 组件的测试。\n\n IOC\n BeanFactory容器\nHelloWorld.java\n12345678910package com.hanyuu;public class HelloWorld &#123;   private String message;   public void setMessage(String message)&#123;    this.message  = message;   &#125;   public void getMessage()&#123;    System.out.println(\"Your Message : \" + message);   &#125;&#125;\nMain.java\n123456789101112package com.hanyuu;import org.springframework.beans.factory.InitializingBean;import org.springframework.beans.factory.xml.XmlBeanFactory;import org.springframework.core.io.ClassPathResource;public class MainApp &#123;   public static void main(String[] args) &#123;      XmlBeanFactory factory = new XmlBeanFactory                             (new ClassPathResource(\"Beans.xml\"));      HelloWorld obj = (HelloWorld) factory.getBean(\"helloWorld\");      obj.getMessage();   &#125;&#125;\nBeans.xml\n1234567891011&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\"    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"    xsi:schemaLocation=\"http://www.springframework.org/schema/beans    http://www.springframework.org/schema/beans/spring-beans-3.0.xsd\"&gt;   &lt;bean id=\"helloWorld\" class=\"com.hanyuu.HelloWorld\"&gt;       &lt;property name=\"message\" value=\"Hello World!\"/&gt;   &lt;/bean&gt;&lt;/beans&gt;\n ApplicationContent容器\n\nApplicationContent 接口实现\n\nFileSystemXmlApplicationContext：使用文件完整路径加载bean\nClassPathXmlApplicationContext：在ClassPath中搜索（只需要提供文件名）\nWebXmlApplicationContext：该容器会在一个 web 应用程序的范围内加载在 XML 文件中已被定义的 bean。\n\n\n\nStudent.java\n12345678910package com.hanyuu.test;import lombok.Data;@Datapublic class Student &#123;   private Integer age;   private String name;&#125;\nDemoApplication.java\n123456789101112131415161718192021222324package com.hanyuu.test;import java.io.BufferedWriter;import java.io.File;import java.io.FileWriter;import java.util.Date;import javax.sound.midi.SysexMessage;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import org.springframework.context.support.FileSystemXmlApplicationContext;@SpringBootApplicationpublic class DemoApplication &#123;\tpublic static void main(final String[] args) &#123;\t\t\t\tfinal ApplicationContext applicationContext = new FileSystemXmlApplicationContext(\"beans.xml\");\t\tfinal Student student = (Student) applicationContext.getBean(\"student\");\t\tSystem.out.println(\"Name : \" + student.getName());\t\tSystem.out.println(\"Age : \" + student.getAge());\t&#125;\nbeans.xml\n12345678910111213141516171819&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\"    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"    xmlns:context=\"http://www.springframework.org/schema/context\"    xsi:schemaLocation=\"http://www.springframework.org/schema/beans    http://www.springframework.org/schema/beans/spring-beans-3.0.xsd    http://www.springframework.org/schema/context    http://www.springframework.org/schema/context/spring-context-3.0.xsd\"&gt;   &lt;context:annotation-config/&gt;   &lt;!-- bean definitions go here --&gt;   &lt;!-- Definition for student bean --&gt;   &lt;bean id=\"student\" class=\"com.hanyuu.test.Student\"&gt;      &lt;property name=\"name\"  value=\"Hanyuu\" /&gt;      &lt;property name=\"age\"  value=\"3\"/&gt;   &lt;/bean&gt;&lt;/beans&gt;\n Bean 定义\n\n\n\n属性\n描述\n\n\n\n\nclass\n强制性，并且指定用来创建 bean 的 bean 类。\n\n\nname\n指定唯一的 bean 标识符。在基于 XML 的配置元数据中，你可以使用 ID 和/或 name 属性来指定 bean 标识符。\n\n\nscope\n指定由特定的 bean 定义创建的对象的作用域\n\n\nconstructor-arg\n注入依赖关系\n\n\nproperties\n注入依赖关系\n\n\nautowiring mode\n注入依赖关系\n\n\nlazy-initialization mode\n延迟初始化\n\n\ninitialization 方法\n在 bean 的所有必需的属性被容器设置之后，调用回调方法\n\n\ndestruction 方法\n当包含该 bean 的容器被销毁时，使用回调方法\n\n\n\n 配置元数据来源\n\n基于 XML 的配置文件。\n基于注解的配置\n基于 Java 的配置\n\n xml样例\n123456789101112131415161718192021222324252627282930&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\"    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"    xsi:schemaLocation=\"http://www.springframework.org/schema/beans    http://www.springframework.org/schema/beans/spring-beans-3.0.xsd\"&gt;   &lt;!-- A simple bean definition --&gt;   &lt;bean id=\"...\" class=\"...\"&gt;       &lt;!-- collaborators and configuration for this bean go here --&gt;   &lt;/bean&gt;   &lt;!-- A bean definition with lazy init set on --&gt;   &lt;bean id=\"...\" class=\"...\" lazy-init=\"true\"&gt;       &lt;!-- collaborators and configuration for this bean go here --&gt;   &lt;/bean&gt;   &lt;!-- A bean definition with initialization method --&gt;   &lt;bean id=\"...\" class=\"...\" init-method=\"...\"&gt;       &lt;!-- collaborators and configuration for this bean go here --&gt;   &lt;/bean&gt;   &lt;!-- A bean definition with destruction method --&gt;   &lt;bean id=\"...\" class=\"...\" destroy-method=\"...\"&gt;       &lt;!-- collaborators and configuration for this bean go here --&gt;   &lt;/bean&gt;   &lt;!-- more bean definitions go here --&gt;&lt;/beans&gt;\n 区别\n\n\n功能\n\nBeanFactory提供了最简单的功能（实例化对象和获取对象）\nApplicationContent提供了MessageSource（国际化）、ResourceLoader（资源访问）、载入多个上下文、ApplicationEventPublisher（消息发送、响应机制）和AOP（拦截器）\n\n\n\n加载机制\n\nBeanFactory懒加载\nApplicationContext启动时全部加载\n\n\n\n 作用域（Scope）\n\n\n\n作用域\n描述\n\n\n\n\nsingleton\n该作用域将 bean 的定义的限制在每一个 Spring IoC 容器中的一个单一实例(默认)。\n\n\nprototype\n该作用域将单一 bean 的定义限制在任意数量的对象实例。\n\n\nrequest\n该作用域将 bean 的定义限制为 HTTP 请求。只在 web-aware Spring ApplicationContext 的上下文中有效。\n\n\nsession\n该作用域将 bean 的定义限制为 HTTP 会话。 只在web-aware Spring ApplicationContext的上下文中有效。\n\n\nglobal-session\n该作用域将 bean 的定义限制为全局 HTTP 会话。只在 web-aware Spring ApplicationContext 的上下文中有效。\n\n\n\n Reference\n\n\nhttps://wiki.jikexueyuan.com/project/spring/\n\n\nhttps://blog.csdn.net/pythias_/article/details/82752881\n\n\n","plink":"ilucia.github.io/springLearn/"},{"title":"Oracle数据库复习提纲","date":"2020-06-20T00:00:00.000Z","updated":"2022-04-27T15:24:01.727Z","content":"[toc]\n Introduction\n\n Instance\np10\nAn Oracle instance:\n\nIs a means to access an Oracle database\nAlways opens one and only one database\nConsists of memory and process structures\n\n Database\np12\nAn Oracle database:\n\nIs a collection of data that is treated as a unit\nConsists of three file types\n\nData files\nControl files\nRedo log files\n\n\n\n Physical Structure\np13\nThe physical structure of an Oracle database is determined by the operating system files that provide the actual physical storage for database information.\n\nControl files\nData files(includes data dictionary)\nRedo log files\n\n Memory Structure\nP14\nOracle’s memory structure consists of two memory areas known as:\n SGA\nSystem Global Area (SGA): Allocated at instance startup, and is a fundamental component of an Oracle Instance\n\n\nThe SGA consists of several memory structures:\n\n\nShared pool\n\n\nDatabase buffer cache\n\n\nRedo log buffer\n\n\nOther structures (e.g. lock and latch management, statistical data)\n\n\nThere are two optional memory structures that can be configured within the SGA:\n\nLarge pool\nJava pool\n\n\n\nSGA is dynamic and sized using SGA_MAX_SIZE.\n\n\nSGA memory allocated and tracked in granules by SGA components\n\nContiguous virtual memory allocation\nSize based on SGA_MAX_SIZE\n\n\n\n Shared Pool\nThe shared pool is used to store the most recently executed SQL statements and the most recently used data definitions.\n\nIt consists of two key performance-related memory structures:\n\nLibrary cache\nData dictionary cache\n\n\nSized by the parameter SHARED_POOL_SIZE.\n\n Library Cache\nThe library cache stores information about the most recently used SQL and PL/SQL statements. The library cache:\n\nEnables the sharing of commonly used statements\nIs managed by a least recently used (LRU) algorithm\nConsists of two structures:\n\nShared SQL area\nShared PL/SQL area\n\n\nHas its size determined by the shared pool sizing\n\n Data Dictionary Cache\n\nThe data dictionary cache is a collection of the most recently used definitions in the database.\n\nIt includes information about database files, tables, indexes, columns, users, privileges, and other database objects.\nDuring the parse phase, the server process looks at the data dictionary for information to resolve object names and validate access.\nCaching the data dictionary information into memory improves response time on queries.\nSize is determined by the shared pool sizing.\n\n\n\n Database Buffer Cache\nThe database buffer cache stores copies of data blocks that have been retrieved from the data files. • It enables great performance gains when you obtain and update data.\n\nIt is managed through a least recently used (LRU) algorithm.\nDB_BLOCK_SIZE determines the primary block size.\n\n Redo Log Buffer Cache\nThe redo log buffer cache records all changes made to the database data blocks.\n\nIts primary purpose is recovery.\nChanges recorded within are called redo entries.\nRedo entries contain information to reconstruct or redo changes.\nSize is defined by LOG_BUFFER.\n\n Large Pool\nThe large pool is an optional area of memory in the SGA configured only in a shared server environment.\n\n\nIt relieves the burden placed on the shared pool.\n\n\nThis configured memory area is used for session memory (UGA), I/O slaves, and backup and restore operations.\n\n\nUnlike the shared pool, the large pool does not use an LRU list.\n\n\nSized by LARGE_POOL_SIZE.\nALTER SYSTEM SET LARGE_POOL_SIZE = 64M;\n\n\n Java Pool\nThe Java pool services the parsing requirements for Java commands.\n\nRequired if installing and using Java.\nIt is stored much the same way as PL/SQL in database tables.\nIt is sized by the JAVA_POOL_SIZE parameter.\n\n PGA\np25\nProgram Global Area (PGA): Allocated when the server process is started\nThe PGA is memory reserved for each user process that connects to an Oracle database\n Process Structure\nAn Oracle process is a program that depending on its type can request information, execute a series of steps, or perform a specific task.\nOracle takes advantage of various types of processes:\n\n\nUser process: Started at the time a database user requests connection to the Oracle server\n\nA user process is a program that requests interaction with the Oracle server.\n\nIt must first establish a connection.\nIt does not interact directly with the Oracle server.\n\n\n\n\n\nServer process: Connects to the Oracle Instance and is started when a user establishes a session.\nA server process is a program that directly interacts with the Oracle server.\n\nIt fulfills calls generated and returns results.\nCan be dedicated or shared server.\n\n\n\nBackground process: Available when an Oracle instance is started\nThe relationship between the physical and memory structures is maintained and enforced by Oracle’s background processes\n\nMandatory background processes\n\nDBWn PMON CKPT LGWR SMON RECO P29\n\n\nOptional background processes\n\nARCn LMON Snnn QMNn LMDn CJQ0 Pnnn LCKn Dnnn P35\n\n\n\n\n\n Logical Structure\np36\nThe logical structure of the Oracle architecture dictates how the physical space of a database is to be used.\nA hierarchy exists in this structure that consists of tablespaces, segments, extents, and blocks.\n\n Processing a SQL Statement\n\nConnect to an instance using:\n\nThe user process\nThe server process\n\n\nThe Oracle server components that are used depend on the type of SQL statement:\n\nQueries return rows.\nDML statements log changes.\nCommit ensures transaction recovery.\n\n\nSome Oracle server components do not participate in SQL statement processing.\n\n Oracle Server\n Database Administration Tools\nP42\n Managing Oracle Instances\np60\n Initialization Parameter Files\n\n\nEntries are specific to the instance being accessed\nThere are two kinds of parameters:\n\nExplicit: Having an entry in the file\nImplicit: No entry within the file, but assuming the Oracle default values\n\n\nMultiple files can be used for a single database to optimize performance in different situations.\nChanges to entries in the file take effect based on the type of initialization parameter file used;\n\nStatic parameter file, PFILE\nPersistent parameter file, SPFILE\n\n\n\n PFILE initSID.ora\n\n\nThe PFILE is a text file that can be modified with an operating system editor.\n\n\nModifications to the file are made manually.\n\n\nChanges to the file take effect on the next startup. • Its default location is $ORACLE_HOME/dbs.\n\n\nexample\n123456789101112131415# Initialization Parameter File: initdb01.oradb_name = db01instance_name = db01control_files = ( /u03/oradata/db01/control01db01.ctl,/u03/oradata/db01/control02db01.ctl)db_block_size = 4096db_block_buffers = 500shared_pool_size = 31457280 # 30M Shared Pooldb_files = 1024max_dump_file_size = 10240background_dump_dest = /u05/oracle9i/admin/db01/bdumpuser_dump_dest = /u05/oracle9i/admin/db01/udumpcore_dump_dest = /u05/oracle9i/admin/db01/cdumpundo_management = autoundo_tablespace = undtbs\n\n\n SPFILE spfileSID.ora\np66\n\n\nBinary file with the ability to make changes persistent across shutdown and startup\n\n\nMaintained by the Oracle server\n\n\nRecords parameter value changes made with the ALTER SYSTEM command\n\n\nCan specify whether the change being made is temporary or persistent\n\n\nValues can be deleted or reset to allow an instance to revert to the default value\nALTER SYSTEM SET undo_tablespace = 'UNDO2';\n\n\nSPFILE can be created from an initSID.ora file using the CREATE SPFILE command, which can be executed before or after instance startup:\nSPFILE FROM PFILE;```12*   example\n*.background_dump_dest=‘ORACLEHOME/admin/db01/bdump′∗.compatible=′9.0.0′∗.controlfiles=′/u03/oradata/db01/ctrl01db01.ctl′,′/u03/oradata/db01/ctrl02db01.ctl′∗.coredumpdest=′ORACLE_HOME/admin/db01/bdump&#x27;\n*.compatible=&#x27;9.0.0&#x27;\n*.control_files=&#x27;/u03/oradata/db01/ctrl01db01.ctl&#x27;,&#x27;/u03/orad\nata/db01/ctrl02db01.ctl&#x27;\n*.core_dump_dest=&#x27;ORACLEH​OME/admin/db01/bdump′∗.compatible=′9.0.0′∗.controlf​iles=′/u03/oradata/db01/ctrl01db01.ctl′,′/u03/oradata/db01/ctrl02db01.ctl′∗.cored​umpd​est=′ORACLE_HOME/admin/db01/cdump’\n*.db_block_buffers=500\n*.db_block_size=4096\n*.db_files=40\n*.db_name=‘db01’\n*.instance_name=‘db01’\n*.remote_login_passwordfile=‘exclusive’\n*.shared_pool_size=31457280 # 30M Shared Pool\n*.undo_management=‘AUTO’\ndb01.undo_tablespace=‘UNDOTBS01’\ndb02.undo_tablespace=‘UNDOTBS02’\n12345678910111213141516171819### Oracle Managed Filesp69Oracle Managed Files (OMF) simplify file administration*   OMF are created and deleted by the Oracle server as directed by SQL commands*   OMF are established by setting two parameters:    *   DB_CREATE_FILE_DEST: Set to give the default location for data files     *   DB_CREATE_ONLINE_LOG_DEST_N: Set to give the default locations for online redo logs and control files, up to a maximum of 5 locations## Starting Up a Databasep73![image-20200621165731327](oracle_review/image-20200621165731327.png)### Start up the instance and open the database:\n\n\nSTARTUP\nSTARTUP PFILE=$ORACLE_HOME/dbs/initdb01.ora\n123456### The ALTER DATABASE Command*   Change the state of the database from NOMOUNT to MOUNT:```ALTER DATABASE db01 MOUNT;\n\nOpen the database as a read–only database:\n\nDATABASE db01 OPEN READ ONLY;```123456### Opening a Database in Restricted Mode*   Use the STARTUP command to restrict access to a database:``` STARTUP RESTRICT\n\nUse the ALTER SYSTEM command to place an instance in restricted mode:\n\nSYSTEM ENABLE RESTRICTED SESSION;```1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162Opening a Database in Read-Only Mode*   A databases can be   opened as a read-only database.*   A read-only database can be used to:    *   Execute queries    *   Execute disk sorts using locally managed tablespaces    *   Take data files offline and online, not tablespaces    *   Perform recovery of offline data files and tablespaces### Shutting Down the Databasep78![image-20200621194559674](oracle_review/image-20200621194559674.png)### Managing an Instance by Monitoring Diagnostic Filesp81### Alert Log FileThe alertSID.log file records the commands and Results of major events while the database is operational.### Background Trace FilesBackground trace files support information errors detected by any background process.### User Trace FileA user trace file is produced by the user process connected to the Oracle server through the server process.# Create Databasep88## Creation Prerequisitesp91To create a new database, you must have the following:*   A privileged account authenticated in one of the following ways:    *   By the operating system    *   Using a password file*   Sufficient memory to start the instance*   Sufficient disk space for the planned database## Planning Database File Locations## Creating a Databasep93base can be created using:*   Oracle Database Configuration Assistant*   The CREATE DATABASE command An Oracle datab## Operating System Environment### PATH\nORACLE_BASE\nORACLE_HOME\nORACLE_SID\nORA_NLS33\nPATH\nsLD_LIBRARY_PATH\n\n##  Database Configuration Assistant\n\np95\n\n## Database Information\n\np97\n\nSpecify: \n\n*   Global database name and SID\n*   The features you want to use for your database, such as:\n    *   Oracle Spatial\n    *   Oracle OLAP Services\n    *   Example Schemas\n*   Mode in which you want the database to operate\n    *   Dedicated server mode\n    *   Shared server mode\n\n## Other Parameters\n\n*   Archive Parameters\n    *   Use for database recovery\n    *   May also be used for a standby database\n*   Data Block Sizing\n    *   Sets the default database block size\n    *   Helps to determine the SORT_AREA_SIZE\n*   File Locations\n    *   Specify paths for trace files\n    *   Specify paths for parameter files\n    *   Database storage – Specify storage parameters\n\n## Creating a Database Manually\n\np101\n\n*   Decide on a unique instance and database name \n*   Choose a database character set \n*   Set the operating system variables\n*   Edit / Create the initialization parameter file\n*   Start the instance (nomount) \n*   Execute the CREATE DATABASE command\n*   Run scripts to generate the data dictionary and accomplish post creation steps\n\n### Preparing the Parameter File\n\n### Creating SPFILE\n\n### Starting the Instance\n\n### Creating the Database\n\n### Creating a Database Using OMF\n\n### After Database Creation\n\nThe database contains:\n\n*   Datafiles, control files, and redo log files\n*   User SYS with the password change_on_install\n*   User SYSTEM with the password manager\n*   Internal tables (but no data dictionary views)\n\n# Data Dictionary Contents and Usage\n\np110\n\n## Data Dictionary\n\nDuring database creation, the Oracle server creates additional object structures within the data files. \n\n*   Data dictionary tables\n*   Dynamic performance tables\n\nThe data dictionary is a set of read-only tables and views that record, verify, and provide information about its associated database.\n\n*   Describes the database and its objects\n*   Includes two types of objects:\n    *   Base tables\n        *   Store description of database\n        *   Created with CREATE DATABASE\n    *   Data Dictionary views\n        *   Summarize base table information\n        *   Created using catalog.sql script\n\n##  Contents\n\np114\n\n## Usage\n\n## Data Dictionary View Categories\n\n## Dynamic Performance Tables\n\n# Maintaining the Control File\n\np122\n\nThe control file is a binary file that defines the current state of the physical database.\n\n*   Loss of the control file requires recovery\n*   Is read at MOUNT stage\n*   Is required to operate\n*   Is linked to a single database\n*   Should be multiplexed\n*   Maintains integrity of database\n*   Sized initially by CREATE DATABASE\n\n## Contents\n\nP125\n\nA control file contains the following entries:\n\n*   Database name and identifier\n*   Time stamp of database creation\n*   Tablespace names\n*   Names and locations of data files and redo log files\n*   Current redo log file sequence number\n*   Checkpoint information\n*   Begin and end of undo segments\n*   Redo log archive information • Backup information\n\n# Maintaining Redo Log Files\n\np132\n\n## Managing Online Redo Logs with OMF\n\np144\n\n## Archived Redo Log Files\n\n# Managing Tablespaces and Data files\n\np150\n\n## Database Storage Hierarchy\n\np153\n\n![image-20200628012952676](oracle_review/image-20200628012952676.png)\n\n## SYSTEM and Non-SYSTEM Tablespaces\n\np154\n\n# Storage Structure and Relationships\n\np179\n\n## Extent Allocation and Deallocation\n\np185\n\n## Database Block\n\n## Database Block Contents\n\n## Data Dictionary Views\n\np196\n\n![image-20200628013426264](oracle_review/image-20200628013426264.png)\n\n## Obtaining Storage Information\n\n# Managing Undo Data\n\n\n\n\n\n\n\n---\n\n\n\n# Oracle数据库结构\n\n它由至少一个表空间和数据库模式对象组成。这里，模式是对象的集合，而模式对象是直接引用数据库数据的逻辑结构。模式对象包括这样一些结构:表、视图、序列、存储过程、同义词、索引、簇和数据库链等。逻辑存储结构包括表空间、段和范围，用于描述怎样使用数据库的物理空间。\n\n总之,逻辑结构由逻辑存储结构(表空间,段,范围,块)和逻辑数据结构(表、视图、序列、存储过程、同义词、索引、簇和数据库链等)组成,而其中的模式对象(逻辑数据结构)和关系形成了数据库的关系设计。\n\n段(Segment):\n\n是表空间中一个指定类型的逻辑存储结构，它由一个或多个范围组成，段将占用并增长存储空间。\n\n数据库的物理存储结构是由一些多种物理文件组成，主要有数据文件、控制文件、重做日志文件、归档日志文件、参数文件、口令文件、警告文件等。\n\n控制文件:存储实例、数据文件及日志文件等信息的二进制文件。alter system set control_files='路径'。V$CONTROLFILE。\n\n数据文件:存储数据，以.dbf做后缀。一句话:一个表空间对多个数据文件，一个数据文件只对一个表空间。dba_data_files/v$datafile。\n\n# Oracle 的 oracle sql*plus常用命令\n\n一、sys用户和system用户\nOracle安装会自动的生成sys用户和system用户\n(1)、sys用户是超级用户，具有最高权限，具有sysdba角色，有create database的权限，该用户默认的密码是change_on_install\n(2)、system用户是管理操作员，权限也很大。具有sysoper角色，没有create database的权限，默认的密码是manager\n(3)、一般讲，对数据库维护，使用system用户登录就可以拉\n注意：也就是说sys和system这两个用户最大的区别是在于有没有create database的权限。\n          \n二、sql\\*plus工具简介\nsql\\*plus是oracle自带的工具软件，主要用于执行sql语句，pl\\sql块。\n操作如下：\n(1)、在D:\\dev\\oracle\\product\\10.2.0\\db_1\\bin\\目录下的sqlplusw.exe。(D:\\dev\\oracle\\为oracle安装目录)\n(2)、在运行栏中输入“sqlplusw”即可\n\n三、sqlplus dos工具简介\n(1)、概述：sqlplus是在dos下操作oracle的工具，其功能和sql*plus相似。\n(2)、操作如下：在运行栏中输入“sqlplus”即可\n\n四、PLSQL Developer工具，需要自己安装，推荐大家使用\n\n五、sql\\*plus常用命令\n1)、连接命令\n1.conn[ect]\n用法：conn 用户名/密码@网络服务名 [as sysdba/sysoper]\n说明：当用特权用户身份连接时，必须带上as sysdba或是as sysoper\neg、\nSQL&gt; show user\nUSER 为 &quot;SCOTT&quot;\nSQL&gt; conn system/oracle@orcl\n已连接。\nSQL&gt; show user\nUSER 为 &quot;SYSTEM&quot;\nSQL&gt;\n以上命令实现类似切换用户的效果\n2.disc/disconn/disconnect\n说明: 该命令用来断开与当前数据库的连接\n3.pssw[ord]\n说明: 该命令用于修改用户的密码，如果要想修改其它用户的密码，需要用sys/system登录。\neg、\nSQL&gt; conn scott/oracle\n已连接。\nSQL&gt; passw\n更改 SCOTT 的口令\n旧口令:\n新口令:\n重新键入新口令:\n口令已更改\nSQL&gt;\n4.show user\n说明: 显示当前用户名\n5.exit\n说明: 该命令会断开与数据库的连接，同时会退出sql*plus\n5.clear screen\n清空屏幕\n\n2)、文件操作命令\n1.start和@\n说明: 运行sql脚本\n案例: sql&gt;@ d:\\a.sql或是sql&gt;start d:\\a.sql\n2.edit\n说明: 该命令可以编辑指定的sql脚本\n案例: sql&gt;edit d:\\a.sql,这样会把d:\\a.sql 这个文件打开\n3.spool\n说明: 该命令可以将sql*plus屏幕上的内容输出到指定文件中去。\n案例: sql&gt;spool d:\\b.sql并输入sql&gt;spool off\neg、\nsql&gt;spool d:\\b.sql;\nsql&gt;select * from emp;\nsql&gt;spool off;\n\n3)、交互式命令\n1.&amp;\n说明：可以替代变量，而该变量在执行时，需要用户输入。\nselect * from emp where job='&amp;job'；\n\n4)、显示和设置环境变量\n概述：可以用来控制输出的各种格式，set show 如果希望永久的保存相关的设\n置，可以去修改glogin.sql 脚本\n1.linesize\n说明：设置显示行的宽度，默认是80个字符\nshow linesize\nset linesize 90\n2.pagesize说明：设置每页显示的行数目，默认是14\n用法和linesize 一样\n至于其它环境参数的使用也是大同小异\n","plink":"ilucia.github.io/oracle_review/"},{"title":"传感器复习提纲","date":"2020-06-15T00:00:00.000Z","updated":"2022-04-27T15:24:01.731Z","content":"[toc]\n Chapter 0 绪论\n 传感器定义\n\n能感受规定的被测量并按照一定的规律转换成可用性好的器件或装置\n\n 传感器组成\n\n敏感元件\n转换元件i\n测量电路\n\n 结构框图\n\n 典型传感器构成方法\n\n自源型\n辅助能源型\n外源型\n相同敏感元件的补偿型\n差动结构补偿型\n不同敏感元件的补偿型\n反馈型\n\n\n 传感器实现信息转换的基本要求\np5\n\n足够的容量\n灵敏度高，精度适当\n响应速度快，工作稳定，可靠性好\n适用性和适应性强\n使用经济\n\n 传感器发展的趋势\n\n发现新效应，开发新材料，新功能\n传感器的多功能集成化和微型化\n传感器的数字化、智能化和网络化\n研究生物感官，开发仿生传感器\n\n Chapter 1 传感器技术基础\n 传感器的一般数学模型\np13\n\n\n最小二乘法\n\n\n对于函数y=k⋅x+by = k\\cdot x+by=k⋅x+b拟合有\n\n\nk=nΣxiyi−ΣxiΣyinΣxi2−(Σxi)2b=Σxi2Σyi−ΣxiΣxiyinΣxi2−(Σxi)2k = \\frac{n\\Sigma x_iy_i-\\Sigma x_i \\Sigma y_i}{n\\Sigma x_i^2-(\\Sigma x_i)^2}\\\\\nb = \\frac{\\Sigma x_i^2\\Sigma y_i-\\Sigma x_i\\Sigma x_iy_i}{n\\Sigma x_i^2-(\\Sigma x_i)^2}\nk=nΣxi2​−(Σxi​)2nΣxi​yi​−Σxi​Σyi​​b=nΣxi2​−(Σxi​)2Σxi2​Σyi​−Σxi​Σxi​yi​​\n\n\n\n\n 静态特性\np12\n\n\n线性度\n\n相对误差\n\n\n\neL=±ΔLmaxyF.S×100%e_L = \\pm \\frac{\\Delta L_{max}}{y_{F.S}}\\times 100\\%\neL​=±yF.S​ΔLmax​​×100%\n*   $\\Delta L_{max}$输出平均值与拟合直线间的最大偏差\n    *   $y_{F.S}$理论满量程输出值\n\n\n\n拟合方法*\n\n理论直线法\n2.  端点直线法\n3.  最佳直线法\n4.  最小二乘法\n\n\n\n回差\n\n正反行程输出的最大差值eH=ΔHmaxyF.S×100e_H = \\frac{\\Delta H_max}{y_{F.S}}\\times 100%eH​=yF.S​ΔHm​ax​×100\n\n\n\n重复性\n\n\n灵敏度\n\n传感器输出量增量与被测输入量增量之比K=ΔyΔxK = \\frac{\\Delta y}{\\Delta x}K=ΔxΔy​\n\n\n\n分辨力\n\n\n阈值\n\n\n稳定性\n\n\n漂移\n\n零点漂移\n灵敏度漂移\n\n时间漂移\n温度漂移\n\n\n\n\n\n静态误差（精度）\n\n三种算法\n\n将非线性、回差、重复性误差按几何法或代数法综合eS=±eL2+eH2+eR2e_S=\\pm \\sqrt{e_L^2+e_H^2+e_R^2}eS​=±eL2​+eH2​+eR2​​、eS=±(eL2+eH2+eR2)e_S=\\pm (e_L^2+e_H^2+e_R^2)eS​=±(eL2​+eH2​+eR2​)\n将全部标准数据相对拟合直线的残差看成随机分布，求出标准偏差σ\\sigmaσ，取2σ2\\sigma2σ或者3σ3\\sigma3σ作为静态误差σ=∑i=1P(Δyi)2p−1\\sigma = \\sqrt{\\frac{\\sum^P_{i=1}(\\Delta y_i)^2}{p-1}}σ=p−1∑i=1P​(Δyi​)2​​\n将系统误差和随机误差分开考虑eS=±∣(Δy)max∣+aσyF.Se_S = \\pm \\frac{|(\\Delta y)_{max}|+a\\sigma}{y_{F.S}}eS​=±yF.S​∣(Δy)max​∣+aσ​\n\n\n\n\n\n 动态特性\np16\n线性常系数微分方程\n∑i=1naidiydti=∑j=0mbjdjxdtj\\sum^n_{i=1} a_i \\frac{d^iy}{dt^i}=\\sum^m_{j=0} b_j \\frac{d^jx}{dt^j}\ni=1∑n​ai​dtidiy​=j=0∑m​bj​dtjdjx​\n(一般传感器bj=0b_j=0bj​=0(除b0b_0b0​))\n传递函数\nH(s)=Y(s)X(s)=∑i=0mbisi∑j=0najsjH(s)=\\frac{Y(s)}{X(s)} = \\frac{\\sum_{i=0}^m b_is^i}{\\sum_{j=0}^n  a_js^j}\nH(s)=X(s)Y(s)​=∑j=0n​aj​sj∑i=0m​bi​si​\n串联相乘、并联相加\ns=σ+jωs =\\sigma +j \\omegas=σ+jω\n “标准”信号函数\n\n正弦函数\n阶跃函数\n\n 频率响应特性\n\n\n正弦信号\n\n输入信号x=Xsin⁡ωtx = X\\sin\\omega tx=Xsinωt 幅值XXX、角频率ω\\omegaω\n输出信号y=Ysin⁡(ωt+φ)y = Y\\sin(\\omega t+\\varphi)y=Ysin(ωt+φ) 幅值YYY、初相角φ\\varphiφ\n幅频特性、动态灵敏度、增益\n\nA(ω)=∣Y(jω)X(jω)∣=YXA(\\omega) = |\\frac{Y(j\\omega)}{X(j\\omega)}|=\\frac{Y}{X}A(ω)=∣X(jω)Y(jω)​∣=XY​\n\n\n相频特性\n\nφ(ω)=arctan⁡{Im[Y(jω)X(jω)]Re[Y(jω)X(jω)]}\\varphi(\\omega)=\\arctan\\{\\frac{Im[\\frac{Y(j\\omega)}{X(j\\omega)}]}{Re[\\frac{Y(j\\omega)}{X(j\\omega)}]}\\}φ(ω)=arctan{Re[X(jω)Y(jω)​]Im[X(jω)Y(jω)​]​}\n\n\n\n\n\n阶跃响应特性\n\n\n阶跃信号 u(t)=0,(t&lt;0) 1,(t&gt;0)u(t) = 0,(t\\lt0)\\ 1,(t\\gt0)u(t)=0,(t&lt;0) 1,(t&gt;0)\n\n\nTODO\n\n\n 传感器典型环节的动态响应\np18\n 零阶环节\n\nKKK静态灵敏度\n微分方程y=b0a0x=Kry = \\frac{b_0}{a_0}x = Kry=a0​b0​​x=Kr\n传递函数Y(s)X(s)=b0a0=K\\frac{Y(s)}{X(s)}=\\frac{b_0}{a_0}=KX(s)Y(s)​=a0​b0​​=K\n\n 一阶环节\n\na1dydt+a0y=b0xa_1\\frac{dy}{dt}+a_0y = b_0xa1​dtdy​+a0​y=b0​x\n时间常数τ=a1/a0\\tau=a_1/a_0τ=a1​/a0​\n静态灵敏度K=b0/a0K = b_0/a_0K=b0​/a0​\nKx=(τs+1)yKx = (\\tau s+1)yKx=(τs+1)y\n传递函数Y(s)X(s)=Kτs+1\\frac{Y(s)}{X(s)}=\\frac{K}{\\tau s+1}X(s)Y(s)​=τs+1K​\n频率特性Y(jω)X(jω)=Kjωτ+1\\frac{Y(j\\omega)}{X(j\\omega)}=\\frac{K}{j\\omega \\tau+1}X(jω)Y(jω)​=jωτ+1K​\n\n 二阶环节\n\n微分方程a2d2ydt2+a1dydt+a0y=b0xa_2\\frac{d^2y}{dt^2}+a_1\\frac{dy}{dt}+a_0y=b_0xa2​dt2d2y​+a1​dtdy​+a0​y=b0​x\n静态灵敏度K=b0a0K = \\frac{b_0}{a_0}K=a0​b0​​\n固有频率ωn=a0/a2\\omega_n=\\sqrt{a_0/a_2}ωn​=a0​/a2​​\n阻尼比ξ=a12a0a2\\xi = \\frac{a_1}{2\\sqrt{a_0a_2}}ξ=2a0​a2​​a1​​\n(1ωn2s2+2ξωns+1)y=Kr(\\frac{1}{\\omega_n^2}s^2+\\frac{2\\xi}{\\omega_n}s+1)y = Kr(ωn2​1​s2+ωn​2ξ​s+1)y=Kr\n传递函数H(s)=Y(s)X(s)=Ks2ωn2+2ξωns+1H(s) = \\frac{Y(s)}{X(s)}=\\frac{K}{\\frac{s^2}{\\omega_n^2}+\\frac{2\\xi}{\\omega_n}s+1}H(s)=X(s)Y(s)​=ωn2​s2​+ωn​2ξ​s+1K​\n频率响应Y(jω)X(jω)=K1−(ωωn2)+j2ξωωn2\\frac{Y(j\\omega)}{X(j\\omega)}=\\frac{K}{1-(\\frac{\\omega}{\\omega_n^2})+j2\\xi\\frac{\\omega}{\\omega_n^2}}X(jω)Y(jω)​=1−(ωn2​ω​)+j2ξωn2​ω​K​\n\n 传感器性能指标一览\np22\n\n\n\n基本参数指标\n环境参数指标\n可靠性指标\n其他指标\n\n\n\n\n量程指标\n温度指标\n工作寿命等\n使用方面\n\n\n灵敏度指标\n抗冲振指标\n\n结构方面\n\n\n精度方面的指标\n其他环境参数\n\n安装连接方面\n\n\n动态性能的指标\n\n\n\n\n\n\n 改善传感器性能的技术途径\np23\n\n结构材料与参数的合理选择\n差动技术\n\n举例一两种差动传感器，举例优点\nTODO\n\n\n平均技术\n稳定性处理\n屏蔽隔离与干扰抑制\n零示法、微差法与闭环技术\n补偿、校正和“有源化”\n集成化、智能化\n\n 合理选择传感器的基本原则与方法\np27\n\n依据测量对象和使用条件确定传感器的类型\n线性范围与量程\n灵敏度\n精度\n频率响应特性\n稳定性\n\n 传感器的标定和校准\np29\n\n静态标定\n动态标定\n\n Chapter 2 电阻式传感器\n 电阻式传感器定义\np34\n\n通过电阻值参数的变化来实现电测非电量的目的的传感器\n类型\n\n电位计式\n应变计式\n压阻式\n磁电阻式\n光电阻式\n热电阻式\n\n\n\n 电阻应变计的基本类型和结构\n\n\n金属材料和非金属材料的应变电阻效应\np34\n\n约定有一长为lll，截面积为AAA，电阻率为ρ\\rhoρ的固态导体，有电阻R=ρlAR =\\rho \\frac{l}{A}R=ρAl​，对变化量有dRR=dll−dAA+dρρ\\frac{dR}{R} = \\frac{dl}{l}-\\frac{dA}{A}+\\frac{d\\rho}{\\rho}RdR​=ldl​−AdA​+ρdρ​，记(dl/l)=ϵ(dl/l)=\\epsilon(dl/l)=ϵ材料的轴向线应变，常用单位μϵ (1μϵ=1×10−6 mm/mm)\\mu\\epsilon\\ (1\\mu\\epsilon = 1\\times10^{-6}\\ ^{mm}/_{mm})μϵ (1μϵ=1×10−6 mm/mm​)，有(dA/A)=2(dr/r)=−2μϵ(dA/A) = 2(dr/r) = -2\\mu\\epsilon(dA/A)=2(dr/r)=−2μϵ，rrr导体半径，μ\\muμ导体材料的泊松比，代入得dR/R=(1+2μ)ϵ+dρ/ρdR/R=(1+2\\mu)\\epsilon+d\\rho/\\rhodR/R=(1+2μ)ϵ+dρ/ρ\n\n\n异同点\n\n\n金属材料的应变电阻效应\ndρρ=CdVV\\frac{d\\rho}{\\rho}=C\\frac{dV}{V}\nρdρ​=CVdV​\nCCC由一定材料加工方式决定的常数\n(dV/V)=(dl/l)+dS/S=(1−2μ)ϵ，(ΔR≪R)ΔRR=[(1+2μ)+C(1−2μ)]ϵ=KmϵKm=(1+2μ)+C(1−2μ)(dV/V)=(dl/l)+dS/S=(1-2\\mu)\\epsilon，(\\Delta R \\ll R)\\\\\n\\frac{\\Delta R}{R}=[(1+2\\mu)+C(1-2\\mu)]\\epsilon = K_m\\epsilon\\\\\nK_m=(1+2\\mu)+C(1-2\\mu)\n(dV/V)=(dl/l)+dS/S=(1−2μ)ϵ，(ΔR≪R)RΔR​=[(1+2μ)+C(1−2μ)]ϵ=Km​ϵKm​=(1+2μ)+C(1−2μ)\n金属材料的电阻相对变化与其线应变成正比。\n\n\n半导体材料的应变电阻效应\ndρρ=πσ=πEϵ\\frac{d\\rho}{\\rho}=\\pi\\sigma=\\pi E\\epsilon\nρdρ​=πσ=πEϵ\n\nσ\\sigmaσ作用于材料的轴向应力\nπ\\piπ半导体材料在受力方向的压阻系数\nEEE半导体材料的弹性模量\n\nΔRR=[(1+2μ)+πE]ϵ=Ksϵ\\frac{\\Delta R}{R}=[(1+2\\mu)+\\pi E]\\epsilon=K_s\\epsilon\nRΔR​=[(1+2μ)+πE]ϵ=Ks​ϵ\n\nKs=1+2μ+πEK_s=1+2\\mu+\\pi EKs​=1+2μ+πE导电丝材的灵敏系数\n\n\n\n\n\n分析\n\n金属材料\n\nK0=Km=(1+2μ)+C(1−2μ)K_0 = K_m =(1+2\\mu)+C(1-2\\mu)K0​=Km​=(1+2μ)+C(1−2μ) 前部分为受力导致几何尺寸的变化，后部分是电阻率的变化\n\n\n非金属材料\n\nK0=Ks=(1+2μ)+πEK_0=K_s=(1+2\\mu)+\\pi EK0​=Ks​=(1+2μ)+πE前部分为尺寸变化、后部分为压阻效应\n\n\n\n\n\n\n\n 静态特性\np38\n\n\n灵敏系数 K\n\nΔRR=Kϵs\\frac{\\Delta R}{R}=K\\epsilon_sRΔR​=Kϵs​\nϵs\\epsilon_sϵs​轴向应变\n\n\n\n横向效应及横向效应系数 H\n\n\n试件收到单向应力σ\\sigmaσ，纵栅和横栅各自敏感ϵx、ϵy，ΔRR=Kxϵx+Kyϵy=K(1+αH)ϵ\\epsilon_x、\\epsilon_y，\\frac{\\Delta R}{R}=K_x\\epsilon_x+K_y\\epsilon_y=K(1+\\alpha H)\\epsilonϵx​、ϵy​，RΔR​=Kx​ϵx​+Ky​ϵy​=K(1+αH)ϵ\n\nKx KyK_x\\ K_yKx​ Ky​纵向、横向灵敏系数\nα=ϵx/ϵy\\alpha=\\epsilon_x/\\epsilon_yα=ϵx​/ϵy​双向应变比\nH=Ky/KxH=K_y/K_xH=Ky​/Kx​双向灵敏系数比\n\n\n\n\n\n机械滞后 ZjZ_jZj​\n\n\n蠕变 θ\\thetaθ  零漂 PθP_\\thetaPθ​\n\n\n极限应变 ϵlim⁡\\epsilon_{\\lim}ϵlim​\n\n\n 动态特性\np40\n\n对正弦应变波的响应\n对阶跃应变波的响应\n疲劳寿命 N\n\n 电阻应变计的温度效应及补偿\np42\n\n\n温度效应\n\n\n设工作温度变化Δt∘C\\Delta t ^\\circ CΔt∘C，有\n(DeltaRR)=αtΔt+K(βs−βt)Δt(\\frac{DeltaR}{R})=\\alpha_t\\Delta t+K(\\beta_s-\\beta_t)\\Delta t(RDeltaR​)=αt​Δt+K(βs​−βt​)Δt\n\nαt\\alpha_tαt​敏感栅材料的电阻温度系数\nKKK应变计的灵敏系数\nβs,βt\\beta_s,\\beta_tβs​,βt​试件和敏感栅材料的线膨胀系数\n\n\n\n热输出\nϵt=(ΔR/R)tK=1KαtΔt+(βs−βt)Δt\\epsilon_t=\\frac{(\\Delta R/R)_t}{K}=\\frac{1}{K}\\alpha_t \\Delta t+(\\beta_s-\\beta_t)\\Delta tϵt​=K(ΔR/R)t​​=K1​αt​Δt+(βs​−βt​)Δt\n\n\n\n\n补偿方法\n\n\n温度自补偿法\n\n单丝\n\n选配敏感栅材料使ϵt=0\\epsilon_t=0ϵt​=0即αt=−K(βs−βt)\\alpha_t=-K(\\beta_s-\\beta_t)αt​=−K(βs​−βt​)\n\n\n双丝\n\n选取电阻温度系数一正一负的两种合金丝−ϵbtϵat≈RaR/RbR=RaRb\\frac{-\\epsilon_{bt}}{\\epsilon_{at}}\\approx\\frac{R_a}{R}/\\frac{R_b}{R}=\\frac{R_a}{R_b}ϵat​−ϵbt​​≈RRa​​/RRb​​=Rb​Ra​​\n\n\n\n\n\n桥路补偿法\n\n\n双丝半桥式\n\n\n\n补偿块半桥法\n\n\n\n\n\n\n\n为什么要补偿\n\n消除对ϵ\\epsilonϵ对测量应变的干扰\n\n\n\n 最广泛应用于电阻应变计的测量电路和特点\np47\n\n\n应变电桥\n\n\n灵敏度高、精度高、测量范围宽，结构电路简单、易于实现温度补偿\n\n\nTODO\n\n\n\n\n\n 电阻应变计\np55\n\n测力传感器\n压力传感器\n位移传感器\n其他应变式传感器\n\n 压阻式传感器\np59\n\n\n压阻效应\nΔRR≈Δρρ=πσ\\frac{\\Delta R}{R}\\approx\\frac{\\Delta \\rho}{\\rho}=\\pi\\sigmaRΔR​≈ρΔρ​=πσ\n\n\nπ\\piπ压阻系数（可能各向异性）\n\n\nσ\\sigmaσ全应力（注意区分横向和纵向）\n\n\n 应用\np61\n\n压阻压力式传感器\n压阻加速度式传感器\n\n Chapter 3 变磁阻式传感器\n 定义\np65\n\n利用磁路磁阻变化引起传感器线圈的电感变化来检测非电量的机电转换装置\n\n 电气参数分析\n\n\n等效电路\n\n线圈电感L=W2/RmL=W^2/R_mL=W2/Rm​，WWW匝数，RmR_mRm​磁路总磁阻\n\n\n闭合磁路\n\nL=W2/RFL = W^2/R_FL=W2/RF​ 导磁体总磁阻\n\n\n\n小气隙\n\nL≈W2/RσL\\approx W^2/R_\\sigmaL≈W2/Rσ​\n\n\n\n统一形式\nL=W2/Rm=W2⋅μ0μeS/lL=W^2/R_m=W^2\\cdot\\mu_0\\mu_eS/l\nL=W2/Rm​=W2⋅μ0​μe​S/l\n\nLLL电感\nμe\\mu_eμe​等效磁导率\nSSS横截面积\nlll磁路长度\nμ0=\\mu_0=μ0​=真空磁导率\n\n\n\n\n\n 品质因素\np68\n​\tQC=无功功率有功功率=ωL/RcQ_C=\\frac{无功功率}{有功功率}=\\omega L/R_cQC​=有功功率无功功率​=ωL/Rc​\n\nTODO\n\n 自感式传感器\np69\n\n变气隙式\n\n输出非线性\n\n\n变面积式\n\n输出可视为线性、线性范围较大\n灵敏度相比变气隙式低\n\n\n螺管式\n\n空气隙大，磁路磁阻大\n灵敏度较低\n线性范围较大\n\n\n差动式自感传感器\n\np71\n\n\n\n 互感式传感器（差动变压器）\np79\n工作原理和类型\n\n变气隙式\n变面积式\n螺管式\n互感传感器和自感传感器的异同点\n\n相同点\n\n都是通过改变衔铁的位置实现被测量的测量，且均有单一结构和对称组成的差动式以改善非线性提高灵敏度\n\n\n差动式自感传感器\n\n改变衔铁位置，改变初、次级线圈间的互感系数来改变相关的物理量\n\n\n自感传感器\n\n改变磁路磁阻来改变自感系数实现被测量的变化\n\n\n\n\n\n 电涡流式传感器\np86\n\n\n基本原理\n\n利用电涡流效应\n\n\n\n\n\n应用 p92\n\n测位移\n测厚度\n测温度\n\n\n\n磁致伸缩效应 p94\n\n铁磁材料在磁场中变化时，在磁场方向伸长或缩短的现象\nλs=(Δl/l)s\\lambda_s=(\\Delta l/l)_sλs​=(Δl/l)s​\n(Δl/l)(\\Delta l/l)(Δl/l)伸缩比\nλ\\lambdaλ磁致伸缩系数\n\n\n\n Chapter 4 电容式传感器\n 定义\np99\n\n将被测非电量的变化转换为电容量变化的传感器\n\n 工作原理\n\n变级距\n变面积\n变介质\n\n 问题和改进措施\np103\n\n等效电路\n边缘效应\n\n保护环\n\n\n静电引力\n寄生电容\n\n 电容式传感器和应用\np109\n\n位移传感器\n加速度\n力和压力\n物位\n\n Chapter 5 磁电式传感器\np115\n 定义\n将输入运动速度或磁量的变化变换成感应电势输出的传感器\n 基本原理与结构形式\ne=−WdΦdte = -W\\frac{d\\Phi}{dt}\ne=−WdtdΦ​\n\neee感应电势\nΦ\\PhiΦ穿过线圈的磁通量\nWWW线圈匝数\n\n\n\n\n变磁通式\n\n旋转型\n平移型\n\n\n恒磁通式\n\n动圈式\n动铁式\n\n\n\n 霍尔元件和霍尔效应\np123\n\n\nUH=1en⋅IBd=RHIBdU_H = \\frac{1}{en}\\cdot\\frac{IB}{d}=R_H\\frac{IB}{d}UH​=en1​⋅dIB​=RH​dIB​\n\nRHR_HRH​霍尔系数\n\n\nKH=RHd=UHIB (V/A⋅T)K_H=\\frac{R_H}{d}=\\frac{U_H}{IB}\\ (V/A\\cdot T)KH​=dRH​​=IBUH​​ (V/A⋅T)\n应用\n\n微位移以及机械振动测量\nTODO\n\n\n\n Chapter 6 压电式传感器\np135\n 定义\n\n具有压电效应的压电器件为核心组成的传感器，有自发电和可逆性，是典型的双向无源传感器件。\n\n （正）压电效应、极化作用\n\n\nD=dT or σ=dTD:电位移/σ:电荷密度;d:压电常数矩阵;T:外应力张量D=dT\\ or\\ \\sigma=dT\\\\\nD:电位移/\\sigma:电荷密度;d:压电常数矩阵;T:外应力张量\nD=dT or σ=dTD:电位移/σ:电荷密度;d:压电常数矩阵;T:外应力张量\n\n\n 逆压电效应、电致伸缩\n\n\nS=dtES:应变;dt:d的逆矩阵;E:外电场强度S = d_tE\\\\\nS:应变;d_t:d的逆矩阵;E:外电场强度\nS=dt​ES:应变;dt​:d的逆矩阵;E:外电场强度\n\n\n\n\n\n 压电材料\n\n压电晶体\n\n石英晶体\n\nx:电轴\ny:机械轴\nz:光轴\n\n\n压电陶瓷\n新型压电材料\n\n 切型和符号\np139\n\n光轴\n电轴\n机轴\n\n 压电陶瓷极化处理\n\n\n\n 石英晶体的压电方程\n\np139\nTODO\n\n 压电式加速度传感器类型\np150\n\n压缩型\n剪切型\n复合型\n\n 逆压电效应的应用\np158\n\n基于逆压电效应的超声波发生器（换能器）和声表面波谐振器是超声检测和声表面检查的关键器件\n\n Chapter 7 热电式传感器\n 热电阻传感器\np163\n\n利用转换原件电磁参量随温度变化的特性，对温度和温度有关的参量进行检测的装置\n\n 热电效应\np167\n\n\n\n 接触电势\nEAB(T)=kTeln⁡NANBEAB(T):AB两种金属在温度T时的接触电势;k=1.38×10−23(J/K):玻尔兹曼常数;e=1.6×10−19(C):电子电荷T:结点处的绝对温度E_{AB}(T)=\\frac{kT}{e}\\ln \\frac{N_A}{N_B}\\\\\nE_{AB}(T):AB两种金属在温度T时的接触电势;\\\\k=1.38\\times10^{-23}(J/K):玻尔兹曼常数;\\\\e=1.6\\times10^{-19}(C):电子电荷\\\\T:结点处的绝对温度\nEAB​(T)=ekT​lnNB​NA​​EAB​(T):AB两种金属在温度T时的接触电势;k=1.38×10−23(J/K):玻尔兹曼常数;e=1.6×10−19(C):电子电荷T:结点处的绝对温度\n 温差电势\nE_A(T,T_0)=\\begin{equation*}\\int_{T_0}^{T}\\sigma_AdT \\end{equation*}\\\\\nE_A(T,T_0):金属A两端温度分别为T与T_0时的温差电势\\\\\n\\sigma_A:温差系数\\\\\nT、T_0:高低温端的绝对温度\n\n 两个结论\n\np168\n\n 热电效应\n 工作定律\n\n中间导体定律\n连接导体定律、中间温度定律\n参考电阻定律\n\n热电偶和热电阻的区别\n热电偶 测量温度原理\n Chapter 8 光电式传感器\np177\n 定义\n以光为测量媒介、以光电器件为转换元件的传感器\n 一般组成\n\n 常用光源\np179\n\n热辐射光源\n气体放电光源\n发光二极管\n激光器\n\n 外光电效应\n在光的照射下，电子逸出物体表面产生光电子发射的现象\n 内光电效应\np180\n 光电导效应\n\n光照射在半导体材料上，材料中处于价带的电子吸收光子能量，通过禁带跃入导带，使导带内电子浓度和价带内空穴增多，激发出光生电子-空穴对，从而使半导体材料产生光电效应。\n\n光敏电阻\n光敏二极管\n光敏三极管\n\n 光生伏特效应\n光照引起PN结两端产生电动势的效应\n\n Chapter 9 光纤传感器\np201\n 光纤波导原理\n\nnisin⁡θi=njsin⁡θj全反射条件：sin⁡θ1&gt;n2n1全反射临界角:sin⁡θc=sin⁡θ0=1n0n12−n22=NANA:数值孔径n_i\\sin\\theta_i=n_j\\sin\\theta_j\\\\\n全反射条件：\\sin\\theta_1\\gt\\frac{n_2}{n_1}\\\\\n全反射临界角: \\sin\\theta_c=\\sin\\theta_0=\\frac{1}{n_0}\\sqrt{n_1^2-n_2^2}=NA\\\\\nNA:数值孔径\nni​sinθi​=nj​sinθj​全反射条件：sinθ1​&gt;n1​n2​​全反射临界角:sinθc​=sinθ0​=n0​1​n12​−n22​​=NANA:数值孔径\n 数值孔径的物理意义\n衡量光纤集光性能的主要参数\n 分类\np204\n 调制解调方式\np205\n\n强度调制与解调\n偏振调制与解调\n相位调制与解调\n频率调制与解调\n\n Chapter 10 数字式传感器\np221\n 定义\n\n能把被测量转换成数字量输出的传感器\n\n 编码器\np233\n\n\n旋转式广电编码器\n\n绝对编码器\n增量编码器\n\n\n频率式传感器\n数字集成式传感器\n\n","plink":"ilucia.github.io/review_sensor/"},{"title":"wsl安装桌面环境","date":"2020-05-24T00:00:00.000Z","updated":"2022-04-27T15:24:01.763Z","content":" 准备工作\n\n\n运行有wsl（笔者使用wsl2）的Windows 10电脑一台（必备）\n\n安装wsl和wsl1升级到wsl2微软官方教程:\n\n\n\nwsl里的文本编辑器（vim,nano等）（强烈推荐，笔者此处使用vim）\n\ne.g. (apt作为包管理器，Ubuntu等)\n  12&gt;   sudo apt install vim&gt;\n\n\n\n身居中国大陆并且没给wsl换源或者不知道换源的小伙伴请参阅tuna镜像站进行换源（非必须，但是可以大大加快安装速度）\n\ne.g. Ubuntu请参阅Ubuntu 镜像使用帮助\n\n\n\n 安装Xfce4和xrdp\n 简介\n\nXfce4是一个轻量可高度定制的类-unix桌面环境，与wsl相性十分相符\nxrdp支持rdp，是Windows原生支持的远程桌面协议，使用“远程桌面连接”即可连接到wsl桌面环境\n\n 安装步骤（此处以Ubuntu 18.04 on Windows 10为例）\n\n\n更新包管理器\n1sudo apt update\n\n\n安装Xfce4和xrdp\n1sudo apt install xfce4 xrdp\n\n\n更改xrdp配置\n\n123echo xfce4-session &gt;~/.xsessionsudo vim /etc/xrdp/startwm.sh#/etc/X11/Xsession 前一行插入 xfce4-session\n\n\n更改xrdp侦听端口\nrdp默认侦听端口为3389，Windows 10本身已经占用（如果开启远程桌面的话），此处为了避免冲突我们更换一下监听端口\n\n12sudo vim /etc/xrdp/xdrp.ini#将port=3389更改为3388或者其他可用端口\n\n\n重启以使配置生效\n1sudo service xrdp restart\n\n\n锵锵！安装完成了。\n\n\n 使用步骤\n\n\n打开Windows的“远程桌面连接”\n\n\n\n地址填写localhost:3388，（显示选项中可以选择更多显示选项，分辨率，大小等）\n\n\n![image-20200524220431099](wslDesktop/image-20200524220431099.png)\n\n\n\nxrdp此时提示输入账户密码（wsl的）\n\n\n\n锵锵！你现在拥有了一个新的桌面环境！\n\n\n\n 后续可选内容\n\n高分屏调整分辨率\n安装中文字体\n各种美化（\n看心情更\n\n","plink":"ilucia.github.io/wslDesktop/"},{"title":"《疾病的群体现象及其测量》笔记","date":"2020-05-16T00:00:00.000Z","updated":"2022-04-27T15:24:01.559Z","content":"\n 声明\n本笔记非医学专业收录，仅供统计参考之用，相关疑问请寻求具有相关资质的医师帮助\n\n\n 约定\n下述所有kkk表示归一化因子，可取100%100\\%100%、1000‰1000‰1000‰等，因为人群研究往往用更大的量级所以很少写100%100\\%100%\n\n[toc]\n 概述\n 疾病的个体表现\n\n症状、体征、功能变化等\n\n 群体现象和分布（三间分布）\n\n时间聚集性\n\n季节性\n\n\n空间聚集性\n\n国家、地区、城乡等\n\n\n人间聚集性\n\n年龄、性别等\n\n\n\n 疾病频率的测量\n概率论特征\n 相对数（率、比、构成比）\n 率（rate）\n\n单位时间（周、月、年）内某现象发生的频率与强度\n分子可以是分母\n描述疾病在人群中发生有多快\n\n 构成比（proportion）\n\n事物内部某一部分单位与事物内部各部分观察单位的综述之比\n分子包含在分母中\n描述受疾病影响的或某特征人群占总人群的比例\n\n 暴露因素的测量\n 疾病频率测量\n 发病频率指标\n 发病率 incidence rate\n反映一定时期、特定人群中某病新病例出现频率\n发病率=一定时期内某人群中某病新病例数同时期暴露人口数发病率=\\frac{一定时期内某人群中某病新病例数}{同时期暴露人口数}\n发病率=同时期暴露人口数一定时期内某人群中某病新病例数​\n\n\nAttention\n\n分子为新发病例数\n分母为可能患病的人群、不同疾病的暴露人口数互有不同\n可以计算发病专率（年龄、性别）\n应进行标准化比较，标准化的率只进行比较，不反映真实水平\n\n\n\nApplication\n\n描述疾病的分布，反映疾病流行强度，评估疾病对人群健康的影响\n探讨发病因素，提出病因假说\n评价防制（治）措施的效果\n\n 累积发病率 cumulative incidence rate, CI\n适用条件：样本大，人口稳定，资料整齐（固定队列）\n 发病密度 incidence density, ID\n适用条件：观察时间长，人口不稳定、存在失访，资料不整齐（动态队列）\n\n\n 罹患率 attrack rate\n\n\n同样为测量新发病例的指标\n\n\n某一局限范围内短时发病率（小时，日，周）\n\n\n局部地区疾病的暴发，食物中毒、传染病及职业中毒等暴发流行情况\n\n\n续发率=潜伏期内易感染者中发病人数易感接触者总人数×k续发率=\\frac{潜伏期内易感染者中发病人数}{易感接触者总人数}\\times k\n续发率=易感接触者总人数潜伏期内易感染者中发病人数​×k\n\n也称二代发病率，是指某些传染病在最短潜伏期到最长潜伏期之间，易感接触者中发病人数占所有易感接触者总数的百分比\n\n 续发率 second attrack rate\n续发率=潜伏期内易接触者中发病人数易接触者总人数×k续发率=\\frac{潜伏期内易接触者中发病人数}{易接触者总人数}\\times k\n续发率=易接触者总人数潜伏期内易接触者中发病人数​×k\n也称二代发病率，是指某些传染病在最短潜伏期到最长潜伏期之间，易感接触者中发病人数占所有易感接触者总数的百分比。\n\nAttention\n\n分子为二代病例，即在一个潜伏期内（最短潜伏期和最长潜伏期之间）易感接触者中发病人数\n将原发病例从分子分母中去除\n集体外感染，短于最短潜伏期或长于最长潜伏期者均不计入\n\n\nApplication\n\n反应传染病传染力强弱的指标\n分析传染病流行的因素\n评价传染病防治措施效果\n\n\n\n 死亡频率指标\n 死亡率 mortality rate\n死亡率=某人群某期死亡总数同期平均人口数×k死亡率=\\frac{某人群某期死亡总数}{同期平均人口数}\\times k\n死亡率=同期平均人口数某人群某期死亡总数​×k\n某时间内某人群中总死亡人数在该人群中所占的比例\n\nAttention\n\n粗死亡率：未经调整的死于所有原因的死亡率，反应一个人群总的死亡水平\n可计算死亡专率（病种，年龄，性别等）\n标化死亡率\n\n婴儿死亡率=某年未满一周岁婴儿死亡数同年活产总数婴儿死亡率=\\frac{某年未满一周岁婴儿死亡数}{同年活产总数}婴儿死亡率=同年活产总数某年未满一周岁婴儿死亡数​\n新生儿死亡率=某年未满28天新生儿死亡总数同年活产总数新生儿死亡率=\\frac{某年未满28天新生儿死亡总数}{同年活产总数}新生儿死亡率=同年活产总数某年未满28天新生儿死亡总数​\n5岁以下儿童死亡率=某年5岁以下儿童死亡总数同年活产总数5岁以下儿童死亡率=\\frac{某年5岁以下儿童死亡总数}{同年活产总数}5岁以下儿童死亡率=同年活产总数某年5岁以下儿童死亡总数​\n孕妇死亡率=某年孕产妇死亡数同年活产总数孕妇死亡率=\\frac{某年孕产妇死亡数}{同年活产总数}孕妇死亡率=同年活产总数某年孕产妇死亡数​\n\n\n\n\nApplication\n\n衡量一个地区人群某一时期的死亡危险性大小，反映一个地区不同时期人群的健康状况和卫生保健工作水平；为卫生保健工作的需求和规划提供科学依据。\n探讨病因和评价防治措施效果\n某些病死率高的疾病（恶性肿瘤、狂犬病）死亡率≈发病率，可用死亡率代替发病率\n\n\n\n 病死率 case fatality rate\n病死率=某时期内因某病死亡人数同期某病病人数×k病死率=\\frac{某时期内因某病死亡人数}{同期某病病人数}\\times k\n病死率=同期某病病人数某时期内因某病死亡人数​×k\n\nAttention &amp; Application\n\n表示某种疾病的死亡概率，可表明疾病的严重程度\n可反映诊治能力等医疗水平\n多用于急性传染病，较少用于慢性病\n用病死率作为评价不同医院的医疗水平时，要注意可比性\n\n\n\n 生存率 survival rate\nn年存活率=随访满n年尚存活的病例随访满n年的病例数×kn年存活率=\\frac{随访满n年尚存活的病例}{随访满n年的病例数}\\times k\nn年存活率=随访满n年的病例数随访满n年尚存活的病例​×k\n接受某种治疗的病人，或患某病的病人经 n 年随访（通常为1、3、5年）后存活的概率\n反映疾病对生命的危害程度，可用于评价某些病程较长疾病的远期疗效（癌症、心血管疾病等）\n 疾病负担指标\n 患病率 prevalence\n某特定数间内、总人口某病新旧病例所占的病例\n期间患病率=某时期特定人群中某病现患（新、旧）病例同期平均人口数期间患病率=\\frac{某时期特定人群中某病现患（新、旧）病例}{同期平均人口数}\n期间患病率=同期平均人口数某时期特定人群中某病现患（新、旧）病例​\n时点患病率=某一时点特定人群中某病现患（新、旧）病例该时点人口数时点患病率=\\frac{某一时点特定人群中某病现患（新、旧）病例}{该时点人口数}\n时点患病率=该时点人口数某一时点特定人群中某病现患（新、旧）病例​\n\n\n发病率增加，则患病率提高\n死亡、痊愈数增加，则患病率下降\n患病率取决于发病率和病程\n\n影响患病率的因素\n\n\n\n患病率升高因素\n患病率降低因素\n\n\n\n\n病程延长\n病程缩短\n\n\n发病率升高\n发病率下降\n\n\n病例迁入\n病例迁出\n\n\n健康者迁出\n健康者迁入\n\n\n诊断水平提高\n治愈率提高\n\n\n报告率提高\n-\n\n\n未治愈者寿命延长\n-\n\n\n易感者迁入\n-\n\n\n\n\n\n当某地某病的发病率和病程在相当长时间内保持稳定时，同时假设人口稳定\n患病率(P)=发病率(I)×病程(T)患病率(P)=发病率(I)\\times病程(T)\n患病率(P)=发病率(I)×病程(T)\n\n\nApplication\n\n反映病程较长的慢性病的流行情况及对人群健康的影响\n可为医疗设施规划，估计医院床位周转、卫生设施及人力的需要量，医疗费用的投入等提供科学依据\n可用来检测慢性病控制效果\n\n\n\n患病率与发病率的比较\n\n\n\n比较内容\n患病率\n发病率\n\n\n\n\n资料来源\n现况调查、筛检等\n疾病报告、疾病监测、队列研究\n\n\n计算分子\n观察期间新发病例和现患病例数之和\n观察期间新发病例数\n\n\n计算分母\n调查人数（时点患病率）平均人口数（期间患病率）\n暴露人口数或平均人口数\n\n\n观察时间\n较短、一般为1个月或者几个月\n一般为一年或者更长时间\n\n\n适用疾病种类\n慢性病或病程较长的疾病\n各种疾病\n\n\n用途\n慢性病或病程较长疾病\n各种疾病\n\n\n影响因素\n较多、影响发病率的因素、病后结局及病人病程等\n相对较少、疾病流行情况，诊断水平、疾病报告质量等\n\n\n\n 感染率 infection rate\n感染率=受检者中阳性人数受检人数×k感染率=\\frac{受检者中阳性人数}{受检人数}\\times k\n感染率=受检人数受检者中阳性人数​×k\n\n某时间内被检人群中某病原体现有感染者（显性/隐性）所占比例\nApplication\n\n评价人群健康状况的常用指标，常用于描述某些传染病或寄生虫病的感染情况、流行态势\n可为制定防治措施以及评价防疫措施的效果提供依据\n\n\n\n 潜在减寿年数 potential years of life lost, PYLL\n某病某年龄组人群死亡者的实际死亡年龄与期望寿命之差的总和；以期望寿命为基准，进一步衡量死亡造成的寿命损失，强调早亡对健康的影响。\nPYLL=∑i=1eaidiPYLL=\\sum^e_{i=1}a_id_i\nPYLL=i=1∑e​ai​di​\n\neee：预期寿命\niii：年龄组（通常计算年龄组中值）\naia_iai​：剩余年龄，ai=e−(i+0.5)a_i=e-(i+0.5)ai​=e−(i+0.5)\ndid_idi​：某年龄组的死亡人数\n\n\nApplication\n\n人群中疾病负担的直接指标\n通过计算和比较各种不同原因所致的寿命减少年数，可反映出各种危险因素、死亡原因等对人群的危害程度\n可用于地区间比较\n可用于筛选确定重点卫生问题或重点疾病，同时也适用于防治措施效果的评价和卫生政策的分析\n\n\n\n 伤残调整寿命年 disability adjusted life year,DALY\n从发病到死亡所损失的全部健康寿命年，包括因早死所致的寿命损失年（years of life lost, YLL）和疾病所致伤残引起的健康寿命损失年（years lived with disability，YLD）两部分\nDALY=YLL+YLDDALY=YLL+YLD\nDALY=YLL+YLD\n\nAppliation\n\n计算各种疾病造成的早死与残疾对健康寿命面损失的综合指标，疾病负担的主要指标之一\n比较和评价地区间卫生状况，跟踪疾病负担的动态变化\n确定危害严重病种、重点人群等，为防治重点提供依据\n成本效益分析\n\n\n\n 其他生命质量指标\n\n病残率 disability rate\n健康寿命年 health life years，HeaLY\n健康期望寿命 active life expectancy\n质量调整生命年 quality-adjusted life year, QALY\n\n 疾病的群体现象\n 疾病的流行强度\n一定时期内疾病在某地区人群中发病率变化及其病例间的联系程度；用以描述某种疾病在某地区人群单位时间内新发病例数量的变化特征\n 流行强度\n 散发（sporadic）\n\n发病率呈历年一般水平，病例间无明显联系，表现为散在发生。\n多与当地近三年该病的发病率进行比较，如果当年发病率未明显超过既往平均水平称为散发。\n\n涉及地域：在范围较大的地区内\n发病数量：发病数量呈历年一般水平\n病例间联系程度：病例间在发病时间和地区间无明显联系\n\n原因\n\n人群维持一定的免疫水平（常年流行或预防接种）\n以隐性感染为主的疾病\n传播机制不易实现的疾病\n长潜伏期传染病\n\n\nAttention\n\n用以描述较大范围（区、县以上），不能用于小范围人口较少的居民区等。小范围少数病例成为散发病例。\n历年的一般发病水平意味着情况相同的年代。\n不能在不同地区或国家间衡量某病是否散发。\n\n\n\n 暴发（outbreak）\n局部地区或集体单位，短时间内突然发生很多症状相同的病人，往往有共同的传染源\n\n原因\n\n传染病：多有共同的传染源和传播途径，多数病人出现在该病的最短和最长潜伏期之间。\n非传染病：食物中毒\n\n\n判断\n\n涉及地域：在一个局部地区或集体单位\n发病数量：短时间出现很多相同的病人\n病例间联系：有流行病学相关性\n\n\n\n 流行（epidemic）\n某地区某病发病率显著超过历年发病率水平（散发）\n\n判断\n\n涉及地域：某地区或某国家\n发病数量：显著超过历年水平\n病例间联系：往往有流行病学相关性\n\n\n\n 大流行（pandemic）\n某地区某病发病率显著超过历年发病率水平，疾病蔓延迅速，涉及面广，短时间内跨越省界、国界形成世界性流行\n\n判定\n\n涉及地域：广\n发病数量：显著超过历年水平\n病例间联系：往往有流行病学相关性\n\n\n\n能够发生大流行的疾病具有传播途径容易实现、传播迅速、人群普遍易感等特点，如流感、霍乱\n 疾病的分布\n 人群分布\n\n年龄、性别、职业、种族/民族、婚姻与家庭、行为生活方式、流动人口、宗教信仰……\n\n 年龄\n年龄与疾病之间的关联比其他因素的作用都强\n随着年龄的增长，几乎大部分疾病的发生频率都会发生变化\n\n年龄分布出现差异的原因\n\n免疫水平和易感性不同\n预防接种改变某些疾病固有的发病特征\n暴露病原因子的机会不同\n暴露的积累\n\n\n\n\n疾病的死亡率存在着明显的性别差异\n各年龄别死亡率男性高于女性\n不同地区或不同疾病有所不同\n男女发病率存在明显差别\n\n男女暴露或接触致病因素的机会不同\n遗传、内分泌、生理解剖等生物性差异\n男女职业的差异\n生活方式、嗜好不同导致性别分布差异\n\n\n不同的物理、化学、生物因素及职业精神紧张，均可导致疾病分布不同\n分析职业与疾病的关系时应当考虑\n\n不同种族、民族的遗传因素不同\n不同民族风俗、饮食和生活习惯不同\n不同民族社会经济状况、医疗保健水平不同\n不同民族定居的自然环境、社会环境不同\n\n\n婚姻与家庭\n\n对健康的影响\n\n对女性健康的影响\n\n性生活、妊娠、分娩、哺乳等\n\n\n近亲婚配\n\n先天畸形\n遗传性疾病\n\n\n家族聚集性\n\n遗传因素+共同生活环境和生活方式\n\n\n\n\n\n\n行为生活方式\n\n有益健康行为\n\n体育锻炼\n合理膳食\n\n\n有害健康行为\n\n吸烟酗酒\n不良性行为\n\n\n\n\n\n\n流动人口\n\n传染病暴发流行的高危人群\n疫区与非疫区间传染病传播纽带\n对性传播疾病的传播起起重要作用\n给儿童计划免疫工作的开展增加难度\n\n\n\n 时间分布\n\n国家间及国内不同地区的分布\n疾病的城乡分布\n疾病的地区聚集性\n地方性疾病（endemic disease）\n\n 地区分布\n\n国家间及国内不同地区的分布\n疾病的城乡分布\n疾病的地区聚集性\n地方性疾病（endemic disease）\n\n有些疾病仅发生在某些地区\n有些疾病虽在全世界均可发生，但不同地区的分布各有特点\n\n日本的胃癌及脑血管病的调整死亡率或年龄死专率居首\n恶性肿瘤已澳大利亚和新西兰最高\n肝癌多见于亚洲、非洲\n乳腺癌多见于欧洲、非洲\n血吸虫：仅限于南方省份\nHIV感染：云南\n鼻咽癌：广东\n食管癌：河南林县\n肝癌：江苏启东\n原发性高血压：北方＞南方\n\n城乡分布\n\n\n\n城市\n农村\n\n\n\n\n人口多、密度大\n人口密度低\n\n\n交通拥挤、人口流动性大\n交通不便，外界交往较少\n\n\n呼吸道传染病易传播\n呼吸道传染病易流行\n\n\n肠道传染病较少\n肠道传染病易流行\n\n\n慢性病及肿瘤发病率较高\n某些地方病发病率较高\n\n\n出现职业性损害\n虫媒传染病发病率较高\n\n\n\n地区聚集性\n\n某地区发病及患病等疾病频率高于周围地区的情况，且不是随机导致。常见于职业暴露、环境污染、疾病暴发等\n\n提示一个感染因子的作用\n提示局部环境污染的存在\n\n\n地方性\n\n统计地方性：与生活条件和卫生习惯有关\n自然地方性：与自然环境有关（病原体、微量元素）\n自然疫源性：疾病的传播不依赖人\n\n\n输入性\n\n本地区不存在或已消灭的疾病从国外或其他地区传入\n\n\n地方性疾病（endemic disease）\n\n局限于某些特定地区内相对稳定并经常发生的疾病\n判断依据\n\n该地区各类居民、各民族发病率高\n其他地区居住的相似人群中发病率低，甚至不发病\n迁入该地区一段时间后，其发病率和当地居民一致\n人群迁出该地区后，发病率下降，患者症状减轻或自愈\n当地易感动物也可发生同样疾病\n\n\n\n\n\n 时间分布\n\n疾病的时间分布是疾病发生发展过程的重要表现形式，它是致病因子、宿主、环境共同作用的结果。\n描述疾病的时间分布常采用二维线图或直方图表示，横坐标为时间，纵坐标为率或病例数。\n\n 短期波动\n以日、周、月计数的疾病流行或疫情暴发，含义与暴发相近\n\n区别\n\n爆发\n\n少量人群、小范围\n\n\n短期波动\n\n较大数量人群、范围较大\n\n\n\n\n类型\n\n传染病\n非传染病\n自然灾害和人为污染\n\n\n\n 季节性\n疾病在一定季节呈现发病率增高的现象\n\n严格季节性\n\n虫媒传染病（如乙脑）\n\n\n季节性升高\n\n呼吸道、肠道传染病\n\n\n\n季节性升高的原因\n\n病原体的生长繁殖受气候影响\n媒介昆虫季节消长均受到温度、湿度、雨量等影响\n与野生动物的生活习性及家畜的生长繁殖有关\n受人们的生活方式、生产劳动条件及医疗卫生水平变化的影响\n与人们暴露病原因子的机会及人群易感性有关\n\n 周期性\n疾病频率按照一定的时间间隔，有规律地起伏波动，每隔若干年出现一个流行高峰的现象\n有关因素\n\n前一次流行病所遗留的易感者数量\n新的易感者补充累计的速度\n人群免疫时间的长短\n病原自身变异速度\n\n有效的预防措施可以改变疾病的周期性规律\n 长期趋势\n对疾病动态的连续数年乃至数十年的观察，在这个长时间内观察探讨疾病的病原体、临床表现、发病率、死亡率等方面所发生的变化\n\n长期编译的原因\n\n病因或致病因素发生了变化\n病原体抗原型别、毒力、致病力发生变异\n诊治条件、药物疗效及新的治疗方法的进化和预防措施的采取等\n等级报告制度完善，疾病的诊断标准、分类发生改变\n人口学资料的变化\n\n\n\n 疾病三间分布的综合描述\n在疾病流行病学研究实践中，常常需要综合地描述和分析疾病在人群、地区和时间上的分布情况，只有这样才能全面获取有关病因线索和流行因素的资料。\n移民流行病学，是进行这种综合描述的一个典型\n\n移民流行病学\n\n通过观察疾病在移民、移居地当地居民及原居地人群间的发病率或死亡率的差异，从而探讨疾病的发生与遗传因素或环境因素的关系，常用于肿瘤、慢性病及某些遗传病的病因和流行因素的探讨。\n当环境是主要因素\n\n移民指移居地当地居民\n\n\n当遗传时主要因素\n\n移民指原居住地人群\n\n\n\n\n\n 疾病预后评价指标\n 疾病的群体发病现象\n","plink":"ilucia.github.io/Epidemiology/"},{"title":"Windows家庭版升级指南","date":"2020-05-11T00:00:00.000Z","updated":"2022-04-27T15:24:01.763Z","content":" Windows家庭版升级指南\n阅读前必知：本文不提供任何破解或者绕过Windows激活的方案，请通过依法依规的形式获得Windows正版授权，请支持正版以维护您和相关公司的利益，敬请知悉，谢谢\n\n\n情景概述\n目前，许多高校为学生购买了Windows kms正版授权，但是很多OEM给电脑预装的是家庭版授权，导致无法直接使用学校的kms激活。为了避免重装浪费时间，在此给出一些无需重装而升级到专业版/企业版的解决方案。\n\n\n\n若您所在的学校没有购买kms，请参考微软官方帮助文档，利用数字许可或者密钥进行升级\n\n\n\n在 设置&gt;激活 中，选择 更改产品密钥，使用以下key将版本转换为企业版/企业版\n\n\n\n升级为不可逆过程，如有必要请事先进行系统备份以便于失败时快速回滚\n\n\n此处key不提供激活功能，仅仅为转版本使用，使用前请先确认您有合法Windows专业版/企业版许可\n\n\n\n\n\n\n家庭版升专业版key\n\nVK7JG-NPHTM-C97JM-9MPGT-3V66T\n4N7JM-CV98F-WY9XX-9D8CF-369TT \nFMPND-XFTD4-67FJC-HDR8C-3YH26 \nVK7JG-NPHTM-C97JM-9MPGT-3V66T\nNPPR9-FWDCX-D2C8J-H872K-2YT43\nW269N-WFGWX-YVC9B-4J6C9-T83GX\nNYW94-47Q7H-7X9TT-W7TXD-JTYPM\nNJ4MX-VQQ7Q-FP3DB-VDGHX-7XM87\nMH37W-N47XK-V7XM9-C7227-GCQG9\nVK7JG-NPHTM-C97JM-9MPGT-3V66T\n\n\n\n家庭版升企业版key\n\nNPPR9-FWDCX-D2C8J-H872K-2YT43\n\n\n![image-20200511181943914](windows-10-upgrading-home-to-pro/image-20200511181943914.png)\n\n\n\n\n升级完成后，系统已经变更为专业版/企业版，此时可以使用学校/组织提供的kms服务器进行激活。您可以参照学校或组织提供的kms激活方案继续完成激活。\n\n东南大学kms许可操作说明：https://nic.seu.edu.cn\n\n\n\n\n 遇到其他问题\n许可问题请请参阅微软支持，关于本文操作问题请致函并说明问题以便笔者补充常见问题以帮助更多人。\n","plink":"ilucia.github.io/windows-10-upgrading-home-to-pro/"},{"title":"Java反射机制备忘","date":"2020-03-29T17:14:00.000Z","updated":"2022-04-27T15:24:01.727Z","content":" 概述\n\n反射的概念是由Smith在1982年首次提出的，主要是指程序可以访问、检测和修改它本身状态或行为的一种能力，通过反射可以调用私有方法和私有属性，大部分框架也都是运用反射原理的。java通常是先有类再有对象，有对象就可以调用方法或者属性，java中的反射其实是通过Class对象来调用类里面的方法。\n主要是指程序可以访问，检测和修改它本身状态或行为的一种能力，并能根据自身行为的状态和结果，调整或修改应用所描述行为的状态和相关的语义。\n一个类有多个组成部分，例如：成员变量、方法、构造方法等，反射就是加载类,并解剖出类的各个组成部分。\n\n\n\n反射主要提供的功能\n\n在运行时判断任意一个对象所属的类\n在运行时构造任意一个类的对象\n在运行时判断任意一个类所具有的成员变量和方法\n在运行时调用任意一个对象的方法\n生成动态代理\n\n\n\n优点\n\n能够运行时动态获取类的实例，大大提高系统的灵活性和扩展性\n与Java动态编译相结合，可以更多功能\n\n\n\n缺点\n\n性能较低\n不安全\n破坏了类的封装性\n\n\n\n相关类\n12345java.lang.Class;java.lang.reflect.Constructor;java.lang.reflect.Field;java.lang.reflect.Method;java.lang.reflect.Modifier;\n\n\n 通过对象获取保证的包名和类名\n文件结构\n123C:.└─Hanyuu        Demo.java\nDemo.java\n1234567package Hanyuu;class Demo&#123;    public static void main(String[] args) &#123;        Demo demo = new Demo();        System.out.println(demo.getClass().getName());    &#125;&#125;\n输出\n1Hanyuu.Demo\n 实例化类对象\nDemo.java\n12345678910111213141516package Hanyuu;class Demo&#123;    public static void main(String[] args) throws ClassNotFoundException &#123;        Demo demo = new Demo();        Class&lt;?&gt; fornameClass = null;        Class&lt;?&gt; getClass = null;        Class&lt;?&gt; dotClass = null;        // throws ClassNotFoundException        fornameClass = Class.forName(\"Hanyuu.Demo\");        getClass = new Demo().getClass();        dotClass = Demo.class;        System.out.println(fornameClass.getName());        System.out.println(getClass.getName());        System.out.println(dotClass.getName());    &#125;&#125;\n输出\n123Hanyuu.DemoHanyuu.DemoHanyuu.Demo\n 获取父类对象\n Reference\n\nJAVA反射\njava反射机制深入理解剖析\n\n","plink":"ilucia.github.io/java_reflection/"},{"title":"Java GC 机制备忘","date":"2020-03-26T12:00:00.000Z","updated":"2022-04-27T15:24:01.727Z","content":" GC\n\n垃圾回收(Garbage Collection)是Java虚拟机(JVM)垃圾回收器提供的一种用于在空闲时间不定时回收无任何对象引用的对象占据的内存空间的一种机制。\n垃圾回收回收的是无任何引用的对象占据的内存空间而不是对象本身。换言之，垃圾回收只会负责释放那些对象占有的内存。对象是个抽象的词，包括引用和其占据的内存空间。当对象没有任何引用时其占据的内存空间随即被收回备用，此时对象也就被销毁。\n\n 对象引用\n\n\n强引用\n\n\n软引用\nSoftReference:内存不够时被回收\n\n\n弱引用\nWeakReference:下一次GC时被回收\n\nReferenceQuene\n\n\n\n虚引用\nPhantomReference:目的是在被GC时获得通知\n\n\n 垃圾回收算法\n\n\n找到所有存活对象\n回收被无用对象占用的内存空间\n\n\n 判断对象是否是垃圾\n 引用计数 (Reference Counting Collector)\n\n堆中的每个对象都有引用计数器\n当对象被创建并被初始化赋值后，计数设置为1\n每多一个引用计数，加一，引用失效（超过生命周期，被设置了一个新值），减一\n回收所有引用计数为0的对象，并对其引用的所有对象计数减一\n优点\n\n简单高效\n对程序不被长时间打断的实时环境比较有利\n\n\n缺点\n\n难以检测循环引用\n增加程序执行开销\n\n\nJVM\n\n早期JVM使用引用计数\n目前大多数JVM使用对象引用遍历（根搜索算法）\n\n\n\n 根搜索算法 (Tracing Collector)\n\n\n\n根集 (Root Set)\n​\t正在执行的Java程序可以访问的引用变量(不是对象)的集合（包括局部变量、参数和类变量）\n​\t程序可以使用引用变量访问对象的属性和调用对象的方法\n\n\n\n\n\n通过一系列名为“GC Roots”的对象作为起始点，寻找对应的引用节点\n\n\n递归从这些引用节点向下寻找引用节点\n\n\n生成的链称为引用链，当一个对象没有被任何引用链上的引用节点引用时，证明对象不可用\n\n\nJava和C#目前采用Tracing Collector方法\n\n\n 标记可达对象\n\n\nGC Root\n\n虚拟机栈中引用的对象（栈帧中的本地变量表）\n方法区中的常量引用的对象\n方法区中的类静态属性引用的对象\n本地方法栈中JNI (Native方法) 的引用对象\n活跃线程\n\n\n标记步骤\n\n以GC Root对象开始，对内存中整个对象图进行遍历并标记所有访问到的对象为存活\n未被标记的对象将在后面被清除\n\n\n\n\n\n\n开始进行标记前，需要先暂停应用线程，否则如果对象图一直在变化的话是无法真正去遍历它的。暂停应用线程以便JVM可以尽情地收拾家务的这种情况又被称之为安全点（Safe Point），这会触发一次Stop The World(STW)暂停。触发安全点的原因有许多，但最常见的应该就是垃圾回收了。\n\n\n暂停时间的长短并不取决于堆内对象的多少也不是堆的大小，而是存活对象的多少。因此，调高堆的大小并不会影响到标记阶段的时间长短。\n\n\n在根搜索算法中，要真正宣告一个对象死亡，至少要经历两次标记过程\n\n如果对象在进行根搜索后发现没有与GC Roots相连接的引用链，那它会被第一次标记并且进行一次筛选。筛选的条件是此对象是否有必要执行 finalize()方法。当对象没有覆盖finalize()方法，或finalize()方法已经被虚拟机调用过，虚拟机将这两种情况都视为没有必要执行。\n如果该对象被判定为有必要执行finalize()方法，那么这个对象将会被放置在一个名为F-Queue队列中，并在稍后由一条由虚拟机自动建立的、低优先级的Finalizer线程去执行finalize()方法。finalize()方法是对象逃脱死亡命运的最后一次机会（因为一个对象的finalize()方法最多只会被系统自动调用一次），稍后GC将对F-Queue中的对象进行第二次小规模的标记，如果要在finalize()方法中成功拯救自己，只要在finalize()方法中让该对象重新引用链上的任何一个对象建立关联即可。而如果对象这时还没有关联到任何链上的引用，那它就会被回收掉。\n\n\n\nGC判断对象是否可达看的是强引用。\n\n\n\n 回收垃圾对象内存算法\n 标记-清除算法(Tracing Collector)\n\n优点\n\n不需要进行对象移动\n仅仅对不存活的对象进行处理\n\n\n缺点\n\n标记和清除过程的效率都不高，占用额外空间以用于标记空闲区域和大小\n会产生大量不连续的内存碎片\n\n\n\n\n\n 标记-整理算法(Compacting Collect)\n\n让所有对象向一端移动\n清理掉端边界以外的内存\n使用句柄和句柄表\n优点\n\n经过整理之后，新对象的分配只需要通过指针碰撞便能完成 (Pointer Bumping)\n空闲区域的位置可知，碎片化程度低\n\n\n缺点\n\ngc暂停时间变长（复制所有对象+更新引用地址）\n\n\n\n\n\n Copying算法(Copying Collector)\n\n将内存按容量分为大小相等的两块，每次使用其中一块（对象面），当内存用完时，将存活的对象复制到另一块内存上（空闲面），并一次性清理使用过的内存空间\n优点\n\n克服了句柄开销\n解决了堆碎片的垃圾回收\n标记和复制可以同时进行\n每次只对一块内存进行回收，运行高效\n只需移动栈顶指针，按顺序分配内存，实现简单\ngc时无需考虑碎片问题\n\n\n缺点\n\n空间利用率低下\n\n\n\n\n复制算法比较适合于新生代（短生存期的对象），在老年代（长生存期的对象）中，对象存活率比较高，如果执行较多的复制操作，效率将会变低，所以老年代一般会选用其他算法，如标记—整理算法。一种典型的基于Coping算法的垃圾回收是stop-and-copy算法，它将堆分成对象区和空闲区，在对象区与空闲区的切换过程中，程序暂停执行。\n\n\n\n Adaptive Collector\n监控当前堆的使用情况，选择适当算法的GC(综合)\n Java内存空间\n\n\n\n程序计数器：是一块较小内存，可以看作是当前线程所执行的字节码的行号指示器。每条线程都需要有一个独立的程序计数器，各个线程之间计数器互不影响。\n\n\nJava虚拟机栈：Java虚拟机栈也是线程私有，他的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧用于存储局部变量、操作数、操作数栈、动态链接、方法出口等信息。每一个方法的调用过程直至执行完成的过成，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。\n\n\n局部变量表:存放了编译期可知的各种基本数据类型、对象引用和returnAddress类型。如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常;如果虚拟机可以动态扩展，如扩展时无法申请到足够的内存，就会抛出OutOfMemoryError异常。\n\n\n本地方法栈：与虚拟机栈类似，他们之间的区别是虚拟机栈为虚拟机执行Java方法（字节码）服务，而本地方法栈则为虚拟机使用到的Native方法服务。\n\n\nJava堆：Java堆（Java Heap）是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域。在此内存区域中唯一目的就是存放对象实例，几乎所有的对象都在这里分配内存。\nJava堆是垃圾收集器管理的主要区域。也叫“GC堆”。从内存回收的角度来看，由于现在的收集器基本都采用分代收集算法，所以Java堆还可以细分为：新生代和老年代;在细致一点的有Eden空间、From Survivor空间、To Survivor空间等。从内存分配的家读来看，线程共享的Java堆中可能划分出多个线程私有分配缓冲区（Thread Local Allocation Buffer，TLAB）。不过无论如何划分，都与存放内容无关，无论那个区域，存储的都是对象实例，进一步划分的目的是为了更好地回收内存，或者更快的分配内存。Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可。\n\n\n方法区（Method Area）：和Java堆一样也是各个线程共享的内存区域，他用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译后的代码等数据。使用永久代实现方法区。\n\n\n Java的堆内存\n\nJava的堆内存基于Generation算法（Generational Collector）划分为新生代、年老代和持久代。新生代又被进一步划分为Eden和Survivor区，最后Survivor由FromSpace（Survivor0）和ToSpace（Survivor1）组成。所有通过new创建的对象的内存都在堆中分配，其大小可以通过-Xmx和-Xms来控制。\n分代收集，是基于这样一个事实：不同的对象的生命周期是不一样的。因此，可以将不同生命周期的对象分代，不同的代采取不同的回收算法（4.1-4.3）进行垃圾回收（GC），以便提高回收效率。\n\n\n\n\n年轻代(Young Generation)\n几乎所有新生成的对象首先都是放在年轻代的。新生代内存按照8:1:1的比例分为一个Eden区和两个Survivor(Survivor0,Survivor1)区。大部分对象在Eden区中生成。当新对象生成，Eden Space申请失败（因为空间不足等），则会发起一次GC(Scavenge GC)。回收时先将Eden区存活对象复制到一个Survivor0区，然后清空Eden区，当这个Survivor0区也存放满了时，则将Eden区和Survivor0区存活对象复制到另一个Survivor1区，然后清空Eden和这个Survivor0区，此时Survivor0区是空的，然后将Survivor0区和Survivor1区交换，即保持Survivor1区为空， 如此往复。当Survivor1区不足以存放 Eden和Survivor0的存活对象时，就将存活对象直接存放到老年代。当对象在Survivor区躲过一次GC的话，其对象年龄便会加1，默认情况下，如果对象年龄达到15岁，就会移动到老年代中。若是老年代也满了就会触发一次Full GC，也就是新生代、老年代都进行回收。新生代大小可以由-Xmn来控制，也可以用-XX:SurvivorRatio来控制Eden和Survivor的比例。\n\n\n年老代(Old Generation)\n在年轻代中经历了若干次垃圾回收后仍然存活的对象，就会被放到年老代中。因此，可以认为年老代中存放的都是一些生命周期较长的对象。内存比新生代也大很多(大概比例是1:2)，当老年代内存满时触发Major GC即Full GC，Full GC发生频率比较低，老年代对象存活时间比较长，存活率标记高。一般来说，大对象会被直接分配到老年代。所谓的大对象是指需要大量连续存储空间的对象，最常见的一种大对象就是大数组。\n\n\n持久代(Permanent Generation)\n用于存放静态文件（class类、方法）和常量等。持久代对垃圾回收没有显著影响，但是有些应用可能动态生成或者调用一些class，例如Hibernate 等，在这种时候需要设置一个比较大的持久代空间来存放这些运行过程中新增的类。对永久代的回收主要回收两部分内容：废弃常量和无用的类。\n永久代空间在Java SE8特性中已经被移除。取而代之的是元空间（MetaSpace）。因此不会再出现“java.lang.OutOfMemoryError: PermGen error”错误。\n\n\n特征\n\n对象优先在Eden分配\n大对象直接进入老年代\n长期存活的对象进入老年代\n\n\n\n\n新生代GC（Minor GC/Scavenge GC）：发生在新生代的垃圾收集动作。因为Java对象大多都具有朝生夕灭的特性，因此Minor GC非常频繁(不一定等Eden区满了才触发)，一般回收速度也比较快。在新生代中，每次垃圾收集时都会发现有大量对象死去，只有少量存活，因此可选用复制算法来完成收集。\n老年代GC（Major GC/Full GC）：发生在老年代的垃圾回收动作。Major GC，经常会伴随至少一次Minor GC。由于老年代中的对象生命周期比较长，因此Major GC并不频繁，一般都是等待老年代满了后才进行Full GC，而且其速度一般会比Minor GC慢10倍以上。另外，如果分配了Direct Memory，在老年代中进行Full GC时，会顺便清理掉Direct Memory中的废弃对象。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用标记—清除算法或标记—整理算法来进行回收。\n新生代采用空闲指针的方式来控制GC触发，指针保持最后一个分配的对象在新生代区间的位置，当有新的对象要分配内存时，用于检查空间是否足够，不够就触发GC。当连续分配对象时，对象会逐渐从Eden到Survivor，最后到老年代。\n\n 垃圾回收器(GC)\n\n串行垃圾回收器（Serial Garbage Collector）\n并行垃圾回收器（Parallel Garbage Collector）\n并发标记扫描垃圾回收器（CMS Garbage Collector）\nG1垃圾回收器（G1 Garbage Collector）\n\n\n\n\n串行垃圾回收器\n串行垃圾回收器通过持有应用程序所有的线程进行工作。它为单线程环境设计，只使用一个单独的线程进行垃圾回收，通过冻结所有应用程序线程进行工作，所以可能不适合服务器环境。它最适合的是简单的命令行程序（单CPU、新生代空间较小及对暂停时间要求不是非常高的应用）。是client级别默认的GC方式。\n\n通过JVM参数-XX:+UseSerialGC可以使用串行垃圾回收器。\n\n\n\n2、并行垃圾回收器\n并行垃圾回收器也叫做 throughput collector 。它是JVM的默认垃圾回收器。与串行垃圾回收器不同，它使用多线程进行垃圾回收。相似的是，当执行垃圾回收的时候它也会冻结所有的应用程序线程。\n适用于多CPU、对暂停时间要求较短的应用上，是server级别默认采用的GC方式。可用-XX:+UseParallelGC来强制指定，用-XX:ParallelGCThreads=4来指定线程数。\n3、并发标记扫描垃圾回收器\n并发标记垃圾回收使用多线程扫描堆内存，标记需要清理的实例并且清理被标记过的实例。并发标记垃圾回收器只会在下面两种情况持有应用程序所有线程。\n（1）当标记的引用对象在Tenured区域；\n（2）在进行垃圾回收的时候，堆内存的数据被并发的改变。\n相比并行垃圾回收器，并发标记扫描垃圾回收器使用更多的CPU来确保程序的吞吐量。如果我们可以为了更好的程序性能分配更多的CPU，那么并发标记上扫描垃圾回收器是更好的选择相比并发垃圾回收器。\n JVM实现情况\nHotSpot（JDK 7)虚拟机提供的几种垃圾收集器\n垃圾收集算法是内存回收的理论基础，而垃圾收集器就是内存回收的具体实现。用户可以根据自己的需求组合出各个年代使用的收集器。\n1.Serial（SerialMSC）（Copying算法）\nSerial收集器是最基本最古老的收集器，它是一个单线程收集器，并且在它进行垃圾收集时，必须暂停所有用户线程。Serial收集器是针对新生代的收集器，采用的是Copying算法。\n2.Serial Old （标记—整理算法）\nSerial Old收集器是针对老年代的收集器，采用的是Mark-Compact算法。它的优点是实现简单高效，但是缺点是会给用户带来停顿。\n2.ParNew （Copying算法）\nParNew收集器是新生代收集器，Serial收集器的多线程版本。使用多个线程进行垃圾收集，在多核CPU环境下有着比Serial更好的表现。\n3.Parallel Scavenge （Copying算法）\nParallel Scavenge收集器是一个新生代的多线程收集器（并行收集器），它在回收期间不需要暂停其他用户线程，其采用的是Copying算法，该收集器与前两个收集器有所不同，它主要是为了达到一个可控的吞吐量。追求高吞吐量，高效利用CPU。吞吐量一般为99%。 吞吐量= 用户线程时间/(用户线程时间+GC线程时间)。适合后台应用等对交互相应要求不高的场景。\n4.Parallel Old（ParallelMSC）（标记—整理算法）\nParallel Old是Parallel Scavenge收集器的老年代版本（并行收集器），使用多线程和Mark-Compact算法。吞吐量优先。\n5.CMS  （标记—整理算法）\nCMS（Current Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器，它是一种并发收集器，采用的是Mark-Sweep算法。高并发、低停顿，追求最短GC回收停顿时间，CPU占用比较高。响应时间快，停顿时间短，多核CPU 追求高响应时间的选择。\n6.G1\nG1收集器是当今收集器技术发展最前沿的成果，它是一款面向服务端应用的收集器，它能充分利用多CPU、多核环境。因此它是一款并行与并发收集器，并且它能建立可预测的停顿时间模型。\nG1垃圾回收器适用于堆内存很大的情况，他将堆内存分割成不同的区域，并且并发的对其进行垃圾回收。G1也可以在回收内存之后对剩余的堆内存空间进行压缩。并发扫描标记垃圾回收器在STW情况下压缩内存。G1垃圾回收会优先选择第一块垃圾最多的区域。\n通过JVM参数 –XX:+UseG1GC 使用G1垃圾回收器。\nJava 8 的新特性：\n在使用G1垃圾回收器的时候，通过 JVM参数 -XX:+UseStringDeduplication 。 我们可以通过删除重复的字符串，只保留一个char[]来优化堆内存。这个选择在Java 8 u 20被引入。\n我们给出了全部的几种Java垃圾回收器，需要根据应用场景，硬件性能和吞吐量需求来决定使用哪一种。\n新生代收集器使用的收集器：Serial、PraNew、Parallel Scavenge。\n老年代收集器使用的收集器：Serial Old、Parallel Old、CMS。\n 垃圾回收执行时间和注意事项\nGC分为Scavenge GC和Full GC。\nScavenge GC ：发生在Eden区的垃圾回收。\nFull GC :对整个堆进行整理，包括Young、Tenured和Perm。Full GC因为需要对整个堆进行回收，所以比Scavenge GC要慢，因此应该尽可能减少Full GC的次数。在对JVM调优的过程中，很大一部分工作就是对于FullGC的调节。\n有如下原因可能导致Full GC：\n1.年老代（Tenured）被写满;\n2.持久代（Perm）被写满;\n3.System.gc()被显示调用;\n4.上一次GC之后Heap的各域分配策略动态变化.\n 与垃圾回收时间有关的两个函数\n\n\nSystem.gc()方法\n命令行参数监视垃圾收集器的运行：\n使用System.gc()可以不管JVM使用的是哪一种垃圾回收的算法，都可以请求Java的垃圾回收。在命令行中有一个参数-verbosegc可以查看Java使用的堆内存的情况，它的格式如下：\njava -verbosegc classfile\n需要注意的是，调用System.gc()也仅仅是一个请求(建议)。JVM接受这个消息后，并不是立即做垃圾回收，而只是对几个垃圾回收算法做了加权，使垃圾回收操作容易发生，或提早发生，或回收较多而已。\n\n\nfinalize()方法\n概述：在JVM垃圾回收器收集一个对象之前，一般要求程序调用适当的方法释放资源。但在没有明确释放资源的情况下，Java提供了缺省机制来终止该对象以释放资源，这个方法就是finalize（）。它的原型为：\nprotected void finalize() throws Throwable\n在finalize()方法返回之后，对象消失，垃圾收集开始执行。原型中的throws Throwable表示它可以抛出任何类型的异常。\n意义：之所以要使用finalize()，是存在着垃圾回收器不能处理的特殊情况。假定你的对象（并非使用new方法）获得了一块“特殊”的内存区域，由于垃圾回收器只知道那些显示地经由new分配的内存空间，所以它不知道该如何释放这块“特殊”的内存区域，那么这个时候Java允许在类中定义一个finalize()方法。\n特殊的区域例如：1）由于在分配内存的时候可能采用了类似 C语言的做法，而非JAVA的通常new做法。这种情况主要发生在native method中，比如native method调用了C/C方法malloc()函数系列来分配存储空间，但是除非调用free()函数，否则这些内存空间将不会得到释放，那么这个时候就可能造成内存泄漏。但是由于free()方法是在C/C中的函数，所以finalize()中可以用本地方法来调用它。以释放这些“特殊”的内存空间。2）又或者打开的文件资源，这些资源不属于垃圾回收器的回收范围。\n换言之，finalize()的主要用途是释放一些其他做法开辟的内存空间，以及做一些清理工作。因为在Java中并没有提够像“析构”函数或者类似概念的函数，要做一些类似清理工作的时候，必须自己动手创建一个执行清理工作的普通方法，也就是override Object这个类中的finalize()方法。比如：销毁通知。\n一旦垃圾回收器准备好释放对象占用的存储空间，首先会去调用finalize()方法进行一些必要的清理工作。只有到下一次再进行垃圾回收动作的时候，才会真正释放这个对象所占用的内存空间。\nJAVA里的对象并非总会被垃圾回收器回收。1 对象可能不被垃圾回收，2 垃圾回收并不等于“析构”，3 垃圾回收只与内存有关。也就是说，并不是如果一个对象不再被使用，是不是要在finalize()中释放这个对象中含有的其它对象呢？不是的。因为无论对象是如何创建的，垃圾回收器都会负责释放那些对象占有的内存。\n当 finalize() 方法被调用时，JVM 会释放该线程上的所有同步锁。\n\n\n 触发主GC的条件\n\n当应用程序空闲时,即没有应用线程在运行时,GC会被调用。因为GC在优先级最低的线程中进行,所以当应用忙时,GC线程就不会被调用,但以下条件除外。\nJava堆内存不足时,GC会被调用。当应用线程在运行,并在运行过程中创建新对象,若这时内存空间不足,JVM就会强制地调用GC线程,以便回收内存用于新的分配。若GC一次之后仍不能满足内存分配的要求,JVM会再进行两次GC作进一步的尝试,若仍无法满足要求,则 JVM将报“out of memory”的错误,Java应用将停止。\n在编译过程中作为一种优化技术，Java 编译器能选择给实例赋 null 值，从而标记实例为可回收。\n由于是否进行主GC由JVM根据系统环境决定,而系统环境在不断的变化当中,所以主GC的运行具有不确定性,无法预计它何时必然出现,但可以确定的是对一个长期运行的应用来说,其主GC是反复进行的。\n\n 少GC开销的措施\n\n\n根据上述GC的机制,程序的运行会直接影响系统环境的变化,从而影响GC的触发。若不针对GC的特点进行设计和编码,就会出现内存驻留等一系列负面影响。为了避免这些影响,基本的原则就是尽可能地减少垃圾和减少GC过程中的开销。具体措施包括以下几个方面:\n\n\n不要显式调用System.gc()\n此函数建议JVM进行主GC,虽然只是建议而非一定,但很多情况下它会触发主GC,从而增加主GC的频率,也即增加了间歇性停顿的次数。\n\n\n尽量减少临时对象的使用\n临时对象在跳出函数调用后,会成为垃圾,少用临时变量就相当于减少了垃圾的产生,从而延长了出现上述第二个触发条件出现的时间,减少了主GC的机会。\n\n\n对象不用时最好显式置为Null\n一般而言,为Null的对象都会被作为垃圾处理,所以将不用的对象显式地设为Null,有利于GC收集器判定垃圾,从而提高了GC的效率。\n\n\n尽量使用StringBuffer,而不用String来累加字符串\n\n\n由于String是固定长的字符串对象,累加String对象时,并非在一个String对象中扩增,而是重新创建新的String对象,如Str5=Str1+Str2+Str3+Str4,这条语句执行过程中会产生多个垃圾对象,因为对次作“+”操作时都必须创建新的String对象,但这些过渡对象对系统来说是没有实际意义的,只会增加更多的垃圾。避免这种情况可以改用StringBuffer来累加字符串,因StringBuffer是可变长的,它在原有基础上进行扩增,不会产生中间对象。\n\n\n能用基本类型如Int,Long,就不用Integer,Long对象\n基本类型变量占用的内存资源比相应对象占用的少得多,如果没有必要,最好使用基本变量。\n\n\n尽量少用静态对象变量\n静态变量属于全局变量,不会被GC回收,它们会一直占用内存。\n\n\n分散对象创建或删除的时间\n集中在短时间内大量创建新对象,特别是大对象,会导致突然需要大量内存,JVM在面临这种情况时,只能进行主GC,以回收内存或整合内存碎片,从而增加主GC的频率。集中删除对象,道理也是一样的。它使得突然出现了大量的垃圾对象,空闲空间必然减少,从而大大增加了下一次创建新对象时强制主GC的机会。\n\n\n 关于垃圾回收的几点补充\n经过上述的说明，可以发现垃圾回收有以下的几个特点：\n（1）垃圾收集发生的不可预知性：由于实现了不同的垃圾回收算法和采用了不同的收集机制，所以它有可能是定时发生，有可能是当出现系统空闲CPU资源时发生，也有可能是和原始的垃圾收集一样，等到内存消耗出现极限时发生，这与垃圾收集器的选择和具体的设置都有关系。\n（2）垃圾收集的精确性：主要包括2 个方面：（a）垃圾收集器能够精确标记活着的对象；（b）垃圾收集器能够精确地定位对象之间的引用关系。前者是完全地回收所有废弃对象的前提，否则就可能造成内存泄漏。而后者则是实现归并和复制等算法的必要条件。所有不可达对象都能够可靠地得到回收，所有对象都能够重新分配，允许对象的复制和对象内存的缩并，这样就有效地防止内存的支离破碎。\n（3）现在有许多种不同的垃圾收集器，每种有其算法且其表现各异，既有当垃圾收集开始时就停止应用程序的运行，又有当垃圾收集开始时也允许应用程序的线程运行，还有在同一时间垃圾收集多线程运行。\n（4）垃圾收集的实现和具体的JVM 以及JVM的内存模型有非常紧密的关系。不同的JVM 可能采用不同的垃圾收集，而JVM 的内存模型决定着该JVM可以采用哪些类型垃圾收集。现在，HotSpot 系列JVM中的内存系统都采用先进的面向对象的框架设计，这使得该系列JVM都可以采用最先进的垃圾收集。\n（5）随着技术的发展，现代垃圾收集技术提供许多可选的垃圾收集器，而且在配置每种收集器的时候又可以设置不同的参数，这就使得根据不同的应用环境获得最优的应用性能成为可能。\n针对以上特点，我们在使用的时候要注意：\n（1）不要试图去假定垃圾收集发生的时间，这一切都是未知的。比如，方法中的一个临时对象在方法调用完毕后就变成了无用对象，这个时候它的内存就可以被释放。\n（2）Java中提供了一些和垃圾收集打交道的类，而且提供了一种强行执行垃圾收集的方法–调用System.gc()，但这同样是个不确定的方法。Java 中并不保证每次调用该方法就一定能够启动垃圾收集，它只不过会向JVM发出这样一个申请，到底是否真正执行垃圾收集，一切都是个未知数。\n（3）挑选适合自己的垃圾收集器。一般来说，如果系统没有特殊和苛刻的性能要求，可以采用JVM的缺省选项。否则可以考虑使用有针对性的垃圾收集器，比如增量收集器就比较适合实时性要求较高的系统之中。系统具有较高的配置，有比较多的闲置资源，可以考虑使用并行标记/清除收集器。\n（4）关键的也是难把握的问题是内存泄漏。良好的编程习惯和严谨的编程态度永远是最重要的，不要让自己的一个小错误导致内存出现大漏洞。\n（5）尽早释放无用对象的引用。大多数程序员在使用临时变量的时候，都是让引用变量在退出活动域(scope)后，自动设置为null，暗示垃圾收集器来收集该对象，还必须注意该引用的对象是否被监听，如果有，则要去掉监听器，然后再赋空值。\n 补充\n Java内存泄露\n（1）静态集合类像HashMap、Vector等的使用最容易出现内存泄露，这些静态变量的生命周期和应用程序一致，所有的对象Object也不能被释放，因为他们也将一直被Vector等应用着。\n123456Static Vector v = new Vector();for (int i = 1; i&lt;100; i++)&#123;\tObject o = new Object();\tv.add(o);\to = null;&#125;\n在这个例子中，代码栈中存在Vector 对象的引用 v 和 Object 对象的引用 o 。在 For 循环中，我们不断的生成新的对象，然后将其添加到 Vector 对象中，之后将 o 引用置空。问题是当 o 引用被置空后，如果发生 GC，我们创建的 Object 对象是否能够被 GC 回收呢？答案是否定的。因为， GC 在跟踪代码栈中的引用时，会发现 v 引用，而继续往下跟踪，就会发现 v 引用指向的内存空间中又存在指向 Object 对象的引用。也就是说尽管o 引用已经被置空，但是 Object 对象仍然存在其他的引用，是可以被访问到的，所以 GC 无法将其释放掉。如果在此循环之后， Object 对象对程序已经没有任何作用，那么我们就认为此 Java 程序发生了内存泄漏。\n（2）各种连接，数据库连接，网络连接，IO连接等没有显示调用close关闭，不被GC回收导致内存泄露。\n（3）监听器的使用，在释放对象的同时没有相应删除监听器的时候也可能导致内存泄露。\n GC性能调优\nJava虚拟机的内存管理与垃圾收集是虚拟机结构体系中最重要的组成部分，对程序（尤其服务器端）的性能和稳定性有着非常重要的影响。性能调优需要具体情况具体分析，而且实际分析时可能需要考虑的方面很多，这里仅就一些简单常用的情况作简要介绍。\n我们可以通过给Java虚拟机分配超大堆（前提是物理机的内存足够大）来提升服务器的响应速度，但分配超大堆的前提是有把握把应用程序的Full GC频率控制得足够低，因为一次Full GC的时间造成比较长时间的停顿。控制Full GC频率的关键是保证应用中绝大多数对象的生存周期不应太长，尤其不能产生批量的、生命周期长的大对象，这样才能保证老年代的稳定。\nDirect Memory在堆内存外分配，而且二者均受限于物理机内存，且成负相关关系。因此分配超大堆时，如果用到了NIO机制分配使用了很多的Direct Memory，则有可能导致Direct Memory的OutOfMemoryError异常，这时可以通过-XX:MaxDirectMemorySize参数调整Direct Memory的大小。\n除了Java堆和永久代以及直接内存外，还要注意下面这些区域也会占用较多的内存，这些内存的总和会受到操作系统进程最大内存的限制：1、线程堆栈：可通过-Xss调整大小，内存不足时抛出StackOverflowError（纵向无法分配，即无法分配新的栈帧）或OutOfMemoryError（横向无法分配，即无法建立新的线程）。\nSocket缓冲区：每个Socket连接都有Receive和Send两个缓冲区，分别占用大约37KB和25KB的内存。如果无法分配，可能会抛出IOException：Too many open files异常。关于Socket缓冲区的详细介绍参见我的Java网络编程系列中深入剖析Socket的几篇文章。\nJNI代码：如果代码中使用了JNI调用本地库，那本地库使用的内存也不在堆中。\n虚拟机和GC：虚拟机和GC的代码执行也要消耗一定的内存。\n 代码分析垃圾回收过程\n123456public class SlotGc&#123;        public static void main(String[] args)&#123;             byte[] holder = new byte[32*1024*1024];              System.gc();        &#125;&#125;\n代码很简单，就是向内存中填充了32MB的数据，然后通过虚拟机进行垃圾收集。在Javac编译后，在终端执行如下指令：java -verbose:gc SlotGc来查看垃圾收集的结果，得到如下输出信息：\n[GC 208K-&gt;134K(5056K), 0.0017306 secs]\n[Full GC 134K-&gt;134K(5056K), 0.0121194 secs]\n[Full GC 32902K-&gt;32902K(37828K), 0.0094149 sec]\n注意第三行，“-&gt;”之前的数据表示垃圾回收前堆中存活对象所占用的内存大小，“-&gt;”之后的数据表示垃圾回收堆中存活对象所占用的内存大小，括号中的数据表示堆内存的总容量，0.0094149 sec 表示垃圾回收所用的时间。\n从结果中可以看出，System.gc(（）运行后并没有回收掉这32MB的内存，这应该是意料之中的结果，因为变量holder还处在作用域内，虚拟机自然不会回收掉holder引用的对象所占用的内存。\n修改代码如下：\n1234567public class SlotGc&#123;          public static void main(String[] args)&#123;      &#123;          byte[] holder = new byte[32*1024*1024];          &#125;          System.gc();      &#125;&#125;\n加入花括号后，holder的作用域被限制在了花括号之内，因此，在执行System.gc（）时，holder引用已经不能再被访问，逻辑上来讲，这次应该会回收掉holder引用的对象所占的内存。但查看垃圾回收情况时，输出信息如下：\n[GC 208K-&gt;134K(5056K), 0.0017100 secs]\n[Full GC 134K-&gt;134K(5056K), 0.0125887 secs]\n[Full GC 32902K-&gt;32902K(37828K), 0.0089226 secs]\n很明显，这32MB的数据并没有被回收。下面我们再做如下修改：\n123456789public class SlotGc&#123;        public static void main(String[] args)&#123;    &#123;               byte[] holder = new byte[32*1024*1024];               holder = null;             &#125;         System.gc();    &#125;&#125;\n这次得到的垃圾回收信息如下：\n[GC 208K-&gt;134K(5056K), 0.0017194 secs]\n[Full GC 134K-&gt;134K(5056K), 0.0124656 secs]\n[Full GC 32902K-&gt;134K(37828K), 0.0091637 secs]\n说明这次holder引用的对象所占的内存被回收了。\n首先明确一点：holder能否被回收的根本原因是局部变量表中的Slot是否还存有关于holder数组对象的引用。\n在第一次修改中，虽然在holder作用域之外进行回收，但是在此之后，没有对局部变量表的读写操作，holder所占用的Slot还没有被其他变量所复用。所以作为GC Roots一部分的局部变量表仍保持者对它的关联。这种关联没有被及时打断，因此GC收集器不会将holder引用的对象内存回收掉。 在第二次修改中，在GC收集器工作前，手动将holder设置为null值，就把holder所占用的局部变量表中的Slot清空了，因此，这次GC收集器工作时将holder之前引用的对象内存回收掉了。\n当然，我们也可以用其他方法来将holder引用的对象内存回收掉，只要复用holder所占用的slot即可，比如在holder作用域之外执行一次读写操作。\n为对象赋null值并不是控制变量回收的最好方法，以恰当的变量作用域来控制变量回收时间才是最优雅的解决办法。另外，赋null值的操作在经过虚拟机JIT编译器优化后会被消除掉，经过JIT编译后，System.gc（）执行时就可以正确地回收掉内存，而无需赋null值。\n Reference\n\n浅谈Java的垃圾回收机制（GC）\n\n","plink":"ilucia.github.io/java_gc/"},{"title":"使用OpenSSL生成SSL数字认证以用于Nginx的HTTPS通信","date":"2020-03-22T00:00:00.000Z","updated":"2022-04-27T15:24:01.727Z","content":"\n\n生成私钥\nopenssl genrsa -out private.pem 2048\n\n\n利用生成的私钥生成公钥\nopenssl req -x500 -key private.pem -out cert.pem -days 3650\n\n\n修改配置文件\n123456789101112131415161718server &#123;\tlisten 443;    \tssl on;    \tssl_certificate /etc/ssl/cacert.pem;        \t# path to your cacert.pem    \tssl_certificate_key /etc/ssl/privkey.pem;      # path to your privkey.pem      server_name seafile.example.com;      server_tokens off;      # ......      proxy_pass http://127.0.0.1:8000;      proxy_set_header   Host $host;      proxy_set_header   X-Real-IP $remote_addr;      proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;      proxy_set_header   X-Forwarded-Host $server_name;      proxy_set_header   X-Forwarded-Proto https;  proxy_read_timeout  1200s;&#125;\n\n\n强制将http请求转为https请求\n123456server &#123;        listen  80;        listen  [::]:80;        rewrite ^ https://$http_host$request_uri? permanent;        server_tokens off;&#125;\n\n\n","plink":"ilucia.github.io/openssl/"},{"title":"数据库实践复习提纲","date":"2020-03-17T00:00:00.000Z","updated":"2022-04-27T15:24:01.715Z","content":" PL/SQL\n\n\nDDL\n\n\nDML\n\n\nDCL\n\n\nTCL\n\n\n\n\n创建同义词\n\n\ncreate synonym A for B;\n\n同一用户的同一名称空间内对象名不得重复\n伪列\n数据字典\n\n View\n","plink":"ilucia.github.io/Review/database/"},{"title":"传感器导论","date":"2020-03-11T23:03:06.000Z","updated":"2022-04-27T15:24:01.643Z","content":" Chapter 1\n 传感器\n\n\n传感器\n\n\n将被测信号转换为电/光信号\n\n\n组成\n\n\n敏感元件\n\n\n转换元件\n\n\n转换（测量）电路\n\n\ne.g.\n\n\n\n测量分类\n\n被测量\n\n热工量\n\n温度、热量、比热；压力、压差、真空度；流量、流速、风速\n\n\n机械量\n\n位移（线、角）、尺寸、形状；力、力矩、应力、；重量、质量；转速、线速度、震动幅度、频率、加速度、噪声；\n\n\n物性和成份量\n\n气体、液体化学成分；酸碱度、盐度等\n\n\n状态量\n\netc\n\n\n\n\n原理\n\n电阻式\n光电式\n电感式\n谐振式\n电容式\n霍尔式\n阻抗式\n超声式\netc……\n\n\n\n\n\n分类目的\n\n\n一般要求\n\n足够的容量（量程）\n灵敏度高，精度适当\n响应速度快，工作稳定，可靠性好\n使用性和适应性强使用经济\n\n\n\n\n\n\n数据丢失\n\n 传感器的选择标准\n\n依据测量对象和使用条件选定传感器类型\n了解使用条件\n线性范围与量程\n灵敏度\n精度\n频率响应特性\n稳定性\n\n 传感器的标定和校准\n\n静态标定\n动态标定\n\n Chapter 2 电阻式传感器\n 基本结构\n 应变电阻效应\n设有一段长为lll，截面积为AAA，电阻率为ρ\\rhoρ的固态导体，有\nR=ρlAR=\\rho\\frac{l}{A}\nR=ρAl​\n\n有(μ\\muμ:导体材料的泊松比)\ndRR=(1+2μ)ϵ+dρρ\\frac{dR}{R}=(1+2\\mu)\\epsilon+\\frac{d\\rho}{\\rho}\nRdR​=(1+2μ)ϵ+ρdρ​\n 金属材料的应变电阻效应\n金属材料电阻率相对变化与体积相对变化的关系\ndρρ=CdVV\\frac{d\\rho}{\\rho}=C\\frac{dV}{V}\nρdρ​=CVdV​\nΔRR=[(1+2μ)=C(1−2μ)]ϵ=KmϵKm=(1+2μ)=C(1−2μ)\\frac{\\Delta R}{R}=[(1+2\\mu)=C(1-2\\mu)]\\epsilon=K_m\\epsilon\\\\\nK_m=(1+2\\mu)=C(1-2\\mu)\nRΔR​=[(1+2μ)=C(1−2μ)]ϵ=Km​ϵKm​=(1+2μ)=C(1−2μ)\n 半导体材料的应变电阻效应\n 压阻效应\ndρρ=πσ=πEϵ\\frac{d\\rho}{\\rho}=\\pi\\sigma=\\pi E\\epsilon\nρdρ​=πσ=πEϵ\nσ\\sigmaσ:作用于材料的轴向盈利，π\\piπ：半导体材料在受力方向的亚族系数，EEE:半导体材料的弹性模量\nΔRR=[(1+2μ)+πE]ϵ=KsϵKm=(1+2μ)+πE\\frac{\\Delta R}{R}=[(1+2\\mu)+\\pi E]\\epsilon = K_s\\epsilon\\\\\nK_m=(1+2\\mu)+\\pi E\nRΔR​=[(1+2μ)+πE]ϵ=Ks​ϵKm​=(1+2μ)+πE\n 导电丝材料的应变电阻效应\nΔRR=K0ϵK0:导电丝材料的灵敏系数\\frac{\\Delta R}{R}=K_0\\epsilon\\\\\nK_0:导电丝材料的灵敏系数\nRΔR​=K0​ϵK0​:导电丝材料的灵敏系数\n 电阻式应变计的材料和类型\n\n 电阻应变计的主要特性\n 静态特性\n 灵敏系数\n在一定应变范围内有\nΔRR=Kϵxϵx:应变计轴向应变\\frac{\\Delta R}{R}=K\\epsilon_x\\\\\n\\epsilon_x:应变计轴向应变\nRΔR​=Kϵx​ϵx​:应变计轴向应变\n 横向效应\n\nΔRR=Kxϵx+Kyϵy=Kx(1+αH)ϵxKx:纵向灵敏系数Ky:横向灵敏系数\\frac{\\Delta R}{R}=K_x\\epsilon_x+K_y\\epsilon_y=K_x(1+\\alpha H)\\epsilon_x\\\\\nK_x:纵向灵敏系数\nK_y:横向灵敏系数\nRΔR​=Kx​ϵx​+Ky​ϵy​=Kx​(1+αH)ϵx​Kx​:纵向灵敏系数Ky​:横向灵敏系数\n横向效应减小灵敏系数和相对电阻比\n 机械滞后\n 蠕变与零漂\n反应长期稳定性\n 应变极限\n 动态特性\n\n正弦应变波\n阶跃应变波\n疲劳寿命\n\n 评定应变计主要特性的精度指标\n 电阻应变计的温度效应及其补偿\n 温度效应\n(ΔRR)=αtΔt+K(βs−β−t)Δtαt:敏感栅材料的电阻温度系数K:应变计的灵敏系数βs、βt:试件和敏感栅材料的线膨胀系数(\\frac{\\Delta R}{R})=\\alpha_t\\Delta t+K(\\beta_s-\\beta-t)\\Delta t\\\\\n\\alpha_t:敏感栅材料的电阻温度系数\\\\\nK:应变计的灵敏系数\\\\\n\\beta_s、\\beta_t:试件和敏感栅材料的线膨胀系数\n(RΔR​)=αt​Δt+K(βs​−β−t)Δtαt​:敏感栅材料的电阻温度系数K:应变计的灵敏系数βs​、βt​:试件和敏感栅材料的线膨胀系数\n有相对热输出：\nϵt=ΔRRtK=1tαtΔt+(βs−βt)Δt\\epsilon_t=\\frac{\\frac{\\Delta R}{R}_t}{K}=\\frac{1}{t}\\alpha_t\\Delta_t+(\\beta_s-\\beta_t)\\Delta_t\nϵt​=KRΔR​t​​=t1​αt​Δt​+(βs​−βt​)Δt​\n 热输出补偿\n\n\n温度自补偿法\n\n\n单丝自补偿\n\n\n双丝自补偿\n\n使αt=−K(βs−βt)\\alpha_t=-K(\\beta_s-\\beta_t)αt​=−K(βs​−βt​)\n\n\n\n\n\n桥路补偿法\n\n\n双丝半桥式\n\n\n\n补偿块法\n\n\n\n\n\n粘结剂选用\n\n\n 测量电路\n 应变电桥\n\n\n\n电桥结构\n\n\n\n电源\n\n直流电桥\n\n只能接入电阻\n\n\n交流电桥\n\n可以接入电阻电容电感\n\n\n\n\n\n工作方式\n\n平衡桥式电路\n不平衡桥式电路\n\n\n\n桥臂关系\n\n对输出端对称\n对电源端对称\n半等臂\n全等臂\n\n\n\n电压输出桥的输出特性\n\nU0=R1R3−R2R4(R1+R2)(R3+R4)⋅UU_0 = \\frac{R_1R_3-R_2R_4}{(R_1+R_2)(R_3+R_4)}\\cdot U\nU0​=(R1​+R2​)(R3​+R4​)R1​R3​−R2​R4​​⋅U\n\n\n电压灵敏度\nSu=(ΔU0ΔR1R1)=U4S_u = (\\frac{\\Delta U_0}{\\frac{\\Delta R_1}{R_1}})=\\frac{U}{4}\nSu​=(R1​ΔR1​​ΔU0​​)=4U​\n\n\n功率输出桥\nRL=R1R2R1+R2+R3R4R3+R4=RrR_L = \\frac{R_1R_2}{R_1+R_2}+\\frac{R_3R_4}{R_3+R_4} = R_r\nRL​=R1​+R2​R1​R2​​+R3​+R4​R3​R4​​=Rr​\n\n\n非线性误差和补偿\n\n\n应变计式传感器\n\n应用和测量范围广\n分辨率和灵敏度高\n结构轻小，对试件影响小，对复杂环境适应性强，etc…\n\n\n\n调平\n\n\n 变磁阻式传感器\n\n\n\n线圈电感\nL=W2RmRm:磁路总磁阻L = \\frac{W^2}{R_m}\\\\\nR_m:磁路总磁阻\nL=Rm​W2​Rm​:磁路总磁阻\n\n\n铜损电阻\n\n\n涡流损耗电阻\n\n\n磁滞损耗电阻\n\n\n总耗散因数和品质因数\n\n\n\n","plink":"ilucia.github.io/Review/SensorTechnology/"},{"title":"DevOps CICD 零基础简介和实践","date":"2020-03-01T00:00:00.000Z","updated":"2022-04-27T15:24:01.715Z","content":" \n 关于DevOps和CICD\n 一些前置名词介绍\n\n\n敏捷开发：(Agile software development)是一种应对快速变化的需求的一种软件开发能力。相对于『非敏捷』，更强调程序猿团队和产品设计团队的紧密协作、面对面的沟通、频繁交付新的软件版本、紧凑而自我组织型的团队、能够更好的适应需求变化的代码编写和团队组织方法。\n\n\n持续集成：(Continuous Integration) 是一种软件开发实践，即团队开发人员经常集成他们的工作，通常每个成员每天至少集成一次，也就意味着每天可能会发生多次集成。每次的集成都通过自动化的构建（包括编译、发布、自动化测试）来验证\n\n\n持续部署：(Continuous Deployment) 通过自动化的构建、测试和部署循环来快速交付高质量的产品。某种程度上代表了一个开发团队工程化的程度。\n\n\n持续交付：(Continuous Delivery:CD) 让软件的产出过程在一个短周期内完成，以保证软件可以稳定、持续的保持在随时可以释出的状态。它的目标在于让软件的建制、测试与释放变的更快以及更频繁。这种方式可以减少软件开发的成本与时间，减少风险。\n\n\n 为什么需要DevOps?\n\n\n传统软件开发流程：\n\n规划→编码→构建→测试→发布→部署→维护\n开发\n\n规划、编码和构建\n\n\n测试\n\n测试\n\n\n运维\n\n发布、部署和维护\n\n\n早期的软件交付模型：瀑布模型（Waterfall）模型\n\n缺点\n\n反应迟缓、流程越往后走更改需求带来的额外成本急速上升\n\n\n\n\n\nDevOps\n\n\n\nDevelopment &amp; Operations\n\n\nDevOps是一组过程、方法与系统的统称，用于促进开发、技术运营和**质量保障（QA）**部门之间的沟通、协作与整合。\n\n\n\n\n\n从目标来看，DevOps就是让开发人员和运维人员更好地沟通合作，通过自动化流程来使得软件整体过程更加快捷和可靠。\n\n\n在DevOps的流程下，运维人员会在项目开发期间就介入到开发过程中，了解开发人员使用的系统架构和技术路线，从而制定适当的运维方案。而开发人员也会在运维的初期参与到系统部署中，并提供系统部署的优化建议。\n\n\nDevOps的实施，促进开发和运维人员的沟通，增进彼此的理解。\n\n\n\n\n\n\n\n CICD实践：以GitHub action平台为例\n UI\n\n Creating a workflow file\nAt a high level, these are the steps to add a workflow file. You can  find specific configuration examples in the sections that follow.\n\nAt the root of your repository, create a directory named .github/workflows to store your workflow files.\nIn .github/workflows, add a .yml or .yaml file for your workflow. For example, .github/workflows/continuous-integration-workflow.yml.\nUse the “Workflow syntax for GitHub Actions” reference documentation to choose events to trigger an action, add actions, and customize your workflow.\nCommit your changes in the workflow file to the branch where you want your workflow to run.\n\n Sample\n1234567891011121314151617181920name: Greet Everyone# This workflow is triggered on pushes to the repository.on: [push]jobs:  build:    # Job name is Greeting    name: Greeting    # This job runs on Linux    runs-on: ubuntu-latest    steps:      # This step uses GitHub's hello-world-javascript-action: https://github.com/actions/hello-world-javascript-action      - name: Hello world        uses: actions/hello-world-javascript-action@v1        with:          who-to-greet: 'Mona the Octocat'        id: hello      # This step prints an output (time) from the previous step's action.      - name: Echo the greeting's time        run: echo 'The time was $&#123;&#123; steps.hello.outputs.time &#125;&#125;.'\n Triggering a workflow with events\nYou can configure a workflow to start once:\n\nAn event on GitHub occurs, such as when someone pushes a commit to a repository or when an issue or pull request is created.\nA scheduled event begins.\nAn external event occurs.\n\n Getting started with a workflow\nTo help you get started, this guide shows you some basic examples. For the full GitHub Actions documentation on workflows, see “Configuring workflows.”\n\n Customizing when workflow runs are triggered\n\n\nSet your workflow to run on push events to the master and release/* branches\n12345on:  push:    branches:    - master    - release/*\n\n\nSet your workflow to run on pull_request events that target the master branch\n1234on:  pull_request:    branches:    - master\n\n\nSet your workflow to run every day of the week from Monday to Friday at 2:00 UTC\n123on:  schedule:  - cron: &quot;0 2 * * 1-5&quot;\n\n\nFor more information, see “Events that trigger workflows.”\n Running your jobs on different operating systems\nGitHub Actions provides hosted runners for Linux, Windows, and macOS.\nTo set the operating system for your job, specify the operating system using runs-on:\n1234jobs:  my_job:    name: deploy to staging    runs-on: ubuntu-18.04\nThe available virtual machine types are:\n\nubuntu-latest, ubuntu-18.04, or ubuntu-16.04\nwindows-latest, windows-2019, or windows-2016\nmacOS-latest or macOS-10.14\n\nFor more information, see “Virtual environments for GitHub Actions.”\n Using an action\nActions are reusable units of code that can be built and distributed by anyone on GitHub. You can find a variety of actions in GitHub Marketplace, and also in the official Actions repository.\nTo use an action, you must specify the repository that contains the action. We also recommend that you specify a Git tag to ensure you are using a released version of the action.\n1234- name: Setup Node  uses: actions/setup-node@v1  with:    node-version: &apos;10.x&apos;\nFor more information, see “Workflow syntax for GitHub Actions.”\n Running a command\nYou can run commands on the job’s virtual machine.\n12- name: Install Dependencies  run: npm install\nFor more information, see “Workflow syntax for GitHub Actions.”\n Running a job across a matrix of operating systems and runtime versions\nYou can automatically run a job across a set of different values, such as different versions of code libraries or operating systems.\nFor example, this job uses a matrix strategy to run across 3 versions of Node and 3 operating systems:\n123456789101112131415161718192021jobs:  test:    name: Test on node $&#123;&#123; matrix.node_version &#125;&#125; and $&#123;&#123; matrix.os &#125;&#125;    runs-on: $&#123;&#123; matrix.os &#125;&#125;    strategy:      matrix:        node_version: [&apos;8&apos;, &apos;10&apos;, &apos;12&apos;]        os: [ubuntu-latest, windows-latest, macOS-latest]    steps:    - uses: actions/checkout@v1    - name: Use Node.js $&#123;&#123; matrix.node_version &#125;&#125;      uses: actions/setup-node@v1      with:        node-version: $&#123;&#123; matrix.node_version &#125;&#125;    - name: npm install, build and test      run: |        npm install        npm run build --if-present        npm test\nFor more information, see “Workflow syntax for GitHub Actions.”\n Running steps or jobs conditionally\nGitHub Actions supports conditions on steps and jobs using data present in your workflow context.\nFor example, to run a step only as part of a push and not in a pull_request, you can specify a condition in the if: property based on the event name:\n123steps:- run: npm publish  if: github.event == &apos;push&apos;\n Reference\n\nhttps://help.github.com/en/actions/\nhttps://zhuanlan.zhihu.com/p/34291715\nhttps://zhuanlan.zhihu.com/p/91371659\n\n\n非商业用途，不当引用导致利益纠纷与本人无关\n\n","plink":"ilucia.github.io/cicd/"},{"title":"低成本个人NAS搭建解决方案（带内网穿透）","date":"2019-12-10T00:00:00.000Z","updated":"2022-04-27T15:24:01.579Z","content":" Hardware\n\nPC 或者 Raspberrypi 3b+ 一台\n周边设备（键盘、鼠标、树莓派的储存卡之类）\n可用的网络链接（内网有内网穿透方案）\n\n Software\n\n操作系统下载\n\nx86/x86_64\n\nwindows\ndeepin\nubuntu\n\n\narmv7 (Raspberry 3b(+)/4b)\n\nraspbian\n\n\n\n\n\n\n搭建NAS可以使用server版本，机子有其他用途也可以使用其他版本\n\n Step\n\n以Raspberry 3b+、Raspbian Buster with desktop、Nignx、Seafile Community组合为例。\n\n\n安装操作系统，安装流程参见各下载链接的官方安装文档\n测试网络连接\n国内用户使用Luiux系统请替换源以加速后续安装。\n\ntuna\n\n\n找到对应的发行版然后戳右边问号小圆圈即可跳转到换源页面,比如raspbian的换源页面为https://mirrors.tuna.tsinghua.edu.cn/help/raspbian/\n\n\n安装seafile服务\n\n跳转到下载页面选择对应的服务器端程序，raspberry服务器端链接，下载最新的release的.tar.gz文件（无gui环境可以使用wget下载）\n参照seafile的官方教程:部署Seafile 服务器（使用SQLite）进行安装，我们假定你并未更改默认的端口号（file端口8082,hub端口8000,若更改了请自行在后续说明中自行对应即可)\n启动seafile测试能在localhost上访问到seafile服务\n`http://localhost:8000’\n\n\n安装Nginx服务\nsudo apt install nginx安装完后启动Nginx(apt装完后直接启动) http://localhost能访问到Nginx的默认页面\n将Nginx服务请求转接到seafile上\n编辑/etc/nginx/site-enabled/default或者Nginx目录下的nginx.conf文件(windows)，建立服务器配置，将根节点转接到hub端口(8000)，将/server节点转接到file端口(8082)，参考如下\n\n123456789101112  server &#123;        listen 80 default_server;\t# 监听在80端口，ipv4        listen [::]:80 default_server;\t# 监听在80端口, ipv6        location / &#123;\t# 节点                proxy_pass http://127.0.0.1:8000/;\t# 转发端口                client_max_body_size 8000m;\t# 请求体大小限制（决定上传下载文件大小上限）        &#125;        location /server/ &#123;                proxy_pass http://127.0.0.1:8082/;                client_max_body_size 8000m;        &#125;&#125;\n\n在seafile上进行设置\n\n管理员账户登陆，选择系统设置，设置，URL\n设置SERVICE_URL和FILE_SERVER_ROOT为http://[计算机名]和http://[计算机名]/server（树莓派计算机名默认为raspberrypi）\n\n\n做内网穿透（可选）\n\n使用zerotier，新建一个账号并创建一个网络\n在服务器上安装zerotier，下载并安装客户端\n加入网络（gui直接戳戳按钮，zerotier-cli请参阅zerotier-cli）\n\n\n\n Finish\n[](￣▽￣)*\n使用设备只需要安装zerotier并加入对应网络即可通过访问http://[服务器计算机名]即可\n","plink":"ilucia.github.io/Others/privateNas/"},{"title":"软件测试小结","date":"2019-12-02T00:00:00.000Z","updated":"2022-04-27T15:24:01.703Z","content":"[toc]\n 概述\n 软件测试产生背景\n\n\n软件危机*\n软件的可靠性没有保障、维护费用不断上升、进度无法预测、成本增长无法控制、程序员无限增加等，形成软件开发局面失控的状态。\n\n\n缺陷累计放大\n\n\n缺陷出现原因\n\n产品说明书（主要原因）\n\n随意、易变、沟通不足\n\n\n设计（次要原因）\n\n随意、易变、沟通不足\n\n\n编码\n\n软件复杂度、进度压力、低级错误\n\n\n其他\n\n理解错误、测试错误\n\n\n\n缺乏规范化工程约束→缺陷的不断累积与放大效应\n\n\n\n阶段\n正确需求\n需求缺陷\n设计缺陷\n编码缺陷\n未发现缺陷\n\n\n\n\n需求阶段\n√\n√\n-\n-\n-\n\n\n设计阶段\n√\n√\n√\n-\n-\n\n\n编码阶段\n√\n√\n√\n√\n-\n\n\n测试阶段\n√\n√\n√\n√\n√\n\n\n\n\n\n有关测试观点的正确理解\n\n\n软件工程\n将系统化的、严格约束的、可量化的方法应用于软件的开发、运行和维护，即将工程化应用于软件\n\n\n\n\n 软件测试基本概念\n\n\n测试定义\n\nBill Hetzelt  定义\n\n测试就是建立一种信心，认为程序能够按照预期设想运行\n核心思想：测试是试图验证软件是可工作的\n\n\nGlenford J. Myers 定义\n\n测试是为发现错误而执行一个程序或系统的过程\n核心思想：测试是尽可能多地发现软件错误\n三个重要观点\n\n测试是为了证明程序有错，而不是证明程序无错误\n一个好的测试用例是在于他能发现至今未发现的错误\n一个成功的测试时发现了至今未发现的错误的测试\n\n\n\n\nIEEE Std 729-1983\n\n使用人工或是自动手段来运行或测定某个系统的过程，其目的在于检验它是否满足规定的需求或是弄清预期结果与实际结果之间的差别\n\n\nIEEE Std 610.12-1990\n1. 在特定的条件下运行系统或构建，观察或记录结果，对系统的某些方面做出评价\n2. 分析某个软件项已发现现存和要求的条件之差别并评价此软件项的特性\n\n\n\n测试与调试\n\n\n测试目的\n\n\n确保软件质量\n找出软件错误和缺陷，降低软件发布后潜在错误和缺陷造成的损失；验证软件是否能满足用户需求，树立对软件的信心。\n\n\n确保软件开发过程方向的正确性\n通过分析错误产生的原因帮助发现当前开发工作所采用的软件过程的缺陷，促进软件过程改进；为风险评估提供信息\n\n\n\n\n测试原理/原则\n\n\n用户至上\n所有测试都应追溯到用户需求。最严重的错误是导致软件是导致软件无法满足的需求。测试的目标是在用户发现缺陷前找到它们。\n\n\n测试是有计划的活动\n测试计划制定先于测试的执行；测试贯穿于全部软件生存周期。\n\n\n缺陷出现的集群性\n80%的错误可能源于20%的模块。\n\n\n测试应从“小规模”走向“大规模”\n最初测试单个程序模块，然后在集成的模块中找缺陷，最后在整个系统中找缺陷，最后在整个系统中找缺陷\n\n\n穷尽测试（完全测试）不可能\n\n输入量太大\n输出结果太多\n执行路径太多\netc\n\n\n\n有效的测试应由第三方独立进行\n有些测试应避免有开发人员进行\n\n\n测试无法揭示所有缺陷\n测试可以报告说有缺陷存在，但没有缺陷的话却不能说明软件没有缺陷\n\n\n测试的杀虫剂悖论\n潜在缺陷对已进行的测试具有免疫力\n\n\n测试是有风险的行为\n\n\n并非所有的缺陷都需要修复\n\n没有足够的时间\n不算真正的代码缺陷\n修复风险太大\n不值得修复\netc\n\n\n\n\n\n\n\n测试过程*\n\n拟定软件的测试计划\n编制软件测试大纲\n设计和生成测试用例\n\n测试用例定义\n\n一组输入即运行前提条件，和为某特定目标而生成的预期结果（测试用例的实质）\n一个文档，详细说明输入、期望输出，和为一测试项所准备的一组执行条件（测试用例的一种存在方式）\n\n\n测试用例设计准则\n\n代表性\n\n合理与不合理\n合法与非法\n边界和越界\n极限数据\n各种操作环境\netc\n\n\n可判定性\n可再现性\n\n\n\n\n实施测试\n分析测试结果（测试报告）\n\n收集测试结果\n生成测试报告\n\n\n\n\n\n测试用例（三要素）\n\n输入\n执行条件\n期望输出\n\n\n\n软件测试类型\n\n\nv模型\n\n需求分析↘概要设计↘详细设计↘编码V单元测试↗集成测试↗系统测试↗验收测试\n\n\n\nw模型\n\n\n\nx模型\n\n\n\n前置测试模型\n\n\n\nh模型\n\n\n\n\n\n软件测试w模型\n\n\n 软件测试现状和趋势\n\n\n软件测试的地位（工作量百分比）*\n\n\n\n阶段\n需求分析\n设计\n编码\n测试\n运行和维护\n\n\n\n\n\n20%\n15%\n20%\n45%\n-\n\n\n\n\n\n 白盒测试\n\n静态白盒测试\n\n\n在不执行代码的条件下有条理地仔细审查软件设计、体系结构和代码，从而找出软件缺陷的过程，有时被称为结构化分析\n\n\n尽早发现软件缺陷\n\n\n为后继测试中设计测试用例提供思路\n\n\ndesk checking\n\n\nPeer preview\n\n\nwalk through\n\n\nInspection\n\n\n动态白盒测试方法\n\n\n定义\n一种基于源程序或代码的测试方法。依据原程序或代码逻辑结构，生成测试用例以尽可能多地发现并修改源程序错误。\n白盒分为静态白盒测试和动态白盒测试\n\n\n实施者\n\n\n单元测试\n\n一般由开发人员进行\n\n\n\n集成测试\n\n\n测试人员和开发人员共同完成\n\n\n步骤\n\n\n动态\n\n程序图\n生成测试用例\n执行测试\n分析覆盖标准\n判定测试结果\n\n\n\n\n\n静态\n\n桌面检查\n代码走查\n代码审查\n\n\n\n优点\n\n检测代码中的判断和路径\n解释隐藏在代码中的错误\n对代码的测试比较彻底\n\n\n\n缺点\n\n无法检测代码中的不可达路径\n不验证需求规格\n\n\n\n\n\n基于控制流覆盖的测试\n\n语句覆盖测试\n\n语句覆盖\n\n程序中每条语句都执行一次\n\n处理错误的代码片段\n小概率事件（恶作剧）\n不可达代码\n较为脆弱，某些严重问题\n\n\n\n\n\n\n条件测试\n\n判定覆盖（分支覆盖）\n\n每个判断取值True和False各一次\n优点\n\n简单，包含语句覆盖并避免了语句覆盖覆盖的问题\n\n\n缺点\n\n忽略了表达式内的条件，不能发现每个条件的错误\n\n\n\n\n条件覆盖\n\n每个判断中的条件的取值至少满足一次\n不能保证程序所有分支都被执行\n\n\n判定条件覆盖\n每个条件和由条件组成的判断的取值至少满足一次\n\n错误屏蔽\n\n指原子条件取值改变不会影响判定结果，因此该条件上的取值错误是不可见的。\n\n\n注意短路\n\n\n\n\n条件组合覆盖\n\n每个条件的取值组合至少出现一次\n2n2^n2n（n为原子条件数），代价昂贵\n测试用例的约简\n\n利用短路效应寻找最小测试用例集\n\n\n\n\n路径测试\n\n路径覆盖\n\n优点\n\n相对彻底的测试\n\n\n缺点\n\n路径分支可能以指数级增加(2n2^n2n)\n存在不可达路径\n并未测试各个分支中的条件\n\n\n考虑了各种判定结果的所有可能组合但是不能覆盖判定条件中结果的各种情况\n覆盖能力较强但是不能替代条件覆盖和条件组合覆盖标准\n覆盖程序中的所有路径\n\n\n\n\n\n\n\n\n基于控制流的测试\n\n\n基本路径测试\n\n\n流程图→流图→（环复杂度）→基本路径→测试用例\n\n\n流图用来描述程序中的逻辑控制流\n\n\n节点\n\n\n表示一个或多个语句\n\n\n边\n\n\n表示控制流\n\n\n域\n\n\n由边和节点限定的区间\n\n\n基本路径\n\n\n任何贯穿程序 、至少引入一组新的处理语句或一个新判断的程序通道\n\n\n环复杂度是所有语句被执行一次所需测试用例数的上限\n\n\n\n环复杂度\n含义\n\n\n\n\n1-10\n良好\n\n\n11-20\n中等\n\n\n21-50\n复杂\n\n\n&gt;50\n无法理解\n\n\n\n\n\n\n\n\n\n\n基本路径集寻找算法\n\n确认从入口到出口的最短基本路径\n从入口到第一个未被先后评估为真和假两种结果的条件语句\n改变该条件语句的赋值\n重复步骤2-5直至所有基本路径都被找到\n\n\n\n循环测试\n\n嵌套循环\n先测试最内层循环\n*  按照简单循环测试\n\n由里向外，测试上层循环\n\n此层以外的所有外层循环变量取最小值\n此层以内所有嵌套内层循环变量取典型值\n\n\n重复上一条规则直至所有各层循环测试完毕\n对全部各层循环同时取最小循环次数或者同时取最大循环次数\n\n\n串接循环\n\n若串接循环的各个循环相互独立\n\n分别用简单循环测试\n\n\n若两个循环不独立\n\n把第一个循环看作外循环，第二个循环看作内循环，用测试嵌套循环的办法来处理\n\n\n\n\n非结构循环\n\n结构化再处理\n\n\n\n\n\n\n\n数据流测试\n\n\n数据流测试\n\n\n基本定义\n\n\nP——程序\n\n\nG§——程序图（流图）\n\n\nV——变量集合\n\n\nPATH§——P的所有路径集合\n\n\nDEF(v,n)——在节点n定义了变量v(变量赋值语句)\n\ne.g. input x; x = 2;\n\n\n\nUSE(v,n)——在节点n使用了变量v\n\ne.g. print x; a = 2 + x;\n\n\n\nP-use——USE(v,n)，谓词使用，即条件判断语句中\n\ne.g. if b &gt; 6\n\n\n\nC-use——USE(v,n)，运算使用，位于运算中\n\n\ne.g. x = 3 + b\n\n\nO-use——输出使用\nL-use——定位使用（数组）\nI-use——迭代使用（循环）\n\n\n\n\n\n\ndu-path——定义-使用路径\n\n给定PATH§中的某条路径，如果定义节点DEF(v,m)为该路径的起始节点，使用节点USE(v,n)为该路径的终止节点，则该路径是v的一条du-path\n\n\n\ndc-path——定义-清除路径\n\n如果变量v的某个定义-使用路径，除起始节点外没有其他定义节点，则该变量路径是变量v的定义-清除路径\n\n\n\n\n\n数据流覆盖测试\n\n对于给定的程序，构造相应的程序图\n\n\n\n\n找出所有变量的du-path（可以约简）\n3.  考察测试用例对这些路径的覆盖程度\n\n\n\n常用覆盖标准\n\nRapps和Weyuker标准\n\nAll-Paths\n\n路径覆盖\n\n\nAll-Edges\n\n分支覆盖\n\n\nAll-Nodes\n\n语句覆盖\n\n\nAll-Defs\n\n每个定义节点都有一条dc-path\n\n\nAll-P-Use\n\n每个定义节点都有一条dc-path\n\n\nAll-P-Uses/some-C-Uses\nAll-C-Uses/Some-P-Uses\nAll-Users\n\n每个变量的定义节点都有一条dc-path到达该变量的使用节点\n\n\nAll-du-path\n\n\nNtafos标准\nUral标准\nLaski和Korel标准\n\n\n\n\n\n\n\n\n\n 白盒测试工具\n\n测试工具分类*\n\n静态分析工具\n动态分析工具\n\n\n测试工具的作用*\n\n提高代码效率\n降低测试成本\n\n\n\n 控制流覆盖的测试\n\n短路问题\n使用尽可能少的测试用例\n测试用例要体现控制流覆盖的特点\n对各个控制流覆盖标准有明确认识\n\n语句\n判定\n条件\n判定条件\n条件组合\n路径\n\n\n\n\n控制流覆盖不使用程序流图\n\n 基本路径测试\n\n正确画出流程图，出自组合条件的判定\n使用多种方法计算圈（环）复杂度\n正确得出基本路径（顺序）\n不是所有基本路径都能写出测试用例\n\n 数据流测试\n\n不考虑数据流覆盖的各种标准\n能够找出定义节点和使用节点\n列举出所有可能的DU路径\n进行DU路径约简\n\n 黑盒测试\n 黑盒测试基本概念\n\n定义*\n\n一种基于规格说明，不要求考察代码，以用户视角进行的测试\n\n\n意义*\n\n黑盒测试有助于软件产品的总体功能验证\n\n检查明确需求和隐含需求\n采用有效输入和无效输入\n包含用户视角\n\n\n\n\n目的\n\n有时无法获取程序代码\n尽早进行黑盒测试可以尽早发现软件功能缺陷\n弥补遗漏的逻辑缺陷\n适用于测试的各个阶段\n\n单元测试\n集成测试\n系统测试\n回归测试\n\n\n\n\n实施者\n\n专门的软件测试部门：有经验的测试人员\n\n\n步骤*\n\n规格说明书\n生成测试用例\n执行测试\n判定测试结果\n\n\n进入退出条件\n\n 黑盒测试方法基础\n\n\n基于需求的测试（RTM）*\n\n\n目的\n\n确认软件需求规格说明书列出的需求\n\n\n\n前提\n\n需求规格已经经过仔细评审\n隐含需求明确化\n\n\n\n需求规格说明样本\n\n需求规格说明\n\n\n\n\n序号\n需求标识\n需求描述\n优先级\n\n\n\n\n\n\n\n\n\n\n\n\n需求跟踪矩阵样本\n\n\n\n\n需求标识\n需求描述\n优先级\n测试条件\n用例标识\n测试阶段\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n需求跟踪矩阵(RTM)\n\n作用\n\n可跟踪每个需求的测试状态而不会遗漏任何需求\n优先执行优先级高的测试用例，尽早发现高优先级区域内缺陷\n可导出特定需求对应的测试用例清单\n评估测试工作量和测试进度的重要数据\n\n\n\n\n测试执行数据样本\n\n\n\n\n序号\n需求标识\n优先级\n测试用例\n用例总数\n通过用例\n未通过用例\n通过率\n缺陷数\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n需求跟踪矩阵\n\n\n\n需求标识\n需求描述\n优先级\n测试条件\n用例标识\n测试阶段\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n作用\n\n可跟踪每个需求的测试状态而不会遗漏任何需求\n优先执行优先级高的测试用例，尽早发现高优先级区域内缺陷\n可导出特定需求对应的测试用例清单\n评估测试工作量和测试进度的重要数据\n\n\n\n\n\n正面测试*\n\n测试用例通过一组预期输出验证产品需求\n证明软件对于每条规格说明和期望都能通过\n\n\n\n负面测试*\n\n展示当输入非预期输入时产品没有失败\n使用产品没有设计和预想到的场景，尝试使系统垮掉\n负面测试不能映射到需求\n\n\n\n 黑盒测试方法\n\n\n等价划分\n\n原理\n\n将程序的输入域划分为数据类，以便导出测试用例\n他试图定义一个测试用例以发现各类错误，从而减少测试用例数目，降低测试工作量\n\n\n等价类（划分）\n\n如果软件行为对一组值来说是相同的，则称这组值为等价类\n产生同一个预期输出的一组输入值叫一个划分\n有效等价类\n\n完全满足产品规格说明的输入数据构成的集合\n\n\n无效等价类\n\n不满足程序输入要求或者无效的输入数据构成的集合\n\n\n划分类型\n\n布尔表达式\n\n一个有效等价类True\n一个无效等价类False\n\n\n范围\n\n一个有效等价类，范围内\n两个无效等价类，大于小于\n\n\n数据个数\n\n一个有效等价类，正确个数\n两个无效等价类，大于小于\n\n\n集合的某个子集\n\n一个有效等价类，正确集合\n若干无效等价类\n\n\n一组列表形式的数据\n\n多个有效等价类，每个输入数据为一个等价类\n1个无效等价类\n\n\n要求符合几个规则\n\n多个有效等价类\n若干无效等价类\n\n\n\n\n步骤\n\n划分准则\n确定有效等价类和无效等价类\n从等价类中选取样本数据\n根据需求写预期结果\n加入特殊值\n执行测试\n\n\n\n\n\n\n\n边界值分析\n\n\n软件的两个主要缺陷源\n\n条件\n边界\n\n\n\n边界值分析\n\n\n原因\n\n使用比较操作符时未仔细分析\n多种循环和条件检查方法引起的困惑\n对边界附近需求的理解不够\n\n\n\n测试边界\n\n第一个-1/最后一个+1\n开始-1/完成+1\n最小值-1/最大值+1\n\n\n\n界定边界值\n\nn存在边界值的参数个数\nm边界值条件个数\n\n\n\nPaul Jorgensen公式\n\n\n4n+1 基本边界测试\n\n\nmin\n\n\nmin+1\n\n\nmax-1\n\n\nmax\n\n\n一个典型值\n\n\n\n\n\n6n+1 健壮性边界测试\n\n\nmin-1\n\n\nmin\n\n\nmin+1\n\n\nmax-1\n\n\nmax\n\n\nmax+1\n\n\n一个典型值\n\n\n\n\n\n3m 边界条件测试\n\nself-1\nself\nself+1\n\n\n\n\n\n\n\n\n\n因果分析法\n\n因果图\n（需求规格说明书）→生成因果列表→（起因结果列表）→建立决策表→（决策表）→生成测试用例\n表示\n\n原因 CiC_iCi​\n结果 EiE_iEi​\n\n\n因果4种关系\n\n\n\n\n\n\n\n输入约束4种\n\n\n\n\n\n输出约束1种\n\n\n\n\n决策表\n\n\n\n\n-\n1\n2\n3\n4\n…\n\n\n\n\n条件C1\n\n\n\n\n\n\n\n条件C2\n\n\n\n\n\n\n\n条件Cn\n\n\n\n\n\n\n\n行动A1\n\n\n\n\n\n\n\n行动A2\n\n\n\n\n\n\n\n行动An\n\n\n\n\n\n\n\n测试用例（输出）\n\n\n\n\n\n\n\n\n\nStep\n\n分析规格说明书，识别原因和结果\n在因果图之间连接原因和结果\n表明原因之间以及结果之间的约束条件\n因果图转换为因果图列表进而生成决策表\n决策表的规则转换为测试用例\n\n\n\n\n\n决策表\n\n\n组成\n\n\n条件桩\n\n列出所有可能问题\n\n\n\n条件项\n\n解除条件所有可能取值\n\n\n\n动作桩\n\n列出可能采取的操作\n\n\n\n动作项\n\n在条件项的各种取值情况下应采取的动作\n\n\n\n决策规则，贯穿条件项和动作项的一列\n\n\n\n构造决策表\n\n列出所有的条件桩和条件项\n填入条件项\n填入动作项，得到初始决策表\n简化决策表，合并相似规则\n\n\n\n化简\n\n\n合并相似规则\n\n\n\n\n\n\n基于模型的测试*\n* 原理\n  * 软件执行过程可分解为若干对象和连接对象之间的关系\n    * 测试序列可视为验证对象间所期望的关系是否满足\n  \n* 适用领域\n  * 有限状态建模\n    * 工作流建模\n  * 数据流建模\n    * 时间建模\n\n\n模型化软件\n\n\n\n正交数组测试\n\n\n利用真叫测试再加上特殊用例测试，基本上可以均匀分散地覆盖到各种情况，又能大大减少测试用例个数\n\n\n正交表\n\n\n构成\n\n因子：输入参数\n水平：输入取值\n因子数：正交表中列的个数\n水平数：单个因子的取值个数\n行数：正交表行数\n记法：L行数(水平数因子数)L{行数}(水平数^{因子数})L行数(水平数因子数)\n\n\n\n正交表的正交性\n\n整齐可比\n\n每个因子的每个水平出现的次数完全相同\n\n\n均匀分散\n\n任意两列的水平搭配是完全相同的\n\n\n\n\n\n\ne.g.\n\n\nL4(23)L4(2^3)L4(23)\n\n\n\n\n1\n2\n3\n\n\n\n\n1\n1\n1\n1\n\n\n2\n1\n2\n2\n\n\n3\n2\n1\n2\n\n\n4\n2\n2\n1\n\n\n\n\n\n\n\n\n\n\n\nStep\n\n确定因子和水平\n判断是否能使用正交数组（因子少于2则不适用）\n选择合适的正交表\n把变量值映射到表中\n正交测试用例制作\n补充测试用例\n\n\n\n正交表选择\n\n正交表因子个数≥实际因子数\n正交表每个因子书的水平个数≥实际每个因子数的水平个数\n正交表的行数\n\n选择最少的正交表\n\n\n\n\n\n把变量值映射到表中\n\n正交测试用例制作\n补充测试用例\n\n\n\n\n\n蜕变测试\n\n\n随机测试\n 黑盒测试工具\n\n测试工具原理\n\n以GUI自动化测试工具为例\n\n运行北侧软件的同时，捕获过程中的键鼠操作，生成脚本文件，这个脚本文件可以被修改和回放\n\n\n\n\n作用\n\n\n\n 等价划分和边界值分析\n\n等价类划分一定要考虑全面，分为有效等价类和 无效等价类，并统一编号\n写测试用例时，每个等价类至少有一个测试用例\n边界值分析可考虑边界值和条件值\n边界值要考虑需求的限制、数据类型的限制、系统的限制等多种限制条件\n\n 因果图和决策表\n\n能够列出原因和结果列表\n因果图的画法\n根据因果图得出因果列表，进一步得出决策表\n决策表约简\n\n 单元测试和集成测试\n 软件测试\n\n基本概念*\n\n软件单元\n\n一个应用程序中的最小可测部分\n\n\n定义\n\n单元测试\n\n对最小的软件设计单元的验证工作\n\n\n模块测试\n\n对最小的软件设计模块的验证工作\n\n\n\n\n意义\n\n消除软件单元本身的不确定性\n其他测试阶段的必要的基础环节\n\n\n目标\n\n单元体现了预期的功能\n单元的运行能够覆盖预先设定的各种逻辑\n单元工作中：内部数据能够保持完整性\n可以接受正确数据，也能处理非法数据\n在数据边界上，单元能正常工作\n单元算法合理，性能良好\n扫描单元代码没有发现任何安全性问题\netc\n\n\n实施者\n\n软件开发人员\n\n\n关注点\n\n模块功能\n内部逻辑处理\n数据结构\n性能\n安全\n\n\n\n\n单元测试流程\n\n技术和步骤\n\n先设计测试用例，然后执行测试\n进入条件\n\n编码开始：设计测试数据并执行测试\n\n\n退出条件\n\n完成测试计划\n发现并修正错误\n预算和开发时间\n\n\n\n\n模块或构件接口\n\n目标\n\n进出模块/构件的数据流正确\n\n\n关注点\n\n接口名称、参数个数、类型、顺序的匹配\n输出或返回值的及其类型是否正确\n\n\n\n\n局部数据结构\n\n目标\n\n数据在模块执行中都维持完整性和正确性\n\n\n关注点\n\n局部数据定义和使用过程的正确性\n局部数据结构对全局数据机构的影响\n\n\n\n\n边界条件\n\n目标\n\n保证模块在边界条件上能够正确执行\n\n\n关注点\n\n数据机构中的边界\n控制流中的边界\n\n\n\n\n独立路径\n\n目标\n\n保证模块中的每条独立（基本）路径都要走一遍，使得所有语句都被执行过一次\n\n\n关注点\n\n对路径的选择性测试（基本路径测试+循环测试）\n\n\n\n\n处理错误的路径\n\n保证错误处理的正确性，软件的健壮性\n\n\n\n\n驱动器和程序桩\n\n驱动器\n\n对底层或子层模块进行测试时所编制的调用被测模块的程序，用以模拟被测模块的上级模块。\n\n\n程序桩\n\n对上层模块进行测试时，所编制的替代下层模块的程序，用以模拟被测模块工作过程中所调用的模块。\n\n\n高内聚低耦合可以让驱动器和测试桩编写更加简单并已于发现错误\n\n\n\n 集成测试\n\n概念*\n\n把单独的软件模块结合在一起作为整体接受测试\n\n\n接口*\n\n内部接口\n外部接口\n接口提供方法\n\nAPI\nSDK\n\n\n桩程序\n\n\n实施者\n\n软件测试人员\n软件开发人员\n\n\n瞬时集成测试\n\n当所有构建都通过单元测试，就把他们组合成一个最终系统，并观察它能够正常运转\n缺陷\n\n无休止的错误，修复困难\n一次性结合，难以找出错误原因\n容易和其他错误混淆\n\n\n\n\n增量集成测试\n\n特点\n\n将程序分成小的部分进行构造和测试\n\n\n优点\n\n错误容易分离和修正\n接口容易彻底测试\n\n\n缺点\n\n会有额外开销\n\n\n自顶向下\n\n深度优先\n广度优先\n优点\n\n尽早发现高层控制和决策错误\n最多只需要一个驱动器\n每步只增加一个模块\n\n\n缺点\n\n对底层模块的行为验证比较晚\n需要编写额外程序模拟未测试的模块\n部分测试用例由于依赖其他层次的模块，在该模块未测试之前，这些测试用例的输入输出很难确定\n\n\n\n\n自底向上\n\n从原子模块构造并集成测试\n优点\n\n尽早确认底层行为\n无需编写程序桩\n对实现特定功能的树容易表示输入输出\n\n\n缺点\n\n推迟确认高层行为\n需编写驱动器\n组合子树时，有许多元素要集成\n\n\n\n\n混合式集成\n\n综合\n\n\n\n\n\n 测试插装\n\n黑盒插装*\n\n随机数据生成器（随机测试）\n作用\n\n避免只测试所知道的将奏效的场景\n\n\n\n\n白盒插装*\n\n语句覆盖插桩\n分支覆盖插桩\n条件覆盖插桩\n插桩\n\n生成特定状态，检验状态的可达性\n显示或读取内部数据的私有数据\n检测不变数据\n检测前提条件\n人为触发事件时间\n检测事件时间\n\n\n\n\n\n 系统测试、确认测试和回归测试\n 系统测试\n\n\n概念\n\n定义\n\n对完整集成后的产品和解决方案的测试，用来评价系统对具体需求规格说明的功能和非功能的符合性的测试\n\n\n意义（特点）\n\n既是测试产品功能也是测试产品非功能的唯一测试阶段\n\n\n目的\n\n发现可能难以直接与模块或接口关联的缺陷\n发现产品设计、体系和代码的基础问题（产品级缺陷）\n\n\n实施者\n\n独立测试团队（引入独立视角，有助于发现遗漏缺陷）\n\n\n引入时机\n\n集成测试之后（基础的程序逻辑错误和缺陷已更正后）\n\n\n实施原因\n\n在测试中引入独立视角\n在测试中引入客户视角\n在测试用模拟用户的使用环境\n测试产品功能和非功能的问题\n建立对产品的信心\n分析和降低产品发布的风险\n保证满足所有需求，产品具备交付确认测试条件\n\n\n\n\n\n功能测试\n\n\n设计/体系结构测试\n\n\n原理\n\n对照设计和体系结构开发和测试用例，从而整理出产品级测试用例\n集成测试用例关注模块或组件间交互，而系统功能测试用例关注整个产品的行为\n\n\n\n方法\n\n\n体系结构静态测试\n\n体系结构分析\n对体系机构的特征进行建模、分析\n\ne.g.\n\n对类定义的一致性分析\n\n\n\n\n\n\n\n体系结构的动态测试\n\n\n\n测试用例特征\n建议\n\n\n\n\n测试用例关注代码逻辑、数据结构和产品单元\n单元测试\n\n\n测试用例关注组件接口\n集成测试\n\n\n测试用例关注的是不能为用户所看到的产品实现\n单元测试\\集成测试\n\n\n测试用例综合了客户使用和产品实现\n系统测试\n\n\n\n\n\n\n\n\n\n业务垂直测试\n\n\n原理\n\n针对不同业务纵深的产品，根据业务定制测试用例，验证业务运作和使用\n\n\n\n应用范围\n\n通用的工作流自动化系统在不同商业领域的应用\n\n\n\n方法\n\n\n模拟\n\n测试需求和业务流\n\n\n\n复制\n\n\n获取客户数据流和过程，针对特殊业务进行定制\n\n定制：改变系统的一般工作流，以适用于不同业务纵深\n术语：尽量使用各个业务领域的专属名词\n\n\n\n\n\n\n\n\n\n部署测试\n\n验证系统能够满足客户的部署需求\n目的\n\n特定产品版本短期内是否能够成功使用\n\n\n离场部署\n\n在产品开发组织内运行，以确保客户部署需求的（模拟）部署测试\n\n\n现场部署（离场部署的扩展）\n\n现场部署是指在客户场地中的资源和环境都发布后，实施的一种部署方案\n\n采集系统的采集系统真实数据，建立镜像测试环境，重新执行用户操作\n引入新产品，进行新业务操作，同实对比事务处理情况，以确定新系统能否能够替代老系统\n\n\n\n\n\n\n\nAlpha/Beta测试\n\nAlpha测试\n\n用户在开发环境下进行的受控测试\n特点\n\n不由程序员或测试员完成，但开发者会在现场\n\n\n\n\n在Alpha测试达到一定程度后进行Beta测试\nBeta测试\n\n用户在实际使用环境下进行测试，一种可以把待测产品交给客户收集反馈意见的机制\n特点\n\n开发者通常不在现场\n\n\n挑战\n\n客户数量\n\n客户充分了解产品\n\n\n\n\n\n\n\n\n\n符合性的认证、标准和测试\n\n产品需要通过主流硬件、操作系统、数据库和其他基础设施构建上进行的验证，并符合相关法规和行规\n主流基础设施\n\n操作系统\n硬件\n数据库\netc\n\n\n约定和法律要求\n\n质量行业标准\n法规\n技术领域标准\n\n\n\n\n\n\n\n非功能测试\n\n非功能测试用于验证系统的质量因素\n\n理解产品行为、设计体系和体系结构\n针对不同配置和资源对产品进行测试\n手机和分析响应数据\n评判产品质量\n\n\n非功能测试的最大挑战：设置配置\n原因\n\n难以预测用户的使用环境\n对配置进行组合测试的代价太高\n建立测试环境成本高\n很难准确预测客户使用的数据\n\n\n配置环境\n\n模拟环境\n真实客户环境\n\n\n可伸缩性测试/容量测试\n可靠性测试\n压力测试\n互操作性测试/兼容性测试\n可使用性与易获得性测试\n国际化测试\n性能测试\n安全性测试\n\n\n\n 确认测试\n\n概念*\n\n定义\n\n检查产品是满足在项目的需求阶段定义的确认规则，或者说是否具备在真实环境中使用的条件\n\n\n引入时机\n\n系统测试之后\n\n\n测试用例\n\n测试用例数量较少，目的不是为了发现缺陷\n\n\n测试环境\n\n近似实际场景下进行\n\n\n\n\n实施者\n\n客户或客户代表\n\n\n目的*\n\n验证和接受产品\n\n\n产品确认\n\n对现有测试用例进行分类形成确认准则\n\n\n规程确认\n\n根据交付规程进行定义\n\n\n确认准则\n\n服务约定等级\n\n\n执行\n\n开发组织\n\n辅助客户完成确认测试\n\n\n确认测试团队\n\n产品管理层+支持团队+咨询团队\n\n90%成员具有产品业务过程知识\n10%成员属于技术测试团队\n\n\n\n\n开发组织的测试团队应当与确认测试团队不断沟通，提供采集测试数据和分析测试结果的帮助\n\n\n\n 回归测试\n\n概念*\n\n回归测试是对之前已修改过、经过修改的程序进行的重新测试，以保证该修改没有引入新的错误或者由于更改而发现之前未发现的错误\n回归测试要保证增强型或改正型修改使软件正常进行并且不影响已有的功能\n\n\n意义\n\n保证软件维护时未更改的代码功能不会收到影响\n保证软件模块区域和持续维护过程与回归测试的协作关系，是回归测试成为一个每月/每周/每日的常规活动\n实现软件整个生命周期的测试\n\n\n引入时机\n\n单元测试\n集成测试\n系统测试\n引入原则\n\n开发过程中发生修改或维护，就有必要进行回归测试\n\n\n\n\n特点\n\n测试计划\n\n常规测试\n\n已有的带有测试用例的测试计划\n\n\n回归测试\n\n更改的规格说明书、修改过的程序和需要更新的旧测试计划\n\n\n\n\n测试范围\n\n常规测试\n\n整个程序\n\n\n回归测试\n\n被修改部分的正确性以及它与原有功能的整合\n\n\n\n\n时间分配\n\n常规测试\n\n测试时间实现有预算\n\n\n回归测试\n\n测试时间不包含在进度表中\n\n\n\n\n开发信息\n\n常规测试\n\n随时可获得开发信息\n\n\n回归测试\n\n只需保留开发信息保证回归测试正确\n\n\n\n\n完成时间\n\n常规测试\n\n所需时间长\n\n\n回归测试\n\n只需测试软件的一部分，测试时间短\n\n\n\n\n执行频率\n\n常规测试\n\n高频率的活动\n\n\n回归测试\n\n由系统被修改而触发的周期性活动、\n\n\n\n\n\n\n过程\n\n提出软件测试修改需求\n进行软件修改\n选择测试用例（选择正确的测试用例集）\n执行测试\n识别失败结果\n识别错误\n排除错误\n\n\n策略\n\n全部重新测试\n\n不用进行测试用例选择\n\n\n有选择地重新测试\n\n灵活、适用于测试用例较多的情形\n\n\n\n\n重新确认测试用例\n组测试*\n\n多模块集成工作差错\n\n\n波及效应\n\n保证软件修改后仍然保持一致性与完整性\n需求的波及效应\n设计的波及效应\n代码的波及效应\n测试用例的波及效应\n步骤\n\n开始\n实施初始修改\n识别收到潜在影响的区域\n需要进一步修改一保持一致性？\n\ny:\n\n决定如何修改\ngo to 1\n\n\nn:\n\ncontinue\n\n\n\n\n结束\n\n\n\n\n\n","plink":"ilucia.github.io/Review/SoftwareTest/"},{"title":"Hackathon 华东 @2019 赛事主办回顾与反思","date":"2019-11-30T00:00:00.000Z","updated":"2022-04-27T15:24:01.579Z","content":" 引言\n2019年11月23、24日，Hackathon 华东 @ 2019 赛事在东大九龙湖校区顺利举行，作为主办方负责人，我在组织这场大型赛事的活动中有一点经验和反思，望可以作为自己日后举办类似赛事的经验也可以供读者们参考。\n 先决条件\n要顺利举办一场赛事，离不开资金和行政的支持；\n\n\n财政\n在前期规划过程中，hackathon拉的赞助时间一开始定在赛事前一个月，事实上作为赛事主办方去寻找赞助这个本身就是一种不可靠（指不能保证资金筹集）的行为，当我把策划书时间表提供给公司审阅时，公司负责人立即指出赞助安排过迟的问题，恰好当时时间也比较充裕，我们调整了拉赞助的时间。事实证明这个选择是对的。因为各种问题，我们没有拉到额外的赞助。最终我们的活动经费来源全部依靠了微软中国和微软亚洲研究院。\n\n\n行政\n由于赛事在东南大学九龙湖校区内举行，选手的比赛场地、入门许可和饭食等问题都要依托于校方的支持，所以提前一定时间向学校提出赛事和申请，由于学校机构较多，我们一开始为了寻找应该向哪个单位租借机房也耗费了很久的时间（等相关部门回复需要一定的时间，辗转了几次累计的时间会在半个月左右）。\n\n\n基于以上问题，我建议此类赛事的财政和行政准备一般不低于一个半月为佳，并制定周密的计划书和完成清单，这能帮助负责人理清各项事宜的细节和追踪进度。\n 准备工作\n\n\n邀请\n\n\n参赛选手邀请\n报名窗口期建议在15-20天为以宜，报名结束到赛事开始建议在半个月左右，所以请至少在赛事开始前一个半月准备报名站点搭建和报名文案，传媒渠道，选手（答疑）群等事项的准备\n建站建议\n\n\n赛事宣传页\n\n我们使用了Hexo静态网页、托管于GitHub（国内也可以试试腾讯云）。这样免去了服务器和运维方面的成本。markdown也可以轻松胜任简易编写、快速上线、功能丰富的需求，Hexo的自带丰富模板也足够方便美观。这个我为Hackathon赛事搭建的主页 https://hackathon2019eastchina.github.io/ \n\n\n\n报名信息采集\n\n静态网页本身并不支持表单提交功能，为此我们可以嵌入Microsoft form的iframe组件，（markdown支持一部分Html语法，可以直接嵌入iframe）（处于兼容性问题考虑，可以再给个指向Microsoft form的链接）\n\n这样，建站服务就完成啦\n\n\n\n\n评委和导师邀请\n​\t由于老师往往都有一定的排课和出差等安排，建议提前一个月邀请。\n\n\n\n\n物资准备\n\n建议列出采购清单并分派购买任务（注意提醒自己和经手人索要发票），提前一个月准备为宜（考虑到丢件的可能）\n预算不足的组织可以考虑协商后续通过发票报销\n\n\n\n\n","plink":"ilucia.github.io/Others/reviewOfHackathon/"},{"title":"编译原理小结","date":"2019-10-07T00:00:00.000Z","updated":"2022-04-27T15:24:01.595Z","content":"[TOC]\n Chapter 1\n\nNone\n\n Chapter 2 Language &amp; Syntax Description\n Language &amp; syntax description\n\n\nAlphabet\n\nNon-empty set of symbols，usually expressed in $\\Sigma$、$V$ or Other Upper-case Greece Letter\n\n\nSymbol (Character)\n\nElements in alphabet, finest elements in a language\n\n\nString\n\nFinite sequence of symbols in the Alphabet.\n\nNotes: Null-string is string without any symbol, written as e。\n\n\n\n\nA = {α1\\alpha_1α1​,α2\\alpha_2α2​,…} B ={β1\\beta_1β1​,β2\\beta_2β2​}\nAB = {αβ∣α∈A and β∈B}\\{\\alpha\\beta|\\alpha\\in A\\ and\\ \\beta \\in B\\}{αβ∣α∈A and β∈B}\nA0={ε}A^0=\\{\\varepsilon\\}A0={ε}\n\n\nClosure\nA∗=A0∪A1∪A2...A^*=A^0\\cup A^1\\cup A^2...A∗=A0∪A1∪A2...\n\n\nPositive closure\nA+=A1∪A2∪A3...A^+=A^1\\cup A^2 \\cup A^3...A+=A1∪A2∪A3...\n\n\n\n\nSentence\n\n A set of strings based on symbols in the Alphabet in  certain construction rules\n\n\nLanguage\n\n Sets of sentences in the Alphabet.\n\n Notes: By convention, a symbol is expressed as a,b,c,…；a string is expressed as $\\alpha$,$\\beta$,$\\gamma$…；a set of strings is expressed in A,B,C….\n\n\n\nGrammar\n\nGrammar(G)\nNone-terminal symbol(VNV_NVN​)\nTerminal symbol(VTV_TVT​)\nStart symbol(S)\nProduction§\n\n→\nA→αA\\rightarrow \\alphaA→α\n\n\nDerivation(Leftmost &amp; Rightmost)\nReduction\nSentential form,  Sentence &amp; Language\nRecursive definition of grammar rules\nExtended notations of grammar rules\n\n\nFormal definition\n\nGrammar\n\nquadruple (VN,VT,P,SV_N,V_T,P,SVN​,VT​,P,S)\n\n\nCatalog of grammars\n\n0-type grammar (Phrase grammar or grammar without limitation)\n\nto any production α→β\\alpha\\rightarrow\\betaα→β in P (α∈V+,β∈V∗)(\\alpha\\in V^+,\\beta\\in V^*)(α∈V+,β∈V∗) ,there is at least  a non-terminal symbol in α\\alphaα\n\n\n1-type grammar (context-sensitive grammar or length-added grammar)\n\nto any production α→β\\alpha\\rightarrow\\betaα→β in P, there is the limitation of ∣β∣≥∣α∣|\\beta|\\ge|\\alpha|∣β∣≥∣α∣ **expect for S→εS\\rightarrow\\varepsilonS→ε,if S→εS\\rightarrow\\varepsilonS→ε, S can not appear in the right side for any production.\nfor any production α→β\\alpha\\rightarrow\\betaα→β in P, αAβ→αγβ (α,β∈V∗)\\alpha A\\beta\\rightarrow\\alpha\\gamma\\beta\\ (\\alpha,\\beta\\in V^*)αAβ→αγβ (α,β∈V∗) expect for S→εS\\rightarrow\\varepsilonS→ε\n\n\n2-type grammar (context-free grammar)\n\nEvery production in P is of the form A→βA\\rightarrow\\betaA→β where A∈VN,β∈V∗A\\in V_N,\\beta\\in V^*A∈VN​,β∈V∗\n\n\n3-type grammar (Regular grammar, right-linear grammar or left-linear grammar)\n\nEvery production in P is of the form A→αB,A→αA\\rightarrow\\alpha B,A\\rightarrow\\alphaA→αB,A→α, or A→BαA\\rightarrow B\\alphaA→Bα,A→αA\\rightarrow\\alphaA→α,where AAA,B∈VN,α∈VT∗B\\in V_N,\\alpha\\in V_T^*B∈VN​,α∈VT∗​\n\n\n\n\n\n\nGrammar Simplification\n\ndelete productions like P→PP\\rightarrow PP→P\ndelete productions who can not be used in the derivations\ndelete productions who can not derive a terminal string\n\n\nConstruct context-free grammar without ε-production\n\nit should follow conditions as followings\n\nIf there is the production S→ε of the form in P, S should not appear in right-side of any production, where S is the start symbol of the grammar;\nThere are no other ε-productions in P\n\n\nHow to construct\n\nG=(VN,VT,P,S)→G′=(VN′,VT′,P′,S′)G=(V_N,V_T,P,S)\\rightarrow G&#x27;=(V&#x27;_N,V&#x27;_T,P&#x27;,S&#x27;)G=(VN​,VT​,P,S)→G′=(VN′​,VT′​,P′,S′)\nfind out all non-terminal symbols that can derive ε after some steps, and put them into the set V0V_0V0​\nconstruct the P’s set of productions of G’ as following steps:\n\n\nIf an symbol in V0V_0V0​ appears in the right side of a production, change the production into two production respectively; put the new productions into P\nput the productions relating to the symbol into P’ except for ε-production relating to the symbol\nif there exists the production of the form S→εS\\rightarrow \\varepsilonS→ε in P,change the production into S’→ε∣SS’\\rightarrow \\varepsilon |SS’→ε∣S and put them into  P’P’P’,let S’S’S’ be the start symbol of G’G’G’, let V’N=VN∪{S′}V’_N=V_N\\cup \\{S&#x27;\\}V’N​=VN​∪{S′}\n\n\n\n\nSyntax tree and ambiguity of a grammar\n\nBasic terms in a syntax tree\n\nSub-tree\nPruning sub-tree\nSentential form\n\n\n\n\n\n Chapter 3 Lexical analysis\n Approaches to implement a lexical analyzer\n\n\nSimple approach\n\n\nConstruct a diagram that illustrates the structure of the tokens of the source language , and then to hand-translate the diagram into a program for finding tokens\n\nEfficient lexical analyzers can be produced in this manner\n\n\n\n\n\nPattern-directed programming approach\n\n\nPattern Matching technique\n\n\nSpecify and design program that execute actions triggered by patterns in strings\n\n\nIntroduce a pattern-action language called Lex for specifying lexical analyzers\n\nPatterns are specified by regular expressions\n\n\n\n\n\n\nA compiler for Lex can generate an efficient finite automation recognizer for the regular expressions\n\n The role of the lexical analyzer\n\n\nFirst phase of a compiler\n\n\nMain task\n\nTo read the input characters\nTo produce a sequence of tokens used by the parser for syntax analysis\nAs an assistant of parser\n\n\n\nInteraction of lexical analyzer with parser\n\n\n\n\n\n\n\n、Processes in lexical analyzers\n*　Scanning\n*　Pre-processing\n* Strip out comments and white space\n* Macro functions\n*　Correlating error messages from compiler with source program\n*　A line number can be associated with an error message\n*　Lexical analysis\n\n\nTerms of the lexical analyzer\n\nToken\n\nTypes of words in source program\nKeywords, operators, identifiers, constants, literal strings, punctuation symbols(such as commas,semicolons)\n\n\nLexeme\n\nActual words in source program\n\n\nPattern\n\nA rule describing the set of lexemes that can represent a particular token in source program\nRelation {&lt;.&lt;=,&gt;,&gt;=,==,&lt;&gt;}\n\n\n\n\n\nAttributes for Token\n\nA pointer to the symbol-table entry in which the information about the token is kept\n\n\nE.g E=M*C**2\n\n&lt;id, pointer to symbol-table entry for E&gt;\n&lt;assign_op,&gt;\n&lt;id, pointer to symbol-table entry for M&gt;\n&lt;multi_op,&gt;\n&lt;id, pointer to symbol-table entry for C&gt;\n&lt;exp_op,&gt;\n&lt;num,integer value 2&gt;\n\n\nLexical Errors\n\nDeleting an extraneous character\nInserting a missing character\nReplacing an incorrect character by a correct character\nTransposing two adjacent characters(such as , fi=&gt;if)\nPre-scanning\n\n\n\nInput Buffering\n\nTwo-buffer input scheme to look ahead on the input and identify tokens\nBuffer pairs\nSentinels(Guards)\n\n\n\n Specification of tokens\n\nRegular definition of tokens\n\nregular expression (RE)\n\n\nregular languageL(r)\nrule of regular expression over alphabet Σ\\SigmaΣ\n\nε→{ε}\\varepsilon \\rightarrow \\{\\varepsilon \\}ε→{ε}\nα∣β\\alpha|\\betaα∣β\nαβ\\alpha \\betaαβ\nα∗\\alpha*α∗\nα+\\alpha+α+\nα?\\alpha ?α?\n[a−z][a-z][a−z]\n\n\n\n Recognition of tokens\n\n\ntask of recognition of token in a lexical analyzer\n\n\nIsolate the lexeme for the next token in the input buffer\n\n\nproduce output pair like &lt;id,pointer to table entry&gt;\n\nA example translation table\n\n\n\nRE\nToken\nAttribute-value\n\n\n\n\nif\nif\n-\n\n\nid\nid\nPointer to table entry\n\n\n&lt;\nrelop\nLT\n\n\n\n\n\n\nmethod to recognition of token\n\n\n\n\nTransition diagram(Stylized flowchart)\n\n\neach state gets a segment of code\nuse nextchar() to read a character and move to next state\n\n\n\n\n\nFA ( Finite Automation )\n\n\nDeterministic or non-deterministic FA\n\nＮFA contains more than one transition out of a state may possible on the same input symbol while DFA not.\n\n\n\nDFA\n\n\nquintuple M(S,Σ,move,s0,F)M(S,\\Sigma,move,s_0,F)M(S,Σ,move,s0​,F)\n\n\nSSS: a set of states\n\n\nΣ\\SigmaΣ: the input symbol alphabet\n\n\nmovemovemove: a transition function, mapping from S×ΣS\\times \\SigmaS×Σ to SSS, move(s,a)=S’move(s,a)=S’move(s,a)=S’\n\n\ns0s_0s0​: the start state\n\n\nFFF: a set of states FFF distinguished as accepting states\n\nF⊆S,s0∈SF\\subseteq S,s_0 \\in SF⊆S,s0​∈S\n\n\n\n\n\nnote\n\nno state has an ε\\varepsilonε\nfor each state s and input symbol a, there is at most one edge labeled a leaving s\ntransition graph are used to describe a FA\nA DFA accepts an input string x if and only if there is some path in the transition graph from start state to some accepting state\n\n\n\n\n\nNFA\n\n\nquintuple M(S,Σ,move,s0,F)M(S,\\Sigma,move,s_0,F)M(S,Σ,move,s0​,F)\n\n\nSSS: a set of states\n\n\nΣ\\SigmaΣ: the input symbol alphabet\n\n\nmovemovemove: a transition function, mapping from S×ΣS\\times \\SigmaS×Σ to SSS, move(s,a)=2Smove(s,a)=2^Smove(s,a)=2S\n\n\ns0s_0s0​: the start state\n\n\nFFF: a set of states FFF distinguished as accepting states\n\n2S⊆S,F⊆S,s0∈S2^S\\subseteq S, F\\subseteq S,s_0 \\in S2S⊆S,F⊆S,s0​∈S\n\n\n\n\n\nnote\n\nϵ\\epsilonϵ is a legal input symbol\n\n\n\n\n\nConvert of an NFA to a DFA\n\navoid ambiguity\n\n\n\nObtain ε-closure(T)\n\n\npush all states in T onto stack\n\n\ninitialize ε-closure(T) to T;\n\nwhile stack is not empty do{\n​\tpop the top element of the stack into t;\n​\tfor each state u with an edge from t to u labeled ε do{\n​\t\tif u is not in ε-closure(T){\n​\t\t\tadd u to ε-closure(T)\n​\t\t\tpush u into stack\n​\t\t}\n​\t}\n}\n\n\n\nInput\n\n\nNFA $N = (S,\\Sigma,move,S_0,Z)$\n\n\n\nOutput\n\n\nDFA $D = (Q,\\Sigma,\\delta,I_0,F)$\n\n\n\n\n\nSubset construciton\n\n\n\nI0=ϵ−clousure(S0),I0∈QI_0 = \\epsilon-clousure(S_0),I_0\\in QI0​=ϵ−clousure(S0​),I0​∈Q\n\n\nforeach\\ I_i,I_i \\in Q \\\n\\ let I_t = \\epsilon-clousure(move(I_i,a) \\\n\\ if\\ I_t\\notin Q\\ then\\ put\\ I_t\\ into Q\n\n\n\nrepeat step2 until there is no new state to put into QQQ\n\n\nletF={I∣I∈Q,I∩Z&lt;&gt;Φ}let F = \\{I|I\\in Q,I \\cap Z&lt;&gt;\\Phi\\}letF={I∣I∈Q,I∩Z&lt;&gt;Φ}\n\n\n\n\n\n\nminimizing the number of states of a DNA\n\n\nInput\n\nDFA M={S,Σ,move,s0,F}M = \\{S,\\Sigma,move,s_0,F\\}M={S,Σ,move,s0​,F}\n\n\n\nOutput\n\nDFA M′M&#x27;M′ accepting the same language as M and having as few states as possible\n\n\n\nAlgorithm\n\nConstruct an initial partition ∏ of the set of states with two groups: the accepting states F and the non-accepting states S-F. ∏0＝{I01,I02}\nFor each group I of ∏**i ,partition I into subgroups such that two states s and t of I are in the same subgroup if and only if for all input symbols a, states s and t have transitions on a to states in the same group of ∏**i ; replace I in *∏**i+1_*by the set of subgroups formed.\nIf ∏**i+1 =∏**i ,let ∏**final =∏**i+1 and continue with step (4). Otherwise,repeat step (2) with ∏**i+1\nChoose one state in each group of the partition ∏**final as the representative for that group. The representatives will be the states of the reduced DFA M’. Let s and t be representative states for s’s and t’s group respectively, and suppose on input a there is a transition of M from s to t. Then M’ has a transition from s to t on a.\nIf M’ has a dead state(a state that is not accepting and that has transitions to itself on all input symbols),then remove it. Also remove any states not reachable from the start state.\n\n\n\n\n\n\n\n\n\nRE to NFA\n\nMethod\n\nParse r into its constituent sub-expressions\nε\n\n\n\n\na∈Σa\\in \\Sigmaa∈Σ\n\n\n\n\n\n\n\n\n\n\nFA to RE\n\n\nRegular Grammar to NFA (Right linear grammar to FA)\n\n\nInput G=(VN,VT,P,S)G = (V_N,V_T,P,S)G=(VN​,VT​,P,S)\n\n\nOutput FA M=(Q,Σ,move,q0,Z)M = (Q,\\Sigma,move,q_0,Z)M=(Q,Σ,move,q0​,Z)\n\n\nMethod\n\nConsider each non-terminal symbol in G as a state, and add a new state T as an accepting state.\nLet Q=VN∪{T},S＝VT,q0＝SQ=V_N\\cup\\{T\\} , S ＝ V_T , q_0 ＝SQ=VN​∪{T},S＝VT​,q0​＝S; if there is the production S→εS\\rightarrow \\varepsilonS→ε, then Z={S,T},elseZ={T}Z=\\{S,T\\}, else Z=\\{T\\}Z={S,T},elseZ={T}\nFor the productions similar as A1 → aA2，construct move(A1,a)= A2\nFor the productions similar as A1 → a, construct move(A1,a)= T\nFor each a in Σ, move(T,a)=ψ, that means the accepting states do not recognize any terminal symbol.\n\n\n\n\n\n\n\nFA to Right-linear grammar\n\nInput M=(S,Σ,f,s0,Z)M=(S,\\Sigma,f,s_0,Z)M=(S,Σ,f,s0​,Z)\nOutput Rg=(VN,VT,P,s0)R_g = (V_N,V_T,P,s_0)Rg​=(VN​,VT​,P,s0​)\nMethod\n\nif s0∉Zs_0\\notin Zs0​∈/​Z\n\nFor the mapping f(Ai,a)=Ajf(A_i,a)=A_jf(Ai​,a)=Aj​ in M Ai→aAjA_i\\rightarrow aA_jAi​→aAj​\n\n\nif s0∈Zs_0\\in Zs0​∈Z\n\nadd a new production Ai→aA_i\\rightarrow aAi​→a,Ai=→a∣aAjA_i=\\rightarrow a|aA_jAi​=→a∣aAj​\n\n\n\n\n\n\n\n\n\n design of a lexical analyzer generator\n\n\n\nLex specification\n\ndeclaration\ntranslation rules\nauxiliary procedures\n\n\n\nDeclaration\n12345678910%&#123;   /*definitions of manifest constants LT,LE,EQ,GT,GE,IF,THEN,ELSE,ID*/  %&#125;/*regular expression*/  delim [\\t\\n]ws   &#123;delim&#125;+  letter  [A-Za-z]digit  [0-9]    id    &#123;letter&#125;(&#123;letter&#125;|&#123;digit&#125;)*\n\n\nmodel\n\n\n\n Chapter 4 Syntax analysis\n approaches to implement a syntax analyzer\n roles of the parser\n\n\nmain task\n\nObtain a string of tokens from the lexical analyzer\nVerify that the string can be generated by the grammar of related programming language\nReport any syntax errors in an intelligible fashion\nRecover from commonly occurring errors so that it can continue processing the remainder of its input\n\n\n\nposition\n\n\n\nmethods\n\nuniversal parsing method\ntop-down method\n\nBuild parse trees from the top(root) to the bottom(leaves)\nThe input is scanned from left to right\nLL(1) grammars (often implemented by hand)\n\n\nbottom-up method\n\nStart from the leaves and work up to the root\nThe input is scanned from left to right\nLR grammars(often constructed by automated tools)\n\n\n\n\n\nSyntax error handling\n\nerror levels\nsimple-to-state goals of the error handler\nerror-recovery strategies\n\npanic mode\nphrase level\n\n\nerror-recovery strategies\n\n\n\n top-down parsing\n\n\nideas\n\nFind a leftmost derivation for an input string\nConstruct a parse tree for the input starting from the root and creating the nodes of the parse tree in preorder\n\n\n\nmain methods\n\nPredictive parsing (no backtracking)*\nRecursive descent (involve backtracking)\n\n\n\nleft recursion\n\n\nImmediate recursion P→Pα∣βP\\rightarrow P\\alpha|\\betaP→Pα∣β\n\n\nIndirect recursion P→Aa,A→PbP\\rightarrow Aa,A\\rightarrow PbP→Aa,A→Pb\n\n\nsolve\n\nconvert left recursion to right recursion\n\n\n\nP\\rightarrow P\\alpha|\\beta \\\nP\\rightarrow \\beta\\alpha* \\\nP\\rightarrow \\beta P&#039;\\\nP&#039;\\rightarrow \\alpha P&#039;|\\varepsilon\n\n\n\n\neliminating ambiguity of a grammar\n\nrewriting the grammar\n\nstmt→if expr then stmt|if expr then stmt else stmt|other\nstmt→matched-stmt|unmatched-stmt\nmatched-stmt→if expr then matched-stmt else matched-stmt|other\nunmatched-stmt→if expr then stmt|if expr then matched-stmt else unmatched-stmt\n\n\n\n\n\nLeft factoring\n\nrewrite the production to defer the decision until we have seen enough of the input to make right choice\nA→δβ1∣δβ2∣δ⋅⋅⋅βnA\\rightarrow \\delta \\beta_1|\\delta \\beta_2|\\delta \\cdot\\cdot\\cdot \\beta_nA→δβ1​∣δβ2​∣δ⋅⋅⋅βn​\nA→δA′,A′→β1∣beta2∣⋅⋅⋅∣βnA\\rightarrow \\delta A&#x27;,A&#x27;\\rightarrow \\beta_1|beta_2|\\cdot\\cdot\\cdot|\\beta_nA→δA′,A′→β1​∣beta2​∣⋅⋅⋅∣βn​\n\n\n\npredictive parsers methods\n\nTransition diagram based predictive parser\nNon-recursive predictive parser\n\n\n\ntransition diagram based predictive parsers\n\ntransition diagram\n\ncreate an initial and final state\nfor each production A→X1X2...XnA\\rightarrow X_1X_2...X_nA→X1​X2​...Xn​,create a path from initial to the final state,with edge labeled X1,X2,...,XnX_1,X_2,...,X_nX1​,X2​,...,Xn​\n\n\n\n\n\nnon-recursive predictive parsing\n\n\nthe determining the production to be applied for a non-terminal\n\n\ntable-driven and use stack\n\n\n\npredictive parsing program\n\nX: the symbol on top of the stack\na: the current input symbol\nIf X=a=$, the parser halts and announces successful completion of parsing\nIf X=a!=$, the parser pops X off the stack and advances the input pointer to the next input symbol\nIf X is a non-terminal, the program consults entry M[X,a] of the parsing table M. This entry will be either an X-production of the grammar or an error entry.\n\n\n\nFirst\n\n\nIf a is any string of grammar symbols, let FIRST(a) be the set of terminals that begin the string derived from a\n\n\nIf a→e, then e is also in FIRST(a)\n\n\nα∈V∗,First(α)={a∣α→a....,a∈VT}\\alpha\\in V^*,First(\\alpha) = \\{a|\\alpha \\rightarrow a....,a\\in V_T\\}α∈V∗,First(α)={a∣α→a....,a∈VT​}\n\n\nCompute\n\n\nIf x is terminal,then First(x)={x}\n\n\nIf x→ε, add ε to First(x)\n\n\nIf x in non-terminal, and X→Y1Y2…Yk,Yj∈(VN∪VT),1≤j≤k,then\n123456789&#123;     j=1; FIRST(X)=&#123;&#125;; //initiate        while ( j&lt;k and ε∈ FIRST(Yj)) &#123;            FIRST(X)=FIRST(X)∪(FIRST(Yj)-&#123;ε&#125;)           j=j+1       &#125;       IF (j=k and ε∈ FIRST(Yk))            FIRST(X)=FIRST(X) ∪ &#123;ε&#125;   &#125;\n\n\n\n\n\n\nFollow\n\nFor non-terminal A, to be the set of terminals a that can appear immediately to the right of A in some sentential form.\nFollow(A)={a∣S→...Aa...,a∈VT}Follow(A) = \\{a|S\\rightarrow ...Aa...,a\\in V_T\\}Follow(A)={a∣S→...Aa...,a∈VT​}\nIf S→...A,then $∈Follow(A)S\\rightarrow ...A,then\\ \\$\\in Follow(A)S→...A,then $∈Follow(A)\nCompute\n\nPlace $ in FOLLOW(S), where S is the start symbol and ​$ is the input right end-marker\nIf there is A→aBb in G, then add (First(b)-ε) to Follow(B)\nIf there is A→aB, or A→aBb where FIRST(b) contains ε，then add Follow(A) to Follow(B).\n\n\n\n\n\nPPT ( Predictive Parsing Tables )\n\nInput Grammar G\nOutput Parsing table M\nmethod\n\nFor each production A→a , do steps 2 and 3\nFor each terminal a in FIRST(a), add A→a to M[A,a]\nIf ε is in FIRST(a), add A→a to M[A,b] for each terminal b in FOLLOW(A). If e is in FIRST(a) and $ is in FOLLOW(A), add A→a to M[A,$]Make each undefined entry of M be error.\nMake each undefined entry of M be error.\n\n\n\n\n\n\n\n\n\n\nLL(1) Grammars\n\n\nDefinition\n\n\nA grammar whose parsing table has no multiply-defined entries is said to be LL(1)\n\n\nThe first “L” stands for scanning the input from left to right\n\n\nThe second “L” stands for producing a leftmost derivation\n\n\n“1” means using one input symbol of look-ahead\n\ns.t each step to make parsing action decisions.\n\n\n\nNote\n\nNo ambiguous can be LL(1)\nLeft-recursive grammar cannot be LL(1)\nA grammar G is LL(1) if and only if whenever A→a | b are two distinct productions of G\n\n\n\n\n\ntransform a grammar to LL(1) grammar\n\nEliminating all left recursion\nLeft factoring\n\n\n\n\n\n bottom-up parsing\n\n\nShift-reduce parsing\n\n\nhandles\n\n\nhandle pruning\n\n\n\nDefinition of operator grammar\n\nThe grammar has the property that no production right side is e or has two adjacent non-terminals\n\n\n\n\n\nLR parsing\n\n\nAn efficient, bottom-up syntax analysis technique that can be used to parse a large class of context-free grammars\n\n\nLR(K)\n\nL: left-to-right scan\nR:construct a rightmost derivation in reverse\nk:the number of input symbols of look ahead\n\n\n\nadvantages\n\nIt can recognize virtually all programming language constructs for which context-free grammars can be written\nIt is the most general non backtracking shift-reduce parsing method\nIt can parse more grammars than predictive parsers can\nIt can detect a syntactic error as soon as it is possible to do so on a left-to-right scan of the input\n\n\n\nSLR\n\nSimple LR\n\n\n\nLR(1)\n\ncanonical LR\n\n\n\nLRLR\n\n\nlook ahead LR\n\n\n\n\n\nnote\n\nThe driver program is the same for all LR parsers; only the parsing table changes from one parser to another\nThe parsing program reads characters from an input buffer one at a time\nSi is a state, each state symbol summarizes the information contained in the stack below it\nEach state symbol summarizes the information contained in the stack\nThe current input symbol are used to index the parsing table and determine the shift-reduce parsing decision\nIn an implementation, the grammar symbols need not appear on the stack\n\n\n\nParsing table\n\nAction\n\nAction[S,a]: S represent the state currently on top of the stack, and a represent the current input symbol. So Action[S,a] means the parsing action for S and a\nShift\n\nThe next input symbol is shifted onto the top of the stack\nShift S, where S is a state\n\n\nReduce\n\nThe parser knows the right end of the handle is at the top of the stack, locates the left end of the handle within the stack and decides what non-terminal to replace the handle. Reduce by a grammar production A→a\n\n\nAccept\n\nThe parser announces successful completion of parsing\n\n\nError\n\nThe parser discovers that a syntax error has occurred and calls an error recovery routine.\n\n\n\n\nAction conflict\n\nShift/reduce conflict\n\nCannot decide whether to shift or to reduce\n\n\nReduce/reduce conflict\n\nCannot decide which of several reductions to make\n\n\n\n\nGoto\n\na goto function that takes a state and grammar symbol as arguments and produces a state\n\n\n\n\n\nAlgorithm\n\nThe next move of the parser is determined by reading the current input symbol a, and the state S on top of the stack,and then consulting the parsing action table entry action[S,a].\nIf action[Sm,ai]=shift S,the parser executes a shift move ,enter the S into the stack,and the next input symbol ai+1 become the current symbol.\nIf action[Sm,ai]=reduce A→a, then the parser executes a reduce move. If the length of a is g, then delete g states from the stack, so that the state at the top of the stack is Sm- g . Push the state S’=GOTO[Sm- g,A] and non-terminal A into the stack. The input symbol does not change.\nIf action[Sm*,ai]*=accept, parsing is completed.\nIf action[Sm*,ai]*=error, the parser has discovered an error and calls an error recovery routine.\n\n\n\nSj   means shift and stack state j, and the top of the stack change into（j,a）\n\n\nrj   means reduce by production numbered j\n\n\nAccept  means accept\n\n\nblank    means error\n\n\n\n\n\n\n\n\nCanonical LR(0)\n\n\nAn LR(0) item of a grammar G is a production of G with a dot at some position of the right side\n\n\n•Such as: A → XYZ yields the four items:\n–A→•XYZ . We hope to see a string derivable from XYZ next on the input.\n–A→X•YZ . We have just seen on the input a string derivable from X and that we hope next to see a string derivable from YZ next on the input.\n–A→XY•Z\n–A→X YZ•\n\n\n•The production A®e generates only one item, A®•.\n\n\n•Each of this item is a viable prefixes\n\n\n\n\nConstruct LR(0) collection\n\n\nDefine a augmented grammar\n\n\nIf G is a grammar with start symbol S,the augmented grammar G’ is G with a new start symbol S’, and production S’ ®S\n•The purpose of the augmented grammar is to indicate to the parser when it should stop parsing and announce acceptance of the input\n\n\n\n\nthe Closure Operation\n\n•If I is a set of items for a grammar G, then closure(I) is the set of items constructed from I by the two rules:\n\n\n\nthe Goto Operation\n\n•Form: goto(I,X),I is a set of items and X is a grammar symbol\n\n\n\n\n\nThe Sets-of-Items Construction\n12345678void ITEMSETS-LR0()&#123;    C:=&#123;CLOSURE(S` →•S)&#125;      /*initial*/      do   &#123;  for (each set of items I in C and each grammar symbol X )        IF  (Goto(I,X) is not empty and not in C)            &#123;add Goto(I,X) to C&#125;   &#125;while  C is still extending&#125;\n\n\n\n\n\n\n\nSLR(1) Parsing Table Algorithm\n\nInput. An augmented grammar G\nOutput. The SLR parsing table functions action and goto for G`\nMethod.\n\nConstruct C={I0,I1,…In}, the collection of sets of LR(0) items for G`.\nState i is constructed from Ii. The parsing actions for state i are determined as follows:\n\nIf [A®a•ab] is in Ii and goto(Ii,a)= Ij, then set ACTION[i,a]=“Shift j”, here a must be a terminal.\nIf [A®a• ]ÎIk, then set ACTION[k,a]=rj for all a in follow(A); here A may not be S`, and j is the No. of production A®a .\n\n\nThe goto transitions for state I are constructed for all non terminals A using the rule: if goto (Ii,A)= Ij, then goto[i,A]=j\nAll entries not defined by rules 2 and 3 are made “error”\nThe initial state of the parser is the one constructed from the set of items containing [S` ® S•].\nIf any conflicting actions are generated by the above rules, we say the grammar is not SLR(1).\n\n\n\nEvery SLR(1) grammar is unambiguous, but there are many unambiguous grammars that are not SLR(1).\n\n\n\n\n\nConstruction of the sets of LR(1) items\n\n\nInput. An augmented grammar G\n\n\nOutput. The sets of LR(1) items that are the set of items valid for one or more viable prefixes of G`\n\n\nMethod. The procedures closure and goto and the main routine items for constructing the sets of items.\n123456789101112131415161718192021function closure(I);&#123; do &#123; for (each item (A→α•Bβ,a) in I,                 each production B → γ in G`,                 and each terminal b in FIRST(βa)                 such that (B→• γ ,b) is not in I  )            add (B→• γ ,b) to I;         &#125;while there is still new items add to I;    return I&#125;function  goto(I,X);&#123; let J be the set of items (A→αX•β,a) such that (A→α• X β,a) is in I ;    return closure(J)&#125;Void items (G`);&#123;C=&#123;closure(&#123; (S`→•S,$)&#125;)&#125;;  do &#123; for (each set of items I in C and each grammar symbol X          such that              goto(I,X) is not empty and not in C )           add goto(I,X) to C        &#125; while there is still new items add to C;  &#125;\n//TODO page 155.\n\n\n\n\n LR parsers\n🚧under construction🚧\n12","plink":"ilucia.github.io/Review/CompilationPrinciple/"},{"title":"Jupyter和conda协同工作环境搭建和常见错误处理","date":"2019-10-03T00:00:00.000Z","updated":"2022-04-27T15:24:01.731Z","content":" 避坑安装方法\n\n如果您还没有安装jupyter notebook，那么按照如下方法可以让jupyter和conda协同工作\n\n123456# 在base环境下# 安装jupyter本体pip install jupyter# 安装nb_jupyterpip install nb_conda# 完成\n\n好啦，开始使用就完事辣~\n\n 关于其他方法安装导致故障的原因和修复\n 方法a\n\n\n安装ipykernel：\n1conda install ipykernel\n\n\n在虚拟环境下创建kernel文件：\n1conda install -n [环境名] ipykernel\n\n\n激活conda环境：\n1source activate [环境名]\n\n\n将环境写入notebook的kernel中\n  1python -m ipykernel install --user --name[环境名] --display-name &quot;[显示名])&quot;\n\n\n Fix\n环境配置列表在%userprofile%\\Appdata\\Roaming\\jupyter\\kernels\\[环境名]\\kernel.json下，手动修正即可\n 调试思路\nconda的工作就是更换环境变量，可以使用sys.path查看conda是否正常工作\n","plink":"ilucia.github.io/python/jupyter/"},{"title":"共享Jupyter notebook环境","date":"2019-10-02T00:00:00.000Z","updated":"2022-04-27T15:24:01.731Z","content":"\n\n生成配置文件\n 1jupyter notebook --generate-config\n\n\n生成密码\n12345In [1]: from notebook.auth import passwdIn [2]: passwd()Enter password: Verify password: Out[2]: &apos;sha1:***************************************************&apos;\n\n\n修改config文件\n1/[user]/.jupyter/jupyter_notebook_config.py\n1234c.NotebookApp.ip=&apos;*&apos;\t# allow all networkc.NotebookApp.password = u&apos;sha:******************&apos;c.NotebookApp.open_browser = Falsec.NotebookApp.port =8888 #port to share\n\n\n启动\n1jupyter notebook\n\n\n","plink":"ilucia.github.io/python/jupyterShare/"},{"title":"非标准数据简单网格化的一种方法","date":"2019-07-22T00:00:00.000Z","updated":"2022-04-27T15:24:01.579Z","content":" 场景概述\n有些时候为了让坐标数据可视化，当我们有需要绘制等高线图之类的场景时，我们需要根据现有的分布不规则的数据点映射到网格点上，比如我们有如下坐标点，每个坐标点都有自己的价格属性，我们需要画一张价格位于地理位置的分布图。此处的不同颜色点是因为做了k-means聚类分析，与本话题无关暂且不表，之前有讨论如何做简单的k-means聚类分析。根据聚类的价格分布，我们最终得到一张地形图如下，具体操作方法见下文。\n\n 一般方法\n此处使用的方法借鉴了地理方向GIS系统绘制等高线地形图的一种较为简单的实现的方案。在若干坐标点中，必定能找到包裹每个网格点的最小三角形（mesh）是待赋值的网格点，pointA，B，C是既有不规则坐标点。对坐标点mesh的高度（价格）赋值我们可以从A，B，C三点中赋值，此处为了简化计算，我的赋值策略是按mesh点到各个point的距离倒数的加权赋值\nHeightmesh=ρA×HeightA+ρB×HeightB+ρC×HeightCHeight_{mesh} = \\rho_A\\times Height_A+ \\rho_B\\times Height_B+ \\rho_C\\times Height_C\nHeightmesh​=ρA​×HeightA​+ρB​×HeightB​+ρC​×HeightC​\nρA=1distance(mesh,A)×K\\rho_A = \\frac{1}{distance(mesh,A)\\times K}\nρA​=distance(mesh,A)×K1​\nρB,ρC\\rho_B,\\rho_CρB​,ρC​同理\nK=1distance(mesh,A)+1distance(mesh,B)+1distance(mesh,C)K=\\frac{1}{distance(mesh,A)}+\\frac{1}{distance(mesh,B)}+\\frac{1}{distance(mesh,C)}\nK=distance(mesh,A)1​+distance(mesh,B)1​+distance(mesh,C)1​\n 具体实现\n相关实现如下，（非相关其他文件未给出）\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687# countour.py# 等高线绘制from core import constimport osimport reimport sysfrom json import loadsimport matplotlib.pyplot as pltimport numpy as npsys.path.append('.\\\\')def pri(x, y, points: dict):    '''    - x,y is the position of the mesh point    - points is a list of the nearest three data points    '''    minList = list()    for i in points:        if i is not None:            dis = (i['E'] - x) ** 2 + (i['N'] - y) ** 2            if len(minList) &lt; 3:                minList.append([dis, i])                continue            if dis &lt; max([x[0] for x in minList]):                minList.sort(key=lambda x: x[0])                del (minList[-1])                minList.append([dis, i])    pri = 0    for i in minList:        pri += i[1]['price'] / i[0] / sum([1 / x[0] for x in minList])    return pridef draw(points: dict):    delta = 0.02    x = np.arange(        const.LONGITUDE_LOWER,        const.LONGITUDE_UPPER,        delta    )    y = np.arange(        const.LATITUDE_LOWER,        const.LATITUDE_UPPER,        delta    )    X, Y = np.meshgrid(x, y)    row = list()    for j in y:        line = list()        for i in x:            line.append(pri(i, j, points))        row.append(line)    Z = np.array(row)    fig, ax = plt.subplots()    CS = ax.contour(X, Y, Z, 20)    ax.clabel(CS, inline=True)    ax.contourf(X, Y, Z, 100, cmap=plt.cm.jet)    ax.set_title('contour for %d centers' % len(points))    fileName = os.path.join(        const.OUTPUT_PATH, 'P01contour%d.jpg' % len(points))    plt.savefig(fileName)if __name__ == '__main__':    for folder, subFolder, fileNameList in os.walk(const.OUTPUT_PATH):        if folder == const.OUTPUT_PATH:            for fileName in fileNameList:                # 匹配坐标文件                if re.match('^P01point\\d+\\.json$', fileName):                    f = os.path.join(folder, fileName)                    print(f)                    with open(f, 'r') as w:                        f = w.read()                    rawData = loads(f)                    for key, item in enumerate(rawData):                        if item is not None:                            rawData[key] = &#123;                                'price': sum([x['no'] for x in item]) /                                len([x['no']for x in item]),                                'E': item[0]['E'],                                'N': item[0]['N']                            &#125;                    draw(rawData)\n","plink":"ilucia.github.io/Others/positionMesher/"},{"title":"提升Powershell使用体验","date":"2019-07-17T00:00:00.000Z","updated":"2022-04-27T15:24:01.763Z","content":" 终端（Terminal）推荐\n Windows Terminal\nGitHub地址：https://github.com/microsoft/terminal\n\n主题推荐 GitHub地址：https://github.com/mbadolato/iTerm2-Color-Schemes/tree/master/windowsterminal\n笔者自己配的主题：https://github.com/HanyuuLu/toolbox/tree/master/poshTheme\n\n Fluent Terminal\nGitHub地址：https://github.com/felixse/FluentTerminal\n Cmder\nGitHub地址：https://github.com/cmderdev/cmder\n PowerShell 美化\n oh-my-posh\n 安装\n\n若您从未更改过powershell的执行权限（或者不知道此物为何物），则需要更改powershell的执行权限以运行脚本\n需要管理员权限\n\n1Set-ExecutionPolicy Bypass\n\n安装posh-git\n\n1Install-Module posh-git -Scope CurrentUser\n\n安装oh-my-posh本体\n\n1Install-Module oh-my-posh -Scope CurrentUser\n 启用\n 手动启动\n12Import-Module oh-my-posh    # 导入模块Set-Theme Paradox   # 使用Paradox主题\n 伴随powershell自启\n如果profile指向的文件存在，则powershell启动时会顺带启动profile指向的文件存在，则powershell启动时会顺带启动profile指向的文件存在，则powershell启动时会顺带启动profile指向的脚本，所以我们将上述语句写入该文件中\n123New-Item $PROFILE -Type File    # 创建文件，若提示文件已存在则可以直接编辑文件\"Import-Module oh-my-posh    # 导入模块\" &gt;&gt; $PROFILE\"Set-Theme Paradox   # 使用Paradox主题\" &gt;&gt; $PROFILE\n 字体更换\n 更纱黑体\n常规字体是没有办法完全显示oh-my-posh的powerline字符的，因此我们需要一种好看的powerline字符\n\n笔者在此安利Sarasa Gothic / 更纱黑体 / 更紗黑體 / 更紗ゴシック\n微软应用商店下载\nGithub Release下载\n\n 字体更换简介\n建议在以下位置更换使用 Sarasa Term SC 字体（Term为终端字体，SC为简体中文，其他简写请参考应用商店或github readme说明）\n\ncmd\npowershell\nFluent Terminal\nWindows Terminal\nvsCode （编辑器和内置终端）\nVisual Studio\n其他可能使用到终端或者编辑代码的位置\n\n","plink":"ilucia.github.io/windows/oh-my-posh/"},{"title":"简单的k-means实践","date":"2019-07-15T00:00:00.000Z","updated":"2022-04-27T15:24:01.559Z","content":"\n本文来自于笔者在肝数模过程中的亲身实践，如果仅仅是了解可以直接观看，如果想要复现可以戳实践环境获得开发环境（处于安全考虑，在2019年国赛打完之前此链接的仓库为private，请谅解）\n\n 场景概述\n笔者需要对一个excel数据表中的记录（含有经纬度信息），表格字段如下\n\n\n\nA\nB\nC\nD\nE\n\n\n\n\n任务号码\n任务gps纬度\n任务gps经度\n任务标价\n任务执行情况\n\n\n\n我们现在需要将字段B和C中的经纬度提取为坐标并将这些坐标分类，在这里我们使用k-means方法来大致观察坐标并分类（手动实现没用轮子.jpg）\n 实验环境\n\npython 3(笔者使用python 3.6)\n\n 基本原理\n k-means\nk-means的大致思路\n\n在数据集中随机挑选x个数据作为中心点（x为聚类数量）；\n每个数据挑选最近的中心点，围绕这个中心点的所有数据点成为一个聚类。（此处我们的距离使用欧氏距离）；\n完成！\n\n 一些不尽如人意的地方和问题\n\n数据集本身位置，事先未必能较为准确的预估聚类的个数（甚至大致范围也难以确定）；\n由于挑选聚类是随机的，可能这些点选择的不尽人意。\n如何评估随机生成的聚类中心的质量？\n\n 成果预览\n\nP.S. 此处展示了聚类为3的输出，地图是后期通过其他方式贴合上去的，至于贴合方法……有缘更新吧……\n\n\n\n 解决方案&amp;实现\n 聚类逻辑代码\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151from math import sqrtfrom random import randint, randomimport matplotlib.pyplot as pltfrom dataReader import dataReaderclass Classifier:    # 初始化、读入数据库、标定数据范围    def __init__(self):        # 原始数据        self.rawData = dataReader()[0]        # 下标下限        self.LOWER_LIMIT = 0        # 下标上限        self.UPPER_LIMIT = len(self.rawData) - 1    # 产生一组不重复的随机中心    def generateRandomCenter(self, typeCount: int):        # 随机中心（聚类）数        self.typeCount = typeCount        # 随机中心编号列表        self.coreList = list()        while len(self.coreList) &lt; self.typeCount:            key = randint(self.LOWER_LIMIT, self.UPPER_LIMIT)            if key in self.coreList:                continue            self.coreList.append(key)        # print('[center]%s' % str(self.coreList))    # 聚类计算    def calc(self):        # 聚类列表        self.classList = [list() for _ in range(self.typeCount)]        for i in self.rawData:            key = float('inf')            ptr = -1            for j in self.coreList:                distance = dis(i, self.rawData[j])                if key &gt; distance:                    ptr = self.coreList.index(j)                    key = distance            self.classList[ptr].append(i)        # print('[info] calc finished 😂')    # 绘制聚类图    def draw(self):        plt.rcParams['font.sans-serif'] = ['SimHei']        plt.rcParams['axes.unicode_minus'] = False        plt.figure(figsize=(30, 20), dpi=100)        plt.xlim(112, 115)        plt.ylim(22, 24)        plt.xlabel('经度/°E')        plt.ylabel('纬度/°N')        plt.title(            '%d centers with average distance %.4f'            % (self.typeCount, self.totalAverage)        )        # print(str(self.coreList))        handerList = list()        for i in self.classList:            col = (random(), random(), random())            handerList.append(                plt.plot([x[2] for x in i], [x[1] for x in i],                     'x', color=col)            )        # plt.text(112.74, 23.8, str(self.coreList), ha='left', fontsize=8)        plt.legend(self.coreList)        plt.draw()        # plt.show()        # plt.text(4, 1, t, ha='left', rotation=15, wrap=True)        plt.savefig('resPic\\%s.jpg' % str(self.typeCount))    # 计算得分（平均距离）    def score(self):        # 每个分组的平均距离        self.averageList = list()        try:            for key in range((len(self.coreList))):                self.averageList.append(                    sum([dis(x, self.rawData[self.coreList[key]])                         for x in self.classList[key]]) /                    len(self.classList[key])                )        except Exception:            Exception(\"bad center!\")        # print('[average]')        self.totalAverage = 0        # 加权平均        for i in self.averageList:            self.totalAverage +=  \\                i*len(self.classList[self.averageList.index(i)])            # print('\\t[group %d]\\t%f' % (self.averageList.index(i), i))        self.totalAverage /= len(self.rawData)        # print('\\t[total]\\t\\t%f' % self.totalAverage)        return self.totalAverage    # 单次运行    def run(self):        self.generateRandomCenter(10)        self.calc()        self.score()    # 给定聚类数多次随机取表现较好值    def des(self, typeCount: int):        # 最优结果、得分暂存变量        score = float('inf')        resList = None        # 连续conn次没有得到更优化的结果的次数        conn = 0        # 尝试次数计数器        counter = 0        while (conn &lt; 100):            counter += 1            # print('[attempt %d with %d times better]' % (counter, conn))            self.generateRandomCenter(typeCount)            self.calc()            try:                tempScore = self.score()            except Exception:                print(\"[ERROR]\\tbad center occured skip.\")                continue            if tempScore &lt; score:                resList = self.coreList                score = tempScore                conn = 0            else:                conn += 1        # 还原最佳聚类现场以便后续画图        self.coreList = resList        self.calc()        print('[info]\\tdes finish with best score %f' % score)        print(resList)        return resListdef dis(obj1: list, obj2: list):    assert isinstance(obj1, list), \\        '[ERROR] 第一个参数应当为list,输入的参数类型为$s' % str(type(obj1))    assert isinstance(obj2, list), \\        '[ERROR] 第二个参数应当为list,输入的参数类型为$s' % str(type(obj2))    return sqrt((obj1[1] - obj2[1]) ** 2 + (obj1[2] - obj2[2]) ** 2)if __name__ == '__main__':    exp = Classifier()    for i in range(3, 20):        print('[center counter]\\t%d' % i)        exp.des(i)        exp.draw()\n 数据处理和读入代码\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import xlrdimport sys# import datetimedef dataConverter(src: list)-&gt;list:    res = list()    res.append(src[0])    for i in range(1, 4):        res.append(src[i])    res.append(int(src[4]))    return resdef dataReader():    fileName = None    try:        fileName = sys.argv[-1]        print('[fileName]%s' % fileName)    except Exception:        print('no file name')    data = list()    try:        workbook = xlrd.open_workbook(filename=fileName)        for i in range(workbook.nsheets):            data.append(list())            rangeRow = workbook.sheet_by_index(i).nrows            sheet = workbook.sheet_by_index(i)            for x in range(rangeRow):                temp = sheet.row_values(x)                if temp[0] == '任务号码':                    continue                data[i].append(dataConverter(temp))    except Exception as e:        print('bad data file')        print('\\t[Exception]\\t%s' % str(e))        exit()    # for i in data:    #     for x in i:    #         print(x)    print('😀[info]\\tdata fetched successfully')    return dataif __name__ == '__main__':    data = dataReader()    for sheet in data:        for x in sheet:            print(x)","plink":"ilucia.github.io/Others/k-means/"},{"title":"Python中遍历List时删除元素","date":"2019-07-13T00:00:00.000Z","updated":"2022-04-27T15:24:01.731Z","content":" 场景复现\n\n举一个简单的栗子\n\n123456789&gt;&gt;&gt; numList = list(range(10))&gt;&gt;&gt; for i in range(len(numList)):...     del(numList[i])...Traceback (most recent call last):  File \"&lt;stdin&gt;\", line 2, in &lt;module&gt;IndexError: list assignment index out of range&gt;&gt;&gt; print(numList)[1, 3, 5, 7, 9]\n\n这里还有另一个栗子\n\n123456&gt;&gt;&gt; numList = list(range(10))&gt;&gt;&gt; for i in numList:...     numList.remove(i)... &gt;&gt;&gt; print(numList)[1, 3, 5, 7, 9]\n 错误原因\n\n不难发现在遍历python的list的时候删除该list的元素这个操作往往不会按照我们的预期运行\n当使用for发起遍历操作时，for的遍历顺序已经确定了，删除操作会导致列表索引的变化，这可能引起\n\n元素没有按照预期删除\n数组访问越界\n\n\n\n 解决方案\n\n\n删除操作在遍历操作之后(记录待删除元素)\n123456789101112&gt;&gt;&gt; delList = list() &gt;&gt;&gt; numList = list(range(10))&gt;&gt;&gt; for i in numList:  ...     if i % 2 == 0:...             delList.append(i)... &gt;&gt;&gt; for i in delList: ...     numList.remove(i)... &gt;&gt;&gt; numList[1, 3, 5, 7, 9]&gt;&gt;&gt;\n\n\n使用替代数组\n\n\nFilter\n123456789101112&gt;&gt;&gt; numList = list(range(10))&gt;&gt;&gt; numList = filter(lambda x : x % 2 == 0, numList)&gt;&gt;&gt; print(numList)&lt;filter object at 0x000002B358100470&gt;&gt;&gt;&gt; for i in numList:...     print(i)... 02468\n\n\nList\n1234&gt;&gt;&gt; numList = list(range(10))                   &gt;&gt;&gt; numList = [x for x in numList if x % 2 == 0]&gt;&gt;&gt; numList[0, 2, 4, 6, 8]\n\n\n\n\n遍历list的备份\n1234567&gt;&gt;&gt; numList = list(range(10))                   &gt;&gt;&gt; for i in numList[:]:...     if i % 2 == 0:...             numList.remove(i)... &gt;&gt;&gt; numList[1, 3, 5, 7, 9]\n\n\n逆序遍历\n1234567&gt;&gt;&gt; numList = list(range(10))   &gt;&gt;&gt; for i in range(len(numList) - 1, -1 , -1):...     if numList[i] % 2 == 0:...             del(numList[i])... &gt;&gt;&gt; numList[1, 3, 5, 7, 9]\n\n\n","plink":"ilucia.github.io/python/delInList/"},{"title":"操作系统原理总结","date":"2019-06-18T23:03:06.000Z","updated":"2022-04-27T15:24:01.619Z","content":"[TOC]\n Chapter 1 Introduction\n\n\nSystem view\n_ Resource allocator\n_ Control program\n\n\nDual-Mode Operation\n_ User mode\n_ Kernel mode\n_ privileged instruction\n_ \n_ \n_ Hardware\n_ CPU protection\n_ timer\n_ time sharing\n_ memory protection\n_ Base register\n_ Limit register\n_ I/O protection\n_ all I/O instruction are privilege instructions\n\n\nDevelopment of OS * mainframe systems\n\t\t*   NO OS\n\t\t*   **batch systems**\n\t\t*   **multiprogramming systems**\n\t\t*   **time sharing systems**\n\n\t*   desktop systems\n\n\t*   multiprocessor systems\n\n\t*   distributed systems\n\n\t*   clustered systems\n\n\t*   real-time systems\n\n\t*   handheld systems\n\n\t*   现代操作系统的特征\n\n\t\t*   **并发性Concurrence**\n\t\t*   **共享性Sharing**\n\t\t*   **虚拟性Virtual**\n\t\t*   **异步性Asynchronism**\n\t\t*   提高CPU利用率，充分发挥并发性：**程序之间、设备之间、设备与CPU之间**均**并发**\n\n\t*   Pr：\n\n\t\t批处理系统、多道程序系统和分时系统的技术特性\n\n\n\n Chapter 2 Operating-System Structures\n\n功能和服务的差别：\n\n功能对内：自行实现\n服务对外：可以调用其他功能代为实现\n\n\ncommon function of OS\n\nprocess management\n\nprocess synchronization\nprocess communication\ndeadlock handling\n(分布式)\n\n\nmain memory management\nsecondary-storage management\nfile management\nI/O system management\n\n\nOperating System Services(Services for helping users)\n\nProgram execution\nI/O operations\nFile-system manipulation\nCommunications\nError detection\nResource allocation\nAccounting(审计)\nProtection\n\n\nOperating System Interface\n\nInterface to programs\n\nSystem calls\n\nSystem-call interface(SCI)\nApplication Programming Interface(API)\n\nmanaged by runtime support library\n\n\n\n\n\n\n\nTypes of System calls\n\nProcess control\nFile management\nDevice management\nInformation maintenance\nCommunications\n\n\n\n\n\n\nPR. Why do user use APIs rather than system calls directory?\nAns\n\n跨平台能力（提供相同的 API 封装）移植性好\n模块化封装，可维护性好\n简化了程序编写\n提高了执行效率\n\n\n\n\nOperating System Structure\n\nSimple structure\nLayered structure\n\nvirtual machines\n\n\nMicrokernel structure\n\nBenefis\n\neasier to extend\neasier to port\nmore reliable\nmore secure\n\n\n\n\nModules\nPR:设计操作系统时采用的模块化内核方法和分层方法在那些方面类似？那些方面不同？\n\n\nOperating system design and implementation\n小结\n\n操作系统概念（管理资源、支持程序运行、方便用户使用的程序集）\n操作系统的基本目标：方便性和高效性\n引导程序：中断、中断处理程序、中断向量\n储存结构：内存（小、易失）二级储存（大、非易失）、分层结构\nI/O 结构：设备控制器（本地缓冲）、DMA\n硬件保护：双重模式操作、特权指令、I/O 保护、内存保护、CPU 保护\n操作系统的发展：e.g: 多道程序设计\n操作系统的功能：进程（CPU）管理、内存管理、磁盘管理、文件管理、I/O 管理、用户接口\n操作系统服务：程序执行、I/O 操作、文件系统操作、通信、错误检测与处理、资源分配、统计、保护\n操作系统接口：用户接口（CLI、GUI）、程序接口（系统调用（参数传递、类型））、SCI、API\n操作系统结构\n\n\n\n Chapter 3 Process\n\n\nProcess\n\ntest section(program code)\nprogram counter\ncontents of the processer’s registers\nHeap-stack\ndata section\n\n\nCharacteristic of process\n\nDynamic 动态性\nIndependency 独立性\nConcurrence 并发性\nStructure 结构化\n\n\nPR.进程和程序是两个密切相关的概念，请阐述他们之间的区别和联系\nProcess state\n\n\nProcess control block(PCB)\n\n\n\n\n\nProcess scheduling queues\n\nJob queue (in main memory)\n\nReady queue\ndevice queues\n\nprocess migration between the various queues\n\n\n\n\n\n\nSchedulers\n\nLong-term scheduler(秒级、分钟级，作业调度)\nShort-term scheduler(毫秒级，CPU 调度)\nMedium-term scheduler(swapping)\n\n\nI/O bound process\nCPU bound process\nContext switch\n\nThe context of a process is represented in PCB of the process and includes the values of CPU registers.\n保存执行后的上下文信息\n上下文切换会带来开销\n尽量减少上下文切换以减少开销\n\n\n\n\n\n\n\n\n\nOperation on Process\n\n\nProcess creation\n\n\nchild process(unique process identifier(int)), tree of process\n\n\nresource sharing\n\nparent and children shall all resources\nchildren share subset of parent’s resources\nparent and child share no resources\n\n\n\nExecution\n\nParent and children execute concurrently\nParent waits until children terminate\n\n\n\nAddress space\n\n\nchild duplicate of parent\n\n\nchild has a program loaded into it (new text section)\n\n\nUNIX examples\n\n\nfork() :create new process\n\n\nexec() :used after a fork to replace the process’s memory space with a new program\n\n\n\n\n\n\n12345678910111213141516pid = fork();if(pid&lt;0)\t/* error occured */&#123;    printf(stderr,\"Fork failed\");    exit(-1);&#125;else if(pid==0)\t/* child process */&#123;    execlp(\"/bin/ls\",\"ls\",NULL);&#125;else\t/* parent process */&#123;    wait(NULL);\t/* wait for child process to finish */    printf(\"Child complete\");    exit(0);&#125;\n\n\n\n\nProcess Termination\n\nexit() process executes last statement and asks the operating system to delete it\n\noutput data from child to parent (via wait)\nProcess’s resources are deallocated by OS\n\n\nabort() parent may terminate execution of children process\n\nchild has exceeded allocated resources\ntask assigned to child is no longer required\nparent is exiting *not all of the operation system supports Cascading termination(级联终止)\n\n\n\n\n\n\n\n\n\n\n\nInter-process Communication(IPC)\n\n\nIndependent process cannot affect or be effected by the execution of another process\n\n\nCooperating process can affect or be effected by the execution of another process\n\n\nAdvantages\n\n\nInformation sharing\n\n\nComputation speed-up\n\n\nModularity\n\n\nConvenience\n\n\n\n\n\n\nShared memory &amp; Message passing\n\n\n\n\nShared-memory Systems\n\t- requiring communication process to establish a region of shared memory\n\t- a shared memory region resides in the address space of the process creating the shared memory segment\n\t- the processes are responsible for ensuring that they are not writing to the **same location simultaneously**\n\t\t- Producer-Consumer Problem\n\n\n\nMessage-passing Systems\n\t- MPS has two operations\n\n\t\t- send()\n\t\t- receive()\n\n\t- communication link\n\n\t\t1. link may be unidirectional or bidirectional (双向)\n\n\t\t2. a link may be associated with many processes\n\n\t\t- direct communication\n\n\t\t\t- send(P,message) send a message to process P\n\t\t\t- receive(Q,message)  receive a message from process Q\n\n\t\t- indirect communication\n\n\t\t\t- mailboxes\n\n\t\t\t\t- each mailbox has a unique id\n\n\t\t\t\t- two processes can communicate only if the share a mailbox\n\n\t\t\t\t- Operations\n\n\t\t\t\t\t&gt; 1. create a new mailbox\n\t\t\t\t\t&gt; 2. send and receive messages through mailbox\n\t\t\t\t\t&gt; 3. destroy a mail box\n\n\n\nSynchronization\n\t- Blocking: synchronous\n\t- Non-blocking: asynchronous\n\n\n\nBuffering\n\t- **Zero capacity** sender must wait for receiver\n\t- **Bounded capacity** finite length of $n$ messages, sender must wait if link full\n\t- **Unbounded capacity** infinite length, sender never blocks\n\n\n\n\n\n\n\nCommunication in Client-Server System\n\nSockets\nRemote Procedure Calls\nRemote Method Invocation (Java)\n\n\n\n Chapter 4 Threads\n\n\nMultithreading Models\n\n\nA thread is a flow of control within a process\n\n\nthread is a basic unit of CPU execution (known as light weight Process(LWP))\n\n\nprocess (heavy weight process(HWP)) has a single thread of control\n\n\nmultithreaded process contains several different flows of control within the same address space\n\n\nThread\n\n\nhas\n\nthread ID\nprogram counter\nregister set\nstack\n\n\n\nshare\n\n\ncode section\n\n\ndata section\n\n\nother OS resources(file and signals)\n12\n\n\nBenefits\n12- resource sharing- economy(low cost in overhead of creating and context-switch)\n\n\n\n\nUser Threads\n\n\nuser threads are supported above the kernel. The kernel is not aware of user threads\n\n\nLibrary provides all support for thread creation, termination, joining and scheduling\n\n\nmore efficient(no kernel intervention)\n\n\nif one thread is blocked, every other threads of the same process are also blocked(containing process is blocked)\n\n\n\n\nKernel Threads\n\n\nkernel threads are usually slower than the user threads\n\n\nblocking one thread will not cause other threads of the same process to block\n\n\nthe kernel can schedule threads on different processors(in a multiprocessor environment)\n\n\nPr.\n\n进程和线程之间的区别和联系\n用户级线程和内核级线程的区别\n\n\n\n\n\n\n\nMultithreading models\n\n\nmany to one\n\nonly one thread in the one process can access the kernel at a time\ntrue concurrency is not gained\n\n\n\n\n\none to one\n\n\neach user-level thread maps to kernel thread\n\n\nproviding more concurrency\n\n\nrestricting the number of threads supported by the system\n\n\n\n\n\n\nmany to many\n\n\nallow many user level threads to be mapped to many kernel threads\n\n\n\n\n\n\n\n\n\n\n\n\nThread Libraries\n\nstatus\n\n\n123456789101112131415161718192021int pthread_create(tid,attr,function,arg);/* * pthread_t *tid \thandle of created thread * const pthread_attr_t *attr \tattribes of thread to be created * void *(*function)(void) \tfunction to be mapped to thread * void * arg \tsingle argument to function */int pthread_join(tid,val_ptr);/* * pthread_t *tid \thandle of joinable thread * void ** var_ptr \texit value rturn by joined thread */void pthread_exit(void *status);int pthread_cancel(pthread_t thread);\t//terminated immediatelyint pthread_kill(pthread_t thread,int sig);\n\nCreateThread\nGetCurrentThreadId\nGetCurrentThread\nSuspendThread/ResumeTread\nExitThread\nTerminateThread\nGetExitCodeThread\nGetThreadTimes\n\n\n\nThreading Issues\n\n\nOperating System Examples\n\n\n//TODO 关于线程的实现\n\n\nPr.\n\n信号机制和中断机制的异同\n\n\n\nThread Pools\n\nadvantages - faster to service a request(save the time to create new thread) - allow the number of threads in the application to be bound to the size of the pool\n\n\n\nThread specific data\n\nthreads belonging to a process share the data of the process\nallows each thread to have its own copy of data\nwhen using a thread pool, each thread may be assigned a unique identifier\n\n\n\nScheduler activations\n\n\nupcalls\n\n\n Chapter 5 CPU Scheduling\n\n\nMaximum CPU utilization obtained with multiprogramming\n\n\nThe success of CPU scheduling depends on an property of processes:CPU-I/O Burst Cycle\n\nprocess execution consists of a cycle of CPU execution and I/O wait.\n\n\n\nCPU-bound\n\na few very long CPU bursts\n\n\n\nI/O-bound\n\nmany short CPU bursts\n\n\n\n\n\nWhen the CPU is idle, the OS must select another ready process to run\n\n\nThis selection process is carried out by the short-term scheduler\n\n\nThe CPU scheduler selects a process from the ready queue and allocates the CPU to it\n\n\nThere are many ways to organize the ready queue(e.g. FIFO)\n\n\n\n\nCircumstances that scheduling may take place\n\n\nA process switches from the running state to the terminated state(finished)\n\n\nA process switches from the running state to the wait state(e.g. IO operation)\n↑ 主动操作 ↑ 非抢占式调度\n\n↓ 被动中止 ↓ 抢占式调度 → 同步机制\n\n\nA process switched from the running state to the ready state(e.g. a interrupt occurs)\n\n\nA process switches from the wait state to the ready state(e.g. I/O completion)\n\n\nA process switches from the new state to ready state(e.g. a higher priority process ready)\n\n\nPreemptive(抢占式)\n\ncost associated with access to shared data\nWhen the kernel is in its critical section modifying some important data .\nspecial attention to situation\n\n\n\nNon-preemptive\n\nscheduling occurs when a process voluntarily terminates(主动结束) (case1)or enters the wait state(case2)\nsimple but very inefficient\n\n\n\nPr.\n​ 对于计算中心，抢占式调度和非抢占式调度哪一种比较适合\n\nDispatcher(调度) module\n\nswitching context\nswitching to user mode\njumping to the proper location in the user program to restart that program\n\n\nDispatch latency\n\nthe dispatcher should be as fast as possible\n\n\n\n\n\nScheduling criteria\n\n\nCPU utilization\n\nkeep the CPU as busy as possible\nlightly|40%|-|90%|heavily\n\n\n\nThroughput(吞吐)\n\nhigher throughput means more jobs get done\n\n吞吐量和 CPU 利用率有相关性但并没有直接关系\n\n\nTurnaround time\n\nThe time period from job submission to completion is the turnaround time\n\ntturnaround=twaitingTimeBeforeEnteringTheSystem+twaitingTImeInTheReadyQueue+twaitingTImeInAllOtherEvents+ttimeTheProcessActuallyRunningOnTheCPUt_{turnaround}=\\\\t_{waitingTimeBeforeEnteringTheSystem}+\\\\ t_{waitingTImeInTheReadyQueue}+\\\\t_{waitingTImeInAllOtherEvents}+\\\\t_{timeTheProcessActuallyRunningOnTheCPU}\ntturnaround​=twaitingTimeBeforeEnteringTheSystem​+twaitingTImeInTheReadyQueue​+twaitingTImeInAllOtherEvents​+ttimeTheProcessActuallyRunningOnTheCPU​\n\n\n\n\nWaiting time\n\ntime in ready queue\n\n\n\nResponse time\n\nthe time form the submission of a request\n\n\n\nOptimization Criteria\n\nMAX CPU utilization\nMAX throughtput\nMIN turnaround time(average)\nMIN waiting time\nMIN response time\n\n\n\n为什么需要 CPU 调度\n大多数任务是CPU和I/O交替使用，\n导致CPU和I/O至少有一个空闲，\n通过调度让需要执行I/O的任务去执行I/O。\n把CPU给需要CPU的任务运行。\n\n\nScheduling Algorithms\n\n\nFirst-Come-First-Served Scheduling (FCFS)\n\ncan easily implemented using a queue\nnot preemptive\nconvoy effect (护航效应)\ntroublesome for time-sharing systems\n\n\n\nShort-Job-First Scheduling (SJF)\n\nsorted in next CPU burst length\ncan be nonpreemptive and preemptive\nminimum average waiting time for a given set of process\npredict CPU burst: exponential averaging\nlong jobs may meet starvation!!!\n\n\n\nPriority Scheduling\n\n\neach process has a priority\n\n\npriority may be determined internally or externally\n\ninternal priority\n\ntime limits\nmemory requirement\nnumber of files\netc.\n\n\nexternal priority\n\nimportance of the process (not controlled by the OS)\n\n\n\n\n\nstarvation/Indefinite block\na lower priority may never have a chance to run\n\nAging\n\ngradually increase the priority of process what wait in the system for a long time\n\n\n\n\n\n\n\nRound_Robin Scheduling (RR)(轮询)\n\ndesigned for time-sharing systems\neach process is assigned a time quantum/slice\nIf the process uses CPU for less than one time quantum, it will release the CPU voluntarily (主动退出)\nwhen one time quantum is up , that process is preempted by the scheduler and moved to the tail of the list\nTypically, higher average time than SJF, better response time\ntime quantum is too large → FCFS\ntime quantum is to small → processor sharing (并发)\n\nshorter time quantum means more context switches\n\n\nin general, 80% of the CPU bursts should be shorter than the time quantum\n\n\n\n\nMultilevel Queue Scheduling (多级队列)\n\n\npartitioned into separate queues\n\nforeground (interactive)\nbackground (batch)\n\n\n\nEach process is assigned permanently to one queue based on some properties of the process\n\n\nEach queue has its own scheduling algorithm\n\n\nforeground - RR\n\n\nbackground -FCFS\n\n\n\n\n\nScheduling must be done between the queues\n\nFixed priority scheduling (possibility of starvation)\nTime slice\n\neach queue gets a certain amount of CPU time which it can schedule amongst its processes\n\n\n\n\n\n\n\n\n\nMultilevel Feedback Queue Scheduling\n\n\nallows process to move between queues\n\n\naging can be implemented this way\n\n\nIf a process use more/less CPU time, it is moved to a queue of lower/higher priority → I/O/CPU-bound process will be in higher/lower priority queues\n\n\nexp\n\n\n\n\n\nnumber of queues\nscheduling algorithms for each queue\nmethod used to determine when to upgrade a process\nmethod used to determine when to demote a process\nmethod used to determine which queue a process will enter when that process needs service\n\n\n\n\n\nMultiple-Processor Scheduling\n\nHomogeneous(同构) processors\nLoad balancing\n\npush migration\npull migration\n\n\nAsymmetric multiprocessing (非平衡处理)\n\nonly on processor accesses the system data\n\nalleviating(降低) the need for data shring\n\n\n\n\nSymmetric multiprocessing (SMP)\n\ntwo processors do not choose the same process\n\n\nProcessor Affinity (侵核)\n\nmost SMP systems try to avoid migration of processes from one processor to another\n\nSoft/Hard Affinity (执行过程中可以/不可以侵核)\n\n\n\n\n\n\n\nReal-Time Scheduling\n\nHard real-time systems\nthe scheduler either admits a process and guarantees that the process will complete on-time, or reject the request (resource reservation)\nsecondary storage and virtual memory will cause unavoidable delay\nHard real-time systems usually have special software on special hardware\n\n\n\nSoft real-time systems\n\neasily doable(可行) within a general system\nmay cause unfair resource allocation and longer delay(starvation) for noncritical tasks.\nthe CPU scheduler must prevent aging to occur(critical tasks may have lower priority)\nThe dispatch latency must be small\n\n\n\nPriority Inversion\n\na high-priority process needs to access the data that is currently being accessed by a low-priority process → The high-priority process is blocked by the low-priority process\npriority-inheritance protocol\n\n\n\nThread Scheduling\n\nUser-level threads\n\nthread library\n\n\nKernel-level threads\n\nscheduled by OS\n\n\nuser-level threads must ultimately be mapped to an associated kernel-level thread\nLocal scheduling → User-level Thread\n\nProcess-contention Scope (PCS)\n\n\nGlobal Scheduling → Kernel-level Thread\n\nSystem-contention Scope (SCS)\n\n\n\n\n\nAlgorithm Evaluation\n\n\nDeterministic modeling (Analytic evaluation) 确定情况下 的情形证明\n\n\nQueueing models 队列模型\n\n\nSimulations 仿真\n\n\nImplementation 证明\n从上往下证明力越强，越难证明\n\n\n\n\nOperating System\n\nScheduling threads using preemptive and priority-based scheduling algorithms (Real time, system, time sharing, interactive)\nThe default scheduling class for a process is time sharing (multilevel feedback queue)\n\n\n\n Chapter 6 Process Synchronization\n\n\nBounded-buffer\n\t1234567891011121314151617181920212223242526272829303132//Shared data#define BUFFER_SIZE 10typedef struct&#123;    //...&#125; item;item buffer[BUFFER_SIZE];int in = 0;int out = 0;int counter = 0;//Producer processitem nextProduced;while(1)&#123;    while(counter == BUFFER_SIZE);    \t//do nothing    buffer[in] = nextProduced;    in = (in + 1) % BUFFER_SIZE;    counter++;&#125;//Consumer processitem nextConsumed;while(1)&#123;    while(counter == 0)        //do nothing    nextConsumed = buffer[out];    out = (out + 1) % BUFFER_SIZE;    counter--;&#125;\n\n\n\nAtomic operation\n\t- counter++\n\t- counter—\n\n\n\nRace condition\n\t- two or more processes/thread access and manipulate the same data concurrently\n\t- the outcome of the execution depends on the particular order in which the access takes place\n\t- To prevent race conditions, concurrent processes must be synchronized\n\n\n\nThe Critical-Section Problem\n\t- Each process has a code segment, called critical section\n\n\t- **Problem**: ensure that when one process is executing in its critical section, no other process is allowed to execute in its critical section\n\n\t- The critical-section problem is to design a protocol that processes can use to cooperate\n\n\t\t┌────────────┐\n\n\t\t|    entry section      |\n\n\t\t├────────────┤\n\n\t\t|    critical section    |\n\n\t\t├────────────┤\n\n\t\t|       exit section      |\n\n\t\t├────────────┤\n\n\t\t|remainder section |\n\n\t\t└────────────┘\n\n\t\t**critical section must run in a mutually exclusive way.**\n\n\n\nSolution to Critical-Section Problem\n\t- Mutual Exclusion (互斥、忙等) → 防止冲突\n\t- Progress (空闲让进) → 进展性\n\t- Bounded Waiting (有限等待) → 进展性\n\t\t- &lt;small&gt;防止饥饿，让权等待，多CPU：死锁&lt;/small&gt;\n\t- **the solution cannot depend on relative speed of processes and scheduling policy**\n\t- Mutual Exclusion\n\n\n\nBakery Algorithm\n\t1234567891011121314151617//shared databoolean choosing[n];\t//falseint number[n];\t\t\t//0do&#123;    choosing[i] = true;    number[i] = max(number[0],number[1],...,number[n-1])+1;    choosing[i] = false;    for(j = 0; j &lt; n; ++j)    &#123;        while(choosing[j]);        while((number[j] != 0)&amp;&amp;((number[j],j)&lt;(number[i],i)));    &#125;    //critical section    number[i] = 0;    //remainder section&#125;while(1)\n\n\n\nInterrupt Disabling\n\t- disable interrupts → critical section → enable interrupts\n\t- When interrupts are disabled, no context switch will occur in a critical section\n\t- Infeasible in a multiprocessor system because all CPUs must be informed\n\t- Some feature that depend on interrupts (e.g. clock) may not work properly\n\n\n\nMutual Exclusion (互斥锁)\n\t- TestAndSet\n\n\t\t123456boolean TestAndSet(boolean &amp;target)&#123;\tbooean rv = &amp;target;    &amp;target = true;    return rv;&#125;\n\n\t\t12345678910//shared databoolean lock = false;//Process Pdo&#123;    while(TestAndSet(lock));    //critical section    lock = false;    //remainder section&#125;\n\n\n\nSwap\n\t- **atomically** swap two variables\n\n\t\t123456void Swap(boolean &amp;a,boolean &amp;b)&#123;    boolean temp = &amp;a;    &amp;a = &amp;b;    &amp;b = temp;&#125;\n\n\t\t12345678910111213141516//Global shared databoolean lock;\t//false//Local variable for each processboolean key;Process Pido&#123;\tkey = true;\twhile(key == true)    &#123;    \tSwap(lock,key);    &#125;    //critical section    lock = false;    //remainder section&#125;\n\n\n\nSemaphores\n\t12345678910wait(S)&#123;\twhile(S &lt;= 0);\t\t--S;&#125;signal(S)&#123;    ++S:&#125;\n\n\t- Count semaphore\n\t- Binary semaphore (mutex locks)\n\n\n\nbusy waiting (Spinlock)\n\n\nblock itself (阻塞方法，使用 PCB 唤醒)\n\t- Define a semaphore as a record\n\n\t\t12345typedef struct&#123;    int value;    struct process *L;\t//waiting queue&#125;semaphore;\n\n\t\t- block()\n\t\t- wakeup(P)\n\n\t\t123456789101112131415161718wait(S)&#123;    S.value--;    if (s.value &lt; 0)    &#123;        //add this process to S.L;        block();    &#125;&#125;signal(S)&#123;\tS.value++;    if(S.value &lt;= 0)    &#123;        //remove a process P from S.L;        wakeup(P);    &#125;&#125;\n\n  - if the semaphore is negative, its magnitude is the number of process waiting on that semaphore\n  - Busy waiting has not been **completely** eliminated\n  - furthermore, we have limited busy waiting to the critical sections of the wait() and signal() operations\n\n\n\nDeadlock and Starvation\n\t&lt;small&gt;临界资源、同步关系&lt;/small&gt;\n\n\t- Bounded-Buffer Problem\n\n\t\t123456789101112131415161718192021//Shared dataSemaphore full = 0,empty = n,mutex = 1;do\t//Producer&#123;    //produce an item in nextP    wait(empty);    wait(mutex);    //add nextP to buffer    signal(mutex);    signal(full);&#125;while(1);do\t//Consumer&#123;    wait(full);    wait(mutex);    //remove an item from buffer to nextC    signal(mutex);    signal(empty);    //consume the item in nextC&#125;while(1);\n\n\t- Readers and Writers Problem\n\n\t\t- Reader first\n\t\t- Writer first\n\n\t\t123456789101112131415161718192021222324//Shared dataint readcount;semaphore wrt = 1,mutex = 1;int readcount = 0;do&#123;    wait(wrt);    //writing    signal(wrt);&#125;while(1);do\t\t//Error: 写者饥饿问题&#123;    wait(mutex);    readcount++;    if(readcount == 1)        wait(wrt);    signal(mutex);    //reading    wait(mutex);    readcount--;    if(readcount == 0)        signal(wrt);    signal(mutex);&#125;\n\n\t- Dining-Philosophers Problem\n\n\t- 过独木桥问题\n\n\t\t123456//Shared dataint countA = 0;\t//A方向上已在独木桥上的行人数目int countB = 0;\t//B方向上已在独木桥上的新人数目semaphore MA = 1;\t//countA的互斥锁semaphore MB = 1;\t//countB的互斥锁semaphore mutex = 1;\t//实现互斥使用\n\n\t\t- A方向过桥\n\n\t\t\t123456789101112131415161718do&#123;    wait(MA);    countA++;    if (count == 1)    &#123;        wait(mutex);    &#125;    signal(MA);    //过桥    wait(MA);    countA--;    if(countA == 0)    &#123;        signal(mutex);    &#125;    signal(MA);&#125;while(1);\n\n\n\nMonitors (管程)\n\t- High-level synchronization construct that allows the safe sharing of an abstract data type among concurrent processes\n\n\t\t1234567891011121314monitor monitor-name&#123;\tshared variable declarations\tproceudre body P1()    &#123;    \t//...    &#125;    \tproceudre body P2()    &#123;    \t//...    &#125;    //...    &#123;//initialization code&#125;&#125;\n\n\t- no more than one process can be executing within a monitor\n\n\t- when a process calls a monitor procedure and the monitor has a process running, the caller will be blocked outside the monitor\n\n\t- Mutual exclusion is guaranteed with in a monitor\n\n\t\t![](/Review/OS/1555948188580.png)\n\n\t\t![](OS/1555948188580.png)\n\n\n\nCondition variables\n- x,y\n\n\t- x.wait() means that the process invoking this operation is suspended until another process invokes x.signal();\n\t- x.signal() operation resumes exactly one suspended process. If no process is suspended, the signal() operation has no effect\n\n\t![](/Review/OS/1555948399247.png)\n\n\t![](OS/1555948399247.png)\n\n\n\t|                          Semaphores                          |                     Condition Variables                      |\n\t| :----------------------------------------------------------: | :----------------------------------------------------------: |\n\n\n\n| Can be used anywhere, but not in a monitor | Can only be used in monitors |\n| wait() does not always block its caller | wait() always blocks its caller |\n| signal() either releases a process, or increase the semaphore counter | signal() either releases a process ,or the signal is lost as if it never occurs |\n| If signal() release a process, the caller and the release both continue | If signal() release a process, either the caller or the released continues, but not both | - 管程是公用数据结构，进程是私有数据结构 - 管程集中管理共享变量上的同步操作，临界区分散在每个进程中 - 管程管理共享资源，进程占用系统资源和实现系统并发性 - 管程被欲使用的共享资源的进程调用，管程和调用它的进程不能并发工作，进程之间能并发工作 - 管程是语言或操作系统的成分，不必创建或撤销，进程有生命周期，有创建有消亡\n Chapter 7 Deadlocks\n\n\nsystem model\n\nDeadlock\n\nResources types R1 ,R2 …,Rm\nCPU cycles, memory space, I/O devices, files and so on\neach resource type Ri has Wi instances\nrequest → use → release\n\n\n\n\n\ndeadlock characterization\n\n\nThe conditions for deadlock\n\nmutual exclusion\nhold and wait\nno preemption\ncircular wait\n\n\n\nresource allocation graph\n\n\nedges E,process P,resource R\n\n\nrequest edge Pi→Rj\n\n\nassignment edge Rj→Pi\n\n\n\n\n\n\n\n死锁一定循环，循环未必死锁\n当实例只有一个资源时，有循环就会死锁\n但是当实例有多个资源时，循环可能导致死锁（如上图）\n\n\n\n\n\n\n\n\n\n\n\nMethods for handling deadlocks\n\nEnsure that the system will never enter a deadlock state\n\nPrevention\n\nbreak conditions\n\n\nAvoidance\n\nthe OS needs more information to determine whether the current request can be satisfied of delayed\n\n\nAllow the deadlock, detect it, and recover.\nJust ignore it and pretend deadlocks will never happened. 😃\n\n\n\n\n\ndeadlock prevention\n\nMutual Exclusion\nhold and wait\n\na process must acquire all resources before it runs\nwhen a process requests for resources, it must hold none\n\nResource utilization might be low, since many resources will be held and unused for a long time\nstarvation is possible. A process that needs some popular resources may have to wait indefinitely\n\n\n\n\nNo preemption\n\nif a process that is holding some resources requests another resource that cannot be immediately allocated to it , then all resources currently being held are preempted(抢占)\n\nif the requested resources are not available\n\nif they are being held by process that are waiting for additional resources, these resources are preempted and given to the requesting process.\nelse, the requesting process waits until the requested resources become available. When it is waiting. its resources may be preempted\n\n\n\n\n\n\nCircular wait\n\na process can only request higher than the resources types it holds\na process must release some higher order resources to request a lower resource\n\n\n\n\n\ndeadlock avoidance\n\n\nall of the process declare the maximum number of resources of each type that it may need\n\n\nthe deadlock-avoidance algorithm dynamically exam the resource-allocation state to ensure that there can never be a circular-wait condition\n\n\nResource-allocation state is defined by the number of available and allocated resources, and the maxium demands of the process\n\n\nSafe state\n\n\nsingle instance of a resource type\n\nresource-allocation-graph algorithm\n\nclaim edge pi→pj indicated that process pi may request resource rj; represented by a dashed line\nclaim edge converts to request edge when a process requests a resource\nwhen a resource is released by a process, assignment edge reconverts to a claim edge\nresource must be claimed a prior in the system\n\n\n\n\n\nmultiple instances of a resource type\n\n\nbanker’s algorithm\n| process | max  | allocation | need |\n| ------- | ---- | ---------- | ---- |\n| P~0~ | [7,5,3] | [0,1,0] |[7,4,3]|\n\n| P1 | [3,2,2] | [2,0,0] |[1,2,2]|\navailable[3,3,2]\n\n\n\n\n\n\ndeadlock detection\n\n\nmaintain wait-for-graph and search for a cycle in the graph\n\n\nnodes are process\n\n\nPi→Pj is waiting for Pj\n\n\nsearch for a cycle\n\n\n\n\n\n\n\n\nrecovery form deadlock\n\nPross termination\n\nAbout all deadlocked process\nAbout one process at a time until the deadlock cycle is established\n\n\nResource preemption\n\nselecting a victim (minimize cost if possible)\nrollback\n\nreturn to some safe state restart process for that state\n\n\nstarvation\n\nsame process may always be picked as victim (aging)\ninclude the number of rollback in the cost factor\n\n\n\n\n\n\n\n Chapter 8 Memory Management\n\n\nbackgroud\n\n\nMain memory and register are only storage CPU can access directly\n\n\na register access per CPU clock\n\n\na main memory access many CPU clcok\n\n\ncache sites between main memory and CPU registers\n\nmemory protect\nbase and limit registers\nhardware address protection\nmultistep processing of a user program\n\nsymbolic address\n\nsource program\n\n\nrelocatable address\n\nobject program\n\n\nabsolute address\n\n\ncomplie time\n\nabsolute code\nos, drive\n\n\nload time\n\nrelocatable code\n\n\nexecution time\n\nneed hardware support\n\n\nLogical &amp; Physical address space\n\nlogical address\n\ngenerated by the CPU; referred to as virtual address\n\n\nphysical address\n\nseen by the memory unit\n\n\nlogical and physical addresses are the same in compile-time and load-time address-binding schemes and differ in execution\n\n\n\n\n\n\n\nMemory-Management Unit(MMU)\n\n\nmaps logical address to physical address\n\n\nthe value in relocation(base) register is added to every address generated by a user process at the time it is sent to memory\n\n\nThe user program deals with logical addresses\n\n\n\n\n\n\nDynamic loading\n\nlinking and loading postponed until execution time\n\n\n\nswapping\n\n\nbacking store: fast disk\n\n\nready queue\n\nconsisting of all processes on the backing store or in memory and are ready to run\nmajor part of swap time is transfer time; total transfer time is directly proportional to the amount of memory swapped\n\n\n\n\n\n\n\n\n\n\n\ncontiguous allocation\n\n\nmain memory is usually divided into two partitions\n\nresident operation system\nuser processes\n\n\n\nrelocation register scheme used to protect user process from each other, and from changing operating system code and data\n\n\nallocation types\n\n\nfixed partitions\n\n\nmemory is divided into n partitions at the startup time and altered later on\n\n\neach partition may contain exactly only one process\n\n\neach partition may have a job queue. Or, all partitions share the same job queue\n\n\n\n\n\n\nvariable partitions\n\n\nhole\n\n\nwhen a process arrives, it is allocated memory from a hole large enough to accommodate it\n\n\nthe partition sized are not fixed\n\n\nos maintains maintains information about\n\n\nallocated partitions\n\n\nfree partitions\n\n\n\n\n\n\nFirst fit\n\n性能较好\n\n\n\nBest fit\n\n使用率最优\n\n\n\nworst fit\n\n烂差\n\n\n\nexternal fragmentation: hole\n\nexternal fragmentation problem exists when there is enough total free memory space to satisfy a request, but the available spaces are not contiguous\ncompaction(一般不用 ,开销较大)\npermitting the physical address space of the processes to be noncontiguous\n\npaging and segmentation\n\n\n\n\n\ninternal fragmentation\n\n\n\n\n\n\n\n\n\n\n\n\npaging\n\n\nphysical memory: pages\n\n\nlogical memory: frames\n\n\npage table\n\nkeep track of all free frames\nto run a program of size n pages, need to find n free frames and load program\nStill have internal Fragmentation\n\n\n\naddress generated by CPU can be divided into\n\n\nPage number§\n\nbase address of each page\n\n\n\nPage offset(d)\n\n\na 2m space logical address\n\n\n\npage number\npage offset\n\n\n\n\np\nd\n\n\nm-n\nn\n\n\n\n\n\n\n\n\n\n\nmost allocate a page table for each process\nin the simplest case, the page table is implemented as a set of dedicated registers\nThe use of registers is fit for the small page tables and not is fit for the large page tables\npage table is kept in main memory\npage-table base register(PTBR) points to the page table\nrequire two memory accesses, one for page table and another for memory\n\n\n\nImplementation of page table(TLB)\n\n\nthe two memory access problem can be solved by the use of special fast-lookup hardware\n\nassociative memory or translation look-aside buffer\n\n\n\n\npage#\nframe#\n\n\n\n\nxxx\nxxx\n\n\n\n\n\nif page# is in associative register, get frame# out. Else, get frame# from page table\n\n\n\n\n\n\n\n\n\n\nsome TLBs store address-space identifiers (ASIDs) in each TLB entry to provide address space protection for process\n\n\nEffective Access Time\n\n\nHit ratio(命中率)(assume memory cycle time is 1 microsecond)\n\n\n\nα\\alphaα\nhit ratio\n\n\n\n\nε\\varepsilonε time unit\nTLB lookup\n\n\neffective access time(EAT)\n(1+ε)α+(2+ε)(1−α)=2+ε−−α(1+\\varepsilon)\\alpha+(2+\\varepsilon)(1-\\alpha)=2+\\varepsilon--\\alpha(1+ε)α+(2+ε)(1−α)=2+ε−−α\n\n\n\n\n\n\n\nMemory protection\n\npage table length register(PTLR) stores the length of a process’s page table\nread-only,read-write,or execute bits(r-w-e permission)\n\n\n\nShared pages\n\n\nshare common code\n\n\none copy of read-only code for many process they need\n\n\n\n\n\n\nstructure of page table\n\n\nHierarchical paging(分层)\n\n\ncommon in 32 bits\n\n\ntwo-level page table\n\n\na logical address is as follows\n\n\n\n\np1 is an index into the outer page table, and p2 is the displacement within the page of the outer page table(页目录表)\n\n\n\n\n\n\nthree-level paging scheme\n\n\n\n\n\n\n\n\n\n\nhashed page tables\n\n\ncommon in address spaces &gt; 32 bits\n\n\nThe virtual page number is hashed into a page table.\n\n\n\n\n\n\ninverted page tables\n\n\nOne entry for each real frame of memory.\n\n\nEntry consists of the virtual address of the page stored in that real memory location, with information about the process that owns that page.\n\n\nDecreases memory needed not to store each page table, but increases time needed to search the table when a page reference occurs.\n\n\nUse hash table to limit the search to one or at most a few page-table entries.\n\n\n\n\n\n\n\n\nsegmentation\n\n\na program is a collection of segments. A segment is a logical unit such as\n\n\nmain program, procedure, function , method, object, object, local variables, global variables, common block, stack, symbol table, arrays\n\n\nlogical address consists of &lt;segment-number,offset&gt;\n\n\nsegment table\n\n\nbase\n\n\nlimit\n\n\n\n\nvalidation bit = 0 → illegal segment\n\n\nread/write/execute privileges\n\n\n\n\n\n\n\n\n\n\n Chapter 9 Virtual Memory\n\n\nbackground\n\nlogic address space can be larger than physical address space\nshares library using virtual memory\ncopy on write\n\nprocess creation\ncopy on write(COW) allows both parent and child processed to initially share the same pages in memory\nif either process modifies a shared page, then only the page is copied\nCOW allows more efficient process creation as only are copied\nfree pages are allocated from a pool of zeroed-filled pages\n\n\n\n\n\ndemand paging\n\n\nbring a page into memory only when it is needed\n\nless I/O needed\nless memory needed\nfaster response\nmore users\n\n\n\npage is needed → reference to it\n\ninvalid reference → abort\nnot in memory → bring to memory\n\n\n\nLazy swapper(Pager)\n\n\nvalid-invalid bit\n\n1- valid and in memory\n0- invalid or not in memory(default)\n\n\n\npage fault\n\n\ninvalid reference &gt; abort\n\n\njust not in memory\n\n\nget empty frame\n\n\nswap page into farame\n\n\nreset tables validation bit = 1\n\n\nrestart instruction\n\n\n\npage fault rate p\np==0, no page faults\np==1, every reference is a fault\nEffective Access Time(EAT)\n\nEAT=(1−p)×memory access time+p(page fault overhead)EAT = (1-p)\\times memory\\ access\\ time + p(page\\ fault\\ overhead)EAT=(1−p)×memory access time+p(page fault overhead)\npage faultoverhead=service the page=fault interrupt+[swap page out]+swap page in+restart overheadpage\\ fault overhead = service  \\ the \\ page = fault \\  interrupt+[swap\\ page\\ out]+swap\\ page\\ in+restart\\ overheadpage faultoverhead=service the page=fault interrupt+[swap page out]+swap page in+restart overhead\n\n\n\n\n\n\n\n\n\npage replacement\n\nlarge virtual memory can be provided on a smaller physical memory\nsame pages may be brought into memory several times\n\n\n\nbasic page replacement\n\nfind a free frame and use it\nif no frame free, use a page replacement algorithm to select a victim frame\nwrite the victim frame to the disk and change the page and frame tables\nread the desired page into the free frame. Update the page and frame tables\nrestart the process\nuse modify bit to reduce overhead of page transfers(if not modified,not write)\nlowest page fault rate\n\n\n\nAlgorithm\n\nFIFO first in first out\nLRU least recently used\nLRU approximation algorithms\n\nsecond chance algorithm\nclock replacement(FIFO)\nif the page to be replaced has reference bit = 1.then\n\nset reference bit 0\nleave page in memory\nreplace next page, subject to same rules\n\n\nReference bit\n\ninitially = 0\nreferenced bit =1\nreplace the one which bit is 0\n\n\nkeep a counter of the number of references that have been made to each page\nLFU\n\nreplace pages with smallest count\n\n\nMFU\n\nbased on the argument that the page with the smallest count was probably just brought in and has yet to be used\n\n\n\n\nOPT 最佳置换算法\n\n\n\nallocation of frames\n\nFixed allocation\n\nequal allocation\nproportional allocation\n\nallocation according to the size of the process\nsi = size of process pi\ns=∑\\sum∑si\nm=total number of frames\nai = allocation for pi = sis×m\\frac{s_i}{s}\\times mssi​​×m\n\n\n\n\npriority allocation\n\nuse a proportional allocation scheme using priorities rather than size\nif process pi generates a page fault\n\nselect for replacement one of its frames\nselect for replacement a frame from a process with lower priority numebr\n\n\nGlobal or local allocation\n\nglobal\n\nselect from all frames\n\n\nlocal\n\nselect from its own set\n\n\n\n\n\n\n\n\n\nthrashing(颠簸)\n\n\n\n\n\n\nif a CPU does not have “enough” frames, the page fault rate is very high\n\nlow CPU utilization\noperating system thinks that it needs to increase the degree of multiprogramming\nanother process is added to the system\n\n\n\nA process is busying swapping pages in and out\n\n\nWhy does paging work\n\nlocality model\n\na locality is a set of pages that are actively used together\nprocess migrates form one locality to another\nlocalities may overlap\n\n\n\n\n\nwhy does the trashing occur\n\nsize of locality &gt; allocated memory size\n\n\n\nWorking set model\n\n\nΔ ≡ working-set window ≡ a fixed number of page references\n\n\nWSSi (Working set of process Pi)\n\n\nto small not encompass entire loclity\n\n\nto large encompass several localities\n\n\n∞ encompass entire program\n\n\n\n\nestablish “acceptable” page fault rate\n\n\n\n\nmemory-mapped files\n\n\nallocation-mapped files\n\n\nallocating kernel memory\n\n\ntreated different form user memory\n\n\noften allocated from a free-memory pool\n\nkernel requests memory for structures of varying sizes\nsome kernel memory needs to be contiguous\n\n\n\nbuddy system\n\n\n\n\nslab allocator\n\n\n\n\n\n\nother consideration\n\nprepaging\npage size\n\nfragmentation ,small page\ntable size, large page\nI/O overhead, large page\nlocality, small page\nTLB reach = TLB size x page size\n\nmultiple page size\n\n\nprogram structure\nI/O interlock\n\n\n\n\n\noperating system examples\n\n\n Chapter 10 File system interface\n\n\nfile concept\n\n\na file is a named collection of related information that is recorded on secondary storage\n\n\ncontiguous logical address space\n\n\nfile structure\n\nsimple record structure\n\nlines\nfixed length\nvariable length\n\n\ncomplex structures\n\nformatted document\nrelocatable load file\n\n\n\n\n\narrributes\n\nname\nldentifier\ntype\nlocation\nsize\nprotection\ntime,date, and user identification\ninformation about file are kept in the directory structure, which is maintained on the disk\n\n\n\noperation\n\ncreate\nwrite\nread\nreposition within file - file seek\ndelete\ntruncate (截短)- erase the contents of a file but keep its arrtibutes\nopen\nclose\ninternal tables\n\nper-process open file table\nsystem-wide open file table\n\n\n\n\n\naccess methods\n\n\nsequential access\n\nrewind/read/wrire\n\n\n\ndirect access\n\n\n\n\ndirectory structure\n\ndisks are split into on or more partitions\neach partition contains information about files within it\nthe information is kept in entries in a device directory or volume table of contents\n\n\n\noperation performed on directory\n\nsearch for a file\ncreate a file\ndelete a file\nlist a directory\nrename a file\ntraverse the file system\n\n\n\norganize the file directory(Logically) to obrain\n\nefficiency = locating a file quickly\nnaming -convenient to users\n\ntwo users can have same for different files\nthe same file can have several different name\n\n\ngrouping - logical grouping of files by properties\n\n\n\nDirectory\n\n\nPr\n\nnaming\ngrouping\npathname\nsame file for different user\nefficient searching\ngrouping capability\n\n\n\nsingle level directory\n\n\n\n\ntwo level directory\n\n\nseparate directory for each user\n\n\n\n\n\n\nTree structured directories\n\n\n\n\nefficient searching\n\n\ngrouping capability\n\n\ncurrent directory( working directory )\n\n\nabsolute / relative path name\n\n\ncreating a new file is done in current directory\n\n\ndelete a file\n\n\nmkdir\n\n\nacyclic graph directories\n\n\nshared subdirectories and files\n\n\ntwo different names(aliasing)\n\n\nif dict deletes count &gt; dangling pointer\n\n\nsolutions\n\nbackpointers, so we can delete all pointers\nentry hold count solution\n\n\n\n\n\n\n\nhow to guarantee no cycles\n\nallow only links to file not subdirections\ngarbage collecton\nevery time a new link is added use a cycle detection algorithm to determine whether it is OK\n\n\n\n\n\n\n\n\n\nfile system mounting\n\na file system must be mounted before it can be accessed\nan unmounted file system is mounted at a mount point\n\n\n\nfile sharing\n\nsharing of files on multi-user system is desirable\nsharing may be done though a protection scheme\non distributed systems, files ay be shared across a network\nnetwork file system(NFS) is a common distributed file sharing method\n\n\n\nprotection\n\nowner / creator control\n\nwhat can be done by whom\n\n\ntype of access\n\nread\nwrite\nexecute\nappend\ndelete\nlist\n\n\n\n\n\n Chapter 11 File system implementation\n\n\nfile system structure\n\nfile structure\n\nlogical storage unit\ncollection of related information\n\n\nfile system resides on secondary storage(disks)\nfile system organized into layers\napplication programs &gt; logical file system &gt; file-organization module &gt; basic file system &gt; I/O control &gt; devices\n\n\n\nfile system implementation\n\n\nfile control block\n\nfile permissions\nfile dates\nfile owner, group, ACL\nfile size\nfile data blocks or pointers to file data blocks\n\n\n\nin memory file system structures\n\n\n\n\nvirtual file systems\n\nvirtual file system(VFS) provide an object oriented way of implementing file systems\nVFS allows the same system call interface (API) to be used for different types of file systems\nThe API is to the VFS interface, rather than any specific type of file system\n\n\n\n\n\ndirectory implementation\n\nlinear list of file names with pointer to the data blocks\n\nsimple to program\ntime consuming to exectute\n\n\nHash table - linear list with hash data structure\n\ndecreases directory search time\ncollisions - situations where two file names hash to the same location\n\n\n\n\n\nallocation methods\n\n\nan allocation method refers to how disk blocks are allocated for files\n\n\ncontiguous allocation\n\n\nsimple\n\n\nrandom access (sequential direct)\n\n\nwasteful of space (dynamic storage allocation problem)\n\n\nfiles cannot grow\n\n\n\nextent-based systems\n\nmany newer file system use a modified contiguous allocation scheme\nextent-based file systems allocate disk blocks in extents\nan extent is a contiguous block of disks\n\nextents are allocated for file allocation\na file consists of one or more extents\n\n\n\n\n\n\n\n\n\nlinked allocation\n\n\neach file is a liked list of disk blocks\n\n\nblocks may be scattered anywhere on the disk\n\n\nsimple\n\n\nno waste of space\n\n\nfiles can grow\n\n\nno random access\n\n\neach block contains a pointer, wasting space\n\n\nblocks scatter everywhere and a large number of disk seeks may be necessay\n\n\nreliability - if a pointer is lost or damaged?\n\n\n\n\nfile allocation table\n\n\n\n\n\n\n\n\nindexed allocation\n\n\nbring all pointers together into the index block\n\n\na file’s directory entry contains a pointer to its index. Hence, the index block of an indexed allocation plays the same role as the page table\n\n\n\n\nrandom access\n\n\nthe indexed allocation suffers from wasted space. The index block may not be fully used\n\n\nthe number of entries of an index table determines the size of a file\n\nOvercome\n\nmultiple index blocks, chain them into a inked list\nmultiple index blocks, but make them into a tree just like the indexed access method(multilevel)\na combination of both\n\n\n\n\n\n\n\n\n\n\n\nfree space management\n\n\nfree space list\n\n\nbit vector\n\n\n\n\nblock number calculation\n= number of bits per word *\nnumber of 0-value words +\noffset of first 1 bit\n\n\nrequires extra space\n\n\neasy to get contiguous files\n\n\n\n\nlinked list\n\n\ncannot get contiguous space easily\n\n\nno waste of space\n\n\n\n\n\n\ngrouping\n\n\n\n\naddress counting\n\n\nto make list short with the following trick\n\n\nblocks are often allocated and freed in groups\n\n\nfor every group, we can store the address of the first free block and the number of the following n free blocks\n\n\n\n\n\n\n\n\nlinked list + grouping\n\n\nlinked list + address + count\n\n\n\n\n\n\nefficiency and performance\n\nefficiency dependent on\n\ndisk allocation and directory management algorithms\ntype of data kept in file’s directory entry\n\n\nperformance\n\ndisk cache\nfree-behind and read-ahead (optimize sequential access)\nvirtual disk, ram disk , etc.\n\n\npage cache\n\n\n\nrecovery\n\nconsistency checking\nback up data from disk to another\nrecover lost file or disk by restoring data from backup\n\n\n\nlog structured file systems (审计和统计)\n\nrecord each update to the file system as a transaction\nall transactions are written to a log\n\n\n\nNFS\n\nnetwork file system\n\n\n\n Chapter 12 mass storage structure\n\n\ndisk structure\n\n\nmagnetic disks provide bulk of secondary storage of modern computers\n\ntransfer rate\n\ndata flow between drive and computer\n\n\npositioning time\n\nrandom access time\n\ntime to move disk arm to desired cylinder (seek time) and time for desired sector to rotate under the disk head (rotational latency)\nhead crash results from disk head making contact with the disk surface\n\n\n\n\ndisk can be removeable\nattached to computer via I/O bus\n\nhost controller in computer uses bus to talk to disk controller built into drive or storage array\n\n\nlogical blocks\n\nsector 0 outmost\nfrom outmost to inner most\n\n\n\n\n\n\n\ndisk attachment\n\nhost attached via an I/O port\nnetwork attached via a network connection\n\n\n\ndisk scheduling\n\n\naccess time\n\nseek time\nrotational latency\n\n\n\ndisk bandwidth\n\nthe total number of bytes transferred, divided by the total time between the first request for service and the completion of the last transfer\n\n\n\nFCFS\n\n\nSSTF(shortest seek time first)\n\n\nmay cause starvation of some requests\n\n\nSCAN - elevator algorithm\n\n\nC-SCAN\n\n\nprovide a more uniform wait time than SCAN\n\n\n\n\n\n\nC-LOOK\n\n\n\n\nSSTF is common and has natural appeal\n\n\nSCAN and C-SCAN perform better for systems that place a heavy load on the disk\n\n\neither SSTF or LOOK is a reasonable choice for the default algorithm\n\n\nperformance depends on the number and types of reuests\n\n\nrequests for disk service can be influences by the file-allocation method\n\n\n\n\ndisk management\n\n\ndisk formatting\n\n\nlow-level formatting, of physical formatting\n\n\ndividing a disk into sectors that the disk controller can read and write\n\n\n\n\npartition\n\n\nlogical formatting\n\nmaking a file system\n\n\n\n\n\n\n\nboot block\n\n\nboot block initializes system\n\n\nthe bootstrap is stored in ROM\nbootstrap loader program\n\n\n\n\n\n\n\n\nError handling\n\n\na disk track with a bad sector\n\n\nsubstituting a spare for the bad sector\n\n\nshifting all the sectors to bypass the bad one\n\n\n\n\n\n\n\n\nswap space management\n\nswap space\n\nswap space can be carved out of the normal file system, or, more commonly, it can be in a separate disk partition\n\n\n\n\n\nRAID structure\n\n\nRedundant Array of Independent Disk (冗余磁盘阵列)\n\n\nimproves reliability via redundancy and performance via parallelism\n\n\nraid is arranged into dix different levels\n\n\n\n\n\n\nstable storage implementation\n\n\ntertiary storage devices\n\n\n​\n","plink":"ilucia.github.io/Review/OS/"},{"title":"高级数据结构复习","date":"2019-06-10T19:59:55.000Z","updated":"2022-04-27T15:24:01.595Z","content":" 平摊分析与基本思路\n Aggregate method （聚集分析）\n Potential Function\nP(i)=amortizedCost(i)−actualCost(i)+P(i−1)P(i)=amortizedCost(i)-actualCost(i)+P(i-1)P(i)=amortizedCost(i)−actualCost(i)+P(i−1)\n∑(P(i)−P(i−1))=∑(amortizedCost(i)−actualCost(i))\\sum(P(i)-P(i-1))=\\sum(amortizedCost(i)-actualCost(i))∑(P(i)−P(i−1))=∑(amortizedCost(i)−actualCost(i))\nP(n)−P(0)=∑(amortizedCost(i)−actualCost(i))P(n)-P(0)=\\sum(amortizedCost(i)-actualCost(i))P(n)−P(0)=∑(amortizedCost(i)−actualCost(i))\nP(n)−P(0)≥0P(n)-P(0)\\geq 0P(n)−P(0)≥0\nWhen P(0)=0,P(i) is the amount by which the first i operations have been over charged\n Accounting method (记账分析)\nGuess that the amortized cost of an increment is 2\nNow show that P(m)-P(0) &gt;= 0 is all for m\n1st increment:\n\none unit of amortized cost is used to pay for the change in bit 0 from 0 to 1\nthe other unit remains as a credit on bit and is used later to pay for the time when bit 0 changes form 1 to 0\n\nnthcreament\n​\t…\nP(m)−P(0)=∑(amotyizedCost(i)−actualCost(i))P(m)-P(0)=\\sum(amotyizedCost(i)-actualCost(i))P(m)−P(0)=∑(amotyizedCost(i)−actualCost(i))\n= amount by which the first m increments have been over charged\n=number of credits\n= number of 1s\n≥0\\geq 0≥0\n Potential method (势能法)\nGuess a suitable potential funciton for whtich P(n)−P(0)≥0P(n)-P(0) \\geq 0P(n)−P(0)≥0 for all n\nDerive amortized cost for ith operation usting ΔP=P(i)−P(i−1)=amortizedCost−actualCost\\Delta P = P(i)-P(i-1)=amortizedCost  - actualCostΔP=P(i)−P(i−1)=amortizedCost−actualCost\namortizedCost=acutalCost+ΔPamortizedCost  = acutalCost + \\Delta PamortizedCost=acutalCost+ΔP\n 数据结构、二叉树与树\n\n\nArbitrary Ordered Trees\n\n\nUse parenthesis notation to represent the tree\n\n\nAs the binary string(((())())((())()())): traverse tree as “(“ for node, then subtrees, then “)”\n\n\n2 Bits per node\n\n\n\n\n\n\nHeap-like notation\n\n\n\n\nOrded threes\n\nparent\nfirst child\nnext sibling\ndegree\nsubtree size\n\n\n\nLevel-order degree sequence\n\n\n\n\n 外排序\n 缓冲使用策略，原因和方法\n\n\nReason\n\n\nnot feasible to input n records, sort and output in sorted order\n\n\nALU-main memory-disk\n\n\nprefetch\n\n\n\n\n3 input/output buffers\n\ninput, small, large\nmiddle\nfill middle group from disk\nif next record ≤\\leq≤ middle-min- send to small\nif next record ≥\\geq≥ middle-max- send to large\nelse remove middle-min- or middle-max from middle and add new record to middle group\nfill input buffer when it gets empty\nwrite small/large buffer when full\nwrite middle group in sorted order when done\ndouble-ended priority queue\n\n\n\nInternal Merge Sort\n\ncreate initial sorted segments\nmerge pairs of sorted segmetns in merge passes, until only 1 segment remains\n\n\n\nExternal Merge Sort\n\nrun generation\n\na run is a sorted sequence of records\n\n\nrun merging\n\n\n\nRun generation\n\nloser tree\n\n\n\nTournament Trees\n\n\nHuffman trees\n\n\nDouble-ended priority queues\n\n\nBuffering\n\n\n 红黑树\n 最小最大堆\n 插入\n只需要将节点插在二叉树的最后一个叶子结点位置，然后比较它对它父亲节点的大小，如果大则停止；如果小则交换位置，然后对父亲节点递归该过程直至根节点。复杂度为O(log(n))O(log(n))O(log(n))。\n一般来说，插入的位置可以不是最后一个叶子节点，可以作为任意中间节点的孩子节点插入，将这个叶子节点变为中间节点后，按上文所说的方法调整节点顺序以保证维持堆特性不变。\n 删除\n要从堆中删除一个节点，用最后一个节点替换掉要删除的节点，然后调整节点顺序以维持堆特性。\n 设计数据结构与算法\n Review\n\nAmoritized analysis\nSuccinct data structures\nFunction for bit vectors\n\nBInary trees\nOrdered tree\n\n\nString matching\n\nBM\n\n\nDouble ended priority\nExternal Sort\n\nbuffer management\n\n\nRed-black trees\naugmenting data structures\n\n","plink":"ilucia.github.io/Review/AdvancedDataStructures/"},{"title":"Win32 API 银行家算法的实现","date":"2019-05-26T00:00:00.000Z","updated":"2022-04-27T15:24:01.559Z","content":"\nPs:就是拿自己写的报告\n\n一、基本信息\n\n\n\n实验题目\n完成人姓名\n学号\n报告日期\n\n\n\n\n银行家算法的实现\nHanyuu\nNone\n2019/0525\n\n\n\n 二、实验目的\n通过实验，加深对多实例资源分配系统中死锁避免方法——银行家算法的理解，掌握 Windows 环境下银行家算法的实现方法，同时巩固利用 Windows API进行共享数据互斥访问和多线程编程的方法。\n 三、实验内容\n\n在 Windows 操作系统上，利用 Win32 API 编写多线程应用程序实现银行家算法。\n创建 n 个线程来申请或释放资源，只有保证系统安全，才会批准资源申请。\n通过 Win32 API 提供的信号量机制，实现共享数据的并发访问\n\n 四、实验步骤，主要数据结构和说明\n 设计思路\n 设计\n\n\n系统的各种资源类型被收纳在ResourceRow中，每个程序都有自己的allocation，max，need的resourceRow对象以表示其对应资源的数量。Container为每个注册的进程分配一个全局唯一的pid。启动进程通过调用start函数调起running工作线程。Container保持对资源的调配，所有线程需要资源都要向container发起请求，使用完毕后要向container声明释放资源。\n 流程图\n123456789101112Process-&gt;Container:Register processnote left of Process:Initialize the containerProcess-&gt;Container:Register max,allocatedNote left of Process:Request some resourcesProcess-&gt;Container:Request some resourcesContainer-&gt;ResourceCols:Check if the resource remained\\n is enough to support all processResourceCols-&gt;Container:Return the resultsContainer-&gt;ResourceCols:Modify the resource listContainer-&gt;Process:Return the results of \\nthe request(Permit/Forbid)Note left of Process:Relsase some resourcesProcess-&gt;Container:Testify the release of the resourceContainer-&gt;ResourceCols:Modify the resource list\n五、程序运行的结果\n\n\n 六、实验体会\n构建一个相对完整的运行体系比纯粹实现一个单独的功能相对要复杂不少。但是拥有良好的可扩展性和易于修改的特性。\n 七、源代码\nProcessRow.h\n123456789101112131415161718192021222324252627282930313233343536#pragma once#include&lt;string&gt;#include&lt;sstream&gt;const unsigned ROW_COUNT = 4;const unsigned MAX_PROCESS = 512;struct ResourceRow&#123;public:\tunsigned res[ROW_COUNT];\tResourceRow()\t&#123;\t\tfor (unsigned i = 0; i &lt; ROW_COUNT; ++i)\t\t&#123;\t\t\tres[i] = 0;\t\t&#125;\t&#125;\tResourceRow(unsigned* input)\t&#123;\t\tfor (int i = 0; i &lt; ROW_COUNT; ++i)\t\t&#123;\t\t\tres[i] = input[i];\t\t&#125;\t&#125;\tstd::string str()\t&#123;\t\tstd::stringstream res;\t\tfor (unsigned i = 0; i &lt; ROW_COUNT; ++i)\t\t&#123;\t\t\tres &lt;&lt; this-&gt;res[i] &lt;&lt; \" \";\t\t&#125;\t\treturn res.str();\t&#125;&#125;;bool operator&gt;=(const ResourceRow&amp; a, const ResourceRow&amp; b);\nProcessRow.cpp\n12345678910#include\"resourceRow.h\"bool operator&gt;=(const ResourceRow&amp; a, const ResourceRow&amp; b)&#123;\tfor (int i = 0; i &lt; ROW_COUNT; ++i)\t&#123;\t\tif (a.res[i] &lt; b.res[i])\t\t\treturn false;\t&#125;\treturn true;&#125;\nProcessCol.h\n123456789101112131415161718192021222324252627#pragma once#include &lt;process.h&gt;#include &lt;Windows.h&gt;#include\"resourceRow.h\"//#include \"Container.h\"//#include \"banker.h\"//extern const unsigned ROW_COUNT = 4;//extern const unsigned MAX_PROCESS = 512;//extern HANDLE mutex;//extern HANDLE Rmutex;//extern class Container;//extern Container* container;class ProcessCol&#123;public:\tunsigned pid;\tResourceRow allocation;\tResourceRow max;\tResourceRow need;\tstatic DWORD WINAPI running(LPVOID lpThreadParemeter);\tHANDLE start();\tProcessCol(unsigned pid);\tProcessCol();&#125;;\nProcessCol.cpp\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108#pragma once#include &lt;process.h&gt;#include &lt;Windows.h&gt;#include\"resourceRow.h\"//#include \"Container.h\"//#include \"banker.h\"//extern const unsigned ROW_COUNT = 4;//extern const unsigned MAX_PROCESS = 512;//extern HANDLE mutex;//extern HANDLE Rmutex;//extern class Container;//extern Container* container;class ProcessCol&#123;public:\tunsigned pid;\tResourceRow allocation;\tResourceRow max;\tResourceRow need;\tstatic DWORD WINAPI running(LPVOID lpThreadParemeter);\tHANDLE start();\tProcessCol(unsigned pid);\tProcessCol();&#125;;#pragma once#include &lt;process.h&gt;#include &lt;Windows.h&gt;#include\"resourceRow.h\"//#include \"Container.h\"//#include \"banker.h\"//extern const unsigned ROW_COUNT = 4;//extern const unsigned MAX_PROCESS = 512;//extern HANDLE mutex;//extern HANDLE Rmutex;//extern class Container;//extern Container* container;class ProcessCol&#123;public:\tunsigned pid;\tResourceRow allocation;\tResourceRow max;\tResourceRow need;\tstatic DWORD WINAPI running(LPVOID lpThreadParemeter);\tHANDLE start();\tProcessCol(unsigned pid);\tProcessCol();&#125;;#pragma once#include &lt;process.h&gt;#include &lt;Windows.h&gt;#include\"resourceRow.h\"//#include \"Container.h\"//#include \"banker.h\"//extern const unsigned ROW_COUNT = 4;//extern const unsigned MAX_PROCESS = 512;//extern HANDLE mutex;//extern HANDLE Rmutex;//extern class Container;//extern Container* container;class ProcessCol&#123;public:\tunsigned pid;\tResourceRow allocation;\tResourceRow max;\tResourceRow need;\tstatic DWORD WINAPI running(LPVOID lpThreadParemeter);\tHANDLE start();\tProcessCol(unsigned pid);\tProcessCol();&#125;;#pragma once#include &lt;process.h&gt;#include &lt;Windows.h&gt;#include\"resourceRow.h\"//#include \"Container.h\"//#include \"banker.h\"//extern const unsigned ROW_COUNT = 4;//extern const unsigned MAX_PROCESS = 512;//extern HANDLE mutex;//extern HANDLE Rmutex;//extern class Container;//extern Container* container;class ProcessCol&#123;public:\tunsigned pid;\tResourceRow allocation;\tResourceRow max;\tResourceRow need;\tstatic DWORD WINAPI running(LPVOID lpThreadParemeter);\tHANDLE start();\tProcessCol(unsigned pid);\tProcessCol();&#125;;\nContainer.h\n12345678910111213141516#pragma once#include\"processCol.h\"class Container&#123;public:\tProcessCol list[MAX_PROCESS];\tunsigned processCount;\tResourceRow avilable;\tvoid print();\tContainer();\tbool pushProcess(ProcessCol* process);\tvoid release(unsigned pid);\tvoid requests(unsigned pid, ResourceRow request);&#125;;\nContainer.cpp\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112#pragma once#include&lt;iostream&gt;#include\"Container.h\"Container* container;extern HANDLE mutex;extern HANDLE Rmutex;void Container::print()&#123;\tstd::cout &lt;&lt; \"[avilable]\" &lt;&lt; avilable.str() &lt;&lt; std::endl;\tfor (unsigned i = 0; i &lt; processCount; ++i)\t&#123;\t\tstd::cout &lt;&lt; list[i].pid &lt;&lt; \"    \" &lt;&lt; list[i].allocation.str() &lt;&lt; \"    \" &lt;&lt; list[i].max.str() &lt;&lt; \"    \" &lt;&lt; list[i].need.str() &lt;&lt; std::endl;\t&#125;\tstd::cout &lt;&lt; std::endl;&#125;Container::Container()&#123;\tprocessCount = 0;\tmutex = CreateSemaphore(nullptr, 1, 1, nullptr);\tRmutex = CreateSemaphore(nullptr, 1, 1, nullptr);\t//for (unsigned i = 0; i &lt; MAX_PROCESS; ++i)\t//&#123;\t//\tlist[i] = nullptr;\t//&#125;&#125;bool Container::pushProcess(ProcessCol* process)&#123;\tif (processCount &gt;= MAX_PROCESS - 1)\t&#123;\t\treturn false;\t&#125;\tprocess-&gt;pid = processCount;\tlist[processCount] = *process;\tprocessCount += 1;\treturn true;&#125;void Container::release(unsigned pid)&#123;\tWaitForSingleObject(mutex, INFINITE);\tfor (unsigned i = 0; i &lt; ROW_COUNT; ++i)\t&#123;\t\tavilable.res[i] += list[pid].allocation.res[i];\t\tlist[pid].allocation.res[i] = 0;\t\tlist[pid].need.res[i] = list[pid].max.res[i];\t&#125;\tstd::cout &lt;&lt; \"pid: \" &lt;&lt; pid &lt;&lt; \" 已释放\" &lt;&lt; std::endl;\tcontainer-&gt;print();\tReleaseSemaphore(mutex, 1, nullptr);&#125;void Container::requests(unsigned pid, ResourceRow request)&#123;\tWaitForSingleObject(mutex, INFINITE);\tResourceRow newAvilable;\tfor (int i = 0; i &lt; ROW_COUNT; ++i)\t&#123;\t\tnewAvilable.res[i] = avilable.res[i];\t&#125;\tunsigned count = this-&gt;processCount;\tbool* flag = new bool[count];\tfor (unsigned i = 0; i &lt; count; ++i)\t&#123;\t\tflag[i] = false;\t&#125;\twhile (count &gt; 0)\t&#123;\t\tbool key = false;\t\tfor (unsigned i = 0; i &lt; this-&gt;processCount; ++i)\t\t&#123;\t\t\tif (flag[i] == false)\t\t\t&#123;\t\t\t\tif (newAvilable.res &gt;= list[i].need)\t\t\t\t&#123;\t\t\t\t\tfor (unsigned j = 0; j &lt; ROW_COUNT; ++j)\t\t\t\t\t&#123;\t\t\t\t\t\tnewAvilable.res[i] += list[i].allocation.res[i];\t\t\t\t\t&#125;\t\t\t\t\tflag[i] = true;\t\t\t\t\tkey = true;\t\t\t\t\tcount -= 1;\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;\t\tif (count == 0)\t\t&#123;\t\t\tstd::cout &lt;&lt; \"pid: \" &lt;&lt; pid &lt;&lt; \" 请求成功\" &lt;&lt; std::endl;\t\t\tfor (unsigned i = 0; i &lt; ROW_COUNT; ++i)\t\t\t&#123;\t\t\t\tlist[pid].allocation.res[i] += request.res[i];\t\t\t\tlist[pid].need.res[i] -= request.res[i];\t\t\t\tavilable.res[i] -= request.res[i];\t\t\t&#125;\t\t\tcontainer-&gt;print();\t\t\tReleaseSemaphore(mutex, 1, nullptr);\t\t\treturn;\t\t&#125;\t\tif (key == false)\t\t&#123;\t\t\tstd::cout &lt;&lt; \"pid: \" &lt;&lt; pid &lt;&lt; \"请求失败\" &lt;&lt; std::endl;\t\t\tcontainer-&gt;print();\t\t\tReleaseSemaphore(mutex, 1, nullptr);\t\t\treturn;\t\t&#125;\t&#125;\tfor (int i = 0; i &lt; ROW_COUNT; ++i)\t&#123;\t\tavilable.res[i] -= request.res[i];\t\tlist[pid].allocation.res[i] += request.res[i];\t\tlist[pid].need.res[i] = list[pid].max.res[i] - list[pid].allocation.res[i];\t&#125;\t//ReleaseSemaphore(mutex, 1, nullptr);&#125;\nBanker.h\n1234567891011#pragma once#include &lt;iostream&gt;#include &lt;Windows.h&gt;#include &lt;process.h&gt;#include &lt;iostream&gt;#include &lt;stdlib.h&gt;#include &lt;string&gt;#include &lt;sstream&gt;#include &lt;time.h&gt;#include\"Container.h\"#include\"processCol.h\"\nBanker.cpp\n123456789101112131415161718192021222324#include\"banker.h\"extern Container* container;int main()&#123;\tsrand((int)time(0));\tcontainer = new Container();\tfor (unsigned i = 0; i &lt; 4; ++i)\t\tcontainer-&gt;pushProcess(new ProcessCol());\tcontainer-&gt;avilable.res[0] = 10;\tcontainer-&gt;avilable.res[1] = 10;\tcontainer-&gt;avilable.res[2] = 20;\tcontainer-&gt;avilable.res[3] = 9;\tHANDLE* hdl = new HANDLE[container-&gt;processCount];\tfor (unsigned i = 0; i &lt; container-&gt;processCount; ++i)\t&#123;\t\thdl[i] = container-&gt;list[i].start();\t&#125;\tfor (unsigned i = 0; i &lt; container-&gt;processCount; ++i)\t&#123;\t\tWaitForSingleObject(hdl[i],INFINITE);\t&#125;\tSleep(40000);&#125;\n","plink":"ilucia.github.io/Others/BankersAlgorithm/"},{"title":"生产者消费者问题解决（windows API和Pthread双解决方案）","date":"2019-05-09T00:00:00.000Z","updated":"2022-04-27T15:24:01.559Z","content":"\nPs:就是拿自己写的报告\n\n 一、实验目的\n通过实验，掌握Windows 和 Linux 环境下互斥锁和信号量的实现方法，加 深对临界区问题和进程同步机制的理解，同时熟悉利用Windows API 和 Pthread API 进行多线程编程的方法\n 二、实验内容\n\n在Windows 操作系统上，利用 Win32 API 提供的信号量机制，编写应用\n程序实现生产者——消费者问题。\n在 Linux 操作系统上，利用 Pthread API 提供的信号量机制，编写应用程\n序实现生产者——消费者问题。\n两种环境下，生产者和消费者均作为独立线程，并通过 empty、full、mutex 三个信号量实现对缓冲进行插入与删除。\n通过打印缓冲区中的内容至屏幕，来验证应用程序的正确性。\n\n 三、实验环境\n\n\nwindows 10 1903\n\n\nWindows API\n\nVisual Studio 2019\n\n\n\nPthread API\n\n\nWIndows Subsystem for Linux\n\n\nUbuntu 4.4.0-18362-Microsoft #1-Microsoft Mon Mar 18 12:02:00 PST 2019 x86_64 x86_64 x86_64 GNU/Linux\n\n\ng++ 7.4.0\n\n\nGNU gdb 8.1.0.20180409-git\n\n\nvisual studio code 1.33.1\n\n\n\n\n\n\n 四、实验步骤\n\n\n思路\n\n\nShared data\n\nSemaphore\n\nfull\t//指示缓冲区中已有内容数目，防止消费者尝试从空的缓冲区中读取内容\nempty //指示缓冲区中可用内容数目，方式生产者尝试向已满的缓冲区中存放内容\nmutex //访问锁，保证同一时刻至多只有一个用户在访问buffer\n\n\ninitially\n\nfull=0\nempty = n\nmutex = 1\n\n\n\n\n\nProducer Process\n123456789do&#123;  // Produce an item in nextp  wait(empty);  wait(mutex);  // add nextp to buffer  signal(mutex);  signal(full);&#125;while(1);\n\n\nConsumer Process\n12345678do&#123;  wait(full);  wait(mutex);  // remove nextp to buffer  signal(mutex);  signal(empty);&#125;while(1);\n\n\n\n\n 五、主要数据结构及说明\n\n信号量\n\nfull\n\n指示缓冲区中已有内容数目，防止消费者尝试从空的缓冲区中读取内容\n\n\nempty\n\n指示缓冲区中可用内容数目，方式生产者尝试向已满的缓冲区中存放内容\n\n\nmutex\n\n访问锁，保证同一时刻至多只有一个用户在访问buffer\n\n\n\n\n缓冲区\n\n实现结构\n\n定长数组\n\n\n逻辑结构\n\n循环队列\n\n\n\n\n\n 六、程序运行的初值和运行结果\n\n\nWindows API\n\n\n初值\n\n\n\n\n运行结果\n\n\n\n\n\n\nPthread API\n\n初值\n\n\n\n\n\n运行结果\n\n\n\n\n\n\n 七、实验体会\n 问题和解决方法\n\nQ\n\ng++编译失败，找不到Pthread链接\n\n\nA\n\n编译路径中不含Pthread,需添加-lpthread\n\n\n\n 体会和收获\n\ng++ gdb多线程调试经验\nwindows API调试Pthread调试经验\n\n 八、源代码\n\n\nsource code\n\n\nwindows API\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677#include &lt;iostream&gt;#include &lt;Windows.h&gt;#include &lt;process.h&gt;#include &lt;iostream&gt;#include &lt;stdlib.h&gt;#include &lt;time.h&gt;constexpr unsigned BUFFER = 10;HANDLE empty;HANDLE full;HANDLE mutex;int in = 0, out = 0;int buffer[BUFFER];void print()&#123;\tfor (int i = 0; i &lt; BUFFER; ++i)\t&#123;\t\tstd::cout &lt;&lt; buffer[i]&lt;&lt;' ';\t&#125;\tstd::cout &lt;&lt; std::endl;&#125;HANDLE WINAPI producer(LPVOID lpParameter)&#123;\tdo\t&#123;\t\tWaitForSingleObject(empty, INFINITE);\t\tWaitForSingleObject(mutex, INFINITE);\t\tbuffer[in] = rand() % BUFFER;\t\tin = (++in) % BUFFER;\t\tstd::cout &lt;&lt; \"product at \" &lt;&lt; in &lt;&lt; std::endl;\t\tprint();\t\tReleaseSemaphore(mutex, 1, nullptr);\t\tReleaseSemaphore(full, 1, nullptr);\t\tSleep(200);\t&#125; while (true);\treturn 0L;&#125;HANDLE WINAPI consumer(LPVOID lpParameter)&#123;\tdo\t&#123;\t\tWaitForSingleObject(full, INFINITE);\t\tWaitForSingleObject(mutex, INFINITE);\t\tbuffer[out] = -1;\t\tout = (out + 1) % BUFFER;\t\tstd::cout &lt;&lt; \"consume at \" &lt;&lt; out &lt;&lt; std::endl;\t\tprint();\t\tReleaseSemaphore(mutex, 1, nullptr);\t\tReleaseSemaphore(empty, 1, nullptr);\t\tSleep(200);\t&#125; while (true);\treturn 0L;&#125;int main()&#123;\tsrand((unsigned)time);\tfor (int i = 0; i &lt; BUFFER; ++i)\t&#123;\t\tbuffer[i] = -1;\t&#125;\tDWORD\tDW;\tempty = CreateSemaphore(nullptr, BUFFER, BUFFER, nullptr);\tfull = CreateSemaphore(nullptr, 0, BUFFER, nullptr);\tmutex = CreateSemaphore(nullptr, 1, 1, nullptr);\tHANDLE p = CreateThread(nullptr, 0, (LPTHREAD_START_ROUTINE)producer, nullptr, 0L, nullptr);\tHANDLE c = CreateThread(nullptr,0, (LPTHREAD_START_ROUTINE)consumer, nullptr, 0L, nullptr);\tHANDLE p1 = CreateThread(nullptr, 0, (LPTHREAD_START_ROUTINE)producer, nullptr, 0L, nullptr);\tHANDLE c1 = CreateThread(nullptr, 0, (LPTHREAD_START_ROUTINE)consumer, nullptr, 0L, nullptr);\tWaitForSingleObject(p, INFINITE);\tWaitForSingleObject(c, INFINITE);\tWaitForSingleObject(p1, INFINITE);\tWaitForSingleObject(c1, INFINITE);\treturn 0;&#125;\n\n\nPthread API\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#include &lt;stdio.h&gt;#include &lt;pthread.h&gt;#include &lt;iostream&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;semaphore.h&gt;#include &lt;time.h&gt;const int BUFFER = 10;sem_t empty, full;pthread_mutex_t mutex;int in = 0;int out = 0;int buffer[BUFFER];void print()&#123;\tfor (int i = 0; i &lt; BUFFER; ++i)\t&#123;\t\tprintf(\"%d \", buffer[i]);\t&#125;\tprintf(\"\\n\");&#125;void *Lproducer(void *arg)&#123;\tdo\t&#123;\t\tsem_wait(&amp;empty);\t\tpthread_mutex_lock(&amp;mutex);\t\tstd::cout &lt;&lt; \"product at \" &lt;&lt; in&lt;&lt;std::endl;\t\tbuffer[in] = rand() % BUFFER;\t\tin = (++in) % BUFFER;\t\tprint();\t\tpthread_mutex_unlock(&amp;mutex);\t\tsem_post(&amp;full);\t\tsleep(1);\t&#125; while (true);\treturn NULL;&#125;void *Lconsumer(void *arg)&#123;\tdo\t&#123;\t\tsem_wait(&amp;full);\t\tpthread_mutex_lock(&amp;mutex);\t\tstd::cout &lt;&lt; \"consumer at\" &lt;&lt; out&lt;&lt;std::endl;\t\tbuffer[out] = -1;\t\tout = (++out) % BUFFER;\t\tprint();\t\tpthread_mutex_unlock(&amp;mutex);\t\tsem_post(&amp;empty);\t\tsleep(1);\t&#125; while (true);\treturn NULL;&#125;int main()&#123;\tfor (int i = 0; i &lt; BUFFER; ++i)\t&#123;\t\tbuffer[i] = -1;\t&#125;\tpthread_t c,c1;\tpthread_t p,p1;\tsem_init(&amp;full, 0, 0);\tsem_init(&amp;empty, 0, BUFFER);\tpthread_create(&amp;c, NULL, Lconsumer, NULL);\tpthread_create(&amp;c, NULL, Lconsumer, NULL);\tpthread_create(&amp;p, NULL, Lproducer, NULL);\tpthread_create(&amp;p, NULL, Lproducer, NULL);\tpthread_join(c, NULL);\tpthread_join(p, NULL);\tpthread_join(c1, NULL);\tpthread_join(p1, NULL);\treturn 0;&#125;\n\n\n\n\n","plink":"ilucia.github.io/Others/boundedBuffer/"},{"title":"算法分析与设计","date":"2019-04-24T23:03:06.000Z","updated":"2022-04-27T15:24:01.595Z","content":"[TOC]\n\n课程内容\n\n\n\n\n算法高级理论\nNP完全性理论与近似性算法\n\n\n\n\n高级算法\n随机化算法、线性规划与网络流\n\n\n基础算法\n递归分治、动态规划、贪心算法、回溯与分支限界\n\n\n算法基础理论\n算法分析与问题的复杂性\n\n\n\n Chapter 1 概述\n\n渐近分析记号\n\n渐近上界OOO\n渐进下界Ω\\OmegaΩ\n紧渐进界Θ\\ThetaΘ\n非紧上界ooo\n非紧下界ω\\omegaω\n\n\nO的运算性质\nNP完全性理论\n\nEasy problem\n\n存在多项式时间算法的问题\n\n\nHard problem\n\n需要指数时间算法解决的问题\n\n\n不可解问题\nP&amp;NP\n判定问题\nk确定性算法和P类问题\n\n对于某个判定问题Π，存在一个非负整数k，对于输入规模为n的实例，能够以O(nk)O(n^k)O(nk)的时间运行一个确定性算法，能够判定的问题\n\n\n非确定性算法和NP类问题\n\n对于某个问题Π，存在一个非负整数k，对于输入规模为n的实例，能够以O(nk)O(n^k)O(nk)的时间运行一个非确定性算法，能够判定的问题\n\n\nNP完全问题(NPC问题)\n\n令Π是个判定问题，如果问题Π属于NP问题，并且对NP类问题中的每一个问题Π’，都有Π′∝pΠ\\Pi&#x27;\\propto_p\\PiΠ′∝p​Π，则称问题为NPC问题\n\n\nNP难问题\n\n令Π是个判定问题，如果对于NP类问题中的每一个问题Π’，都有Π′∝pΠ\\Pi&#x27;\\propto_p\\PiΠ′∝p​Π，则称问题为NP难问题\n\n\n\n\n\n Chapter 2\n 递归与分治策略\n\n\n递归\n\n双递归函数\n整数划分问题\nHanoi问题\n迭代法求解\n\n正确性-归纳验证\n数学归纳法\n\n\n优缺点\n\n\n\n分治\n\n特征\n\n\n问题规模缩小到一定程度可以容易地解决\n\n\n最优子结构性质该问题可以分解为若干个规模较小的相同问题\n\n\n利用该问题分解出的子问题的解可以合并为该问题的解\n\n\n子问题相互独立子问题不包含公共子问题\n\n平衡子问题\n\n\n二分搜索\n大整数乘法\n\n\n\n还原迭代法\n\n\n公式法\nT(n)=\n\\begin{equation}\n\\left\\{\n    \\begin{array}{lr}\n    O(1)\\  n = 1 \\\\\n    aT(\\frac{n}{b})+f(n) \\ n&gt;1\n    \\end{array}\n\\right.\n\\end{equation}\n\n基于还原迭代法，可以得到递归方程的解\nT(n)=nlogba+∑i=0logbn−1aif(nbi)T(n)=n^{log_ba}+\\sum_{i=0}^{log_b{n-1}}a^if(\\frac{n}{b^i})\nT(n)=nlogb​a+i=0∑logb​n−1​aif(bin​)\n\n复杂度分析\n\n\n\n递归树法\n\n\n主定理\n\n设a≥1a\\geq1a≥1,b&gt;1b&gt;1b&gt;1是常数，f(n)f(n)f(n)为函数，T(n)T(n)T(n) 为非负数，且T(n)=aT(nb)+f(n)T(n)=aT(\\frac{n}{b})+f(n)T(n)=aT(bn​)+f(n)，则\n\n若f(n)=O(nlogba−ϵ))f(n)=O(n^{log_ba-\\epsilon}))f(n)=O(nlogb​a−ϵ)),存在ϵ&gt;0\\epsilon&gt;0ϵ&gt;0是常数，则有T(n)=Θ(nlogba)T(n)=\\Theta(n^{log_ba})T(n)=Θ(nlogb​a)\n若f(n)=O(nlogba))f(n)=O(n^{log_ba}))f(n)=O(nlogb​a))，则有T(n)=Θ(nlogbalog n)T(n)=\\Theta(n^{log_ba}log\\ n)T(n)=Θ(nlogb​alog n)\n若f(n)=O(nlogba+ϵ))f(n)=O(n^{log_ba+\\epsilon}))f(n)=O(nlogb​a+ϵ))，存在ϵ&gt;0\\epsilon&gt;0ϵ&gt;0是常数，且对所有充分大的n有af(nb)≤cf(n)af(\\frac{n}{b})\\leq cf(n)af(bn​)≤cf(n)，c&lt;1是常数，则有T(n)=Θ(f(n))T(n)=\\Theta(f(n))T(n)=Θ(f(n))\n\n\n\n\n\nStrassen矩阵乘法\n\n\n二分归并排序/合并排序\n\n\n快速排序\n\n\n最接近点对问题\n\n\n\n\n\n\n Chapter 3\n 动态规划\n\n\n最优化问题\n\n\n最优性原理\n\n每一阶段的决策仅依赖前一阶段产生的状态\n最优子结构性质\n\n\n\n解空间、约束条件、可行解、目标函数、最优解、最优化问题\n\n\n重叠子问题\n\n\n无后效\n\n\n找零问题\n\n\n使用表记录所有已经解决的子问题\n\n\n最短路径问题\n\n\n矩阵连乘问题\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253//3d1-1 重叠子问题的递归最优解//A1 30*35 A2 35*15 A3 15*5 A4 5*10 A5 10*20 A6 20*25//p[0-6]=&#123;30,35,15,5,10,20,25&#125;#include &quot;stdafx.h&quot;#include &lt;iostream&gt; using namespace std;  const int L = 7; int RecurMatrixChain(int i,int j,int **s,int *p);//递归求最优解void Traceback(int i,int j,int **s);//构造最优解int main()&#123;\tint p[L]=&#123;30,35,15,5,10,20,25&#125;;    int **s = new int *[L];\tfor(int i=0;i&lt;L;i++)      &#123;  \t\ts[i] = new int[L];      &#125; \tcout&lt;&lt;&quot;矩阵的最少计算次数为：&quot;&lt;&lt;RecurMatrixChain(1,6,s,p)&lt;&lt;endl;\tcout&lt;&lt;&quot;矩阵最优计算次序为：&quot;&lt;&lt;endl;\tTraceback(1,6,s);\treturn 0;&#125;int RecurMatrixChain(int i,int j,int **s,int *p)&#123;\tif(i==j) return 0;\tint u = RecurMatrixChain(i,i,s,p)+RecurMatrixChain(i+1,j,s,p)+p[i-1]*p[i]*p[j];\ts[i][j] = i;\tfor(int k=i+1; k&lt;j; k++)\t&#123;\t\tint t = RecurMatrixChain(i,k,s,p) + RecurMatrixChain(k+1,j,s,p) + p[i-1]*p[k]*p[j];\t\tif(t&lt;u)\t\t&#123;\t\t\tu=t;\t\t\ts[i][j]=k;\t\t&#125;\t&#125;\treturn u;&#125;void Traceback(int i,int j,int **s)&#123;\tif(i==j) return;\tTraceback(i,s[i][j],s);\tTraceback(s[i][j]+1,j,s);\tcout&lt;&lt;&quot;Multiply A&quot;&lt;&lt;i&lt;&lt;&quot;,&quot;&lt;&lt;s[i][j];\tcout&lt;&lt;&quot; and A&quot;&lt;&lt;(s[i][j]+1)&lt;&lt;&quot;,&quot;&lt;&lt;j&lt;&lt;endl;&#125;\n\n\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071//3d1-2 矩阵连乘 备忘录递归实现//A1 30*35 A2 35*15 A3 15*5 A4 5*10 A5 10*20 A6 20*25//p[0-6]=&#123;30,35,15,5,10,20,25&#125;#include \"stdafx.h\"#include &lt;iostream&gt;using namespace std;const int L = 7;int LookupChain(int i, int j, int **m, int **s, int *p);int MemoizedMatrixChain(int n, int **m, int **s, int *p);void Traceback(int i, int j, int **s); //构造最优解int main()&#123;\tint p[L] = &#123;30, 35, 15, 5, 10, 20, 25&#125;;\tint **s = new int *[L];\tint **m = new int *[L];\tfor (int i = 0; i &lt; L; i++)\t&#123;\t\ts[i] = new int[L];\t\tm[i] = new int[L];\t&#125;\tcout &lt;&lt; \"矩阵的最少计算次数为：\" &lt;&lt; MemoizedMatrixChain(6, m, s, p) &lt;&lt; endl;\tcout &lt;&lt; \"矩阵最优计算次序为：\" &lt;&lt; endl;\tTraceback(1, 6, s);\treturn 0;&#125;int MemoizedMatrixChain(int n, int **m, int **s, int *p)&#123;\tfor (int i = 1; i &lt;= n; i++)\t&#123;\t\tfor (int j = 1; j &lt;= n; j++)\t\t&#123;\t\t\tm[i][j] = 0;\t\t&#125;\t&#125;\treturn LookupChain(1, n, m, s, p);&#125;int LookupChain(int i, int j, int **m, int **s, int *p)&#123;\tif (m[i][j] &gt; 0)\t&#123;\t\treturn m[i][j];\t&#125;\tif (i == j)\t&#123;\t\treturn 0;\t&#125;\tint u = LookupChain(i, i, m, s, p) + LookupChain(i + 1, j, m, s, p) + p[i - 1] * p[i] * p[j];\ts[i][j] = i;\tfor (int k = i + 1; k &lt; j; k++)\t&#123;\t\tint t = LookupChain(i, k, m, s, p) + LookupChain(k + 1, j, m, s, p) + p[i - 1] * p[k] * p[j];\t\tif (t &lt; u)\t\t&#123;\t\t\tu = t;\t\t\ts[i][j] = k;\t\t&#125;\t&#125;\tm[i][j] = u;\treturn u;&#125;void Traceback(int i, int j, int **s)&#123;\tif (i == j)\t\treturn;\tTraceback(i, s[i][j], s);\tTraceback(s[i][j] + 1, j, s);\tcout &lt;&lt; \"Multiply A\" &lt;&lt; i &lt;&lt; \",\" &lt;&lt; s[i][j];\tcout &lt;&lt; \" and A\" &lt;&lt; (s[i][j] + 1) &lt;&lt; \",\" &lt;&lt; j &lt;&lt; endl;&#125;\n\n最长公共子序列\n背包问题\n\n1234567891011121314151617181920212223242526272829303132333435363738#include&lt;iostream&gt;#include&lt;cstring&gt;using namespace std;int main()&#123;    int N;//物品个数 5    int V;//背包容量 15    cin &gt;&gt; N &gt;&gt; V;    int weight[N + 1];// 5 4 7 2 6    int value[N + 1];// 12 3 10 3 6    weight[0] = value[0] = 0;    int maxTotalValue[V + 1]; //maxTotalValue[i]:背包已装容量为i时,背包里所装物品的最大总价值    memset(maxTotalValue, 0, sizeof(maxTotalValue));    for(int i = 1; i &lt;= N; i++)        cin &gt;&gt; weight[i] &gt;&gt; value[i];    for(int j = 1; j &lt;= N; j++)        for(int i = 0; i &lt;= V; i++)            &#123;                cout &lt;&lt; \"背包已装容量:\" &lt;&lt; i &lt;&lt; endl;                if(i &gt;= weight[j])                    &#123;                        if(maxTotalValue[i] &gt;= value[j] + maxTotalValue[i - weight[j]])                            //cout &lt;&lt; \"背包中未装入物品:\" &lt;&lt; j &lt;&lt; endl;                            ;                        else                            &#123;                                maxTotalValue[i] = maxTotalValue[i - weight[j]] + value[j];                                cout &lt;&lt; \"背包中已装入物品:\" &lt;&lt; j &lt;&lt; endl;                            &#125;                    &#125;                else                    //cout &lt;&lt; \"背包中未装入物品:\" &lt;&lt; j &lt;&lt; endl;                    ;            &#125;    cout &lt;&lt; \"背包能装物品的最大总价值:\" &lt;&lt; maxTotalValue[V] &lt;&lt; endl;    return 0;&#125;\n Chapter 4\n 贪心算法\n\n局部最优选择\n*近似解\n找零问题\n最优子结构性质\n贪心选择性质\n活动选择问题\n最优前缀码问题\n最小生成树\n\nPrim算法\nKruskal算法\n\n\n单源最短路径问题\n\n Chapter 5\n 回溯法\n\n\n问题的解向量\n\n\n深度优先、广度优先\n\n\n多米诺性质\n\n\n图着色问题\n\n\n搜索树\n\n\n剪枝\n\n\n会场分配问题\n\n\n解空间\n\nM叉树、子集树、排列树\n\n\n\n回溯\n\n递归回溯\n迭代回溯\n\n\n\n Chapter 6\n 分支限界法\n\n广度优先、最小耗费优先\n队列式分支限界法\n优先队列式分支限界法\n栈式分支限界法\n估值\n代价函数\n最短路径问题\n\nDijakstra算法\n\n\n最大团问题\n\n Chapter 7\n 随机化算法\n\n\n伪随机数\n\n\n随机数值算法\n\n主要用于数值问题求解\n算法的输出往往是近似解\n近似解的精确度与算法执行时间成正比\n\n\n\nSherwood算法\n\n\nta‾(n)=∑x∈XntA(x)∣Xn∣\\overline{t_a}(n)=\\sum_{x\\in X_n}\\frac{t_A(x)}{|X_n|}\nta​​(n)=x∈Xn​∑​∣Xn​∣tA​(x)​\n\n\n主打平均性能\n\n\nLas Vegas算法\n\n随机算法运行一次得到正确解或者无解\n可反复运行LV算法，直到得到正确解为止\n\n\n\nMonte Carlo算法\n\n\n设p是一个实数，且12&lt;p&lt;1\\frac{1}{2}&lt;p&lt;121​&lt;p&lt;1。如果一个MC算法对于问题的任一实例得到正确解的概率不小于p，则称该MC算法是p正确的，且称p−12p-\\frac{1}{2}p−21​是该算法的优势。\n\n\n如果对于同一个实例，Monte Carlo算法不会给出两个不同的正确解答，则称该Monte Carlo算法是一致的\n\n\n如果重复运行一个一致的p正确的MC算法，每次都进行随机选择，即可产生不正确解的概率→任意小\n\n\n对于一个一致的p正确MC算法，要提高正确解的概率，只要执行该算法若干次，并选择出现频次最高的解即可。\n\n\n如果重复调用一个一致的(12+ϵ)(\\frac{1}{2}+\\epsilon)(21​+ϵ)正确的MC算法2m-1次，得到正确解的概率至少为1−δ1-\\delta1−δ,其中\n\n\n\n\nδ=12−ϵ∑i=0m−1(2ii)(14−ϵ2)i≤(1−4ϵ2)m4ϵπm\\delta=\\frac{1}{2}-\\epsilon\\sum_{i=0}^{m-1}\n\\begin{pmatrix}2i\\\\i\\end{pmatrix}\n(\\frac{1}{4}-\\epsilon^2)^i\\leq\\frac{(1-4\\epsilon^2)^m}{4\\epsilon\\sqrt{\\pi m}}δ=21​−ϵi=0∑m−1​(2ii​)(41​−ϵ2)i≤4ϵπm​(1−4ϵ2)m​\n\n主元素问题\n素数测试\n\n","plink":"ilucia.github.io/Review/Algorithm/"},{"title":"计算机网络复习","date":"2019-04-24T10:03:06.000Z","updated":"2022-04-27T15:24:01.603Z","content":"[TOC]\n Chapter 1\n\n计算机网络分类\n\n跨度\n\nPAN、LAN、MAN、WAN、Internet\n\n\n拓补结构\n\nBUS、Star、Ring、Mesh\n\n\n管理性质\n\n公用网、专用网\n\n\n交换方式\n\n电路交换、报文交换、分组交换\n\n\n网络功能\n\n通信子网、资源子网\n\n\n\n\n通信协议的三要素\n\n语法：确定通信双方通信时数据报文的格式\n语义：确定通信双方的通信内容的含义\n时序：指出通信双方信息交互的顺序，如建立连接、数据传输、数据重传、 终止连接\n\n\n\n Chapter 2\n\n\n网络通信基本原理\n\n\n基本概念\n\n\n信道带宽\n\n信道可以不失真地传输信号的频率范围(Hz)\n信道带宽取决于信道的质量\n\n\n\n信道容量\n\n信道在单位时间内可以传输的最大信号量\n数据通信领域：以Data transfer rate(数据传输速率)的形式表 示：信道在单位时间内可以传输的最大比特数\n\n\n\nNyquist‘s Theorem\n\n信道带宽（H）,信道容量（B）,信道数据速率（C）\n无噪声下的B与H的关系： B = 2 × H（Baud)\n无噪声下的C与H的关系： C = 2 × H × log2N (bps) 其中：N为一个码元可取的离散值个数\n\n\n\nShannon’s Theorem\n\n\n信道带宽（H）,信道容量（B）,信道数据速率（C）\n\n\n有热噪声时C、H和噪声的关系：C = H× log2 (1+S/N) (bps)\n其中S为信号功率， N为噪声功率，S/N为信噪比，通常把信噪比表示成 10×lg(S/N) 分贝(dB)\n\n\n\n\n\n\n波特率\n\n每秒钟电平变化的次数（Hz）\n\n\n\n数据传输速率\n\n数据传输速率 = 波特率 × log2N (N 为每个码元的取值个数)\n\n\n\n性能指标\n\n速率\n\n信道/网络的额定数据传送速率(bps)，非实际速率\n\n\n带宽\n\n模拟信号具有的频带宽度\n数据通信领域指单位时间内网络中的某信道所能通过的“最高 数据率”\n\n\n吞吐量\n\n单位时间内通过网络(或信道、接口)的实际数据量。受网络带 宽或网络的额定速率的限制，常用每秒传送的字节数或帧数来表示\n\n\n时延\n\n数据(比特、报文或分组)从网络(或链路)一端传送到另一端所需的 时间。包括：\n\n发送时延：主机或网络设备发送数据帧（第1位到最后1位）所需要的时间发送时延=数据帧长度(bit)/发送速率(bit/s)\n传播时延：电磁波在信道中传播一定的距离需要花费的时间 传播时延=信道长度(m)/电磁波的传播速率（光纤约为2*105m/s，铜线为 2.3 *105m/s ）\n处理时延：主机或设备收到分组后的处理时间（分析首部、数据部分、差 错检验、选择路由等）\n排队时延：输入队列中排队等待处理，输出队列中排队等待转发\n\n\n数据在网络的总时延=发送+传播+处理+排队时延\n\n\n时延带宽积\n\n带宽时延积=传播时延×带宽，表示在特定时间该网络上的最大 数据量–已发送但尚未确认的数据\n若发送端连续发送数据，则在发送的第一个比特即将达到终点 时，发送端己经发送的比特数\n\n\n往返时间RTT\n\n双向交互一次所需的时间，包括中间结点的处理时延、排队时 延以及转发时延。为避免出错，数据传输常采用应答式交互\n\n\n利用率\n\nChannel utilization rate(信道利用率):\n\n信道传输数据的时间百分比，空闲时的信道利用率是零\n信道利用率并非越高越好（堵塞增加了时延），参见高速公路的车流量\n\n\nNetwork utilization rate(网络利用率):\n\n全网络的信道利用率的加权平均值。\n当网络的利用率接近最大值1 时，网络的时延就趋于无穷大(通常超过 50%时，需准备扩容)\n\n\n\n\n\n\n\n\n\n通信系统\n\n\n\n\n调制解调器\n\n调制解调\n调制方法\n\n调幅\n调频\n调相\n组合调制\n\n\n\n\n\n编码解码\n\n\n编码\n\nPulse code modulation ，PCM，脉码调制技术\n采样、量化、编码\nNyquist Sampling Theorem\n\n最大频率为 F 的模拟信号 被不失真还原的前提条件是 取样频率不低于 2F\n\n\n\n\n\n\n\n\n\n通信编码\n\nNRZI（不归零交替编码）\n\n相邻比特点评变化情况\n\n变化1\n不变化0\n\n\n\n\n曼彻斯特编码\n\n一个比特时间一分为二，在此时间内发生低电平到高电平的变化 表示1，高电平到低电平的变化表示0\n编码中含有同步信息(每个比特中部的电平跃变信号)\n\n\n差分曼彻斯特比编码\n\n一个比特时间一分为二，表示的值依赖于前一比特的最终电平状态\n前半部分电平不同于前一比特的最终电平状态：0\n前半部分电平相同于前一比特的最终电平状态：1\n\n\n\n\n\n传输方式\n\n\n并行传输\n\n\n串行传输\n\n同步传输\n\n依靠双方始终的精确同步\n\n同步模式：一个或多个特定的字符或者符号组合\n\n\n\n\n异步传输\n\n单个字符独立传输\n\n独特的起始位和终止位\n\n\n\n\n\n\n\n检错码\n\n校验字段（冗余信息）\n奇偶校验\n\n奇/偶校验\n水平垂直偶校验码\n\n\nCRC（循环校验码）\n\n\n\n多路复用\n\n\n频分多路复用FDM\n\n\n\n\n时分多路复用TDM\n\n\n\n\n波分多路复用WDM\n\n\n数据交换\n\n电路交换\n\n在数据传输之前，源点和目的点之间需要建立了一条独 占的物理电路（即使通信线路空闲，也不能供其他用户使用），包 含建立线路、数据传输、释放线路三个阶段\n\n\n报文交换\n\n存储转发，无需占用整个物理线路，中间结点根据报文 附加的目的地址确定输出端口和线路，排队等待线路空闲后再转发\n\n\n分组交换\n\n存储转发，对报文交换进行改进，来自上层的报文被分 割成多个分组再通过网络进行发送。目的结点必须等到该报文的所 有分组都到齐之后进行组装，才能将报文交付给上层\n\n\n\n\n\n\n\n Chapter 3\n\n\nOSI/RM模型\n\n\n\n物理层\n数据链路层\n网络层\n传输层\n会话层\n表示层\n应用层\n\n\n\n层间通信\n\n\n\n\n Chapter 4\n\n\n局域网\n\n\nLAN逻辑结构\n\n\nNetwork\n\n广播方式，不需要路由，可省略该层功能\n\n\n\nData link\n\n\nMAC（介质访问控制子层）\n\n定义节点共享传输媒体时采用的访问技术，包括借助于物理层的无差错传输技术等\n\n\n\nLLC（逻辑链路控制子层）\n\n屏蔽不同的MACX子层之间的差异，以便提供统一的接口\n\n\n\n\n\nPhysical\n\n定义结点的传输媒体的接口特性，包括机械特性，电气特性\n\n只有局域网的数据链路层进行了子层划分\n\n\n\n\n\n\n多路访问\n\n\nmultiple-access protocols\n\n\nRandom access protocols\n\nALOHA *\nCSMA*\nCSMA/CD(Carrier sense Multiple access Collision detection载波侦听多路访问冲突检测)\nCSMS/CA\n\n\n\nControlled-access protocols(随机访问竞争)\n\nReservation*\nPolling*\nToken passing(受控访问)\n\n\n\nChannelization protocols(通道化)\n\nFDMA\nTDMA\nCDMA\n\n\n\n\n\n\n\nCSMA/CD\n\n载波侦听(CS)：发送结点在发送信息帧之前必须侦听介质是否处 于空闲状态（说前先听），如果有其他结点在发送数据，则暂时 不要发送数据，以免发生碰撞\n多路访问(MA)：多个结点可以同时访问介质；一个结点发送的 信息帧可以被多个结点接收\n冲突检测(CD)：发送结点在发出信息帧的同时，还必须监听介质， 判断是否发生冲突（边说边听\n当检测到碰撞后\n\n数据碰撞会使总线上传输的信号产生了严重的失真，无法从中恢 复出有用的信息\n每一个正在发送数据的站，一旦发现总线上出现了碰撞，就要立 即停止发送，免得继续浪费网络资源，然后等待一段随机时间 （二进制指数退避）后再次发送\n\n\n\n\n\n\n\n最小帧长度\n\n\n发送方将信息帧全部发往介质时，如果未检测到冲突，则认为发送成功\n\n\n发送方发送的帧长度必须足够大，以确保发送方在检测到冲突时还在发送数据\n\n\n最小帧长度：保证发送结点可以对发送的冲突进行有效的冲突检 测，即保证其发送时间不小于信号在网络中传播距离最远的两个 结点之间传输的时间的2倍\n\n\n10base5：最小帧长度为64字节\n\n10base5\n10:10Mbps\nBase:基带传输\n5:200M\nT: 双绞线\nF:光纤\n\n\n\n\n\nEthernet\n\n\nCSMA/CD\n\n\nDIX标准，与802.3略有区别\n\n\n\n最长数据字段1500（防止缓冲溢出）\n\n\n\n\n\n令牌\n\n\n结点获得媒体使用权的标志，保证有序地访问共享媒体\n\n\n令牌总线 802.4\n\n物理拓扑\n\n总线\n\n\n逻辑拓扑\n\n环\n\n\n半双工\n\n只有获得令牌的结点才能发送 信息，其它结点只能接收信息，或者 被动地发送信息（在拥有令牌的结点 要求下，发送信息）\n\n\n为了保证逻辑闭合环路的形成，每个 结点都动态地维护着一个连接表，该 表记录着本结点在环路中的前继、后 继和本结点的地址，每个结点根据后 继地址确定下一占有令牌的结点\n\n\n\n令牌环网 802.5\n\n物理拓扑\n\n环\n\n\n逻辑拓扑\n\n环\n\n\n单向\n发送方回收帧\n媒体访问\n\n令牌+优先级\n\n\n环中继转发器RPU\n\n\n\n\n\n\n\n\n\n Chapter 5\n\n\n广域网\n\n帧中继网络\n\n一种虚电路广域网，高质量传输媒体应用，速率可达2～155Mb/s，传输差错 率下降，为简化X.25协议，不提供差错处理过程\n工作在物理层和数据链路层，提供部分的网络层功能\n\n\n\n\n\nFR\n\n精简X.25协议\n用光纤等高质量传输媒体，提高速率和降低误码率\n分组重发、流量控制、防止拥塞（正向拥塞通知，反向拥塞通知， 丢失指示等）等处理由端系统完成，降低网络时延\n将路由和简化的2层功能进行集成，提高协议效率\n保持X.25永久虚电路特性，提供虚拟专线服务，减少用户成本\n支持按需分配带宽，在“承诺信息速率”的基础上，支持突发性数 据量“瞬时”超标\n保持网络概念，减少专线方式所需的用户接入线，一条物理连接能 够提供多个逻辑连接\n\n\n\nATM（异步传输模式）\n\n\n基于信元（53B）的分组交换技术\n\n\n面向连接：虚电路\n\n物理链路逻辑上被分为多条虚拟路径(Virtual Path, VP)，VP又 被划分为多条虚拟信道(Virtual Channel, VC)，每个VP和VC都 由标识符标识(VPI和VCI) ，VPI和VCI的组合(VPI/VCI )唯一地 标识了一条VC\n\n\n\n提供预约带宽机制\n\n\n\n\n\n\n\n\n\n\n\n\n Chapter 6\n\n\n网络互连\n\n\n网络互连部件\n\n\n主要进行底层协议的转换\n\n\n转发器\n\n物理层\n\n\n\n网桥\n\n链路层及以下\n\n\n\n路由器\n\n\n网络层及以下\n\n\n\n\n\n\n转发器(Repeater, 中继器、集线器)\n\n\n互连仅在物理层及其下层(传输媒体)存在 差异的网络，延伸网段、改变传输媒体，实现网段之间的电气信号的接收和再生\n\n\n\n\n转发器并不能连接两个局域网，它连接的是同一局域网的两个分段转发器转发每一帧，没有过滤能力\n\n\n\n\n网桥/交换机（Bridge/Switch)\n\n\n用于互连两个独立的子网，实现信息帧的存储 转发，工作在物理层和数据链路层\n\n\n\n\n\n\n执行OSI数据链路层及其下层的协议转换，适用于相同网络或者仅在低两层实现上有 差别的网络之间的互连\n\n\n\n\n网桥(Bridge)的功能\n\n地址过滤：具有统一的数据链路层的编址格式，网桥能够识别各种地址，并根据数据帧的宿地址，有选择地让数据帧穿越网桥\n帧限制：网桥不对帧进行分段，只进行必要的帧格式转换，以适应不同的子网，超长帧则被丢弃，各子网相对独立，控制帧不能穿越网桥\n监控功能：作为单个子网的一部分，参与对子网的监控和对信息帧的校验，具有“存储-转发”的能力，工作过程包括接收帧、检查 帧和转发帧三个部分\n缓冲能力：适应不同子网对媒体访问的控制方式，可以解决数据传输不匹配的子网之间的互连\n透明性：不应影响原有子网的通信能力\n网桥：不同子网的结点间的通信\n\n问题：多个子网互连时，如何找到分属不同子网的结点？\n基本方法：网桥对信息帧宿地址的处理：如果该地址不属于原子网， 则向所有的端口转发（广播)\n结果:大量的&quot;无用帧&quot;被扩散到网络上导致广播风暴（帧在网络上无限制的转发）\n解决方案\n\n设置地址映射表，有选择地进行转发\n分析途经网桥的每个帧，如果宿地址出现在映射表中， 封装/转发该帧至对应网段（端口），否则广播(泛洪)\n\n\n\n\n类型\n\n透明桥/学习桥/自适应桥\n\n网桥环路→地址映射表无法工作→广播风暴\n\n对于存在环路的网络，执行构树过程，确保网络中任意两 个结点之间有且仅有一条路径，可构造基于网桥的支撑树(Span Tree, 生成树)，消除环，多余资源留作备用\n\n目标：任意两个结点之间仅有一条（跨越不同网段）的路径\n原理：逐个增加网桥（端口），一旦出现环路，则阻塞引起该环路的端口\n算法依据：网段为点，桥为边的图中求生成树（支撑树）\n\n\n\n\n\n\n指定路径桥\n\n发送帧的源结点负责路由选择\nIBM令牌环在数据帧中包含路径\n\n源结点知道所发送的帧传输的确切路径，可以直接传输 ，否则，源结点以广播方式向目的结点发送一个用于探测的发现帧（discovery frame)，发现帧将通过网桥互连的局域网中沿着所有可能的路由传送\n在传送过程中，每个发现帧都记录所经过的路由。当这些发现帧到达目的结点 时，就选择出一个最佳路由（跳步数最少的路径）\n指定路径桥可以获得最佳的路径，其缺点是测试帧的发送增加了网络的信息流量，可能形成“广播风暴”，甚至可能导致网络拥塞现象\n\n\n\n\n\n\n收到数据帧后，根据帧的目的地址查地址映射表，然后确定将这个帧转发到哪个接口，或者丢弃(过滤)\n通过网桥互连的局域网，在网络层看是属于同一个网\n\n\n\n以太网交换机\n\n多口的网桥\n同时连通多对接口，使多对主机能同时通信，相互通信的主机独占传输媒介，无碰撞地传输数据(网桥一次只能分析和转发一个帧)\n交换机隔离冲突域\n\n\n\n路由器(Router)：三层交换\n\n网桥的限制：仅适合低二层有差异的网络互连\n为了要互连两个或多个独立的同构或异构的网络，如局域网/广域网、局域网/局域网的互连，需要使用路由器，进行分组的封装和转发，屏蔽3层以下的差异\n通过路由器互连的网络属于不同网段（网络地址不同）：路由器不同接口分配不 同网络的IP地址\n路由器隔离广播域\n路由器的体系结构\n\n执行OSI网络层及其下层协议转换\n网络层主要功能：路由选择\n\n\n路由器的主要功能\n\n寻址：通过路由器互连的网络具有公共的网络地址，并且，网间协议对全网地址 作出规定，以使路由器可以区分各个结点所在的通信子网\n路由选择：相对灵活的路由选择功能，以最快的速度将分组传送通过网络\n\n开放式最短路径优先协议(OSPF：RFC 1247)\n边界网关协议(BGP：RFC 1163)\n内部网关路由协议(IGRP)\n\n\n分组分段/合段：根据子网的分组长度要求，进行分组的分段和合段\n存储-转发、分组格式转换和处理：严格地执行&quot;存储-转发&quot;的原则，即先接收和 存储分组，在完成必要的分组分析和格式转换之后，转发分组至特定的子网\n分组过滤：分组校验（丢弃出错的分组）\n功能主要由软件完成，效率较低，高性能的路由器具有高的价格\n\n\n\n\n\n二层交换\n\n\n网桥、交换机根据帧的宿地址和映射表，不作修改地交换至输出端口(同构网络)， 交换对象为帧\n\n\n\n\n\n\n三层交换\n\n\n根据分组的宿地址和路由表，在路由器上实现分组的交换\n\n\n三层交换机：简化的路由器，二层功能+IP路由，效率高\n\n\n\n\n\n\n\n\n\n\n\n\n虚拟局域网 (virtual LAN)\n\n传统的局域网\n\n以物理网段为基本网络用户单位，如果一个节点接到一个网络设备（HUB、中继器、网桥或交换机）上，那么，它就与其他接在同一设备上的节点属于同一个局域网，可以互发广播报文\n\n\n虚拟局域网简称VLAN，跨接不同物理LAN网段的节点连接成逻辑 LAN网段，处于不同物理网段的用户通过软件设置处于同一局域网中， 形成逻辑的工作组。在同一逻辑工作组中的节点可以互发广播报文\n不同网段上的用户不能处于同一网段中\nVLAN通信\n\n隔离二层广播域：严格地隔离了各个VLAN之间的任何流量，即不同VLAN之间的流量不能直接跨越VLAN的边界\nVLAN直接通信需要使用路由，通过路由将报文从一个VLAN转发到另外一个VLAN\n\n\n\n\n\n Chapter 7\n\n\nInternet\n\n\n\n应用层\n\n工作模式\n\n客户机-服务器\n\n\n\n\n\n\n\n\n\n\n\nTCP Transmission control protocol\n\n\n在IP的基础上，支持面向连接的、可靠的、面向流的投递服务\n\n\n面向流的投递服务\n\n无结构字节流，收发字节顺序完全一致，根据对方给出的窗口值和网络拥塞程度决定//todo\n\n\n\nTCP模块之间建立点对点连接（虚电路）//todo\n\n\n套接字（socket）\n\nIP:socket\n五元组\n\n协议\n源IP\n源端口\n目的IP\n目的端口\n\n\n\n\n\nTCP报文格式\n\n//todoTCP首部最小长度20byte\n\n\n\n\n\nTCP建立连接\n\n三次握手\n\n//todo\n[x] ACK\n[ ] NAK(直接丢弃)\n\n\n\n\n\nTCP拆除连接\n\n四次确认\n\n//todo\n\n\n\n\n\nTCP可靠传输\n\n\n校验\n\n\n字节为单位，体积可变的滑动窗口（可靠传输、流量控制）\n\nTCP建立连接阶段，双方协商窗口尺寸，接收方预留数据缓存区\n\n发送方根据协商结果，发送符合窗口尺寸的数据字节流，并等待对方确认\n发送方根据确认信息，改变发送窗口的尺寸\n\n\n\n确保了可靠性和流量控制\n\n\n超时重传\n\n\n拥塞控制&amp;流量控制\n\n慢启动\n\n拥塞避免\n快重传\n快恢复\n\n\n\n\n\n\n\n网络层\n\nIP 数据投递服务\n\n不可靠、无连接、尽力而为的服务\n\nICMP\n\n\n\n\nIP地址段类型和划分\n专用IP地址\n10.xx.xx.xx\n172.16.00.00~172.31.255.255\n192.168.9.0~192.168.255.255\nIP地址分配\n\n子网掩码\nCIDR\n\n\n路由表\nIP路由过程\n分层次的路由信息协议\n\n局域网\n路由信息协议(RIP)\n\n分布式、基于向量的路由选择协议\n每一个路由器维护从它自己到每一个目的网络的距离记录（跳数）\n不能在两个网络之间同时使用多条路由\n仅和相邻路由器交换信息\n\n\n开放最短路径优先（OSPF Open shortest path first）\n\nDijkstra算法\n使用洪泛传播ISP\n多路径间的负载均衡\n\n\n\n\n\n\n\n数据链路层\n\n地址映射\nIP地址寻址ARP\n物理地址（e.g. MAC address）寻址\n\n\n\n Chapter 8\n\n\n网络安全措施\n\n网络操作系统安全\n局域网安全\nInternet互联安全\n\n\n\n数据安全\n\n加密/解密技术\n密钥管理\n数字签名\n认证技术\n防火墙技术\n\n区分内外网\n\n\n数据加密算法\n\n算法公开、密钥保密\n对称密钥加密\n\n高强度高效率\n密钥管理复杂\n一对一\n\n\n非对称密钥加密\n\n加密效率低\n密钥管理有优势、密钥分配协议\n多对一单项保密通信\n加密算法混合使用\n\n\n内容完整性检查\n\n信息摘录技术\n\n防重放攻击\n\n时间戳\n序列号\n\n\n\n\n\n\n数字签名\n\n信息摘录\n非对称加密\n\n\n认证技术\n\n消息验证\n\n数字签名\n\n\n身份验证\n\n秘密信息\n\n口令\n\n\n物理安全\n\n\n抗否认、防抵赖服务\n第三方认证\n内容保密\n内容完整性\n序列完整性\n实体鉴别\n抗发方否认\n抗收方否认\n\n\n\n\n\n\n\n Chapter 9\n\n简单网络管理协议SNMP\n\n协议数据单元PDU\n\n\n\n","plink":"ilucia.github.io/Review/ComputerNetwork/"},{"title":"软件体系架构","date":"2019-04-23T23:03:06.000Z","updated":"2022-04-27T15:24:01.651Z","content":"[TOC]\n Chapter 1 概述\n\n软件架构产生的背景\n\n软件危机\n\n根源\n\n软件复杂易变，行为特性难于预见，需求向设计缺乏有效的转换导致开发过程中的困难和不可控\n随着软件体系规模越来越大越来越复杂，整个系统的贵和和规格说明越来越重要\n对于大规模复杂软件系统，总体的系统结构设计和规格说明非常重要\n对软件体系的结构的研究有望成为提升软件生产率和解决软件维护问题的有效途径之一\n\n\n软件架构\n\n作用\n\n\n\n\n\n\n软件架构的思想和特征\n\n主要思想\n\n软件架构是一个系统软件的设计图，不仅限于软件系统的总体结构，还包含一些质量属性以及功能与结构之间的映射关系，即设计决策\n软件架构的两个主要焦点集中于系统的总体结构以及需求和实现之间的对应\n主要思想是将注意力集中在系统总体结构的组织上\n筛选按手段是运用抽象方法屏蔽模块间的连接，是人们的认知提升并保持在整体结构的部件的交互层次，并进一步将交互从计算中分离出来，建立“组件+连接件+配置”的软件系统高层结构组织方式\n\n\n特征\n\n注重可重用性——组件及架构及重用\n利益相关者多——平衡需求\n关注点分离——模块化、分治\n质量驱动——关注非功能属性\n提倡概念完整性——强调设计结构是一个持续的过程\n循环风格——用标准方法来处理反复出现的问题\n\n\n\n\n软件架构的发展阶段，各阶段特征\n\n1968-1994 基础研究阶段\n\n1968 NATO 软件架构概念提出\n模块化实践\n\n高内聚低耦合\n模块大小适度\n模块链调用深度不可过多\n接口干净，信息隐藏\n尽可能地复用已有模块（功能独立）\n\n\n\n\n1991-2000 概念体系和核心技术形成阶段\n\n组件技术（component）\n\n\n1996-1999 理论体系丰富发展阶段\n\n软件架构的描述与表述\n软件架构分析、设计与测试\n软件架构发现、演化与重用\n基于软件架构的开发方法\n软件架构的风格\netc…\n\n\n1999-至今 理论完善和普及应用阶段\n\n\n软件架构研究和应用现状\n\n chapher 2 软件架构概念\n\n软件架构定义\n\n一研究人员一般认为\n软件架构就是一个系统的草图\n\n\n组成派定义\n\n组成派关注于软件本身，将软件架构看作构件和交互的集合\n\n\n决策派定义\n\n决策派关注于软件架构中的实体（人），将软件架构视为一系列重要设计决策的集合\n\n\n参考框架定义（一般性定义）：\n\n组件component\n\n角色role\n\n\n连接件connector\n\n端口port\n\n\n配置configuration\n\n\n\n chapter 3 软件架构模型\n\n\n软件架构模型是什么\n\n软件架构建模是对架构设计决策的具象化和文档化\n\n\n\n软件架构建模的五类方法\n\n\n基于非规范图形表示的建模方法\n\n基于图形可视化建模方法\n\n非正式图形表示\n\n盒线图\netc.\n\n\n正式图形表示\n\n树形结构\n树地图\n改进的树地图\n旭日图\n双曲树\n\n\n\n\n\n\n基于UML的建模方法\n\n逻辑视图\n开发视图\n过程视图\n物理视图\n优点\n\n统一标准\n支持多视图结构\n模型操作工具\n统一的交叉引用\n\n\n\n\n\n基于形式化的方法\n\n\n基于UML形式化的方法\n1234567graph LRA[需求分析]--&gt;B[需求文档规格说明]B--&gt;C[UML建模]C--&gt;D[形式化描述和验证]D--&gt;E[程序编码]E--&gt;F[形式规范自动生成和测试变量]F--&gt;G[软件产品]\n\n需求分析到形式化描述和验证占全部工作量的60%~70%\n\n\n\n\n\n软件架构建模方法的发展趋势\n\n\n\n\n第一层次\n\n文本模型\n\n\n\n第二层次\n\n图形可视化模型\n\n\n\n第三层次\n\n\nUML模型\n\n\n第四层次\n\n\n形式化模型\n\n\n第五层次\n\n未来模型\n\n\n\n\n\n Chapter 4 软件架构风格和模式\n\n\n什么是软件架构风格/软件架构惯用模式\n\n描述特定应用领域中系统组织方式的惯用模式\n\n\n\n使用架构风格的好处\n\n作为“可复用的组织模式和习语”，为设计人员的交流提供了公共的术语空间，促进了设计复用和代码复用\n极大地促进了设计的重用性和代码的重用性，并且使得系统的组织结构易被理解\n使用标准的架构风格可较好地支持系统内部的互操作性以及针对特定风格的分析\n\n\n\n经典体系结构风格的特点、优点、缺点、适用范围\n\n数据流风格 加一个批处理序列\n\n\n管道过滤器风格\n\n特点\n\n过滤器是独立运行的部件\n过滤器无法感知其处理上下连接的过滤器\n结果的正确性不依赖与各个过滤器运行的先后次序\n\n\n优点\n\n每个组件行为不受其他组件的影响，整个系统的行为易于理解\n管道-过滤器风格支持功能模块的复用\n基于管道-过滤器风格的系统具有较强的可维护性和可扩展性\n支持一些特定的分析（e.g.吞吐量计算和死锁检测）\n管道-过滤器风格具有并发性\n\n\n缺点\n\n管道-过滤器风格往往导致系统处理过程的成批操纵\n对加密数据流需要在每个模块中进行解析或反解析，增加了过滤器实现的复杂性\n交互处理能力弱\n\n\n\n\n\n\n\n调用返回风格\n\n\n主程序/子程序风格\n\n特点\n\n从功能观点设计系统，通过逐步分解和逐步细化得到系统架构，\n主程序的正确性依赖与它调用的子程序的正确性\n组件为主程序和子程序\n连接件为调用-返回机制\n拓补结构为层次化结构\n\n\n优点\n\n具有很高的数据访问效率（计算共享一个储存区）\n不同的计算功能被划分在不同的模块中\n\n\n缺点\n\n对数据储存格式的变化将会影响几乎所有的模块\n对处理流程的改变与系统功能的增强适应性较差\n这种分解方案难以支持有效的复用\n\n\n\n\n面向对象风格\n\n特点\n\n对象负责维护其表示的完整性\n对象的表示对其他对象而言是隐蔽的\n\n\n优点\n\n对象隐藏了其实现细节、可以在不影响其他对象的情况下改变对象的实现，不仅使得对象的使用变得简单、方便，而且具有很高的安全性和可靠性\n设计者可将一些数据存取操作的问题分解成一些交互代理程序的集合\n\n\n缺点\n\n当一个对象和其他对象通过过程调用等方式进行交互时，必须知道其他对象的标识。无论何时改变对象的标识，都必须修改所有显示调用它的其他对象，并消除由此带来的一些副作用\n\n\n\n\n层次化风格\n\n特点\n\n系统分层\n每个层次由一系列组件组成\n层次之间存在接口\n下层组件向上层组件提供服务，上层组件被看作是下层组件的客户端\n\n\n优点\n\n支持基于可增加抽象层的设计，允许将一个复杂问题分解为一个增量步骤序列的实现\n支持扩展，每一层的改变最多只影响相邻层\n支持重用，只要给相邻层提供相同的接口，它允许系统中同一层的不同实现相互交换使用\n\n\n缺点\n\n不是所有系统都容易采用这种模式来构建\n定义一个合适的抽象层次可能会非常困难，特别是对应标准化的层次模型\n\n\n\n\n\n\n\n独立组件风格\n\n\n\n事件驱动风格\n\n特点\n\n事件发布者不知道那些组件会受到时间的影响；组件不能对事件的处理排序，或者事件发生后的处理结果做任何假设\n从架构上来说，事件驱动系统的组件提供了一个过程集合和一组事件\n过程可以使用显式的方法进行调用，也可以用组件在系统事件中注册。当触发事件时，会自动引发这些过程的调用\n连接件既可以时显式过程调用，也可以是一种绑定事件声明和过程调用的手段\n\n\n优点\n\n事件声明者不需要知道那些组件会影响事件，组件之间关联较弱\n提高软件复用能力。只要在系统事件中注册组件的过程，就可以将该组件继承到系统中\n系统便于升级。只要组件名和事件中所注册的过程名保持不变，原有组件就可以被新组件取代\n\n\n缺点\n\n组件放弃了对计算的控制权，完全由系统来决定\n存在数据交换问题\n该风格中，正确性验证成为一个问题（难以调试）\n\n\n\n\n\n\n\n虚拟机风格\n\n\n\n解释器风格\n\n\n解释器（Interpreter）是一个用来执行其他程序的程序，它针对不同的硬件平台实现了一个虚拟机，将高层次的程序翻译为低抽象层次的所能理解的指令，，以弥合程序语义所期望的与硬件提供的计算引擎之间的差距\n\n\n优点\n\n它有利于实现程序的可移植性和语言的跨平台能力\n\n\n\n它可以对未来的硬件进行模拟和仿真，能够降低测试所带来的复杂性和昂贵花费\n\n\n缺点\n\n额外的间接层次导致了系统性能的下降（e.g. Java without JIT）\n\n\n\n\n\n\n\n\n\n基于规则的系统风格\n\n\n显示里的业务需求经常频繁的发生变化，不断修改代码效率低、成本高。最好把频繁变化的业务逻辑抽取出来，形成独立的规则库\n\n\n规则可独立于软件系统而存在，可以被随时更新\n\n\n系统运行时，读取规则库，依据当前运行状态，从规则库中选择与之匹配的规则解释运行\n| 基于规则的系统     | 解释器风格             |\n| ------------------ | ---------------------- |\n| 知识库             | 待解释程序             |\n| 规则解释器         | 解释器引擎             |\n| 规则与数据元素选择 | 解释器引擎内部控制状态 |\n| 工作内存           | 程序当前的运行状态     |\n\n\n\n\n\n\n仓库风格\n\n\n\n仓库风格\n\n\n特点\n\n仓库是储存和维护数据的中心场所\n仓库式风格的两种组件\n\n中央数据结构组件\n相对独立的组件集合\n\n\n\n\n\n优点\n\n便于模块间的数据共享,方便模块的添加,更新和删除,避免了知识源的不必要的重复储存等\n\n\n\n缺点\n\n对于各个模块,需要一定的同步/加锁机制保证数据结构的完整性和一致性\n\n\n\n\n\n\n\n黑板系统风格\n\n\n特点\n\n\n黑板系统是传统上被用于信号处理方面进行复杂解释的应用程序,以及松散耦合的组件访问共享数据的应用程序\n\n\n黑板架构实现的基本出发点是已经存在一个对公共数据结构进行协同操作的独立程序集合\n\n\n组成部分\n\n\n知识源\n\n\n黑板数据结构\n\n\n控制器\n\n\n\n\n\n\n\n\n\n\n优点\n\n\n便于多客户共享大量数据,他们不关心数据何时有的,谁提供的,怎样提供的\n\n\n既便于添加新的作为知识源代理的应用程序,也便于扩展共享的黑板数据结构\n\n\n知识源可重用\n\n\n支持容错性和健壮性\n\n\n\n\n缺点\n\n\n不同的知识源代理对于共享数据结构要达成一致,而且这也造成对黑板数据结构的修改较为苦难(要考虑到给个代理的调用)\n\n\n需要一定的同步/加锁机制保证数据结构的完整性和一致性,增大了系统复杂度\n\n\n\n\n\n\n\n\n其他\n\n\nC2风格\n\n\n\n特点\n\n\n系统组织规则\n\n系统中的组件和连接件都有一个顶部和一个底部\n组件的顶部应连接到某连接件的底部,组件的底部应连接到某连接件的顶部,不允许组件之间的直接连接\n\n一个连接件可以和任意数目的其他组件和连接件连接\n- 当两个连接件进行直接连接时,必须由其中一个的底部到另一个的底部\n\n\n\n\nC2的内部,通信和处理时分开完成的\n\n\n\n\n\n优点\n- 可使用任何编程语言开发组件,组件重用和替换易实现\n- 由于组件之间相对独立,依赖较小,因而该风格具有一定扩展能力,可支持不同粒度的组件\n- 组件不需共享地址空间\n- 可实现多个用户和多个系统之间的交互\n- 课使用多个工具集和多种媒体类型,动态更新系统框架结构(适合交互系统)\n\n\n缺点\n\n\n不太适合大规模流式系统,以及对数据库使用比较频繁的应用\n\n\n\n客户机/服务器风格（两层C/S架构）\n\n\n\n特点\n\n协作关系\n- 客户机\n- 服务器\n- 客户机和服务器程序配置在分布式环境中时:通过远程调用(RPC)协议进行通信\n优点\n\n客户机组件和服务器组件分别运行在不同的计算机上,有利于分布式数据的组织和处理\n组件之间的位置是相互透明的\n客户机程序和服务器程序可运行在不同的操作系统上,便于实现异构环境和多种不同开发技术的融合\n软件环境和硬件环境的配置具有极大的灵活性,易于系统功能的扩展\n将大规模的业务逻辑分布到多个通过网络连接的低成本的计算机上,降低了系统的整体开销\n\n\n缺点\n\n开发成本高(客户机软硬件要求搞)\n客户机程序的设计复杂度大,客户机负载重\n信息内容和形式单一\nC/S架构升级需要开发人员到现场更新客户机程序,对运行环境进行重新配置,增加了维护费用\n两层C/S结构采用了单一的服务器,同时以局域网为中心,难以扩展到inrtante和Internet\n数据安全性不高\n\n\n\n\n\n\n\n浏览器/服务器风格（三层C/S架构）\n\n特点\n\n相对两层C/S架构的优点\n\n合理地划分三层结构的功能，可以使系统的逻辑结构更加清晰，提高软件的可维护性和可扩充性\n在实现三层C/S架构时，可以更有效地选择运行平台和硬件环境，从而使每一层都具有清晰的逻辑结构，良好的符合处理能力和叫号的开放性\n在C/S结构中，可以分别选择合适的变成语言并行开发\n系统具有较高的安全性\n\n\n在使用三层C/S架构时需要注意以下问题\n\n如果各层之间通信效率不高，及时每一层的硬件配置都很高，系统的整体性能也不会太高\n必须慎重考虑三层之间的通信方法，通信频率和数据传输量，这和提高各层的独立性一样也是实现三层C/S架构的关键性问题\n\n\n\n\n浏览器/服务器风格是三层C/S风格的一种实现方式\n\n与三层C/S结构的解决方案相比，B/S架构在客户机采用了WWW浏览器，把web服务作为应用服务器\n\n\n优点\n\n客户端只需要安装浏览器，操作简单，能够发布动态信息和静态信息\n运用HTTP标准协议和统一客户端软件，能够实现跨平台通信\n开发成本比较低，只需要维护web服务器和中心数据库，客户端升级可以通过升级浏览器是实现\n\n\n缺点\n\n个性化程度低,所有客户端程序的功能都是一样的\n客户端数据处理能力较差,加重了web服务器的工作负担,影响系统的整体性能\n在B/S架构中,数据提交一般以页面为单位,动态交互性不强,不利于在线事务处理(OLTP)\nB/S架构可扩展性比较差,系统安全性难以保障\nB/S架构的应用系统查询中心数据库,其速度要远低于C/S架构\n\n\n\n\n\n平台/插件风格\n\n特点\n\n平台\n\n程序的主题或主框架\n\n内核功能\n插件处理功能\n\n\n\n\n接口\n\n平台扩展接口\n插件接口\n\n\n插件\n\n对软件功能的扩展或补充模块\n\n\n\n\n优点\n\n降低系统各模块之间的互依赖性\n系统模块独立开发,部署,维护\n根据需求动态的组装,分离系统\n\n\n缺点\n\n只服务与该主程序,可重用性差\n\n\n\n\n\n面向Agent风格\n\n特点\n\nAgent\n\n一个能感知环境并主动决策和行为的软件实体\n\n\nAgent组件\n\n对系统处理的高度抽象,具有高度灵活和高度智能特色的软件实体\n自主性,智能性,交互性\n\n\nAgent连接件\n\n对复合型组件的连接,提供通信,协调,转换,接通等服务\n\n\n\n\n优点\n\n面向Agent的软件工程方法对于解决复杂问题是一种好技术,特别是对于分布开放异构的软件环境\n\n\n缺点\n\n大多数结构中Agent自身缺乏社会性结构描述和与环境的交互\n\n\n\n\n\n面向方面软件架构风格\n\n特点\n\n一般认为AOP在传统软件架构基础上增加了方面组件(Aspect Component)这一个新的构成单元,通过 方面组件来封装系统的横切关注点(需求特性或关注点)\n\n\n优缺点\n\n可以定义交叉的关系,并将这些关系应用于跨模块的,彼此不同的对象模型\nAOP同时还可以让我们层次化功能性而不是嵌入功能性,从而使得代码有更好的可读性和易于维护\n他会和面向对象编程很好地合作,互补\n\n\n\n\n\n面向服务架构风格\n\n\n特点\n\n\n面像服务架构模型（SOA）\n\n\n服务\n\n一个粗粒度的，可发现的软件实体\n\n\n\n接口\n\n\n\n\n\n发布\n发现\n绑定和调用\n\n\n\n\n\n优点\n\n灵活性，根据需求变化，重新编排服务\n对IT资产的复用\n使企业的信息建设真正以业务为核心。业务人员根据需求编排服务，而不必考虑技术细节\n\n\n\n缺点\n\n服务的划分很困难\n服务的编排问题\n接口标准可能会带来系统的额外开销和不稳定性\n对硬件IT资产谈不上复用\n目前主流实现方式很多，松散脆弱\n目前主流实现方式局限于不带界面的服务的共享\n\n\n\n\n\n正交架构风格\n\n\n特点\n\n\n由完成不同功能的n个线索（子系统）组成\n\n\n系统具有m个不同抽象级别的层\n\n\n线索之间是相互独立的\n\n\n系统有一个公共驱动层（一般为最高层）和公共数据结构（一般为最底层）\n\n组织层（Layer）\n\n由一组具有相同抽象级别的组件构成\n\n\n线索（Thread）子系统的特例的组件（Component）\n线索是相互独立的，即线索中的组件之间没有相互调用\n\n\n\n\n\n\n\n优点\n\n结构清晰，易于理解。由于线索功能相互独立，组件的位置可以清楚地说明它所实现的抽象层次和负担的功能\n易修改，可维护性强。由于线索之间是相互独立的，所以对一个线索的修改不会影响到其他线索\n可移植性强，重用粒度大。因为正交结构可以为一个领域内的所有应用程序所共享，这些软件有着相同或类似的层次和线索，可以实现架构级的重用\n\n\n\n缺点\n\n在实际应用中，并不是所有软件系统都能完全正交化，或者有时完全正交化的成本太高。因此，在进行应用项目的软件架构设计时，必须反复权衡进一步正交化的额外开销与所得到的更好的性能之间的关系\n\n\n\n\n\n异构风格\n\n特点\n\n在设计软件系统时，从不同角度来观察和思考问题，会对架构风格的选择产生影响\n每一种架构风格都有不同的特点，适用于不同的应用问题，因此，架构风格的选择是多样化的和复杂的\n实际应用中，各种软件架构并不是独立存在的，在一个系统中，往往会有多种架构共存和相互融合，形成更复杂的框架结构，即异构架构\n组合方式\n\n层次结构\n单一组件使用符合的连接件\n\n\n\n\n优点\n\n可以实现遗留代码的重用\n在某些单位中，规定了共享软件包和某些标准，但仍会存在解释和表示习惯上的不同。选择异构架构风格，可以解决这一问题\n\n\n缺点\n\n不同风格之间的兼容问题有时很难解决\n\n\n\n\n\n基于层次消息总线的架构风格（JB/HMB风格）\n\n特点\n\n以青鸟软件生产线的实践为背景，提出了基于层次消息总线的软件架构(Jade bird hierarchical message bus based style)\nJB/HMB风格基于层次消息总线、支持组件的分布和并发，组件之间通过消息总线进行通讯\n消息总线是系统的连接件，负责消息的分派、传递和过滤以及处理结果的返回。各个组件挂接在消息总线上，向总线登记感兴趣的消息类型\n\n\n优点\n\n较好地支持架构设计\n构件之间的耦合性较低\n构建使用灵活\n构建重用性较高\n动态性（支持系统演化）\n\n\n缺点\n\n总线可重用性差\n重用要求高\n\n\n\n\n\n模型-视图-控制器风格\n\n特点\n\n模型\n视图\n控制器\n\n\n优点\n\n多个视图与一个模型相对应。变化一一传播机制确保了所有相关视图都能够及\n时地获取模型变化信息，从而使所有视图和控制器同步，便于维护\n具有良好的移植性。由于模型独立于视图，因此可以方便的实现不同部分的移植\n系统被分割为三个独立的部分，当功能发生变化时，改变其中的一个部分就能满足要求\n\n\n缺点\n\n增加了系统设计和运行复杂性\n视图与控制器连接过于紧密，妨碍了二者的独立重用\n视图访问模型的效率比较低。由于模型具有不同的操作接口，因此视图需要多次访问模型才能获得足够的数据\n频繁访问未变化的数据，也将降低系统的性能\n\n\n\n\n\n\n\n Chapter 5 架构描述语言\n\n什么是软件架构描述语言\n\nADL（Architecture description language）用于任何软件架构的表示形式\n\n\n为何有多种软件架构描述语言\n\n//TODO\n\n\nADL的核心设计元素\n\n组件(Component)\n\n表示系统中主要的计算元素和数据存储，如客户端、服务器、数据库等\n\n\n连接件(Connector)\n\n定义了组件之间的交互关系，如过程调用、消息传递、事件广播等\n\n\n软件架构配置（ArchitectureConfiguration）\n\n描述组件、连接件之间的拓扑关系\n\n\n约束条件（constraint)\n\n定义组件之间依赖、组件与连接件之间依赖的约束\n\n\n\n\n\n Chapter 6 软件架构与敏捷开发\n\n\n敏捷开发的基本理念\n\n强调个体和互动比强调过程和工具更好\n强调获得可运行的软件比强调完成详尽的文档好\n强调与客户合作比强调进行详细的合同谈好\n强调响应变化比强调遵循既定的计划好\n\n\n\n尽早并持续地交付有价值的软件以满足顾客需求\n敏捷流程欢迎需求的变化，并利用这种变化来提高用户的竞争优势\n经常交付可用的软件，发布间隔可以从几周到几个月，能短则短\n业务人员和开发人员在项目开发过程中应该每天共同工作\n选择有进取心的人作为项目核心人员，充分支持并信任他们\n无论团队内外，面对面交流始终是最有效的沟通方式\n可用的软件是衡量项目进展的主要指标\n敏捷流程应能保持可持续发展。责任人，开发者和用户应该能够保持一个长期的，恒定的开发速度\n不断关注技术和设计能增强敏捷能力\n保持简明（尽可能简化工作量的技巧）\n最高的构架，需求和设计出自于自组织的团队\n时时总结如何提高团队效率，并付诸行动\n\n\n\n敏捷开发与架构的设计的关系\n\n软件架构与敏捷开发的出发点是一致的\n\n目的：提高软件开发效率，提高软件质量，降低软件成本，将开发团队的价值最大化（权衡的过程）\n\n\n敏捷开发也要重视软件架构\n敏捷开发改变了软件架构的设计方式\n\n\n\n敏捷开发中如何改变了软件架构的设计方式\n\n\n敏捷开发非常重视软件的架构设计，但是轻架构的详细设计\n\n\n敏捷思想中进传统的架构设计分成\n\n\n种子架构设计\n\n软件的架构层次\n重要模块\n重要的说明类\n\n\n\n详细架构设计\n\n\n\n敏捷开发把传统软件开发前期的详细架构设计分散到了整个敏捷开发软件过程中，以达到提高效率，减少风险的目的\n\n\n\n\n\n\n\n两类常见敏捷架构设计方法\n\n\n规划式设计和演进式设计，具体体现为初始化阶段设计和迭代过程中的设计\n\n\n团队设计\n\n\n群体决策\n\n\n优点\n\n团队设计的理论依据是群体决策。其结论要比个人决策更加完整，避免个人遗漏，相对稳定、周密\n\n\n\n缺点\n\n需要额外付出沟通成本、决策效率低、责任不明\n确等。\n\n\n\n\n\n简单设计\n\n敏捷的思想要求软件架构设计必须是简单设计\n\n表达方式的简单化\n现实抽象的简单化。\n\n敏捷开发中对详细架构描述文档等中间产物的弱化，只满足有效沟通即可\n\n\n现实抽象的简单化\n\n仅针对当前需求建模分析，不做“多余的&quot;工作\n\n\n\n\n简单设计可以降低开发成本、提升沟通效率、增强适应性和稳定性\n\n\n\n\n\n Chapter 7 架构驱动的软件开发\n\n\n架构驱动的软件开发步骤和开发流程\n\n\n步骤\n\n架构需求获取\n基本架构设计\n架构记录和文档化\n架构评估\n架构实现\n架构维护\n\n\n\n开发流程\n\n\n\n\n\n\n质量场景、质量模型\n\n抽象场景\n\n根据软件的使用进行一定层面的分类（如：软件流水线方式、三层结构等），这些分类就会对相应软件提出一定的需求，此类需求即为架构需求的抽象场景\n\n\n质量场景\n\n架构需求要用质量场景进行描述\n\n对于架构师和领域专家来说，需要做的是从抽象场景描述中获得特定的质量属性场景\n通常来说，我们考虑的特定的质量场景是对性能、可移植性、可替换性、可重用性等质量属性产\n生影响时的质量场景\n\n\n\n\n质量模型\n\n软件质量理想模型\n\n质量场景进行描述，可以用来描述，评估和预测质量属性的模型\n可以清晰地描述质量模型中元素和元素之间的相互关系的模型\n实例化的软件质量理想模型和对质量场景的注解\n\n\n\n\n\n\n\n架构的结构\n\n通过一定的结构对软件的架构进行描述，把这样的结构称为架构结构\n架构结构描述了架构的基本信息，也包括了类，方法，对象，文件，库等所有需要人做的设计和编码\n架构视图是由架构结构派生而出的，它可以是架构结构的子部分，也可以是多个架构结构信息的综合\n\n\n\n Chapter 8 软件架构建模方法\n\n\n成功的软件架构应具有的品质\n\n良好的模块化\n适应功能需求的变化，适应技术的变化\n对系统的动态运行有良好的规划\n对数据的良好规划\n明确，灵活的部署规划\n\n\n\n将软件架构的概念和原则引入软件需求阶段有什么好处？不引入可能会引起什么问题？\n\n好处\n\n有助于保证需求规约 ，系统设计之间的可追踪新和一致性，有效保持软件质量\n有助于更有结构性和可重用的需求规约\n\n\n用传统方法产生需求规约，不考虑软件架构概念和原则，，则在软件架构设计阶段建立需求规约与架构的映射将相对困难\n\n\n\n软件架构和软件需求是如何协同演化的？\n\n软件需求和软件架构两者是相辅相成的关系，一方面软件需求影响软件架构设计，另一方面软件架构帮助需求分析的明确和细化\n\n\n\n需求与架构的相互影响可以看作一个螺旋的过程，也是一个双峰的过程\n\n\n\n\n\n\n将软件架构映射到详细设计经常遇到什么问题？如何解决？\n\n问题\n\n缺失重要架构视图，片面强调功能需求\n不够深入，架构设计方案过于笼统，基本还停留在概念性架构的层面，没有提供明确的技术蓝图\n名不副实的分层架构，缺失层次之间的交互接口和交互机制，只进行职责划分\n在某些方面过度设计。\n\n\n解决方案\n\n对于缺失重要架构视图问题，可以针对遗漏的架构视图进行设计\n对于不够深入问题，需要将设计决策细化到和技术相关的层面\n对于名不副实的分层架构问题，需要步步深入，明确各层之间的交互接口和交互机制\n虽然我们必须考虑到系统的扩展性，可维护性等，但切忌过度设计\n\n\n\n\n\nMDAmodel driven architecture基于模型驱动软件架构的基本思想，应用MDA的好处\n\n计算无关模型(CIM.Comutation Independent Model)也称业务模型\n\n描述系统的外部行为和运行环境\n\n\n平台无关模型(PIM,Platform Independent Model)\n\n具有高抽象层次、无关于任何实现技术的模型\n\n\n平台特定模型(PSM,Platform secific Model)\n\n为某种特定实现技量身定做，让你用这种技术中可用现构造来描述系统的模型。PIM会被变换一个或多个PSM\n\n\nMDA开发步骤\n\n用计算无关模型CIM捕获需求\n\n创建平台无关模型PIM\n将PIM转化成为一个或多个平台特定模型PSM，并加入平台特定的规则和代码\n将PSM转化为代码等\n\n\n\n\n基本思想\n\n将软件系统分成模型和实现两部分\n\n模型是对系统的描述，实现是利用特定技术在特定平台或环境中对模型的解释。模型仅仅负责对系统的描述与实现技术无关。这是模型的实现技术无关性\n\n\n\n\n好处\n\n将模型与实现分离后，能够很好的适应技术易变性。由于实现往往高度依赖特定技术和特定平台，当技术发生迁移时，只需针对这种技术作相应的实现，编写相应的运行平台或变换工具。所以，能够比较好的应对实现技术发展带来的挑战\n\n\n\n\n\n架构设计原则\n\n一般原则\n\n商业原则\n数据原则\n应用程序原则\n技术原则\n\n\n关键设计原则\n\n关注分离点\n单一职责原则\n最少知识原则\n\n\n\n\n\n Chapter 15 软件架构评估方法\n\n\n软件架构评估的必要性\n\n软件体系结构的好坏关系到软件产品的好坏，软件产品的好坏关系到软件公司的发展\n通过评估能了解系统的体系结构和重要属性（质量属性），能够屏蔽风险，带来诸多收益\n到目前为止没有很好的自动化评估系统\n\n\n\n软件架构评估的方式分类\n\n基于调查问卷或检查表的评估方式\n基于场景的评估方式\n基于度量的评估方式\n质量属性、（质量）场景基于场景的评估\n\n\n\n体系结构权衡分析方法（ATAM）的相关概念、评估过程（步骤）、优缺点\n\n基本概念\n\n敏感点(Sensitivity point)\n\n敏感点是一个或多个构件的特征\n敏感点可以使设计师搞清楚实现质量目标时应该注意什么\n\n\n权衡点(Tradeoffpoint)\n\n权衡点是影响多个质量属性的特征\n是多个质量属性的敏感点\n权衡点需要进行权衡\n\n\n敏感点影响一个质量属性\n权衡点影响多个质量属性\n风险承担者，涉众，牵涉到的人\n场景\n\n刺激\n环境\n响应\n\n\n\n\n评估过程\n\n陈述，包括通过它进行的信息交流\n\nATAM方法的陈述\n商业动机的陈述\nSA的陈述\n\n\n调查与分析，包括对照体系结构方法评估关键质量属性需求\n\n确定体系结构方法\n生成质量效用树\n分析体系结构方法\n\n\n测试，包括对照所有相关人员的需求检验最新结果\n\n集体讨论并确定场景优先级\n分析体系结构方法\n\n\n形成报告，包括陈述ATAM的结果\n\n结果的表述\n\n\n\n\n\n\n\n软件体系结构分析方法（SAAM）的评估过程（步骤）、优缺点（敏感点、权衡点、效用树…）\n\n\n评估过程\n\n\n\n场景的形成\n体系结构的表述\n场景分类和优先级的确定\n对场景的单个评估\n场景相互作用的评估\n形成总体评估\n\n\n\n\n\n Chapter 9软件架构的演化和维护\n\n\n软件架构演化的目的\n\n维持软件架构自身的有用性\n\n\n\n软件架构演化的实施\n\n\n软件架构演化方式的分类\n\n\n静态演化：需求、过程\n\n\n需求\n\n设计时演化需求\n\n在架构开发和实现过程中对原有架构进行调整，保证软件实现与架构的一致性以及软件开发过程的顺利进行\n运行前演化需求：软件发布之后由于运行环境的变化，需要对软件进行修改升级，在此期间软件的架构同样要进行演化\n\n\n\n\n\n过程\n\n\n\n软件理解\n\n查阅软件文档，分析软件架构，识别系统组成元素及其之间的相互关系，提取系统的抽象表\n示形式\n\n\n需求变更分析\n\n静态演化往往是由于用户需求变化、系统运行出错和运行环境发生改变等原因所引起的,需要找出新的软件需求与原有的差异\n\n\n演化计划\n\n分析原系统，确定演化范围和成本，选择合适的演化计划\n\n\n系统重构\n\n根据演化计划对系统进行重构，使之适应当前的需求\n\n\n系统测试\n\n对演化后的系统进行测试，查找其中的错误和不足之处\n\n\n\n\n\n\n\n动态演化：需求、类型、内容、技术\n\n需求\n\n软件内部执行所导致的体系结构改变\n是软件系统外部的请求对软件进行的重配置\n\n\n类型\n\n交互动态性\n结构动态性\n架构动态性\n\n\n内容\n\n属性改名\n\n在运行过程中，用户可能会对非功能指标进行重新定义，如服务响应时间等\n\n\n行为变化\n\n在运行过程中，用户需求变化或系统自身服务质量的调节，都将引发软件行为的变化。如：为了提高安全级别而更换加密算法；将http协议改为https协议\n\n\n拓扑结构改变\n\n如增、删组件，增、删连接件，改变组件与连接件之间的关联关系等\n\n\n风格变化\n\n一般软件演化后其架构风格应当保持不变，如果非要改变软件的架构风格，也只能将架构风格变为其“衍生&quot;风格，如将两层c/s结构调整为三层c/s结构或c/s和B/s的混合结构\n\n\n\n\n技术\n\n动态软件架构 (SDA, Dynamic Software Architecture)\n动态重配置 (DR, Dynamic Reconfiguration)\n\n\n\n\n\n\n\n软件架构演化原则\n\n\n成本控制原则\n\n\n进度可控原则\n\n\n风险可控原则\n\n\n主体维持原则\n\n\n系统总体结构优化原则\n\n\n平滑演化原则\n\n\n目标一致原则\n\n\n模块独立烟花原则/修改局部化原则\n\n\n影响可控原则\n\n\n复杂性可控原则\n\n\n有利于重构原则\n\n\n有利于重用原则\n\n\n设计原则遵从性原则\n\n\n适应新技术原则\n\n\n环境适应性原则\n\n\n标准依从性原则\n\n\n质量向好原则\n\n\n适应新需求原则\n\n\n\n\n","plink":"ilucia.github.io/Review/SoftwareArchitecture/"},{"title":"systemCall添加自定义项目","date":"2019-03-18T18:14:00.000Z","updated":"2022-04-27T15:24:01.579Z","content":"\np.s:因为这个md解析器有些调皮……所以可能偷偷改了一些样式导致阅读障碍…… \n如果遇到了请帮助我改正这些错误，谢谢。\n\n 一，基本信息\n\n\n\n实验题目\n向 Linux 内核增加一个系统调用\n\n\n\n\n完成人姓名\nHanyuu Furude\n\n\n学号\n你猜( ﹁ ﹁ ) ~→\n\n\n报告日期\n2019/03/18\n\n\n\n 二，实验目的\n通过实验，熟悉 Linux 操作系统的使用，掌握构建与启动 Linux 内核的方法；\n掌握用户程序如何利用系统调用与操作系统内核实现通信的方法，加深对系统调\n用机制的理解；进一步掌握如何向操作系统内核增加新的系统调用的方法，以扩 展操作系统的功能。\n 三，实验内容\n\n\nLinux 环境下的 C 或 C++编译和调试工具的使用。\n\n\n向 Linux 内核增加新的系统调用，系统调用名称和功能自行定义，但必须 实现如下输出功能：“My Student No. is ×××，and My Name is ×××”。\n\n\nLinux 新内核的编译、安装和配置。 4. 编写应用程序以测试新的系统调用并输出测试结果。\n\n\n 四，实验步骤\n 思路\n在计算中，系统调用是计算机程序从其执行的操作系统内核请求服务的编程方式。这可能包括与硬件相关的服务（例如，访问硬盘驱动器）、新进程的创建和执行以及与集成内核服务（如进程调度）的通信。系统调用提供了进程和操作系统之间的基本接口。\n除了一些嵌入式系统之外，大多数现代处理器的体系结构都涉及到一个安全模型。例如，环模型规定了软件可以在多个特权级别下执行：一个程序通常被限制在它自己的地址空间，这样它就不能访问或修改其他正在运行的程序或操作系统本身，并且通常被阻止直接操作硬件设备（如帧缓冲区或网络）设备）。\n通常，系统提供一个库或API，位于正常程序和操作系统之间。在类Unix系统上，该API通常是C库（libc）实现（如glibc）的一部分，glibc为系统调用提供包装函数，通常与它们调用的系统调用命名相同。在Windows NT上，该API是nt dll.dll库中本机API的一部分；这是常规Windows API的实现所使用的未经记录的API，并且直接由Windows上的某些系统程序使用。库的包装函数公开了使用系统调用的普通函数调用约定（程序集级别的子例程调用），并使系统调用更模块化。这里，包装器的主要功能是将要传递给系统调用的所有参数放在适当的处理器寄存器中（也可能放在调用堆栈上），并为内核设置一个唯一的系统调用号。这样，在操作系统和应用程序之间存在的库就增加了可移植性。\n 步骤\n 系统版本\ndeepin-15.9-amd64\n 原内核版本\n4.15.0-29deepin-generic\n\n 后内核版本\n4.19.29\n\n 具体步骤\n\n下载Linux内核4.19.29\n\n\n\n\n解压\n\n\nxz -d linux-4.19.29.tar.xz\ntar -xf linux-4.19.29.tar\n\n\n\n\n将源代码移动到/usr/src文件夹下\n\n\n安装一些后面要用到的依赖\n\n\n笔者在安装时未记录缺少的依赖，应当根据需要安装（安装时提示缺少什么就安装什么）\n\nsudo apt install ncurses-static.x86_64\nsudo apt install openssl-static.x86_64\nsudo apt install libelf-dev\n\n\n\n进入系统调用入口表（记录了System Call的一些基本信息）\n\n\nvim ./arch/x86/entry/systemCallAdds/systemCallAdd_64.tbl\n\n​\t添加自定义的系统调用\n\n\n\n调用号\nabi\n调用名称\n入口（函数名）\n\n\n\n\n548\ncommon\nhanyuu\nsys_hanyuu\n\n\n\n\n\n添加系统调用声明\n\n\nvim ./include/linux/systemCallAdds.h\n\n若函数无参数则填写void\n\n\n实现系统调用\n\n./kernel/sys.c\n\n内核态下应当使用printk()\n用户态下使用printf()\n\n\n\n编译内核\n\n预处理\n\nsudo make menuconfig\n\n无需裁剪内核或者更改直接两次按ESC退出即可\n\n\n编译内核\n\n\nj[n]指示同时允许n个任务参与编译，请根据配置调整，笔者此处配置为\n\nCPU: Intel 8500 (6C6T all for Hyper-V)\nMemory: 40G (15G for Deepin in Hyper-V)\nDisk: Samsung 850 EVO (60G virtual disk)\n\n在Hyper-V虚拟机中该配置表现较为良好\n\n\nsudo make -j64\n截图为完成过后重新演示截图，此处j32，效率稍低\n\n\n\n漫长的编译时光……还是挺吃配置的……\n\n\n\nsudo make modules_install\n\n\n\nmake install\n安装编译好的内核\n\na. 编译完成后，重启\n\nsudo reboot\n\nb. 编写程序调用定义好的System Call\n\nprintk()处于内核态不会直接在屏幕上打印，但是他的输出可以在/proc/kmsg目录下查看\n\n\n使用dmesg也可以查看系统调用。\n​\n 五，主要数据结构及其说明\nLinux 内核包含已知的所有系统调用的列表, 即所谓的 系统调用表(System call)。 每个系统调用都分配一个唯一的数字和一个内核内部函数, 负责实际完成所需的任务。若要执行系统调用, 所需呼叫的数量存储在 CPU 的EAX 寄存器中, 然后触发软件中断 128。根据 FastCall 调用约定, 系统调用上的参数将传入 CPU 寄存器中。\n软件异常 在用户模式下中断程序执行, 并强制在内核模式下执行异常处理程序。这将确保上下文从无特权的环更改为环0。被称为异常处理程序是内核中的一个函数, 它读出 EAX 寄存器, 然后, 如果它包含有效的系统调用号码, 则从系统调用表中相应的内核函数与后续寄存器调用参数。在查看参数后, 从 “用户” 模式请求的任务最终由内核完成。如果此功能返回, 异常处理程序也将成功完成, 正常的程序流将继续在无特权模式下。\n\nmov $6, %eax ; close() ist Systemaufruf 6\nmov $15, %ebx ; Dateideskriptor als erstes Argument\nint $0x80  ; Softwareinterrupt\n\n 六，程序运行时的初值和结果\n无初值，结果为printk()函数中的内容，截图见上文。\n 七，实验体会\nSystem call 作为沟通上下层的连接件，其实现没有想象中的那么难也不算简单，只要敢于尝试就会有所收获。\n 八，源程序并附上注释\n\n./arch/x86/entry/systemCallAdds/systemCallAdd_64.tbl\n\n\n548\tcommon hanyuu sys_hanyuu //添加系统调用入口表\n\n\ninclude/linux/systemCallAdds.h\n\n\namslink sys_hanyuu(void);\t//自定义系统调用声明\n\n\nkernel/sys.c\n\n12345678910111213141516171819/** Hanyuu's system call*/asmlinkage long sys_hanyuu(void)\t//自定义系统调用实现&#123;printk(\"\\n[[hanyuu]] System call start\\n\");printk(\"my student number is [N/A] and my name ls Hanyuu Furude.\");printk(\"\\n[[hanyuu]] System call end\\n\");return 0;&#125;hanyuu.c// 测试程序#include &lt;unisted.h&gt;int main()&#123;systemcall(548);\t//调用自定义系统调用return 0;&#125;","plink":"ilucia.github.io/Others/systemCallAdd/"},{"title":"vim Reference","date":"2019-03-08T18:33:38.000Z","updated":"2022-04-27T15:24:01.595Z","content":"\nVim编辑程序有三种操作模式，分别称为 编辑模式、插入模式 和 命令模式，当运行Vim时，首先进入编辑模式\n在 vim 内部通过 ! 前缀可以执行 shell 命令\n\n编辑模式\n\n\n\n快捷键\nChange\nDelete\nYank(Copy)\n\n\n\n\nLine\ncc\ndd\nyy\n\n\nLetter\ncl\ndl\nyl\n\n\nWord\ncw\ndw\nyw\n\n\n\n跳转\n字符移动\n    h，j，k，l 左下上右\n\n行内移动\n    w 正向移动到相邻单词的首字符\n    b 逆向移动到相邻单词的首字符\n    B 向前一个单词,以空格和TAB为分隔符\n    e 正向移动到相邻单词的尾字符\n    ge 逆向移动到相邻单词的尾字符\n    0 数字０，左移光标到本行的开始；\n    $ 右移光标，到本行的末尾；\n    ^ 移动光标，到本行的第一个非空字符\n\n页移动\n    H 跳转到当前屏幕的第一行\n    M 跳转到本屏显示的中间一行\n    L 跳转到最后一行\n    2H 表示将光标移到屏幕的第２行\n    3L 表示将光标移到屏幕的倒数第3行\n    z + enter 是当前行成为屏幕的第一行\n    z + - 是当前一行成为最后一行\n    ctrl + f 在文件中前移一页（相当于 page down）；\n    ctrl + b 在文件中后移一页（相当于 page up）；\n    ctrl + d 往下滚动半屏\n    ctrl + u 往上滚动半屏\n\n文件移动\n    gg 跳到首行\n    G 调到尾行\n    nG 跳转到n行\n    % 跳到另一边括号\n\n配合查找字符的方式移动\n    fa 正向移动到第一个字符 a 处\n    Fa 逆向移动到第一个字符 a 处\n\n非相邻的单词或字符间移动\n    8w 正向移动到相隔八个单词的首字符\n    4Fa 逆向移动到第四个 a 字符\n\n更大范围的移动\n    * 当光标停留在一个单词上，* 键会在文件内搜索该单词，并跳转到下一处；\n    # 当光标停留在一个单词上，# 在文件内搜索该单词，并跳转到上一处；\n    (/) 移动到 前/后 句 的开始；\n    {/} 跳转到 当前/下一个 段落 的开始。\n    g_ 到本行最后一个不是 blank 字符的位置。\n    fa 到下一个为 a 的字符处，你也可以fs到下一个为s的字符。\n    t, 到逗号前的第一个字符。逗号可以变成其它字符。\n    3fa 在当前行查找第三个出现的 a。\n    F/T 和 f 和 t 一样，只不过是相反方向;\n    gg 将光标定位到文件第一行起始位置；\n    G 将光标定位到文件最后一行起始位置；\n    NG或Ngg 将光标定位到第 N 行的起始位置\n\n搜索匹配\n    /text 向后搜索\n    ？text 向前搜索\n    :g/targetWord 全局搜索\n    :%s/oldWord/newWord/gc 全局替换\n    n 搜索下一个同样的内容\n    N 搜索上一个同样的内容\n\n替换和删除\nVim常规的删除命令是 d、 x (前者删除 行 ，后者删除 字符 ),结合Vim的其他特性可以实现基础的删除功能。将光标定位于文件内指定位置后，可以用其他字符来替换光标所指向的字符，或从当前光标位置删除一个或多个字符或一行、多行\n    gg dG 删除全部内容\n    d0 删除至行首\n    dl 删除当前字符， dl=x\n    dh 删除前一个字符\n    dd 删除当前行\n    dj 删除上一行\n    dk 删除下一行\n    dw 删除到下一个单词开头\n    de 删除到本单词末尾\n    dE 删除到本单词末尾包括标点在内\n    db 删除到前一个单词\n    dB 删除到前一个单词包括标点在内\n    10d 删除当前行开始的10行\n    d$ 删除当前字符之后的所有字符（本行）\n    D 删除当前字符至行尾。D=d$\n    kd gg 删除当前行之前所有行（不包括当前行）\n    jdG 删除当前行之后所有行（不包括当前行）\n    :1,10d 删除1-10行\n    :11,$d 删除11行及以后所有的行\n    :1,$d 删除所有行\n    J 删除两行之间的空行，实际上是合并两行\n    rc 用 c 替换光标所指向的当前字符；\n    nrc 用 c 替换光标所指向的前 n 个字符；\n    5rA 用 A 替换光标所指向的前 5 个字符；\n    x 删除光标所指向的当前字符；\n    nx 删除光标所指向的前 n 个字符；\n    3x 删除光标所指向的前 3 个字符；\n    dw 删除光标右侧的字；\n    ndw 删除光标右侧的 n 个字；\n    3dw 删除光标右侧的 3 个字；\n    db 删除光标左侧的字；\n    ndb 删除光标左侧的 n 个字；\n    5db 删除光标左侧的 5 个字；\n    dd 删除光标所在行，并去除空隙；\n    ndd 删除（剪切） n 行内容，并去除空隙；\n    3dd 删除（剪切） 3 行内容，并去除空隙；\n    Vim常规的替换命令有 c 和 s ，结合Vim的其他特性可以实现基础的替换功能，不过替换命令执行以后，通常会由 编辑模式 进入 插入模式\n    s 用输入的正文替换光标所指向的字符；\n    S 删除当前行，并进入编辑模式；\n    ns 用输入的正文替换光标右侧 n 个字符；\n    nS 删除当前行在内的 n 行，并进入编辑模式；\n    cw 用输入的正文替换光标右侧的字；\n    cW 用输入的正文替换从光标到行尾的所有字符（同 c$ )；\n    ncw 用输入的正文替换光标右侧的 n 个字；\n    cb 用输入的正文替换光标左侧的字；\n    ncb 用输入的正文替换光标左侧的 n 个字；\n    cd 用输入的正文替换光标的所在行；\n    ncd 用输入的正文替换光标下面的 n 行；\n    c$ 用输入的正文替换从光标开始到本行末尾的所有字符；\n    c0 用输入的正文替换从本行开头到光标的所有字符。\n\n复制粘贴\n    yy 拷贝当前行\n    nyy 拷贝当前后开始的n行，比如2yy拷贝当前行及其下一行\n    *“+y 复制 1 行到操作系统的粘贴板\n    *“+nyy 复制 n 行到操作系统的粘贴板\n    :1,10 co 20 将1-10行插入到第20行之后\n    :1,co\n\n    将整个文件复制一份并添加到文件尾部\n    正常模式下按v（逐字）或V（逐行）进入可视模式，然后用jklh命令移动即可选择某些行或字符，再按y即可复制\n    ddp 交换当前行和其下一行\n    xp 交换当前字符和其后一个字符\n    正常模式下按v（逐字）或V（逐行）进入可视模式，然后用jklh命令移动即可选择某些行或字符，再按d即可剪切\n    ndd 剪切当前行之后的n行。利用p命令可以对剪切的内容进行粘贴\n    :1,10d 将1-10行剪切。利用p命令可将剪切后的内容进行粘贴。\n    :1, 10 m 20 将第1-10行移动到第20行之后。\n    x 剪切当前字符\n    3x 剪切当前光标开始向后三个字符\n    X 剪切当前字符的前一个字符。X=dh\n    p 粘贴到下一行或右侧，修改和删除的数据自动到粘贴板中\n    P 粘贴到上一行或左侧\n    如果是要替换别的单词，则先按 v 进入 visual mode，选中要替换的单词，再按粘贴即可,粘贴板中就换成了被替换的单词\n    yiw （yank inner word）在一个单词的任意字母使用,就复制该单词\n    yw 则只是复制从光标所在字母到词尾的部分\n\n撤销和重复\n    u 撤销最近一次修改 undo\n    . 重复最后一条修改正文的命令\n    U 撤销所有修改\n    ctrl + r 取消最后一次的撤销 redo\n\n块编辑\n    v 可进入visual模式，使用标准快捷键移动光标可选择文本块，之后可输入标准编辑命令\n    ctrl + v 列编辑\n    行尾块…\n\n命令行模式下的一些技巧\n    DTc 删除从光标的c之间的所有字符\n    Rc 将光标的字符替换为c\n    nDD 删除n行数据\n    nYY 复制n行数据\n    nX 删除n个字符\n    R 进入替换状态，esc退出\n\n插入模式\n进入\n    i 在当前位置生前插入\n    I 在当前行首插入\n    a 在当前位置后插入\n    A 在当前行尾插入\n    o 在当前行之后插入一行\n    O 在当前行之前插入一行\n    s 删掉当前字符，并进行输入\n    x 删掉当前字符，停留在Normal模式\n\n退出\n    Esc\n    ctrl + O 暂时性的\n    ctrl + C 取消当前的任何操作\n    ctrl + [ 官方推荐替换Esc\n\n移动光标 尽量不要进入插入模式移动光标\n    ctrl + H 光标移当前行行首 imap\n    ctrl + J 光标移下一行行首 imap\n    ctrl + K 光标移上一行行尾 imap\n    ctrl + L 光标移当前行行尾 imap\n    Alt + H 光标左移一格 imap\n    Alt + J 光标下移一格 imap\n    Alt + K 光标上移一格 imap\n    Alt + L 光标右移一格 imap\n\n命令模式\n打开、保存\n:e path_to_file/filename 在已经启动的Vim中打开一个文件\n:w 保存当前编辑的文件\n:w file_temp 将当前文件另存为file_temp\n\n退出\nZZ 保存并退出\n:wq 保存并退出\n:e! 放弃所有修改，并打开原来文件\nShift +Z,Q 无条件退出\nq! 无条件退出\nctrl + Z 退出vim，不推荐，会生成.swp的文件\n\n行号与文件\n    编辑中的每一行正文都有自己的行号，用下列命令可以移动光标到指定行（效果与 编辑模式 下的 ngg 或 nG 相同）\n\n:n 将光标移到第 n 行\n\n命令模式下，可以规定命令操作的行号范围。数值用来指定绝对行号；字符“.”表示光标所在行的行号；字符符“$”表示正文最后一行的行号；简单的表达式，例如“.+5”表示当前行往下的第 5 行。例如\n:345         将光标移到第 345 行\n:345w file   将第 345 行写入 file 文件\n:3,5w file   将第 3 行至第 5 行写入 file 文件\n:1,.w file   将第 1 行至当前行写入 file 文件\n:.,$w file   将当前行至最后一行写入 file 文件\n:.,.+5w file 从当前行开始将 6 行内容写入 file 文件\n:1,$w file   将所有内容写入 file 文件，相当于 :w file 命令\n\n在命令模式下，允许从文件中读取正文，或将正文写入文件\n:w         将编辑的内容写入原始文件，用来保存编辑的中间结果\n:wq        将编辑的内容写入原始文件并退出编辑程序（相当于 ZZ 命令）\n:w file    将编辑的内容写入 file 文件，保持原有文件的内容不变\n:a,bw file 将第 a 行至第 b 行的内容写入 file 文件\n:r file    读取 file 文件的内容，插入当前光标所在行的后面\n:e file    编辑新文件 file 代替原有内容\n:f file    将当前文件重命名为 file\n:f         打印当前文件名称和状态，如文件的行数、光标所在的行号等\n\n字符串搜索\n    在 编辑模式 讲过字符串的搜索，此处的 命令模式 也可以进行字符串搜索，给出一个字符串，可以通过搜索该字符串到达指定行。如果希望进行正向搜索，将待搜索的字符串置于两个 / 之间；如果希望反向搜索，则将字符串放在两个 ? 之间\n\n:/str/               正向搜索，将光标移到下一个包含字符串 str 的行\n:?str?               反向搜索，将光标移到上一个包含字符串 str 的行\n:/str/w file         正向搜索，并将第一个包含字符串 str 的行写入 file 文件\n:/str1/,/str2/w file 正向搜索，并将包含字符串 str1 的行至包含字符串 str2 的行写\n\nVim中的正则表达式\n:/struct/ 要搜索一行正文，这行正文的开头包含 struct 字\n因为它只找出在行中任意位置包含 struct的第一行，并不一定在行的开始包含 struct 。解决问题的办法是在搜索字符串前面加上特殊字符^\n:/^struct/\n也可以用类似办法在搜索字符串后面加上表示行的末尾的特殊字符 $ 来找出位于行末尾的字\n:/struct$/\n\n下表给出大多数特殊字符和它们的含义\n^                放在字符串前面，匹配行首的字；\n$                放在字符串后面，匹配行尾的字；\n\\&lt;               匹配一个字的字头；\n\\&gt;               匹配一个字的字尾；\n.                匹配任何单个正文字符；\n[str]            匹配 str 中的任何单个字符；\n[^str]           匹配任何不在 str 中的单个字符；\n[a-b]            匹配 a 到 b 之间的任一字符；\n*                匹配前一个字符的 0 次或多次出现；\n\\                转义后面的字符。\n\n正文替换\n    利用 :s 命令可以实现字符串的替换\n\n:%s/str1/str2/        用字符串 str2 替换行中首次出现的字符串 str1\n:s/str1/str2/g        用字符串 str2 替换行中所有出现的字符串 str1\n:.,$ s/str1/str2/g    用字符串 str2 替换正文当前行到末尾所有出现的字符串 str1\n:1,$ s/str1/str2/g    用字符串 str2 替换正文中所有出现的字符串 str1\n:g/str1/s//str2/g     功能同上\n:m,ns/str1/str2/g     将从m行到n行的str1替换成str2\n\n从上述替换命令可以看到：\ng 放在命令末尾，表示对搜索字符串的每次出现进行替换,不止匹配每行中的第一次出现；不加 g，表示只对搜索字符串的首次出现进行替换；g 放在命令开头，表示对正文中所有包含搜索字符串的行进行替换操作\ns 表示后面跟着一串替换的命令\n% 表示替换范围是所有行，即全文\n统计当前文件中字符串 str1 出现的次数\n:%s/str1/&amp;/gn\n\n删除正文\nVim的初级删除命令是用 d ，高级删除命令可以用 正则替换 的方式执行\n:d                              删除光标所在行\n:3d                             删除 3 行\n:.,$d                           删除当前行至正文的末尾\n:/str1/,/str2/d                 删除从字符串 str1 到 str2 的所有行\n:g/^\\(.*\\)$\\n\\1$/d              删除连续相同的行，保留最后一行\n:g/\\%(^\\1$\\n\\)\\@&lt;=\\(.*\\)$/d     删除连续相同的行，保留最开始一行\n:g/^\\s*$\\n\\s*$/d                删除连续多个空行，只保留一行空行\n:5,20s/^#//g                    删除5到20行开头的 # 注释\n\n恢复文件\n    Vim 在编辑某个文件时，会另外生成一个临时文件，这个文件的名称通常以 . 开头，并以 .swp 结尾。Vim 在正常退出时，该文件被删除，若意外退出，而没有保存文件的最新修改内容，则可以使用恢复命令 :recover 来恢复文件，也可以在启动Vim时用 -r 选项\n\n选项设置\n    为控制不同的编辑功能，Vim 提供了很多内部选项。利用 :set 命令可以设置选项。基本语法为\n\n:set option 设置选项 option\n\n常见的功能选项包括：\nautoindent        设置该选项，则正文自动缩进\nignorecase        设置该选项，则忽略规则表达式中大小写字母的区别\nnumber            设置该选项，则显示正文行号\nruler             设置该选项，则在屏幕底部显示光标所在行、列的位置\ntabstop           设置按 Tab 键跳过的空格数。例如 :set tabstop=n，n 默认值为 8\nmk                将选项保存在当前目录的 .exrc 文件中\n\n分屏\n    :vsplit（可用缩写 :vsp） 左右分屏\n    :split（可用缩写 :sp） 上下分屏\n    ctrl + w + hjkl 窗口之间移动\n    ctrl + w + w 逆时针遍历\n    ctrl + w = 让所有的屏都有一样的高度；\n    ctrl + w + 增加高度；\n    ctrl + w - 减少高度。\n    另外，也可以在终端里启动vim时就开启分屏操作\n    vim -On file1 file2… 打开 file1 和 file2 ，垂直分屏\n    vim -on file1 file2… 打开 file1 和 file2 ，水平分屏\n\n标签页\n    Vim的标签（Tab）页，类似浏览器的标签页，一个标签页打开一个Vim的窗口，一个Vim的窗口可以支持N个分屏\n\n:tabnew 在Vim中新建一个标签\n:tabnew filename 如果要在新建标签页的同时打开一个文件，则可以在命令后面直接附带文件路径\n\nVim中的每个标签页有一个唯一的数字序号，第一个标签页的序号是0，从左向右依次加一。关于标签页有一系列操作命令，简介如下\n:tN[ext]                跳转到上一个匹配的标签\n:tabN[ext]              跳到上一个标签页\n:tabc[lose]             关闭当前标签页\n:tabdo                  为每个标签页执行命令\n:tabe[dit]              在新标签页里编辑文件\n:tabf[ind]              寻找 'path' 里的文件，在新标签页里编辑之\n:tabfir[st]             转到第一个标签页\n:tabl[ast]              转到最后一个标签页\n:tabm[ove]  N           把标签页移到序号为N位置\n:tabnew [filename]      在新标签页里编辑文件\n:tabn[ext]              转到下一个标签页\n:tabo[nly]              关闭所有除了当前标签页以外的所有标签页\n:tabp[revious]          转到前一个标签页\n:tabr[ewind]            转到第一个标签页\n\n外部工具集成\n    Vim可以与许多外部程序集成，功能十分强大，比如 diff , ctags , sort , xxd 等等\n\ndiff\n    Linux命令 diff 用来对比两个文件的内容，不过对比结果显示在终端里，可读性比较差。结合Vim，在终端里可以直接输入命令 vimdiff，后面跟两个文件名作为参数：\n    vimdiff file1 file2\n    即可在Vim里分屏显示两个文件内容的对比结果，对文件内容差异部分进行高亮标记，还可以同步滚动两个文件内容，更可以实时修改文件内容，方便程度和用户体验大大提高。\n    vimdiff a.txt b.txt\n    如果直接给 -d 选项是一样的\n    vim -d a.txt b.txt\n    除了在终端里开启vimdiff 功能，也可以在打开Vim后，在Vim的命令模式输入相关命令来开启 vimdiff 功能：\n    :diffsplit abc.txt\n    如果你现在已经开启了一个文件，想Vim帮你区分你的文件跟 abc.txt 有什么区别，可以在Vim中用 diffsplit 的方式打开第二个文件，这个时 候Vim会用 split（分上下两屏）的方式开启第二个文件，并且通过颜色，fold来显示两个文件的区别\n    这样Vim就会用颜色帮你区分开2个文件的区别。如果文件比较大（源码）重复的部分会帮你折叠起来。\n    :diffpatch filename\n    通过 :diffpatch 你的patch的文件名，就可以以当前文件加上你的patch来显示。vim会split一个新的屏，显示patch后的信息并且用颜色标明区别。\n    如果不喜欢上下对比，喜欢左右（比较符合视觉）可以在前面加 vert ，例如：\n    :vert diffsplit abc.txt\n    :vert diffpatch abc.txt\n    看完diff，用 :only 回到原本编辑的文件，觉得diff的讨厌颜色还是在哪里，只要用 :diffoff 关闭就好了。\n    还有个常用的diff中的就是 :diffu ,这个是 :diffupdate 的简写，更新的时候用\n\nsort\n    Linux命令 sort 可以对文本内容进行按行中的字符比较、排序，但在终端里使用 sort 命令处理文件，并不能实时查看文件内容。具体用法请自查手册。\n\nxxd\n    vim+xxd 是Linux下最常用的二进制文本编辑工具，xxd其实是Vim外部的一个转换程序，随Vim一起发布，在Vim里调用它来编辑二进制文本非常方便。\n    首先以二进制模式在终端里打开一个文件：\n    vim -b filename\n    Vim 的 -b 选项是告诉 Vim 打开的是一个二进制文件，不指定的话，会在后面加上 0x0a ，即一个换行符。\n    然后在Vim的命令模式下键入：\n    :%!xxd\n    即可看到二进制模式显示出来的文本，看起来像这样：\n\n0000000: 1f8b 0808 39d7 173b 0203 7474 002b 4e49  ....9..;..tt.+NI\n0000010: 4b2c 8660 eb9c ecac c462 eb94 345e 2e30  K,......b..4^.0\n0000020: 373b 2731 0b22 0ca6 c1a2 d669 1035 39d9  7;'1.&quot;.....i.59\n\n然后就可以在二进制模式下编辑该文件，编辑后保存，然后用下面命令从二进制模式转换到普通模式：\n:%!xxd -r\n\n另外，也可以调整二进制的显示模式，默认是 2 个字节为一组，可以通过 g 参数调整每组字节数：\n:%!xxd -g 1         表示每1个字节为1组\n:%!xxd -g 2         表示每2个字节为1组(默认)\n:%!xxd -g 4         表示每4个字节为1组\n\n","plink":"ilucia.github.io/Others/vim/"},{"title":"Keras简单样例代码","date":"2019-02-26T20:30:33.000Z","updated":"2022-04-27T15:24:01.715Z","content":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990# https://tensorflow.google.cn/guide/kerasimport numpy as npimport tensorflow as tffrom tensorflow.keras import layersprint('[tensorflow.version]:', tf.VERSION)print('[tensorflow.keras.version]:', tf.keras.__version__)# 序列模型# 在 Keras 中，您可以通过组合层来构建模型。模型（通常）是由层构成的图。最常见的模型类型是层的堆叠：tf.keras.Sequential 模型。model = tf.keras.Sequential()# adds a densely-connected layer with 64 units to the modelmodel.add(layers.Dense(64, activation='relu'))# add anothermodel.add(layers.Dense(64, activation='relu'))# add a softmax layer with 10 output unitsmodel.add(layers.Dense(10, activation='softmax'))# 配置层# 我们可以使用很多 tf.keras.layers，它们具有一些相同的构造函数参数：# activation：设置层的激活函数。此参数由内置函数的名称指定，或指定为可调用对象。默认情况下，系统不会应用任何激活函数。# kernel_initializer 和 bias_initializer：创建层权重（核和偏差）的初始化方案。此参数是一个名称或可调用对象，默认为 \"Glorot uniform\" 初始化器。# kernel_regularizer 和 bias_regularizer：应用层权重（核和偏差）的正则化方案，例如 L1 或 L2 正则化。默认情况下，系统不会应用正则化函数。# Create a sigmoid layerlayers.Dense(64, activation='sigmoid')# Orlayers.Dense(64, activation=tf.sigmoid)# a liner layer with L1 regularization of factor 0.01 applied to the kernal matrixlayers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))# A linear layer with L2 regularization of factor 0.01 applied to the bias vectorlayers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01))# A linear layer with a kernel initialized to a random orthogonal matrixlayers.Dense(64, kernel_initializer='orthogonal')# A linear layer with a bias vector initialized to 2.0s:layers.Dense(64, bias_initializer=tf.keras.initializers.constant(2.0))# 训练和评估# 设置训练流程# 构建好模型后，通过调用 compile 方法配置该模型的学习流程：model = tf.keras.Sequential([    # Adds a densely-connected layer with 64 units to the model:    layers.Dense(64, activation='relu'),    # Add another:    layers.Dense(64, activation='relu'),    # Add a softmax layer with 10 output units:    layers.Dense(10, activation='softmax')])model.compile(optimizer=tf.train.AdamOptimizer(0.001),              loss='categorical_crossentropy',              metrics=['accuracy'])# tf.keras.Model.compile 采用三个重要参数：# optimizer：此对象会指定训练过程。从 tf.train 模块向其传递优化器实例，例如 tf.train.AdamOptimizer、tf.train.RMSPropOptimizer 或 tf.train.GradientDescentOptimizer。# loss：要在优化期间最小化的函数。常见选择包括均方误差(mse)、categorical_crossentropy 和 binary_crossentropy。损失函数由名称或通过从 tf.keras.losses 模块传递可调用对象来指定。# metrics：用于监控训练。它们是 tf.keras.metrics 模块中的字符串名称或可调用对象。# Configure a model for mean-squared error regression.model.compile(optimizer=tf.train.AdamOptimizer(0.01),              loss='mse',       # mean squared error              metrics=['mae'])  # mean absolute error# Configure a model for categorical classification.model.compile(optimizer=tf.train.RMSPropOptimizer(0.01),              loss=tf.keras.losses.categorical_crossentropy,              metrics=[tf.keras.metrics.categorical_accuracy])data = np.random.random((1000, 32))labels = np.random.random((1000, 10))model.fit(data, labels, epochs=10, batch_size=32)# tf.keras.Model.fit 采用三个重要参数：# epochs：以周期为单位进行训练。一个周期是对整个输入数据的一次迭代（以较小的批次完成迭代）。# batch_size：当传递 NumPy 数据时，模型将数据分成较小的批次，并在训练期间迭代这些批次。此整数指定每个批次的大小。请注意，如果样本总数不能被批次大小整除，则最后一个批次可能更小。# validation_data：在对模型进行原型设计时，您需要轻松监控该模型在某些验证数据上达到的效果。传递此参数（输入和标签元组）可以让该模型在每个周期结束时以推理模式显示所传递数据的损失和指标。data = np.random.random((1000, 32))labels = np.random.random((1000, 10))val_data = np.random.random((100, 32))val_labels = np.random.random((100, 10))model.fit(data, labels, epochs=10, batch_size=32,          validation_data=(val_data, val_labels))","plink":"ilucia.github.io/Tensorflow/keras/"},{"title":"Anaconda导出环境/从外部安装环境","date":"2019-02-25T00:00:00.000Z","updated":"2022-04-27T15:24:01.731Z","content":"\n填坑中…\n导出已有环境：\n\n1conda env export &gt; environment.yaml\n环境会被保存在 environment.yaml文件中。\n当我们想再次创建该环境，或根据别人提供的.yaml文件复现环境时，可以：\n1conda env create -f environment.yaml1","plink":"ilucia.github.io/python/envIO/"},{"title":"再生核希尔伯特空间(RKHS)","date":"2019-02-17T00:00:00.000Z","updated":"2022-04-27T15:24:01.719Z","content":"\n【转载，文末有出处】\n\n 核函数\n每一个函数fff都可以看做一个无限维的向量，那么二元函数K(x,y)K(x,y)K(x,y) 就可以看做是一个无限维的矩阵。如果它满足：\n\n正定性\n\n∫∫f(x)K(x,y)f(y)dxdy≥0\\int \\int f(\\mathrm{x})K(\\mathrm{x},\\mathrm{y})f(\\mathrm{y})d \\mathrm{x} d\\mathrm{y} \\geq 0\n∫∫f(x)K(x,y)f(y)dxdy≥0\n\n对称性:\n\nK(x,y)=K(y,x)K(\\mathrm{x},\\mathrm{y}) = K(\\mathrm{y},\\mathrm{x})\nK(x,y)=K(y,x)\n那么它就是一个核函数。\n与矩阵特征值和特征向量类似，核函数存在特征值和特征函数（将函数看做无限维向量）。也就是，\n∫K(x,y)ψ(x)dx=λψ(y)\\int K(\\mathrm{x},\\mathrm{y}) \\psi (\\mathrm{x}) d\\mathrm{x} = \\lambda \\psi (\\mathrm{y})\n∫K(x,y)ψ(x)dx=λψ(y)\n对于不同的特征值 λ1\\lambda_1λ1​, λ2\\lambda_2λ2​及其对应的特征方程 ψ1(x)\\psi_1(\\mathrm{x})ψ1​(x) , ψ2(x)\\psi_2(\\mathrm{x})ψ2​(x) ,\n∫λ1ψ1(x)ψ2(x)dx=∫λ2ψ2(x)ψ1(x)dx\\int \\lambda_1 \\psi_1(\\mathrm{x}) \\psi_2(\\mathrm{x}) d \\mathrm{x} = \\int \\lambda_2 \\psi_2(\\mathrm{x}) \\psi_1(\\mathrm{x}) d \\mathrm{x}\n∫λ1​ψ1​(x)ψ2​(x)dx=∫λ2​ψ2​(x)ψ1​(x)dx\n因此，&lt;ψ1,ψ2&gt;=∫ψ1(x)ψ2(x)dx=0&lt;\\psi_1, \\psi_2&gt; = \\int \\psi_1(\\mathrm{x}) \\psi_2(\\mathrm{x}) d \\mathrm{x} = 0&lt;ψ1​,ψ2​&gt;=∫ψ1​(x)ψ2​(x)dx=0 。也就是说特征方程是正交的。\n一个核函数对应无穷个特征值 {λi}i=1∞\\{ \\lambda_i \\}_{i=1}^\\infty{λi​}i=1∞​ 和无穷个特征方程 {φi}i=1∞\\{ \\varphi_i \\}_{i=1}^\\infty{φi​}i=1∞​ 。和矩阵类似，\nK(x,y)=∑i=0∞λiψi(x)ψi(y)K(\\mathrm{x},\\mathrm{y}) = \\sum_{i=0}^{\\infty} \\lambda_i \\psi_i(\\mathrm{x}) \\psi_i(\\mathrm{y})\nK(x,y)=i=0∑∞​λi​ψi​(x)ψi​(y)\n这就是Mercer定理。这里， &lt;ψi,ψj&gt;=0,i≠j。{ψ}i=1∞&lt;\\psi_i, \\psi_j&gt;=0 , i \\ne j 。 \\{ \\psi \\}_{i=1}^{\\infty}&lt;ψi​,ψj​&gt;=0,i̸​=j。{ψ}i=1∞​ 是原来函数空间的一组正交基。\nRKHS\n将 {λiψi}i=1∞\\{\\sqrt{ \\lambda_i} \\psi_i \\}_{i=1}^\\infty{λi​​ψi​}i=1∞​ 作为一组正交基构建一个希尔伯特空间 H\\mathcal{H}H 。这个空间中的任何一个函数（向量）都可以表示为这组基的线性组合。如\nf=∑i=1∞fiλiψif= \\sum_{i=1}^{\\infty} f_i \\sqrt{\\lambda_i} \\psi_if=∑i=1∞​fi​λi​​ψi​\n那么 f 就可以表示为 H\\mathcal{H}H 中的一个无限维的向量：\nf=(f1,f2,...)HTf= (f_1,f_2,...)_{\\mathcal{H}}^T\nf=(f1​,f2​,...)HT​\nK(x,y)K(\\mathrm{x},\\mathrm{y})K(x,y) 表示二元函数或无限维矩阵， K(x,⋅)K(\\mathrm{x},\\cdot)K(x,⋅) 就可以表示矩阵第 x 行的一元函数或无限维向量，也就是固定核函数的一个参数为 x\\mathrm{x}x ，那么\nK(x,⋅)=∑i=0∞λiψi(x)ψiK(\\mathbf{x},\\cdot) = \\sum_{i=0}^{\\infty} \\lambda_i \\psi_i (\\mathbf{x}) \\psi_i\nK(x,⋅)=i=0∑∞​λi​ψi​(x)ψi​\n将每一项除去对应的基底，对应到空间 H\\mathcal{H}H中的向量就是\nK(x,⋅)=(λ1ψ1(x),λ2ψ2(x),...)HTK(\\mathrm{x},\\cdot) = ( \\sqrt{\\lambda_1} \\psi_1(\\mathrm{x}), \\sqrt{\\lambda_2} \\psi_2(\\mathrm{x}), ... )_{\\mathcal{H}}^T\nK(x,⋅)=(λ1​​ψ1​(x),λ2​​ψ2​(x),...)HT​\n同样的，\nK(y,⋅)=(λ1ψ1(y),λ2ψ2(y),...)HTK(\\mathrm{y},\\cdot) = ( \\sqrt{\\lambda_1} \\psi_1(\\mathrm{y}), \\sqrt{\\lambda_2} \\psi_2(\\mathrm{y}), ... )_{\\mathcal{H}}^T\nK(y,⋅)=(λ1​​ψ1​(y),λ2​​ψ2​(y),...)HT​\n因此，\n&lt;K(x,⋅),K(y,⋅)&gt;H=∑i=0∞λiψi(x)ψi(y)=K(x,y)。&lt; K(\\mathbf{x},\\cdot), K(\\mathbf{y},\\cdot) &gt;_\\mathcal{H} = \\sum_{i=0}^{\\infty} \\lambda_i \\psi_i (\\mathbf{x}) \\psi_i(\\mathbf{y}) = K(\\mathbf{x},\\mathbf{y}) 。\n&lt;K(x,⋅),K(y,⋅)&gt;H​=i=0∑∞​λi​ψi​(x)ψi​(y)=K(x,y)。\n以上就是核的可再生性(reproducing)，即用核函数来再生两个函数的内积。 H\\mathcal{H}H 也被叫做可再生核希尔伯特空间(RKHS, reproducing kernel Hilbert space)。\n如果定义了一个映射，\nΦ(x)=K(x,⋅)=(λ1ψ1(x),λ2ψ2(x),⋯&ThinSpace;)T\\boldsymbol{\\Phi} (\\mathbf{x}) = K(\\mathbf{x},\\cdot) = (\\sqrt{\\lambda_1} \\psi_1 (\\mathbf{x}), \\sqrt{\\lambda_2} \\psi_2 (\\mathbf{x}), \\cdots )^T\nΦ(x)=K(x,⋅)=(λ1​​ψ1​(x),λ2​​ψ2​(x),⋯)T\n将点 x\\mathrm{x}x 映射到空间 H\\mathcal{H}H 。那么，\n&lt;Φ(x),Φ(y)&gt;H=&lt;K(x,⋅),K(y,⋅)&gt;H=K(x,y)。&lt; \\boldsymbol{\\Phi} (\\mathbf{x}), \\boldsymbol{\\Phi} (\\mathbf{y}) &gt;_\\mathcal{H} = &lt; K(\\mathbf{x},\\cdot), K(\\mathbf{y},\\cdot) &gt;_\\mathcal{H} = K(\\mathbf{x},\\mathbf{y}) 。\n&lt;Φ(x),Φ(y)&gt;H​=&lt;K(x,⋅),K(y,⋅)&gt;H​=K(x,y)。\n因此，我们并不需要知道这个映射是什么，特征空间在哪里，只要是一个对称正定的函数 K ，就必然存在映射 Φ\\PhiΦ 和特征空间 H\\mathcal{H}H ,使得\n&lt;Φ(x),Φ(y)&gt;=K(x,y)。&lt; \\boldsymbol{\\Phi} (\\mathbf{x}), \\boldsymbol{\\Phi} (\\mathbf{y}) &gt; = K(\\mathbf{x},\\mathbf{y}) 。\n&lt;Φ(x),Φ(y)&gt;=K(x,y)。\n这就是所谓的核技巧(kernel trick)。\n\n转载:\n\n再生核希尔伯特空间-cplusplus \n所有权利归原作者所有，非盈利非商业用途，侵删\n\n\n","plink":"ilucia.github.io/deeplearning/RKHS/"},{"title":"将文件从git commit记录中抹除","date":"2019-02-15T00:00:00.000Z","updated":"2022-04-27T15:24:01.719Z","content":" 清理过大的git文件夹\n 列出git历史中最大的deepth个文件\n1git verify-pack -v .git/objects/pack/[fingerPoint].idx | sort -k [deepth] -n | tail -[deepth]\n\n\nexample:\n\ninput\n\n1git verify-pack -v .\\.git\\objects\\pack\\pack-f13f96d5194e9f568b7723e0427cbc343930bfbb.idx\n\noutput\n\n123451a1c62895eb17949c2dd60043e536d6a6afe3626 commit 656 515 122db819c543801fcc5ca910430f61d2532e880be0 tree   37 48 527ac3fb948a48f9164b91ca35264a077d001981ea7 blob   61 63 575non delta: 3 objects.\\.git\\objects\\pack\\pack-f13f96d5194e9f568b7723e0427cbc343930bfbb.pack: ok\n\n\n 查询对应的文件名\n1git rev-list --objects --all | grep [fileFingerPoint]\n\n\nexample:\n\ninput\n\n  1git rev-list --objects --all | grep ac3fb948a48f9164b91ca35264a077d001981ea7\noutput\n  1ac3fb948a48f9164b91ca35264a077d001981ea7 README.md\n 将文件从所有commit中（如果有，删除）\n  1git filter-branch -tree-filter 'rm -f [fileName]' HEAD\n 运行整理\n  1git gc\n 精简不存在的branch\n  1git remote prune [branchName]\n 查看所有分支的所有操作历史\n  1git rflog --all\n\n","plink":"ilucia.github.io/git/gitClear/"},{"title":"lagrange multiplier拉格朗日乘子法","date":"2019-02-13T15:05:58.000Z","updated":"2022-04-27T15:24:01.719Z","content":"基本的拉格朗日乘子法就是求函数f(x1,x2,…)在约束条件g(x1,x2,…)=0下的极值的方法。\n其主要思想是将约束条件函数与原函数联立，从而求出使原函数取得极值的各个变量的解。\n 定义\n对于具有l个等式约束的n维优化问题\nmin f(x1,x2,⋅⋅⋅), s.t. hk(x1,x2,⋅⋅⋅,xn) (k=1,2,⋅⋅⋅,l)min\\ f(x_1,x_2,\\cdot \\cdot \\cdot),\\ s.t. \\  h_k(x_1,x_2,\\cdot\\cdot\\cdot,x_n)\\ (k=1,2,\\cdot\\cdot\\cdot,l)\nmin f(x1​,x2​,⋅⋅⋅), s.t. hk​(x1​,x2​,⋅⋅⋅,xn​) (k=1,2,⋅⋅⋅,l)\n把原目标函数f(x)f(x)f(x)改造成为如下形式的新的目标函数\nF(x,λ)=f(x)+∑k=1lλkhk(x)F(x,\\lambda)=f(x)+\\sum_{k=1}^l\\lambda_kh_k(x)\nF(x,λ)=f(x)+k=1∑l​λk​hk​(x)\n式中的hk(x)h_k(x)hk​(x)就是原目标函数f(x)f(x)f(x)的等式约束条件，而待定系数λk\\lambda_kλk​称为拉格朗日乘子。这种方法称为拉格朗日乘子法。在极值点处，有\n∂F∂λxi=0 (i=1,2,⋅⋅⋅,n)\\frac{\\partial F}{\\partial \\lambda x_i}=0\\  (i=1,2,\\cdot\\cdot\\cdot,n)\n∂λxi​∂F​=0 (i=1,2,⋅⋅⋅,n)\n和\n∂F∂λk=0 (k=1,2,⋅⋅⋅,l)\\frac{\\partial F}{\\partial \\lambda_k}=0\\ (k=1,2,\\cdot\\cdot\\cdot,l)\n∂λk​∂F​=0 (k=1,2,⋅⋅⋅,l)\n，共有n+ln+ln+l个方程，足以算出这n+ln+ln+l个变量，此法也称为升维法。\n 基本原理\n拉格朗日乘子法是一种经典的求解条件极值的解析方法，可将所有约束的优化模型问题转化为无约束极值问题的求解。一般带不等式约束的最优化问题求解如下式：\n\\begin{equation}\n\\left\\{\n\t\\begin{array}{lr}\n\tmin\\  f(x) &amp; \\\\\n\ts.t.\\  g_i(x)\\leq0\\  (j=1,2,\\cdot\\cdot\\cdot,J)\n\t\\end{array}\n\\right.\n\\end{equation}\n\n拉格朗日乘子法是用于变量无关的是常数λi (j=1,2,⋅⋅⋅,J)\\lambda_i\\  (j=1,2,\\cdot\\cdot\\cdot,J)λi​ (j=1,2,⋅⋅⋅,J)分别乘各约束函数gi(x)≤0 (j=1,2,⋅⋅⋅J)g_i(x)\\leq0\\ (j=1,2,\\cdot\\cdot\\cdot J)gi​(x)≤0 (j=1,2,⋅⋅⋅J)并与目标函数相加得到如下的拉格朗日函数：\nL(x,λ,v)=f(x)+∑j=1Jλj[gj(x)+vj2]L(x,\\lambda,v)=f(x)+\\sum_{j=1}^{J}{\\lambda_j[g_j(x)+v^2_j]}\nL(x,λ,v)=f(x)+j=1∑J​λj​[gj​(x)+vj2​]\n，式中：x=[x1,x2,⋅⋅⋅,xj]Tx=[x_1,x_2,\\cdot\\cdot\\cdot,x_j]^Tx=[x1​,x2​,⋅⋅⋅,xj​]T为自变量；λ=[λ1,λ2,⋅⋅⋅,λj]T\\lambda=[\\lambda_1,\\lambda_2,\\cdot\\cdot\\cdot,\\lambda_j]^Tλ=[λ1​,λ2​,⋅⋅⋅,λj​]T为拉格朗日乘子量；v=[v1,v2,⋅⋅⋅,vj]Tv=[v_1,v_2,\\cdot\\cdot\\cdot,v_j]^Tv=[v1​,v2​,⋅⋅⋅,vj​]T为松弛变量。\n则L(x,λ,v)L(x,\\lambda ,v)L(x,λ,v)在x∗​x^*​x∗​处取极值的必要条件为：\n\\begin{equation}\n\\left\\{\n\t\\begin{array}{lr}\n\t\\frac{\\partial L}{\\partial x_k}=\\frac{\\partial f(x)}{\\partial x_k}+\\sum^J_{j=1}{\\lambda_j\\frac{\\partial g(x)}{\\partial x_k}}=0 &amp; \\\\\n\t\\frac{\\partial L}{\\partial \\lambda}=\\sum^J_{j=1}{(g_i(x)+v^2_j)}=0 &amp; \\\\\n\t\\frac{\\partial L}{\\partial v}=\\sum^J_{j=1}2\\lambda_jv_j=0\n\t\\end{array}\n\\right.\n\\end{equation}\n\n，依据上式求得x∗x^*x∗即为最优解。\n\n参考：\n\n拉格朗日乘子法\n拉格朗日乘子法：写得很通俗的文章\n非盈利非商业使用，侵删\n\n\n","plink":"ilucia.github.io/deeplearning/LagrangeMultiplier/"},{"title":"范数","date":"2019-02-12T23:00:00.000Z","updated":"2022-04-27T15:24:01.719Z","content":" L−PL-PL−P范数\n与闵可夫斯基距离的定义一样，L−PL-PL−P范数不是一个范数，而是一组范数，其定义如下\nLp=∑inxipp x=x1,x2,⋅⋅⋅,xnL_p=\\sqrt[p]{\\sum_i^n{x^p_i}}\\  x=x_1,x_2,\\cdot \\cdot \\cdot ,x_n\nLp​=pi∑n​xip​​ x=x1​,x2​,⋅⋅⋅,xn​\n根据P​的变化，范数也有着不同的变化，一个经典的有关P​范数的变化图如下：\n\n\n上图表示了P从∞\\infty∞到000变化时，三维空间中到原点的距离（范数）为111的点构成的图形的变化情况。以常见的L−2L-2L−2范数（p=2p=2p=2）为例，此时的范数也即欧氏距离，空间中到原点的欧氏距离为111的点构成了一个球面。实际上，在0≤p≤10\\leq p\\leq10≤p≤1\n时，LpL_pLp​并不满足三角不等式的性质，也就不是严格意义下的范数。以p=0.5p=0.5p=0.5，二维坐标(1,4),(4,1),(1,9)(1,4),(4,1),(1,9)(1,4),(4,1),(1,9)为例，1+40.5+4+10.5&lt;1+90.5\\sqrt[0.5]{1+\\sqrt{4}}+\\sqrt [0.5]{\\sqrt{4}+1}&lt;\\sqrt[0.5]{1+\\sqrt{9}}0.51+4​​+0.54​+1​&lt;0.51+9​​。因此这里的L-P范数只是一个概念上的宽泛说法。\n L0L0L0范数\n当P=0P=0P=0时，也就是L0L0L0范数，由上面可知，L0L0L0范数并不是一个真正的范数，它主要被用来度量向量中非零元素的个数。用上面的L-P定义可以得到的L-0的定义为：\n∣∣x∣∣=∑1nxi00 x=x1,x2,⋅⋅⋅,xn||x||=\\sqrt[0]{\\sum_1^nx^0_i}\\  x=x_1,x_2,\\cdot \\cdot \\cdot ,x_n\n∣∣x∣∣=01∑n​xi0​​ x=x1​,x2​,⋅⋅⋅,xn​\n这里就有点问题了，我们知道非零元素的零次方为1，但零的零次方，非零数开零次方都是什么鬼，很不好说明L0的意义，所以在通常情况下，大家都用的是：\n∣∣x∣∣0=#(i) with xi≠0||x||_0=\\#(i)\\  with\\  x_i \\neq 0\n∣∣x∣∣0​=#(i) with xi​̸​=0\n在实际应用中，由于L0L0L0范数本身不容易有一个好的数学表示形式，给出上面问题的形式化表示是一个很难(NP难)的问题。所以在实际情况中，L0的最优问题会被放宽到L1或L2下的最优化。\n (Lasso Regression)L1(Lasso\\ Regression)L1(Lasso Regression)L1范数\nL1范数是我们经常见到的一种范数，它的定义如下：\n∣∣x∣∣1=∑i=1n∣xi∣ x=x1,x2,⋅⋅⋅,xn||x||_1=\\sum _{i=1}^{n}|x_i|\\  x=x_1,x_2,\\cdot \\cdot \\cdot ,x_n\n∣∣x∣∣1​=i=1∑n​∣xi​∣ x=x1​,x2​,⋅⋅⋅,xn​\n表示向量xix_ixi​中非零元素的绝对值之和。\nL1范数有很多的名字，例如我们熟悉的曼哈顿距离,最小绝对误差等。使用L1范数可以度量两个向量间的差异，如绝对误差和（Sum of Absolute Difference)。对于L1L1L1范数，它的优化问题如下：min∣∣x∣∣1min||x||_1min∣∣x∣∣1​ 由于L1范数的天然性质，对L1优化的解是一个稀疏解，因此L1L1L1范数也被叫做稀疏规则算子。通过L1L1L1可以实现特征的稀疏，去掉一些没有信息的特征，例如在对用户的电影爱好做分类的时候，用户有100个特征，可能只有十几个特征是对分类有用的，大部分特征如身高体重等可能都是无用的，利用L1L1L1范数就可以过滤掉。\n (Lasso Regression)L2(Lasso\\ Regression)L2(Lasso Regression)L2范数\nL2范数是我们最常见最常用的范数了，我们用的最多的度量距离欧氏距离就是一种L2范数，它的定义如下：\n∣∣x∣∣2=∑i=1nxi2||x||_2=\\sqrt{\\sum_{i=1}^{n}x^2_i}\n∣∣x∣∣2​=i=1∑n​xi2​​\n表示向量元素的平方和再开平方。 像L1L1L1范数一样，L2L2L2也可以度量两个向量间的差异，如平方差和（Sum of Squared Difference）。\n对于L2L2L2范数，它的优化问题如下：min∣∣x∣∣2min||x||_2min∣∣x∣∣2​L2L2L2范数通常会被用来做优化目标函数的正则化项，防止模型为了迎合训练集而过于复杂造成过拟合的情况，从而提高模型的泛化能力。\n L1L1L1与L2L2L2范数的比较\nL2范数越小，可以使得w的每个元素都很小，接近于0，但L1范数不同的是他不会让它等于0而是接近于0. /\n\n\n\n\n但由于L1范数并没有平滑的函数表示，起初L1最优化问题解决起来非常困难，但随着计算机技术的到来，利用很多凸优化算法使得L1最优化成为可能。\n 贝叶斯先验\n从贝叶斯先验的角度看，加入正则项相当于加入了一种先验。即当训练一个模型时，仅依靠当前的训练数据集是不够的，为了实现更好的泛化能力，往往需要加入先验项。\n\n\nL1范数相当于加入了一个Laplacean先验；\n\n\nL2范数相当于加入了一个Gaussian先验。\n如下图所示：\n\n\n\n\n L∞L\\inftyL∞范数\n当P=∞P=\\inftyP=∞时，也就是L−∞L-\\inftyL−∞范数，它主要被用来度量向量元素的最大值。用上面的L-P定义可以得到的L∞L\\inftyL∞的定义为：\n∣∣x∣∣∞=xi∞∞ x=x1,x2,⋅⋅⋅,xn||x||_\\infty=\\sqrt[\\infty]{x^\\infty_i}\\  x=x_1,x_2,\\cdot \\cdot \\cdot ,x_n\n∣∣x∣∣∞​=∞xi∞​​ x=x1​,x2​,⋅⋅⋅,xn​\n与L0L0L0一样，在通常情况下，大家都用的是：∣∣x∣∣∞=max(xi)||x||_\\infty=max(x_i)∣∣x∣∣∞​=max(xi​)来表示L∞L\\inftyL∞\n\n参考文章:\n\n\n几种范数的简单介绍 - Kobe Bryant的专栏 - CSDN博客\n\n\nL0/L1/L2范数的联系与区别\n\n\n机器学习中的范数规则化之（一）L0,L1与L2范数\n非盈利非商业性质，侵删。\n\n\n\n","plink":"ilucia.github.io/deeplearning/norm/"},{"title":"Python 依赖冲突","date":"2019-02-10T11:06:59.000Z","updated":"2022-04-27T15:24:01.715Z","content":"笔者在安装scikit-image包时发现tensorflow import时直接崩溃，后发现scikit-image(后简称skimage)和tensorflow-gpu(后简称tensorflow)都依赖于numpy包，不幸的是，最新版本的scikit-image和tensorflow依赖的numpy包版本不相同并且互相不兼容(　o=^•ェ•)o　┏━┓，笔者也曾经在各搜索引擎寻找解决方案……无非是重装或者更新numpy版本，（然而并没有啥用.jpg）\n如果您也遇到了相同的问题……（先为您默哀一秒）\n目前笔者收集到的的解决方案有如下几种：\n\n更新您的冲突依赖到最新版本（未必有效，笔者这种情况就无解，但是这是代价最小的一种方法，如果能用这种办法解决就再好不过了，所以请有限尝试此办法）\n寻找某个历史版本的包使两者使用相同的numpy版本（如果是其他包的其他依赖冲突则寻找使用冲突依赖的相同版本的包）（至于版本改动带来的功能差异……您只能对应的修改您的实现）\n将您的实现分开使用不同的环境跑（我知道这听起来很不爽但是如果您一定要用冲突的版本可能也只有这个办法了……手动修改实现的巨擘除外）\n使用其他包代替（听起来像废话但是这的确是个方法2333）\n自闭（简单粗暴）（逃）\n我没有发现而您觉得行之有效的任何方法，请务必赐教笔者，感激不尽，orz\n\n 举例说明\n笔者冲突的包是\n\nscipy 1.2.1\ntensorflow 1.12.0\n被依赖的冲突的包是\nnumpy\n报错现象\nRuntimeError: module compiled against API version 0xc but this version of numpy is 0xb\n解决方法\ntensorflow 1.12.0版本过高导致numpy兼容性问题(tensorflow-gpu 1.12.0还有其他已知bug,此处不表)逐级降低tensorflow版本到1.10.0之后发现问题消失可以正常使用\n兼容的一组包\nscipy 1.2.1\ntensorflow 1.10.0\n\n 写在最后\n配置环境一直都是比较玄学的问题(没有经验的情况下),如果您遇到了环境问题,请先保持冷静,保持冷静,冷静,然后,上网看看别人有没有类似的问题,如果没有的话,请耐心探索吧,这也是……一种经验吧……\n","plink":"ilucia.github.io/Tensorflow/packageConflicts/"},{"title":"炼丹路上那些踩过的坑","date":"2019-02-10T00:00:00.000Z","updated":"2022-04-27T15:24:01.715Z","content":" 使用VSCode运行openCV劝退事宜\n您若使用VSCode尝试Debug openCV-Python，我们强烈建议您立刻放弃这样的尝试。因为目前VSCode插件pylint无法正常解析openCV-python.详情请见VSCode团队官方issue\n推荐使用PyCharm或者Vim(高级玩家限定)\n Why I have an error:cv2.waitkey(0) &amp; 0xff\n\n高位的2个字节由Shift, Control, Num lock等状态表示，为了消除他们的影响统一用&amp; 0xff清除这些信息。\n原文摘录，戳我跳转:\nThe answers which have already been posted suggest that some of the unusual values obtained by waitKey are due to platform differences. Below, I propose that (at least on some platforms) the apparently odd behaviour of waitKey is due to keyboard modifiers. This post looks similar to Tomasz’s answer because I initially wrote this as an edit, which was rejected.\nThe keycodes returned by waitKey change depending on which modifiers are enabled. NumLock, CapsLock, and the Shift, Ctrl, and Alt keys all modify the keycode returned by waitKey by enabling certain bits above the two Least Significant Bytes. The smallest of these flags is Shift at 0x10000.\nA modified version of the script Tomasz posted is given below:\n\n123456789101112131415#!/usr/bin/env pythonimport cv2import syscv2.imshow(sys.argv[1], cv2.imread(sys.argv[1]))res = cv2.waitKey(0)print('You pressed %d (0x%x), 2LSB: %d (%s)' % (res, res, res % 2**16,repr(chr(res%256)) if res%256 &lt; 128 else '?'))    # Which give the following results:    # q letter with NumLock:    # You pressed 1048689 (0x100071), 2LSB: 113 ('q')    # Escape key with CapsLock but not NumLock:    # You pressed 131099 (0x2001b), 2LSB: 27 ('\\x1b')    # Space with Shift and NumLock:    # You pressed 1114144 (0x110020), 2LSB: 32 (' ')    # Right Arrow Key with Control, NumLock off:    # You pressed 327507 (0x4ff53), 2LSB: 65363 ('S')\nI hope that helps to explain the unusual behaviour of waitKey and how to get the actual key pressed regardless of the state of NumLock and CapLock. From here it’s relatively simple to do something like:\n 1ctrlPressed = 0 != res &amp; (1 &lt;&lt; 18)\n…as the “control key” flag is bit 19. Shift is at bit 17, the state of CapsLock at bit 18, Alt is at bit 20, and NumLock is at bit 21.\n cuDNN 初始化失败\n\nError : Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\n如果您使用的Tensorflow版本是1.12.0…… \n这可能是个tensorflow的bug、建议回退版本观望， \nissue on github\n %matplotlib inline 报错 invalid syntax\n%matplotlib inline 是jupyter notebook/console的语法，当你调用matplotlib.pyplot绘图函数plot()或生成figure时，在python console里面生成图像。\n如果在其他地方运行，可直接注释。\n","plink":"ilucia.github.io/Tensorflow/commomQuestion/"},{"title":"Medical image Data Processing","date":"2019-02-03T00:00:00.000Z","updated":"2022-04-27T15:24:01.719Z","content":"\n转载自医疗影像数据处理–python处理nifti数据\n\n\ndicom\ndicom是由磁共振设备扫描产生的,一般是一个slice一个文件,\n分析格式: .img/.hdr\nnifti\n由fsl \\ afni \\ spm 共同确定的格式,支持3D,4D影响\n分析格式: img/hdr\ndicom -----&gt; nifti 影像处理流程\n\n\n利用spm将dicom原始数据转换为 分析格式:.img 和.hdr\n利用dcm2nifti工具将dicom数据转为nifti 3d数据\n利用spm进行3d转为4d\n处理nifti数据的可用工具：matlab\\ITK\\VTK\\python.\n我们使用python处理该类型的数据\n开发工具\n语言python2.7\npython module: nipy scipy nibabel matplotlib\n\n 获取数据形态信息及头信息\n123456789101112131415#-*- coding=utf8 -*-import nibabel as nib#import os#from nibabel.testing import data_path#d_path= os.path.join(data_path,\"1.nii\")#data1= nib.load(d_path)data1= nib.load(\"1.nii\")#数据形状print data1.shapeprint data1.affine.shapeimg = data1.get_data()#数据形状,矩阵数据每一维的数据尺寸print img.shape#数据头信息print data1.header\n 获取slice信息生成图像\n123456789101112131415161718#-*- coding=utf8 -*-import nibabel as nibimport matplotlib.pyplot as plt#把slice数据生成图片的方法def show_img(slices):fig, axes = plt.subplots(1, len(slices))for i, slice in enumerate(slices):axes[i].imshow(slice.T, cmap=\"gray\", origin=\"lower\")#读取nifti文件中的slice数据data1= nib.load(\"/home/lee/nifti/1.nii.gz\")img = data1.get_data()#获取单张slice数据slice_0 = img[26, :, :]slice_1 = img[:, 30, :]slice_2 = img[:, :, 16]#生成图表show_img([slice_0, slice_1, slice_2])plt.suptitle(\"show slice image\")","plink":"ilucia.github.io/deeplearning/MedicalimageDataProcessing/"},{"title":"terminology in deeplearning","date":"2019-01-31T23:36:20.000Z","updated":"2022-04-27T15:24:01.715Z","content":"\n交叉熵\nID3\nC4.5\n感知机\nSVM(支持向量机)\nSVM&amp;SVR\n再生核希尔伯特空间\n贝叶斯分类器\n极大似然估计\n图像语义分割\n卷积神经网络应用：基于Tensorflow的CNN/CRF图像分割技术\n运用图像处理解决基于MRI的脑肿瘤图像分割问题\nTensorflow实现FCN\nhttps://blog.csdn.net/taigw/article/details/51401448\nwaiting… (。・∀・)ノ\n\n","plink":"ilucia.github.io/Tensorflow/terminology/"},{"title":"Python炼丹炉（maching learning）环境搭建常见问题","date":"2019-01-31T00:00:00.000Z","updated":"2022-04-27T15:24:01.731Z","content":" Using Anaconda/Conda with Powershell\n\n\n在anaconda/conda中创建虚拟python环境：\nconda create -n env_name python=x.x\n\n\n在anaconda prompt 和 cmd中，激活一个环境：\nactivate env_name\n\n\nPowershell添加conda/anaconda支持：\n\n安装库： 1conda install -n root -c pscondaenvs pscondaenvs\n\n\n\n如果因为某些原因无法通过上述方案安装……请手动下载安装\nOffical Link： https://github.com/BCSharp/PSCondaEnvs\n\n\n\n更改PowerShell配置：\n以管理员身份启动PowerShell，并执行RemoteSigned```1234567``` powershellPS C:\\Hanyuu&gt; Set-ExecutionPolicy RemoteSigned执行策略更改执行策略可帮助你防止执行不信任的脚本。更改执行策略可能会产生安全风险，如http://go.microsoft.com/fwlink/?LinkID=135170 中的 about_Execution_Policies帮助主题所述。是否要更改执行策略?[Y] 是(Y)  [A] 全是(A)  [N] 否(N)  [L] 全否(L)  [S] 暂停(S)  [?] 帮助(默认值为“N”):Y\n\n\n此时可以正常使用Powershell切换到特定环境\n\n\n1activate [EnvironmentName]\n\n原理：其实……就是……加了个……ps1文件替换bat……（呵呵呵~）\n\n\n\n Using Jupyter with anaconda/conda\n\n\n原理：在虚拟环境下缺少kernel.json文件\n\n\nAdd a exists environment into Jupyter\n\n\nInstall ipykernel\n1conda install ipykernel\n\n\nCreate kernel files in virtual environment\n1conda install -n [EnvironmentName] ipykernel\n\n\nactivate virtual environment\n1activate [EnvironmentName]\n\n\nAdd your virtual environment into kernel for notebook\n1python -m ipykernel install --user --name [EnvironmentName] --display-name [EnvironmentDisplayName]\n\n\nopen your jupyter notebook and enjoy your pythoning : )\n1jupyter notebook\n\n\n\n\nIf your environment has not been created…\n1conda create -n [EnvironmentName] python=?.? ipykernel\n\n\nDelete a environment\n1jupyter kernelspec remote [EnvironmentName]\n\n\n Jupyter 自动补全和主题修改\nlink\n","plink":"ilucia.github.io/python/Conda/"},{"title":"Tensorflow卷积和池化","date":"2019-01-30T10:49:28.000Z","updated":"2022-04-27T15:24:01.715Z","content":" 构建基于MNSIT的多层卷积网络\n\n\n演示示例\n摘录自TensorFlow中文社区\n\n 权重初始化\n\n为了创建这个模型，我们需要创建大量的权重和偏置项。这个模型中的权重在初始化时应该加入少量的噪声来打破对称性以及避免0梯度。由于我们使用的是ReLU神经元，因此比较好的做法是用一个较小的正数来初始化偏置项，以避免神经元节点输出恒为0的问题（dead neurons）。为了不在建立模型的时候反复做初始化操作，我们定义两个函数用于初始化。\n\n1234567def weight_variable(shape):  initial = tf.truncated_normal(shape, stddev=0.1)  return tf.Variable(initial)def bias_variable(shape):  initial = tf.constant(0.1, shape=shape)  return tf.Variable(initial)\n\n【Ps】：tf.truncated_normal(shape, mean, stddev) :shape表示生成张量的维度，mean是均值，stddev是标准差。这个函数产生正太分布，均值和标准差自己设定。这是一个截断的产生正太分布的函数，就是说产生正太分布的值如果与均值的差值大于两倍的标准差，那就重新生成。和一般的正太分布的产生随机数据比起来，这个函数产生的随机数与均值的差距不会超过两倍的标准差，但是一般的别的函数是可能的。\n【From】：CSDN\n\n 卷积和池化\n\nTensorFlow在卷积和池化上有很强的灵活性。我们怎么处理边界？步长应该设多大？在这个实例里，我们会一直使用vanilla版本。我们的卷积使用1步长（stride size），0边距（padding size）的模板，保证输出和输入是同一个大小。我们的池化用简单传统的2x2大小的模板做max pooling。为了代码更简洁，我们把这部分抽象成一个函数。\n\n12345def conv2d(x, W):  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')def max_pool_2x2(x):  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1], padding='SAME')\n 第一层卷积\n\n现在我们可以开始实现第一层了。它由一个卷积接一个max pooling完成。卷积在每个5x5的patch中算出32个特征。卷积的权重张量形状是[5, 5, 1, 32]，前两个维度是patch的大小，接着是输入的通道数目，最后是输出的通道数目。 而对于每一个输出通道都有一个对应的偏置量。\n\n12W_conv1 = weight_variable([5, 5, 1, 32])b_conv1 = bias_variable([32])\n\n为了用这一层，我们把x变成一个4d向量，其第2、第3维对应图片的宽、高，最后一维代表图片的颜色通道数(因为是灰度图所以这里的通道数为1，如果是rgb彩色图，则为3)。\n\n1x_image = tf.reshape(x, [-1,28,28,1])\n\nWe then convolve x_image with the weight tensor, add the bias, apply the ReLU function, and finally max pool. 我们把x_image和权值向量进行卷积，加上偏置项，然后应用ReLU激活函数，最后进行max pooling。\n\n12h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)h_pool1 = max_pool_2x2(h_conv1)\n 第二层卷积\n\n为了构建一个更深的网络，我们会把几个类似的层堆叠起来。第二层中，每个5x5的patch会得到64个特征。\n\n12345W_conv2 = weight_variable([5, 5, 32, 64])b_conv2 = bias_variable([64])h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)h_pool2 = max_pool_2x2(h_conv2)\n 密集连接层\n现在，图片尺寸减小到7x7，我们加入一个有1024个神经元的全连接层，用于处理整个图片。我们把池化层输出的张量reshape成一些向量，乘上权重矩阵，加上偏置，然后对其使用ReLU。\n12345W_fc1 = weight_variable([7 * 7 * 64, 1024])b_fc1 = bias_variable([1024])h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n Dropout\n\n为了减少过拟合，我们在输出层之前加入dropout。我们用一个placeholder来代表一个神经元的输出在dropout中保持不变的概率。这样我们可以在训练过程中启用dropout，在测试过程中关闭dropout。 TensorFlow的tf.nn.dropout操作除了可以屏蔽神经元的输出外，还会自动处理神经元输出值的scale。所以用dropout的时候可以不用考虑scale。\n\n12keep_prob = tf.placeholder(\"float\")h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n 输出层\n\n最后，我们添加一个softmax层，就像前面的单层softmax regression一样。\n\n1234W_fc2 = weight_variable([1024, 10])b_fc2 = bias_variable([10])y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n 训练和评估模型\n\n为了进行训练和评估，我们使用与之前简单的单层SoftMax神经网络模型几乎相同的一套代码，只是我们会用更加复杂的ADAM优化器来做梯度最速下降，在feed_dict中加入额外的参数keep_prob来控制dropout比例。然后每100次迭代输出一次日志。\n\n123456789101112131415cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))sess.run(tf.initialize_all_variables())for i in range(20000):  batch = mnist.train.next_batch(50)  if i%100 == 0:    train_accuracy = accuracy.eval(feed_dict=&#123;        x:batch[0], y_: batch[1], keep_prob: 1.0&#125;)    print \"step %d, training accuracy %g\"%(i, train_accuracy)  train_step.run(feed_dict=&#123;x: batch[0], y_: batch[1], keep_prob: 0.5&#125;)print \"test accuracy %g\"%accuracy.eval(feed_dict=&#123;    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0&#125;)\n\n以上代码，在最终测试集上的准确率大概是99.2%。\n\n","plink":"ilucia.github.io/Tensorflow/TensorflowConvandPool/"},{"title":"Tensorflow入坑试水","date":"2019-01-30T10:49:28.000Z","updated":"2022-04-27T15:24:01.715Z","content":" Leadin\n The computation graph\t计算图\n Building the graph\t建立一张图\n1234import tensorflow as tfmatrix1 = tf.constant([[3.,3.]]) # create a constantmatrix2 = tf.constant([[2.],[2.]])product = tf.matmul(matrix1,matrix2)  # create a matlum op(operation)\n Launching the graph in a session 在图中开启一个会话\n1234sess = tf.Session()  # create a session in tensorflowresult = sess.run(product)print(result)sess.close()   # DONT FORGET THIS!\nor\n12with tf.Session as sess:\t# Do something\n Tensors 张量\n Variables 变量\n Constant 常量\n1234567891011121314import tensorflow as tfstate = tf.Variable(0, name = 'Counter')ont = tf.constant(1)new_value = tf.add(state, one)update = tf.assign(state, new_value)init_op = tf.global_variables_initializer()# init_op = tf.initialize_all_variables()# not recommand for that will be disabled shrotly.with tf.Session() as sess:\tsess.run(init_op)\tprint(sess.run(state))\tfor _ in range(3):\t\tsess.run(update)\t\tprint(sess.run([state,one,new_value]))\n Fetch 取回\n Feed 供给\n\nPlaceholder 占位符\n\n12345input1 = tf.placeholder(tf.float32)input2 = tf.placeholder(tf.float32)output = tf.add(input1,input2)with tf.Session() as sess:\tprint(sess.run([output],feed_dict = &#123;input1:[7.], input2:[2.]&#125;))","plink":"ilucia.github.io/Tensorflow/TensorflowLeadin/"},{"title":"Tensorflow参数参阅","date":"2019-01-30T10:49:28.000Z","updated":"2022-04-27T15:24:01.715Z","content":" Tensorflow变量类型\n\n\n\nName\nUseage\n\n\n\n\ntf.Variable\nTensor变量\n\n\ntf.constant\nTensor常量\n\n\ntf.placeholder\nTensor占位符\n\n\ntf.SparseTensor\nTensor稀疏张量\n\n\n\n 设备管理\n 查看设备列表\n1234import osfrom tensorflow.python.client import device_libos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"99\"print(device_lib.list_local_devices())\n样例输出：\n1234567891011121314151617[name: \"/device:CPU:0\"device_type: \"CPU\"memory_limit: 268435456locality &#123;&#125;incarnation: 16586473374130916263, name: \"/device:GPU:0\"device_type: \"GPU\"memory_limit: 1418693427locality &#123;  bus_id: 1  links &#123;  &#125;&#125;incarnation: 9802250829700710596physical_device_desc: \"device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"]\n 指定某设备进行计算\n1234567891011import tensorflow as tf#选择设备 CPU-&gt;CPU:0with tf.device('/gpu:1'):    # '/gpu:0'    # '/cpu:0'    v1 = tf.constant([1.0, 2.0, 3.0], shape=[3], name='v1')    v2 = tf.constant([1.0, 2.0, 3.0], shape=[3], name='v2')    sumV12 = v1 + v2    #config=tf.ConfigProto(log_device_placement=True)打印执行操作所用的设备    with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:        print sess.run(sumV12)\n 使用GPU计算要求\n若要使用Tensorflow-gpu，请检查您是否有算力大于3的NVIDIA显卡。\n\n查询显卡算力地址\n若要使用CUDA加速计算，请确保您已安装CUDA Toolkit,并且按需下载并配置您需要的Deep learning frameworks,目前，我们用到的frameworks有cuDNN,请确保您的framework和CUDA版本配套，否则无法使用。\n\n 使用交互式环境\n 查看Tensor详细情况\n123456789101112131415    #使用CPU进行计算    with tf.device(\"/cpu:0\"):        a = tf.constant([1.0,2.0,3.0,4.0,5.0,6.0],shape=[2,3])        b = tf.constant([1.0,2.0,3.0,4.0,5.0,6.0],shape=[3,2])        c = tf.matmul(a,b)        #查看计算时硬件的使用情况        sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))        print(sess.run(c))#设置运行时候的参数        options = tf.RunOptions(output_partition_graphs=True)        metadata = tf.RunMetadata()        c_val = sess.run(c,options=options,run_metadata=metadata)        print(metadata.partition_graphs)        #关闭session        sess.close()\n ImportError: No module named input_data\n由于版本更新，Tensorflow已经不建议再使用input_data.如果需要继续使用，请查看[input_data.py](../Example/input_data.py)\n\n TensorFlow结构\n\n使用图 (graph) 来表示计算任务.\n在被称之为 会话 (Session) 的上下文 (context) 中执行图.\n使用 tensor 表示数据.\n通过 变量 (Variable) 维护状态.\n使用 feed 和 fetch 可以为任意的操作(arbitrary operation) 赋值或者从其中获取数据.\n\n 基本操作符\n1import tensorflow as tf\n\n常量\n\n123import tensorflow as tfnode0 = tf.constant(3.0,dtype=tf.float32)node1 = tf.constant(3.0,dtype)# also tf.float32 implicitly\n\n会话\n\n12sess = tf.Session()print(sess.run([node0,node1]))\n\n相加计算\n\n12node2 = tf.add(node0, node1)print('node2', sess.run(node2))\n\n矩阵乘法\n\n1node2 = tf.matmul(node0,node1)\n\nPlaceholder占位符\n\n123a = tf.placeholder(tf.float32)b = tf.placeholder(tf.float32)adder_node = a + b  # + provides a shortcut for tf.add(a, b)\n\nfeed_dict\n\n12print(sess.run(adder_node, &#123;a:3, b:4.5&#125;))print(sess.run(adder_node, &#123;a: [1,3], b: [2,4]&#125;))\n\n变量\n\n1234W = tf.Variable([.3], dtype=tf.float32)b = tf.Variable([-.3], dtype=tf.float32)x = tf.placeholder(tf.float32)linear_model = W*x + b\n\n初始化变量\n\n1init = tf.global_variables_initializer()\\\n\n求值\n\n1print(sess.run(linear_model, &#123;x: [1,2,3,4]&#125;))\n\n结束会话\n\n1sess.close()\n\n降维求和\n··· py\nloss = tf.reduce_sum()\n\n123456* 损失函数``` pyy = tf.placeholder(tf.float32)squared_deltas = tf.square(linear_model - y)    #损失函数(y(hat)-y)^2loss = tf.reduce_sum(squared_deltas)            #减小Lossprint(sess.run(loss, &#123;x: [1,2,3,4], y: [0, -1, -2, -3]&#125;))\n\n梯度下降\n\n1234567optimizer = tf.train.GradientDescentOptimizer(0.01) #梯度下降法train = optimizer.minimize(loss)                    #设定损失函数目标sess.run(init)# reset values to incorrect defaults. #初始化变量for i in range(1000):   sess.run(train, &#123;x: [1,2,3,4], y: [0, -1, -2, -3]&#125;)#迭代优化   #print(sess.run([W, b]))print(sess.run([W, b]))                             #现实更新后的W,b的值\n\n\ntf.argmax\n\n12&gt;tf.argmax(input, axis=None, name=None, dimension=None)&gt;\n\n\n此函数是对矩阵按行或列计算最大值\n 参数\n\ninput：输入Tensor\naxis：0表示按列，1表示按行\nname：名称\ndimension：和axis功能一样，默认axis取值优先。新加的字段\n返回：Tensor  一般是行或列的最大值下标向量\n\n\n\n\ntf.cast\n\n1234567&gt;   a = tf.Variable([1,0,0,1,1])&gt;   b = tf.cast(a,dtype=tf.bool)&gt;   sess = tf.Session()&gt;   sess.run(tf.initialize_all_variables())&gt;   print(sess.run(b))&gt;   [ True False False True True]&gt;\n\n\ncast(x, dtype, name=None)\n将x的数据格式转化成dtype.例如，原来x的数据格式是bool，\n那么将其转化成float以后，就能够将其转化成0和1的序列。反之也可以\n\n","plink":"ilucia.github.io/Tensorflow/TensorflowRef/"},{"title":"工具链和工具索引","date":"2019-01-30T00:00:00.000Z","updated":"2022-04-27T15:24:01.559Z","content":" Tech guide\n Coding\n\nleetcode\n\n Cpp online complier\n\ngcc.godbolt(a cpp online complier!)\ncoliru(a cpp online complier!)\n\n common website fast reference\n Version control\n\nGithub\nVisualStudioTeamService\n\n Others\n\nMSDN,I tell you\n\n Tools\n Boost\n\nboost\n\n Opencv\n\nOpenCV [Github Repo]\nOpenCV中文网站\nLearn OpenCV\n\n SQL\n\nMySQL\nMySQL workbench[SQL可视化工具]\nMySQL快速入门教程\nsqlite\n\n Python\n\nPython org\npython3教程【廖雪峰】\nrequests(爬虫)\nbase64-python\nPyQT5\nPyQT5\nxlrd (Excel文档读取)\n\n environment manager\n\nanaconda\nanaconda doc\nMiniconda&amp;doc\n\n node.js\n\nnode.js\nnode.js doc\nnode.js [cn]\n\n GUI tools\n\ncocos creator documentation\ncocos API\ncocos2d-x documentation\ncocos2d-x API\nfairygui\nfairygui_cocos2d-x SDK\nunity3d\n\n Documenting\n Markdown and components\n\nmarkdown\nshields\nmathjax\nreadthedocs\n\n HTML ,ui, color and components\n\n\nhttp://www.w3school.com.cn/xml/index.asp\n\n\nhttp://www.w3school.com.cn/htmldom/dom_intro.asp\n\n\nSAX\n\n\nnippon colors\n\n\n Latex\n\nLatex project\nLatex3 [Github repo]\nLatex with vsCode\n\n Else\n\nResilio Sync[同步工具]\nTranslucentTB[Windows任务栏美化]\nTranslucentTB[Windows任务栏美化，UWP]\nQuickLook[快速文件预览]\nQuickLook[快速文件预览，UWP]\n\n Machine Learning\n Numpy\n\nNumpy and Scipy Documentation\n\n OpenCV\n\nOpenCV Library\nOpenCV 3.4 Ref page\nOpenCV-Python doc\n\n Tensorflow\n\nTensorFlow\nTensorFlow cn\nTensorFlowTach google\nTensorFlow.js\nChainer doc\nkeras\nkeras cn google\nkeras cn\n\n Deep learning\n\nDeep Learning Book En\nDeep Learning Book Cn（github)\n Deep Learning\n Deep Learning MOOC\n Deep Learnign  MOOC_Q&amp;A_Sheet\n\n Cloud\n\nIntel AI DevCloud\n\n CUDA\n\nCUDA\nCUDnn cuda-toolkit\nTHE MNIST DATABASE of handwritten digits\n\n\n[*:These were not accessible because of GFW. : ( ]\n由旧版本主页迁移而来，\n\n","plink":"ilucia.github.io/Link/"},{"title":"Software Engineering Review","date":"2019-01-13T13:16:18.000Z","updated":"2022-04-27T15:24:01.659Z","content":" Chapter 00 Intorduction\n\n软件工程的概念、方法和技术：\n\n软件工程基本概念（软件产品、软件过程、软件开发模型）\n软件工程开发方法和技术\n\n传统的软件工程方法与技术\n面向对象的软件工程方法与技术\n\n\n软件测试策略和技术\n软件项目管理\n\n\n\n Chapter 01 Software and Software Engineering\n\n\nSoftware’s dual role\n\nSoftware is a product (软件即产品（服务）)\n\nTransforms information - produces, manages, acquires, modifies, displays or transmits information;\nDelivers computing potential of hardwora and networks.\n\n\nSoftware is a vehicle(载体) for delivering a product.\n\n\n\nHardware &amp; Software\n\n\nwear out vs. Deterioration 软件老化和变质\n\n\n\n\n\nComponent Based &amp; Custom Built\n\nThe software industry dose seem to be moving (slowly) toward component-based construction.\\\n\n\n\nSoftware Complexity\n\nNo Silver Bullet (智力密集型没有最优解不可预估bug不可避免)\n\n\n\n\nSoftware changeability 软件可更改性\n\nIt must be fixed to eliminate errors. 必须对其进行修复以消除错误。\nIt must be enhanced to implement new functional and non-functional requirements 必须对其进行改进, 以实现新的功能和非功能要求\nSoftware must be adapted to meet the needs of new computing environments or technology.软件必须进行调整, 以满足新的计算环境或技术的需要。\nSoftware must be enhanced to implement new business requirements.必须增强软件以实现新的业务需求。\nSoftware must be extended to make it interoperable with other more modern systems or databases.软件必须进行扩展, 以使其可与其他更现代的系统或数据库进行互操作。\nSoftware must be re-architected to make it viable(切实可行的) within a network environment.必须重新构建软件, 使其在网络环境中可行。\n\n\n\n\n\nSoftware Evolution[Lehman定律]（记标题就行）\n\nThe Law of Continuing Change [持续变化规律] (1974):  E-type systems must be continually adapted else they become progressively less satisfactory.\nThe Law of Increasing Complexity [复杂性增长规律] (1974):  As an E-type system evolves its complexity increases unless work is done to maintain or reduce it.\nThe Law of Self Regulation [自我调控规律] (1974):  The E-type system evolution process is self-regulating with distribution of product and process measures close to normal.\nThe Law of Conservation of Organizational Stability [组织稳定性守恒规律] (1980):  The average effective global activity rate in an evolving E-type system is invariant over product lifetime.\nThe Law of Conservation of Familiarity [保证通晓性规律] (1980): As an E-type system evolves all associated with it, developers, sales personnel, users, for example, must maintain mastery of(熟悉) its content and behavior to achieve satisfactory evolution.\nThe Law of Continuing Growth [持续增长规律] (1980):  The functional content of E-type systems must be continually increased to maintain user satisfaction over their lifetime.\nThe Law of Declining Quality [质量衰减规律] (1996): The quality of E-type systems will appear to be declining unless they are rigorously maintained and adapted to operational environment changes.\nThe Feedback System Law [反馈系统规律] (1996):  E-type evolution processes constitute multi-level, multi-loop, multi-agent feedback systems and must be treated as such to achieve significant improvement over any reasonable base.\n\n\n\n\nSoftware Myths 软件谬论\n\n\nSoftware Myths affect managers, customers (and other non-technical stakeholders) and practitioners\n\n\nSoftware Myths are believable because they often have elements of truth,\n\nbut …\n\nInvariably lead to bad decisions,\n\n\ntherefore …\n\nInsist on reality as you navigate your way through software engineering\n\n\n\n\n\nIf we get behind schedule, we can add more programmers and catch up.\n\n\nA general statement about objectives is sufficient to begin building programs.\n\n\nChange in project requirements can be easily accommodated because software is flexible.\n\n\nManagement Myths\n\n\n\n\n\n“We already have a book of standards and procedures for building software. It does provide my people with everything they need to know …”\n“If my project is behind the schedule, I always can add more programmers to it and catch up …”\n“If I decide to outsource the software project to a third party, I can just relax: Let them build it, and I will just pocket my profits …”\n\n\nCustomer Myths\n\n\n“A general statement of objectives is sufficient to begin writing programs - we can fill in the details later …”\n“Project requirements continually change but this change can easily be accommodated because software is flexible …”\n\n\nPractitioner’s Myths\n\n\n“Let’s start coding ASAP, because once we write the program and get it to work, our job is done …”\n“Until I get the program running, I have no way of assessing its quality …”\n“The only deliverable work product for a successful project is the working program …”\n“Software engineering is baloney[胡扯]. It makes us create tons of paperwork, only to slow us down …”\n\n Chapter 02 Process 软件过程（综述）\n\n\nOverview\n\n\nWhat? 过程是什么？当开发产品或构件系统时，遵循一系列可预测的步骤（即路线图）是非常重要的，它有助于及时交付高质量的产品。\n\n\nWho? 相关人员？管理人员、软件工程师和客户均应该参与过程的定义、建立和测试。\n\n\nWhy?重要性？提高了软件开发活动的稳定性、可控性和有组织性；否则软件活动会失控并变得混乱。\n\n\nSteps?有哪些步骤？ 具体步骤随着所构造的软件类型不同在细节方面有所变化，但对所有过程来讲有很多活动是相同的。\n\n\nWork product?有哪些工作产品？ 是指过程中定义的一系列活动和任务的结果，包括Programs, documents, and data.\n\n\nCorrect process?什么是正确的过程？ Assessment, quality deliverable.\n\n\nIEEE Definition\n\nSoftware Engineering: (1) The application of a systematic, disciplined, quantifiable[系统的、规范的和可量化的] approach to the development, operation, and maintenance of software; that is, the application of engineering to software. (2) The study of approaches as in (1).\n\n\n\n\n\n\n软件过程\n\n软件过程是一个为建造高质量软件所需完成的任务的框架，即形成软件产品的一系列步骤。包括中间产品、资源、角色及过程中采取的方法、工具等范畴。\n\n\n\nSoftware process model\n\nAttempt to organize the software life cycle by\n\ndefining activities involved in software production[软件生产]\ndefining order of activities and their relationships\n\n\nGoals of a software process\n\nstandardization, predictability, productivity, high product quality, ability to plan time and budget requirements\n\n\n\n\n\n早期做法： Code &amp; Fix\n&gt;The earliest approach\n&gt;\n&gt;*   Write code\n&gt;\n&gt;*   Fix it (修复) to eliminate any errors that have been detected, to enhance existing functionality, or to add new features\n&gt;\n&gt;*   Source of difficulties and deficiencies\n&gt;    *   impossible to predict（不可预测性）\n&gt;    *   impossible to manage\n\n\n\n软件危机 Symptoms of inadequacy: the software crisis\n\n\nscheduled time and cost exceeded\n\n\nuser expectations not met\n\n\npoor quality\n\n\nThe size and economic value of software applications require appropriate “process models”\n\n\nProcess model goals (B.Boehm 1988)\n\n\n\n\n\ndetermine the order of stages involved in software development and evolution, and to establish the transition criteria（标准尺度） for progressing from one stage to the next.  These include completion criteria for the current stage plus choice criteria and entrance criteria for the next stage. Thus a process model addresses the following software project questions:确定软件开发和进化所涉及的阶段的顺序, 并建立从一个阶段到下一个阶段的过渡标准。 其中包括当前阶段的完成标准加上选择标准和下一阶段的标准。因此, 流程模型解决了以下软件项目问题:\n\n\nWhat shall we do next?\n\n\nHow long shall we continue to do it?\n\n\n\n\n\n软件过程\n\n\n黑盒观点\n\n\n\n\n\nProblems\n\n\nThe assumption is that requirements can be fully understood prior to development\n\n\nInteraction with the customer occurs only at the beginning (requirements) and end (after delivery)\n\n\nUnfortunately the assumption almost never holds\n\n\n\n\n\n\n白盒观点\n\n\n\n\nAdvantages\n\nReduce risks by improving visibility\nAllow project changes as the project progresses\n\nbased on feedback from the customer\n\n\n\n\n\n\n\n软件开发活动\n\n线性过程模型\n非线性模型\n\n\n\n\n\n过程框架\n\n\n\n通用活动框架（非常重要）\n\n\n\n\n普适性活动 Umbrella Activities\n\nSoftware project management\nFormal technical reviews\nSoftware quality assurance\nSoftware configuration management\nWork product preparation and production\nReusability management\nMeasurement\nRisk management\n\n\n\n能力成熟度模型集成**(CMMI)\n\n\n过程评估 Process Assessment\n\n评估软件过程以确认满足了成功软件工程所必需的基本过程标准(basic\nprocess criteria**)**要求.The process should be assessed to ensure that it meets a set of basic process criteria that have been shown to be essential for a successful software engineering.\n\n\n\n\n Chapter 03 Process Models\n\n软件生命周期、概念、阶段\n软件过程模型\n\n\n\n\nPrescriptive Models[惯例模型]\n\n\nPrescriptive process models advocate an orderly approach to software engineering.\n\nquestion\n\nIf prescriptive process models strive for structure and order, are they inappropriate for a software world that thrives on change?\nYet, if we reject traditional process models (and the order they imply) and replace them with something less structured, do we make it impossible to achieve coordination and coherence in software work?\n\n\n\n\n\nThe waterfall Model 瀑布模型\n\n\n\n\n\n\n(适用于需求较为固定和明确的场景、不适应大量、频繁的更改)\n\nThe requirements are knowable in advance of implementation.\nThe requirements have no unresolved, high-risk implications.\n\n\nrisks due to COTS choices, cost, schedule, performance, safety, security, user interfaces, organizational impacts.\n\n\nThe nature of  the requirements will not change very much.\n\n\nDuring development; during evolution.\n\n\nThe requirements are compatible with all the key system stakeholders’ expectations.\n\ne.g., users, customer, developers, maintainers, investors.\n\n\nThe right architecture for implementing the requirements is well understood.\nThere is enough calendar time to proceed sequentially.~\n\n\n\n\nThe V Model V模型\n\n\n\n\n\nIncremental Models 增量模型\n\n\n\n\nRAD 模型\n\n\n\n\nEvolutionary Models 演化模型\n\n\n\n客户不确定要求 工程师对算法效率 可用性不确定\n帮助客户和工程师了解要构建的内容快速设计和实现\n\n\n\nPrototyping 原型\n\n\n\n\n\n\n原型范式中的问题\nsw 工程师尝试修改原型以用作工作版本\n一旦客户看到工作原型, 她希望很快就能得到工作产品\n\n\n\nThe Spiral 螺旋形\n\n\n\n\n\nFull Spiral Model\n\nRadial dimension[按射线方向]: cumulative cost to date\nAngular dimension[按螺旋方向]: progress through the spiral\n\n\n\n\nUP Unified Process Model 统一过程模型\n\n用例驱动\n以体系结构为中心\n迭代和增量\njia’gou\n\nLife cycle\n\n\n\n\n\n Chapter 04 Agile Development\n\n\n敏捷开发\n\n适应变更\n交流通畅\n客户参与\n有效控制\n原则\n\n尽早交付、持续交付\n欢迎变更、创造优势\n经常交付、间隔紧凑\n开发期间业务人员和开发人员在一起工作\n围绕受激励的个人、提供环境和支持并信任\n团队内部面对面交谈最有效率效果\n可持续开发、赞助人开发者用户长期稳定的开发速度\n关注优秀技能提升敏捷能力\n保持简单\n好的架构、需求、设计出自组织团队\n定时反省、及时调整\n\n\n\n\n\nIndividuals and interactions(交互) over processes and tools\nWorking software over comprehensive documentation\nCustomer collaboration over contract negotiation (谈判)\nResponding to change over following a plan\n​\t(No sliver bullet 自相矛盾而无可奈何)\n增量发布\\多生命周期\n交付产品\n\n可运行软件\n源代码\n\n使用权\n销售权\n\n\n\n\n\n\n极限编程 XP\n\n\nBegins with the creation of user stories\n\n\nAgile team assesses each story and assigns a cost\n\n\nStories are grouped to for a deliverable increment\n\n\nA commitment[承担义务] is made on delivery date[交货日期]\n\n\nAfter the first increment, project velocity is used to help define subsequent delivery dates for other                                                increments\n\n\n\n\n\n\n\n\n\n\n\n Chapter 06 系统工程\n\n系统工程中的概念\n\n元素    （软件生态系统）\n\n软件\n硬件\n人\n数据库（数据）\n文档\n规程\n\n\n层次体系\n\n\n\n\n\n\n系统建模\n\n定义在所考虑视图中满足需要的过程\n描述过程行为和该行为所依据的假设\n明确定义模型的外在和内在输入\n描述有助于工程师理解视图的全部联系\n\n\n系统建模分类\n\nBusiness Process Engineering(PBE)\n\n\n\n Chapter 07 需求工程\n\n\n需求工程任务\n\n\n初启Inception—Establish a basic understanding of the problem and the nature of the solution.\n\n\n启发Elicitation—Draw out the requirements from stakeholders.\n\n\n细化Elaboration—Create an analysis model that represents information, functional, and behavioral\naspects of the requirements.\n\n\n协商Negotiation—Agree on a deliverable system that is realistic for developers and customers.\n\n\n规范Specification—Describe the requirements formally or informally.\n\n\n验证Validation—Review the requirement specification for errors, ambiguities, omissions, and conflicts.\n\n\n需求管理Requirements management—Manage changing requirements.\n\n\n\n\n需求工程工作产品\n\n可行性和必要描述\n系统或产品的范围说明\n参与需求导出的客户、用户和其他利益共同者的列表\n系统技术环境的说明\n需求列表（含领域限制）\n一系列使用场景\n任何能更好的定义需求的原型\n\n\n\n需求开发方法\n\n需求获取：1 开始过程：与客户建立初步交流。2 导出过程：通过访问和调查，获得需求的描述\n需求分析：精化过程，通过分析建模，建立精确的技术模型，说明软件功能，特征和约束。\n需求处理：1 协商过程 2 形成规格说明 3 需求确认\n\n\n\n Chapter 08 模型分析\n\n分析模型的作用\n\nspecifies software’s operational characteristics\nindicates software’s interface with other system elements\nestablishes constraints that software must meet\n\n\n分析模型的构建原则（经验原则）\n\nThe model should focus on requirements that are visible within the problem or business domain. The level of abstraction should be relatively high.\nEach element of the analysis model should add to an overall understanding of software requirements and provide insight into the information domain, function and behavior of the system.\nDelay consideration of infrastructure and other non-functional models until design.\nMinimize coupling throughout the system.\nBe certain that the analysis model provides value to all stakeholders.\nKeep the model as simple as it can be.\n\n\n方法\n\n场景建模\n\n用况use-case\n部署图\n……\n\n\n类建模\n\nclass图\n协作图\n……\n\n\n行为建模\n\n状态转换图\n活动图\n顺序图\n\n\n\n\n\n Chapter 09 设计工程\n\n设计概念\n\n抽象abstraction\n体系结构architecture\n模式patterns\n逐步求精refinement\n模块化modularity\n信息隐藏information hiding\n模块独立functional independence\nRefactoring（重构）\n\n\n\n Chapter 10 架构设计\n\n\n为何进行体系结构设计\n\n体系结构是系统的表示形式, 使软件工程师能够:\n\n分析设计在满足其规定要求方面的有效性,\n在设计更改仍然相对容易的阶段考虑体系结构替代方案, 并且降低与软件建设相关的风险。\n\n\n\n\n\n体系结构风格（style）\n\nData-centered architecture\nData flow architecture\nCall and return architecture\nObject-oriented architecture\nLayered architecture\nEach style describes a system category that encompasses:\n\na set of components (e.g., a database, computational modules) that perform a function required by a system,\na set of connectors that enable “communication, coordination, and cooperation” among components\nconstraints that define how components can be integrated to form the system, and\nsemantic models that enable a designer to understand the overall properties of a system.\n\n\n\n\n\n\nEach style describes a system category that encompasses:\n\na set of components (e.g., a database, computational modules) that perform a function required by a system,\na set of connectors that enable “communication, coordination, and cooperation” among components,\nconstraints that define how components can be integrated to form the system, and\n\n\n\nusemantic models that enable a designer to understand the overall properties of a system.\n\n\n Chapter 11 组件设计\n\n构件\n\nA complete set of software components is defined during architectural design\nBut the internal data structures and processing details of each component are not represented at a level of abstraction that is close to code\nComponent-level design defines the data structures, algorithms, interface characteristics, and communication mechanisms allocated to each component\n\n\n构建设计原则：开关、替换、依赖倒置、接口分离、内聚性、耦合性\n构建设计方法：DPL、程序流程图、决策表\n\n Chapter 13~14 软件测试技术\n\n\nVerification 确保软件正确实现功能\n\n\nValidation 确保软件可追溯需求\n\n\n测试策略\n\n单元测试\n集成测试：big bang, top down, bottom up\n确认测试\n系统测试\n\n\n\n测试用例\n\n\n测试技术\n\n白盒、黑盒\n手工测试、自动化测试\n\n\n\n\n\n\n Chapter 15 软件产品度量\n\n\n\n软件质量\n\n\n一般来讲，软件质量是对明确陈述的功能和性能需求、明确记录的开发标准以及对所有专业化软件开发应具备的隐含特征的符合度。\n\n软件需求是质量测量的基础，不符合需求就是没有质量。\n若未能遵守开发准则，则肯定质量有问题。\n若软件符合显示需求，但未能满足其隐式需求，则软件质量仍然值得怀疑。\n\n\n\n\n\n\n度量框架\n\n\n软件产品：文档、代码、软件等\n度量手段:\n测度（measures）\n度量（metrics）\n指标（Indicators）\n度量原则\n\n•设定度量目标：The objectives of measurement should be established before data collection begins;\n•定义要明确：Each technical metric should be defined in an unambiguous manner;\n•有效理论支持：Metrics should be derived based on a theory that is valid for the domain of application (e.g., metrics for design should draw upon [利用] basic design concepts and principles and attempt to provide an indication of the presence of an attribute that is deemed desirable);\n•度量指标的选择要是最合适的：Metrics should be tailored to best accommodate specific products and processes.\n\n度量过程\n\n•Formulation【公式化】. The derivation of software measures and metrics appropriate for the representation of the software that is being considered.\n•Collection【收集数据】. The mechanism used to accumulate data required to derive the formulated metrics.\n•Analysis【分析结果】. The computation of metrics and the application of mathematical tools.\n•Interpretation【解释评估】. The evaluation of metrics results in an effort to gain insight into the quality of the representation.\n•Feedback【反馈】 Recommendations derived from the interpretation of product metrics transmitted to the software team.\n\n\n\n\n\n过程度量作用：提供能够引导长期的软件过程改进的一组过程指标。\n项目度量作用：使得软件管理者能够（1）评估正在进行中的项目的状态（2）跟踪潜在的分险（3） 在问题造成不良影响前发现他们（4）调整工作流程或任务（5）评估项目团队控制软件工作产品质 量的能力\n产品度量作用：为分析、设计、编码和测试能更客观的执行和更定量的评估提供基础\n\n Chapter 21 软件工程管理\n\n4P模型\n\nPeople — the most important element of a successful project\nProduct — the software to be built\nProcess — the set of framework activities and software engineering tasks to get the job done\nProject — all work required to make the product a reality\n\n\n\nW5HH\n\n Chapter 15，22 过程和项目度量\n\n\n\nMcCall质量因素\n\n\n\nWhy measure\n\nassess the status of an ongoing project\ntrack potential risks\nuncover problem areas before they go “critical”\nadjust work flow or tasks\nevaluate the project team’s ability to control quality of software work products.\n\n\n\n\nMeasures,Metrics,Indicators\n\n\nprocess\n\n\nprocess product\n\n\nproject\n\n\n\n\nmeasures of errors uncovered before release of the software\n\n\ndefects delivered to and reported by end-users\n\n\nwork products delivered (productivity)\n\n\nhuman effort expended\n\n\ncalendar time expended\n\n\nschedule conformance\n\n\nother measures.\n\n\n\n\n\n\n度量的作用\n\n\n Chapter 23 软件项目预算\n\n\n项目计划任务和内容\n\n\n软件项目计划\n\n建立一套务实的策略控制跟踪监视一个复杂的技术项目\n目的：保证最终结果按时高质量。\n\n\n\n属性\n\n\n项目规模\n\n\n项目工作量（人月）\n\n\n项目所需资源\n\n\n项目成本\n\n\n\n\n\n\n\nLOC&amp;FP\n\n\n\n\n\nFP:Function Point 功能点\n\n\n Chapter 24 项目进度安排和跟踪\n\n\n\n\n任务网络、关键路径的作用\n\n\n里程碑\n\n Chapter 25 风险管理\n\n风险具有不确定性和造成损失的特点\n\n\n被动风险和主动风险管理\n\nRisk Management Paradigm（风险过程管理）\n\n\n\nRMMM（Risk,Mitigation,Moritoring and Management）\n\nmitigation:如何避免/转移风险\nmonitoring:监视\nmanagement:管理\n\n\n\n Chapter 26 质量管理\n\n\nMcCall软件质量模型\n软件质量保证活动\n\n\n正式技术评审\n\n\n\n\n软件质量的成本\n\n Chapter 27 变更管理\n\n\n软件配置项、版本、基线etc.\n\n\n软件配置管理流程\n\n\n","plink":"ilucia.github.io/Review/SoftwareEngineering/"},{"title":"Java 复习提纲","date":"2019-01-10T00:00:00.000Z","updated":"2022-04-27T15:24:01.619Z","content":"\n垃圾回收 System.gc()\n\n Chapter 01\n\n数据类型\n\n\n\n\n类型\n容量（bit）\n范围\n包装器\n\n\n\n\nboolean\n1\ntrue\\false\nBoolean\n\n\nchar\n16\nUnicode\nCharacter\n\n\nbyte\n8\n[−128,127][-128,127][−128,127]\nByte\n\n\nshort\n16\n[−215,215−1][-2^{15},2^{15}-1][−215,215−1]\nShort\n\n\nint\n32\n[−231,231−1][-2^{31},2^{31}-1][−231,231−1]\nInteger\n\n\nLong\n64\n[−263,263−1][-2^{63},2^{63}-1][−263,263−1]\nLong\n\n\nfloat\n32\n3.4∗10383.4*10^{38}3.4∗1038\nLong\n\n\ndouble\n64\n1.7∗103081.7*10^{308}1.7∗10308\nDouble\n\n\nvoid\n-\n-\nVoid\n\n\n\n\n\n自动类型转换\n\nbyte,short,char—&gt; int —&gt; long—&gt; float —&gt; double\n\n\n\n数据类型转换int a = (int)3.14159\n\n\nPackage\n\n\nImport\n\n\nClass\n\n\nField\n\n\nMethod\n\n\nObject\n\n\nConstract and Initialization\n\n\nAccess Control\n\n\nJava修饰符\n\n访问控制修饰符 : default, public , protected, private\n非访问控制修饰符 : final, abstract, static, synchronized\n\n\n\n继承\n\n在Java中，一个类可以由其他类派生。如果你要创建一个类，而且已经存在一个类具有你所需要的属性或方法，那么你可以将新创建的类继承该类。\n利用继承的方法，可以重用已存在类的方法和属性，而不用重写这些代码。被继承的类称为超类（super class），派生类称为子类（subclass）。\nJava 源程序与编译型运行区别\n\n一个类可以包含以下类型变量：\n\n局部变量：在方法、构造方法或者语句块中定义的变量被称为局部变量。变量声明和初始化都是在方法中，方法结束后，变量就会自动销毁。\n\n局部变量声明在方法、构造方法或者语句块中；\n\n局部变量在方法、构造方法、或者语句块被执行的时候创建，当它们执行完成后，变量将会被销毁；\n访问修饰符不能用于局部变量；\n局部变量只在声明它的方法、构造方法或者语句块中可见；\n局部变量是在栈上分配的。\n局部变量没有默认值，所以局部变量被声明后，必须经过初始化，才可以使用。\n\n\n\n\n成员变量：成员变量是定义在类中，方法体之外的变量。这种变量在创建对象的时候实例化。成员变量可以被类中方法、构造方法和特定类的语句块访问。\n类变量：类变量也声明在类中，方法体之外，但必须声明为static类型。\n\n类变量也称为静态变量，在类中以static关键字声明，但必须在方法构造方法和语句块之外。\n无论一个类创建了多少个对象，类只拥有类变量的一份拷贝。\n静态变量除了被声明为常量外很少使用。常量是指声明为public/private，final和static类型的变量。常量初始化后不可改变。\n静态变量储存在静态存储区。经常被声明为常量，很少单独使用static声明变量。\n静态变量在第一次被访问时创建，在程序结束时销毁。\n与实例变量具有相似的可见性。但为了对类的使用者可见，大多数静态变量声明为public类型。\n默认值和实例变量相似。数值型变量默认值是0，布尔型默认值是false，引用类型默认值是null。变量的值可以在声明的时候指定，也可以在构造方法中指定。此外，静态变量还可以在静态语句块中初始化。\n静态变量可以通过：ClassName.VariableName的方式访问。\n类变量被声明为public static final类型时，类变量名称一般建议使用大写字母。如果静态变量不是public和final类型，其命名方式与实例变量以及局部变量的命名方式一致。\n\n\n实例变量\n\n实例变量声明在一个类中，但在方法、构造方法和语句块之外；\n当一个对象被实例化之后，每个实例变量的值就跟着确定；\n实例变量在对象创建的时候创建，在对象被销毁的时候销毁；\n实例变量的值应该至少被一个方法、构造方法或者语句块引用，使得外部能够通过这些方式获取实例变量信息；\n实例变量可以声明在使用前或者使用后；\n访问修饰符可以修饰实例变量；\n实例变量对于类中的方法、构造方法或者语句块是可见的。一般情况下应该把实例变量设为私有。通过使用访问修饰符可以使实例变量对子类可见；\n实例变量具有默认值。数值型变量的默认值是0，布尔型变量的默认值是false，引用类型变量的默认值是null。变量的值可以在声明时指定，也可以在构造方法中指定；\n实例变量可以直接通过变量名访问。但在静态方法以及其他类中，就应该使用完全限定名：ObejectReference.VariableName。\n\n\n一个类可以拥有多个方法，在上面的例子中：barking()、hungry()和sleeping()都是Dog类的方法。\n\n\n源文件声明规则\n\n一个源文件中只能有一个public类\n一个源文件可以有多个非public类\n源文件的名称应该和public类的类名保持一致。例如：源文件中public类的类名是Employee，那么源文件应该命名为Employee.java。\n如果一个类定义在某个包中，那么package语句应该在源文件的首行。\n如果源文件包含import语句，那么应该放在package语句和类定义之间。如果没有package语句，那么import语句应该在源文件中最前面。\nimport语句和package语句对源文件中定义的所有类都有效。在同一源文件中，不能给不同的类不同的包声明。\n\n\n\n\n\n接口\n\n在Java中，接口可理解为对象间相互通信的协议。接口在继承中扮演着很重要的角色。\n接口只定义派生要用到的方法，但是方法的具体实现完全取决于派生类。\n\n\n\n继承关键字\n\n继承可以使用 extends 和 implements 这两个关键字来实现继承，而且所有的类都是继承于 java.lang.Object，当一个类没有继承的两个关键字，则默认继承object（这个类在 java.lang 包中，所以不需要 import）祖先类。\nextends关键字\n\n在 Java 中，类的继承是单一继承，也就是说，一个子类只能拥有一个父类，所以 extends 只能继承一个类。\n\n\nimplements关键字\n\n使用 implements 关键字可以变相的使java具有多继承的特性，使用范围为类继承接口的情况，可以同时继承多个接口（接口跟接口之间采用逗号分隔）。\n\n\nsuper 与 this 关键字\n\nsuper关键字：我们可以通过super关键字来实现对父类成员的访问，用来引用当前对象的父类。\nthis关键字：指向自己的引用。\n\n\nfinal关键字\n\nfinal 关键字声明类可以把类定义为不能继承的，即最终类；或者用于修饰方法，该方法不能被子类重写：\n声明类：\n\nfinal class 类名 {//类体}\n\n\n声明方法：\n\n修饰符(public/private/default/protected) final 返回值类型 方法名(){//方法体}\n\n\n\n\n构造器\n\n子类是不继承父类的构造器（构造方法或者构造函数）的，它只是调用（隐式或显式）。如果父类的构造器带有参数，则必须在子类的构造器中显式地通过 super 关键字调用父类的构造器并配以适当的参数列表。\n如果父类构造器没有参数，则在子类的构造器中不需要使用 super 关键字调用父类构造器，系统会自动调用父类的无参构造器。\n\n\n\n\n\n\nJava 抽象类\n\n在面向对象的概念中，所有的对象都是通过类来描绘的，但是反过来，并不是所有的类都是用来描绘对象的，如果一个类中没有包含足够的信息来描绘一个具体的对象，这样的类就是抽象类。\n抽象类除了不能实例化对象之外，类的其它功能依然存在，成员变量、成员方法和构造方法的访问方式和普通类一样。\n由于抽象类不能实例化对象，所以抽象类必须被继承，才能被使用。也是因为这个原因，通常在设计阶段决定要不要设计抽象类。\n父类包含了子类集合的常见的方法，但是由于父类本身是抽象的，所以不能使用这些方法。\n在Java中抽象类表示的是一种继承关系，一个类只能继承一个抽象类，而一个类却可以实现多个接口。\n抽象方法\n\n如果你想设计这样一个类，该类包含一个特别的成员方法，该方法的具体实现由它的子类确定，那么你可以在父类中声明该方法为抽象方法。\nAbstract关键字同样可以用来声明抽象方法，抽象方法只包含一个方法名，而没有方法体。\n抽象方法没有定义，方法名后面直接跟一个分号，而不是花括号。\n声明抽象方法会造成以下两个结果：\n\n如果一个类包含抽象方法，那么该类必须是抽象类。\n任何子类必须重写父类的抽象方法，或者声明自身为抽象类。\n继承抽象方法的子类必须重写该方法。否则，该子类也必须声明为抽象类。最终，必须有子类实现该抽象方法，否则，从最初的父类到最终的子类都不能用来实例化对象。\n\n\n\n\n\n\n抽象类不能被实例化(初学者很容易犯的错)，如果被实例化，就会报错，编译无法通过。只有抽象类的非抽象子类可以创建对象。\n抽象类中不一定包含抽象方法，但是有抽象方法的类必定是抽象类。\n抽象类中的抽象方法只是声明，不包含方法体，就是不给出方法的具体实现也就是方法的具体功能。\n构造方法，类方法（用static修饰的方法）不能声明为抽象方法。\n抽象类的子类必须给出抽象类中的抽象方法的具体实现，除非该子类也是抽象类。\n\n\n\nJava 接口\n\n接口（英文：Interface），在JAVA编程语言中是一个抽象类型，是抽象方法的集合，接口通常以interface来声明。一个类通过继承接口的方式，从而来继承接口的抽象方法。\n接口并不是类，编写接口的方式和类很相似，但是它们属于不同的概念。类描述对象的属性和方法。接口则包含类要实现的方法。\n除非实现接口的类是抽象类，否则该类要定义接口中的所有方法。\n接口无法被实例化，但是可以被实现。一个实现接口的类，必须实现接口内所描述的所有方法，否则就必须声明为抽象类。另外，在 Java 中，接口类型可用来声明一个变量，他们可以成为一个空指针，或是被绑定在一个以此接口实现的对象。\n接口与类相似点：\n一个接口可以有多个方法。\n\n接口文件保存在 .java 结尾的文件中，文件名使用接口名。\n接口的字节码文件保存在 .class 结尾的文件中。\n接口相应的字节码文件必须在与包名称相匹配的目录结构中。\n\n\n接口与类的区别：\n\n接口不能用于实例化对象。\n接口没有构造方法。\n接口中所有的方法必须是抽象方法。\n接口不能包含成员变量，除了 static 和 final 变量。\n接口不是被类继承了，而是要被类实现。\n接口支持多继承。\n\n\n接口特性\n\n接口中每一个方法也是隐式抽象的,接口中的方法会被隐式的指定为 public abstract（只能是 public abstract，其他修饰符都会报错）。\n接口中可以含有变量，但是接口中的变量会被隐式的指定为 public static final 变量（并且只能是 public，用 private 修饰会报编译错误）。\n接口中的方法是不能在接口中实现的，只能由实现接口的类来实现接口中的方法。\n\n\n抽象类和接口的区别\n\n\n抽象类中的方法可以有方法体，就是能实现方法的具体功能，但是接口中的方法不行。\n抽象类中的成员变量可以是各种类型的，而接口中的成员变量只能是 public static final 类型的。\n接口中不能含有静态代码块以及静态方法(用 static 修饰的方法)，而抽象类是可以有静态代码块和静态方法。\n一个类只能继承一个抽象类，而一个类却可以实现多个接口。\n\n Chapter 02 OOP\n\nObject\nClass\nAbstraction\nInheritance\nPolymorphism\nfinalilze();\nAbstraction\ninterface\nimplements\n\n Chapter 03 Exception\n\n检查性异常：最具代表的检查性异常是用户错误或问题引起的异常，这是程序员无法预见的。例如要打开一个不存在文件时，一个异常就发生了，这些异常在编译时不能被简单地忽略。\n运行时异常： 运行时异常是可能被程序员避免的异常。与检查性异常相反，运行时异常可以在编译时被忽略。\n错误： 错误不是异常，而是脱离程序员控制的问题。错误在代码中通常被忽略。例如，当栈溢出时，一个错误就发生了，它们在编译也检查不到的。\nException 类的层次\n\n所有的异常类是从 java.lang.Exception 类继承的子类。\nException 类是 Throwable 类的子类。除了Exception类外，Throwable还有一个子类Error 。\nJava 程序通常不捕获错误。错误一般发生在严重故障时，它们在Java程序处理的范畴之外。\nError 用来指示运行时环境发生的错误。\n\n\n\n\n Chapter 04 Java I/O\n123456File file = new File(\"filePath/fileName\");System.out.println(file.exists());System.out.println(file.isFile());File[] files = file.listFlies(filter);System.out.println(files.length);Arrays.sort(files,comparator);\n\n\nStream\n\nByte stream\n\njava.io.InputStream\n\nint read()\t//read a byte\n\n\njava.io.OutputStream\n\nvoid write(int b)\nvoid write(byte[] b)\n\n\nFileInputStream, FileOutputStream\nPipedInputStream, PipedOutputStream\nByteArrayInputStream, ByteArrayOutputStream\nBufferedInputStream, BufferedOutputStream\nObjectInputStreamm ObjectOutputStream\n\n\nCharacter stream\n\njava.io.Reader\n\nint read()\t//read a char\n\n\njava.io.Writer\n\nvoid write(int b)\nvoid write(char[] c)\n\n\nFileReader, FileWriter\nPipedReader, PipedWriter\nBufferedReader, BufferedWriter\nInpputStreamReader, OutputStreamWriter\n\n\nBridge\n\nInputStreamReader\nOutputStreamWriter\n\n\n\n\n\nFileInputStream\n\n\n1234FileInputStream fis = FileInputStream(file);int  res = fis.read();\t//IOExceptionfis.available();\t//是否可用fis.close();\n1\t\n\n\n\n\nFileOutputStream\n\n\n123 \tfile.createNewFile()fos.write(2);fos.write('a');\n1\t\n\n\n\n\nFileReader\n\n\nFileWriter\n\n\n123   FileWriter w = new FileWriter(new File(\"a.txt\"),true);w.write(\"Hanyuu\".toCharArray());w.flush();\n\n\n\n\nInputStreamReader\n\n\nOutputStreamReader\n\n\nPrintStream\n\n\nDataInputStream, DataOutputStream\n\n\nPrintWriter\n\n\nScanner\n\njava.util.Scanner\n\n\n\nBufferedInputStream, BufferedOutputStream\n\nBufferedInputStream bufferedInput = new BufferedInputStream(new FileInputStream(filename));\n\n123456789101112131415161718192021222324public void testBufferedInput() &#123; try &#123;     /**      * 建立输入流 BufferedInputStream, 缓冲区大小为8      * buffer.txt内容为      * abcdefghij      */     InputStream in = new BufferedInputStream(new FileInputStream(new File(\"buff.txt\")), 8);     /*从字节流中读取5个字节*/     byte [] tmp = new byte[5];     in.read(tmp, 0, 5);     System.out.println(\"字节流的前5个字节为: \" + new String(tmp));     /*标记测试*/     in.mark(6);     /*读取5个字节*/     in.read(tmp, 0, 5);     System.out.println(\"字节流中第6到10个字节为: \" +  new String(tmp));     /*reset*/     in.reset();     System.out.printf(\"reset后读取的第一个字节为: %c\" , in.read()); &#125; catch (Exception e) &#123;     e.printStackTrace(); &#125;&#125;\n\n\n1234567* InputStreamReader* OutputStreamReader* System.in* System.out* System.err* DataOutputStream* DataInputStream\n\n\n Chapter 05 Collection\n\n\nArrays\n\njava.util.Arrays\nArrays.sort()\nArrays.fill(String[],String)\nArray.hashCode(String)\n\n\n\nCollection\n\nSet&lt;E&gt; //non-repeat\n\nSortedSet&lt;E&gt;\n\n\nList&lt;E&gt;\nQuene&lt;E&gt;\n\n\n\nMap\n\n\nHashMap&lt;K,V&gt;\n1234567HashMap&lt;Integer,String&gt; map = new HashMap&lt;Integer,String&gt;();map.put(0,\"Hanyuu\");String name = map.get(0);map.remove(0);Set keySet = map.keySet();Collection valueSet = map.values();Set entrySet = map.entrySet();\n\n\nSortedMap&lt;K,V&gt;\n\n\n\n\nIterator\n\n\nSeqential and Linear\n\n\nUse Array as Backend\n\n\nVarible Length\n\n\nMethods\n123456789add(Object)add(int index,Object)remove(Object)get(int)set(int)indexOf(Objects)clear()Size()toArray()\n\n\nArrayList\n\nArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;();\nArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(100);\nlist.ensureCapacity(1000)\n\n\n\nLinkedList\n123456LinkdList&lt;String&gt; list = new LinkedList&lt;String&gt;();list.add(\"Hanyuu\");Iterator&lt;String&gt; iterator = list.iterator();while(iterator.hasNext())&#123;  System.out.println(iterator.next());&#125;\n\n\n Chapter 07 UI\n\n\njava.jwt\n\n\njavax.swing\n\n\nJFrame frame = new JFrame(String //title);\n\nframe.getContentPane().add(BorderLayout.EAST,button);\nframe.setSize(300,400);\nframe.setVisible(true);\nframe.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);\nContainer cp = frame.getContentPane();\ncp.setLayout(new FloatLayout());\ncp.add(new JPanel)();\n\n\n\nJButton button = new JButton(&quot;Okey&quot;);\n\n\nJComboBox\n\n\nJCheckBox\n\n\nJPanel\n\npnel.setLayout(new FLowLayout(FlowLayout.LEFT));\n\n\n\nJPanel //container\n\nJPanle = new JPanel();\npanel.add(new JTextField(&quot;Hanyuu&quot;));\n\n\n\nJSplistPane\n\n\nJScrollPane\n\n\nGraphics\n\n\nJLabel\n\ngetText();\nsetText();\nsetIcon();\n\n\n\nJTextField\n\n\nJCheckBox\n\n\nJTextArea\n\n\nJRadioButton\n\n\n事件侦听\n\nActionLinstener1234567public class Action implements ActionListener&#123;  public void actionPerformed(ActionEvent event)&#123;    //TODO...  &#125;&#125;JButton exp = new JButton();exp.addActionLintener(new Action());\n\n\n\n\n Chapter 08 Multi-thread\n\n\nrunnable interface\n123456789public class Task implements Runnable&#123;  public void run()&#123;    //TODO...  &#125;&#125;public static void main(String[] args)&#123;  Thread thread = new Thread(new Task(),\"Thread name\");  thread.start();&#125;\n\n\nThread\n\n\n   12345678910public class HanyuuThread extends Thread&#123;  public void run()&#123;    //TODO...  &#125;&#125;public static void main(String[] args)&#123;  HanyuuThread hanyuu = new HanyuuThread();  hanyuu.setName(\"Hanyuu\");  hanyuu.statrt();&#125;\n\nThread.sleep(int)\nString Thread.currentThread().getName();\njoin\ninterrupt()\nyield()\n\n\nyield意味着放手，放弃，投降。一个调用yield()方法的线程告 诉虚拟机它乐意让其他线程占用自己的位置。这表明该线程没 有在做一些紧急的事情。注意，这仅是一个暗示，并不能保证 不会产生任何影响。 \nYield告诉当前正在执行的线程把运行机会交给线程池中拥有相 同优先级的线程。\nYield不能保证使得当前正在运行的线程迅速转换到可运行的状态。\n它仅能使一个线程从运行状态转到可运行状态，而不是等待或阻塞状态\n\n\nnotify()/notifyAll()\n\nnotifyAll() wakes all waiting thread, thus, all waiting thread turn to Ready\nnotify() only wakes one of waiting thread, others remain blocked\n\n\nsleep()\n\njava.lang.Thread`\n\n\nwait()\n\njava.lang.Object\nEach object has a wait method, inherited from java.lang.Object\nwait() method ask current thread to give up exclusive control\nwait() method give other thread a chance to visit the object\nwait() / wait(long timeout)\n\n\nwait() / notifyAll() / notify()\n\nThe object must be locked before visit these methods\nThey can be used in synchronized method of an object\nOr obj.wait() / obj.notifyAll() / obj.notify() in synchorized(obj){…}\nOtherwise: java.lang.IllegalMonitorStateException\n\n\nsynchronized\n\n12345678public class Hanyuu&#123;  public synchronized void onlyOne()&#123;    //TODO...  &#125;  public synchronized void threadSafty()&#123;    //TODO...  &#125;&#125;\n\n Chapter 09 Java &amp; XML\n Chapter 10 JDBC\n\n\nRecord\n\n\nField\n\n\nTable\n\n\nEntity\n\n\nRelations\n\n\nDataBase\n\n\nPrimary key\n\n\nForeign key\n\n\nSelect\n\nSELECT nameA FROM tableA\nSELECT nameA FROM tableA WHERE name &gt; 2\nSELECT nameA FROM tableA WHERE (name &gt; 2 AND name &lt; 10) OR name &gt;300\nSELECT * FROM tableA WHERE name IN ('Hanyuu','Inari')\nSELECT * FROM tableA WHERE date BETWEEN 'Jan-01-2019' AND 'Jan-02-2019'\nSELECT * FROM tableA WHERE name LIKE '%an%'\nSELECT * FROM tableA ORDER BY name DESC/ASC\nSELECT COUNT(DISTINCT name) FROM tableA\n\n\n\nInsert\n\nINSERT INTO tableA (name,Date) VALUES ('Inari','Jan-01-2019')\n\n\n\nRetireval\n\n\nUpdate\n\nUPDATE tableA SET date = 'Jan-01-2019' WEHERE name = 'Hanyuu'\n\n\n\nDelete\n\nDELETE FROM tableA WHERE name = 'Inari'\n\n\n你知道为什么SQL语句大家都选择大写嘛？（hhh）\n\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546package SQL;import java.sql.*;import javax.sql.*;public class SQL &#123;\tpublic static void main(String[] args) &#123;//\t\tResultSet rs;//\t\tStatement statement;//\t\tConnection connection;\t\tConnection connection = null;\t\tStatement statement = null;\t\tResultSet rs = null;\t\ttry &#123;      //注册驱动程序\t\t\tClass.forName(\"com.mysql.cj.jdbc.Driver\");      //创建JDBC连接\t\t\tString dbURL = \"jdbc:mysql://localhost:3306/Hanyuu?user=Hanyuu&amp;password=Hanyuu&amp;useSSL=false&amp;serverTimezone=GMT\";\t\t\tconnection = DriverManager.getConnection(dbURL);      //创建statement\t\t\tString sqlQuery = \"SELECT DISTINCT bookname FROM bookstore\";\t\t\tstatement = connection.createStatement();\t\t\trs = statement.executeQuery(sqlQuery);\t\t\twhile (rs.next()) &#123;\t\t\t\tSystem.out.println(rs.getString(\"bookname\"));\t\t\t&#125;\t\t\tString nsqlQuery = \"SELECT * FROM bookstore\";\t\t\trs = statement.executeQuery(nsqlQuery);      //执行查询语句\t\t\tResultSetMetaData rsmd = rs.getMetaData();\t\t\tfor (int i = 1; i &lt;= rsmd.getColumnCount(); ++i) &#123;\t\t\t\tSystem.out.println(rsmd.getColumnName(i)+'\\t');\t\t\t&#125;\t\t&#125; catch (ClassNotFoundException e) &#123;\t\t\tSystem.out.println(\"无驱动类\");\t\t&#125; catch (SQLException e) &#123;\t\t\te.printStackTrace();\t\t&#125; finally &#123;\t\t\ttry &#123;\t\t\t\trs.close();\t\t\t\tstatement.close();\t\t\t\tconnection.close();\t\t\t&#125; catch (Exception e) &#123;\t\t\t\te.printStackTrace();\t\t\t&#125;\t\t&#125;\t&#125;&#125;\n\n\n构建Prepared statement\n12345678910String sql = \"INSERT INTO tableA (id,name,sorce) VALUES (?,?,?)\";PreparedStatement s =connection.prepareStatement(sql);//add a records.setInt(1,0000);s.setString(2,\"Hanyuu\");s.setInt(3,60);s.addBatch();s.clearParameters();s.executeBatch();s.cleatBatch();\n\n\n Chapter 11 Java network Programming\n\nIP address\nIPv4\nIPv6\nIP\nHost name\nDomain Name\nDNS\n\n123456789101112131415try&#123;  //get InetAddress  InetAddress iAddress = InetAddress.getLocalHost();  //get local IP  String IP = iAddress.getHostAddress().toString();  //get local host name  String hostName = iAddress.getHostName().toString();  System.out.println(\"IP address\"+IP);  System.out.println(\"Host name\"+hostName);&#125;catch (UnknownHostException e)&#123;  e.printStackTrace();&#125;catch(Exception e)&#123;  e.printStackTrace();&#125;\n\n通过主机名获取所有IP\n\n1234567891011121314151617181920212223242526272829303132import java.net.InetAddress;import java.net.UnknownHostException;import java.util.ArrayList;import java.util.Iterator;public class getLocal &#123;\tpublic static void main(String[] args) &#123;\t\ttry &#123;\t\t\tInetAddress ia=InetAddress.getLocalHost();\t\t\tSystem.out.println(ia.getHostAddress());\t\t\tSystem.out.println(ia.getAddress());\t\t\tSystem.out.println(ia.getHostName());\t\t\tString hostName=InetAddress.getLocalHost().getHostName();\t\t\tArrayList&lt;String&gt; allIP=new ArrayList&lt;String&gt;();\t\t\tif (hostName.length()&gt;0)\t\t\t&#123;\t\t\t\tInetAddress[] addresses=InetAddress.getAllByName(hostName);\t\t\t\tfor (int i=0;i&lt;addresses.length;i++)&#123;\t\t\t\t\tallIP.add(addresses[i].getHostAddress().toString());\t\t\t\t&#125;\t\t\t&#125;\t\t\tfor (Iterator iter=allIP.iterator();((Iterator) iter).hasNext();)&#123;\t\t\t\tSystem.out.println(ier.next().toString());\t\t\t&#125;\t\t&#125; catch (UnknownHostException e) &#123;\t\t\te.printStackTrace();\t\t&#125;\t&#125;&#125;\n\nConstructor localhost InetAddress\n\n12345InetAddress addr = InetAddress.getByName(null);InetAddress addr = InetAddress.getByName(\"127.0.0.1\");InetAddress addr = InetAddress.getByName(\"localhost\");InetAddress addr = InetAddress.getLocalHost();byte[] IP = &#123;(byte)127,(byte)0,(byte)0,(byte)1&#125;;\n\nWeb server\nFTP server\nMail server\nPort 1-1024 is occupied by system\nclient\n\n123456789//构建客户端socketSocket client = new Socket(\"hanyuu.ml\",8080);//构建客户端socket（通过InetAddress）InetAddress address = InetAddress.getByName(\"Hanyuu.ml\");Socket client = new Socket(address,8080);InputStream is = socket.getInputStream();OutputStream os = socket.getOutputStream();is.close();os.close();\nExample\n123456Socket socket = new Socket(ip,8008);BufferedReader in = new BufferedReader(new InputStreamReader(socket.getInputStream()),true);out.print(\"Hi\");Thread.sleep(1000);out.println(\"Hello\");socket.close();\n\nserver\n\n1234//创建服务端的ServerSocket监听客户请求ServerSocket server = new ServerSocket(8080);//客户端阻塞，等待连接Socket serverSocket = server.accept();\nExample\n12345678910111213try&#123;  ButteredReader in =new BufferedReader(new InputStreamReader(socket.getInputStream()));  PrintWriter out = new PrintWriter(new BufferedWriter(new OutputStreamWriter(socket.getOutputStream()),true);  while(true)&#123;    String str = in.readLine();    if (str!=null &amp;&amp; str.equals(\"Hi\")) out.println(\"Hi, here is server.\");  &#125;catch(Exception e)&#123;    e.printStackTrace();  &#125;finally&#123;    socket.close();    server.close();  &#125;&#125;\n\nTCP\nUDP\nread a web page\n\n12345678910111213141516171819202122import java.io.BufferedReader;import java.io.InputStreamReader;import java.net.URL;import java.net.URLConnection;public class conn &#123;\tpublic static void main(String[] args) &#123;\t\ttry&#123;\t\t\tURL coseURL = new URL(\"http://cose.seu.edu.cn\");\t\t\tURLConnection connection =coseURL.openConnection();\t\t\tBufferedReader in = new BufferedReader(new InputStreamReader(connection.getInputStream()));\t\t\tString html = in.readLine();\t\t\twhile(html!=null)&#123;\t\t\t\tSystem.out.println(html);\t\t\t\thtml=in.readLine();\t\t\t&#125;\t\t&#125;catch (Exception e)&#123;\t\t&#125;\t&#125;&#125;\n","plink":"ilucia.github.io/Review/Java/"},{"title":"数据结构小结","date":"2019-01-08T11:47:06.000Z","updated":"2022-04-27T15:24:01.715Z","content":" 性能度量\n\n算法的时间复杂度和空间复杂度合称为算法的复杂度。\n\n 时间复杂度\n\n\n时间频度 一个算法中的语句执行次数称为语句频度或时间频度。记为T(n)。\n\n\n时间复杂度 一般情况下，算法中基本操作重复执行的次数是问题规模n的某个函数，用T(n)T(n)T(n)表示，若有某个辅助函数f(n)f(n)f(n),使得当nnn趋近于无穷大时，T(n)f(n){\\frac{T(n)}{f(n)}}f(n)T(n)​的极限值为不等于零的常数，则称f(n)f(n)f(n)是T(n)T(n)T(n)的同数量级函数。记作T(n)=O(f(n))T(n)=O(f(n))T(n)=O(f(n)),称O(f(n))O(f(n))O(f(n))为算法的渐进时间复杂度，简称时间复杂度。\n常见的时间复杂度有：常数阶O(1)O(1)O(1),对数阶O(log2n)O(log_{2}n)O(log2​n),线性阶O(n)O(n)O(n), 线性对数阶O(n⋅log2n)O(n\\cdot log_{2}n)O(n⋅log2​n),平方阶O(n2)O(n^{2})O(n2)，立方阶O(n3)O(n^{3})O(n3),…， k次方阶O(nk)O(n^{k})O(nk) ,指数阶O(kn)O(k^{n})O(kn)。\n\n\n最坏时间复杂度和平均时间复杂度 　最坏情况下的时间复杂度称最坏时间复杂度。一般不特别说明，讨论的时间复杂度均是最坏情况下的时间复杂度。\n\n\n记号\n渐进精确记号Θ(n)\\Theta(n)Θ(n)\n渐进上界记号O(n)O(n)O(n)\n渐进下界记号Ω(n)\\Omega(n)Ω(n)\n\n\n求时间复杂度\n\n\n如果算法的执行时间不随着问题规模n的增加而增长,此类算法的时间复杂度是O(1)。\n 12345678910x=91;y=100;while(y&gt;0)    if(x&gt;100) &#123;    x=x-10;    y--;&#125;else &#123;    x++;&#125;\n解答： T(n)=O(1)T(n)=O(1)T(n)=O(1)，\n\n\n当有若干个循环语句时，算法的时间复杂度是由嵌套层数最多的循环语句中最内层语句的频度f(n)决定的。\n 12345x=1;for(i=1;i&lt;=n;i++)   for(j=1;j&lt;=i;j++)      for(k=1;k&lt;=j;k++)          x++;\n该程序段中频度最大的语句是x++，则该程序段的时间复杂度为T(n)=O(n3/6+T(n)=O(n3/6+T(n)=O(n3/6+ 低次项 )=O(n3))=O(n3))=O(n3)\n\n\n算法的时间复杂度不仅仅依赖于问题的规模，还与输入实例的初始状态有关。\n\n\n时间复杂度评价性能\n一般将渐近时间复杂度T(n)=O(f(n))T(n)=O(f(n))T(n)=O(f(n))简称为时间复杂度，其中的f(n)f(n)f(n)一般是算法中频度最大的语句频度。\n\n\n\n\n 空间复杂度\n一个程序的空间复杂度是指运行完一个程序所需内存的大小。利用程序的空间复杂度，可以对程序的运行所需要的内存多少有个预先估计。一个程序执行时除了需要存储空间和存储本身所使用的指令、常数、变量和输入数据外，还需要一些对数据进行操作的工作单元和存储一些为现实计算所需信息的辅助空间。程序执行时所需存储空间包括以下两部分。　　\n1. 固定部分。这部分空间的大小与输入/输出的数据的个数多少、数值无关。主要包括指令空间（即代码空间）、数据空间（常量、简单变量）等所占的空间。这部分属于静态空间。\n2. 可变空间，这部分空间的主要包括动态分配的空间，以及递归栈所需的空间等。这部分的空间大小与算法有关。\n\t&gt; 一个算法所需的存储空间用$f(n)$表示。$S(n)=O(f(n))　$　其中$n$为问题的规模，$S(n)$表示空间复杂度。\n\n 数组\n抽象数据类型（Abstract Data Type，ADT）\n1234567891011class  GeneralArray &#123;// a set of pairs &lt;index, value&gt; where for each value ofindex in IndexSet there is a value of type float. IndexSet is a finite ordered set of one or more dimensions.public:    GeneralArray(int j, RangeList list, float initValue = defaultValue);// This constructor creates a j dimensional array of floats; the range of the kth dimension is given by the kth element of list. For all i∈IndexSet, insert &lt;i, initValue&gt; into the array.    float  Retrieve(index i);// if (i∈IndexSet) return the float associated with i in the array;else throw an exception.    void Store(index i, float x);// if (i∈IndexSet) replace the old value associated with i by x;  else throw an exception.&#125;; //end of GeneralArray\n 顺序表\n\n多项式\n\n基本操作：求长度、遍历、取数、存数、插入、删除\n基本结构\n\n\n\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960class Polynomial; // forward declarationclass Term &#123;friend Polynomial;private:     float coef; // coefficient     int exp;     // exponent&#125;;class Polynomial &#123;public:\t///...  private:   Term *termArray;   int capacity; // size of termArray   int terms; // number of nonzero terms&#125;Polynomial Polynomial::Add(Polynomial b)&#123; // return the sum of the polynomials *this and b.\tPolynomial c;\tint aPos = 0, bPos = 0;\twhile ((aPos &lt; terms) &amp;&amp; (b &lt; b.terms))\t\tif (termArray[aPos].exp == b.termArray[bPos].exp)\t\t&#123;\t\t\tfloat t = termArray[aPos].coef + termArray[bPos].coef;\t\t\tif (t)\t\t\t\tc.NewTerm(t, termArray[aPos].exp);\t\t\taPos++;\t\t\tbPos++;\t\t&#125;\t\telse if (termArray[aPos].exp &lt; b.termArray[bPos].exp)\t\t&#123;\t\t\tc.NewTerm(b.termArray[bPos].coef,b.termArray[bPos].exp);\t\t\tbPos++;\t\t&#125;\t\telse\t\t&#123;\t\t\tc.NewTerm(termArray[aPos].coef, termArray[aPos].exp);\t\t\taPos++;\t\t&#125;\t// add in the remaining terms of *this\tfor (; aPos &lt; terms; aPos++)\t\tc.NewTerm(termArray[aPos].coef, termArray[aPos].exp);\t// add in the remaining terms of b\tfor (; bPos &lt; b.terms; bPos++)\t\tc.NewTerm(b.termArray[bPos].coef, b.termArray[bPos].exp);\treturn c;&#125;void Polynomial::NewTerm(const float theCoeff,const int theExp)&#123; // add a new term to the end of termArray.\tif (terms == capacity)\t&#123; // double capacity of termArray\t\tcapacity *= 2;\t\tterm *temp = new term[capacity]; // new array\t\tcopy(termArray, termAarry + terms, temp);\t\tdelete[] termArray; // deallocate old memory\t\ttermArray = temp;\t&#125;\ttermArray[terms].coef = theCoeff;\ttermArray[terms++].exp = theExp;&#125;\n\n时间复杂度分析：\n\n插入：\n\n无需翻倍时：O(1)O(1)O(1)\n翻倍时（内存不足）:O(m+n+O(m + n +O(m+n+ 在数组加倍中花费的时间 )))\n\n\n翻倍（内存扩容）：\n\n\nO(∑i=1k2i)=O(2k+1)=O(2k)O(\\sum_{i=1}^{k}{2^{i}})=O(2^{k+1})=O(2^{k})\nO(i=1∑k​2i)=O(2k+1)=O(2k)\n\n由于 c.terms&gt;2k−1c.terms&gt;2^{k-1}c.terms&gt;2k−1 , m+n∈c.termsm+n\\in c.termsm+n∈c.terms实际使用时间为O(c.terms)=O(m+n)O(c.terms)=O(m+n)O(c.terms)=O(m+n)\n\n\n\n\n\n 稀疏矩阵\n12345678910class SparseMatrix &#123; // a set of &lt;row, column, value&gt;, where row, column are non-negative integers and form a unique combination; value is also an integer. public:      SparseMatrix ( int r, int c, int t);      // creates a r∈c SparseMatrix with a capacity of t nonzero terms      SparseMatrix Transpose ( );      // return the SparseMatrix obtained by transposing *this      SparseMatrix  Add ( SparseMatrix b);      SparseMatrix  Multiply ( SparseMatrix b); &#125;;\n123456class  SparseMatrix;class  MatrixTerm &#123;friend class SparseMatrix;Private:    int row, col, value;&#125;;\n\n转置\n\n 1234567891011121314151617 SparseMatrix SparseMatrix::Transpose()&#123; // return the transpose of *this\tSparseMatrix b(cols, rows, terms);\tif (terms &gt; 0)\t&#123; //nonzero matrix\t\tint currentB = 0;\t\tfor (int c = 0; c &lt; cols; c++)\t\t// transpose by columns\t\t\tfor (int i = 0; i &lt; terms; i++) // find and move terms in column c\t\t\t\tif (smArray[i].col == c)\t\t\t\t&#123;\t\t\t\t\tb.smArray[CurrentB].row = c;\t\t\t\t\tb.smArray[CurrentB].col = smArray[i].row;\t\t\t\t\tb.smArray[CurrentB++].value = smArray[i].value;\t\t\t\t&#125;\t&#125; // end of if (terms &gt; 0)\treturn b;&#125;\n\n快速转置\n\n12345678910111213141516171819202122232425262728 SparseMatrix SparseMatrix::FastTranspose()&#123; // return the transpose of *this in O(terms+cols) time.\tSparseMatrix b(cols, rows, terms);\tif (terms &gt; 0)\t&#123; // nonzero matrix\t\tint *rowSize = new int[cols];\t\t7int *rowStart = new int[cols];\t\t// compute rowSize[i] = number of terms in row i of b\t\tfill(rowSize, rowSize + cols, 0); // initialze\t\tfor (i = 0; i &lt; terms; i++)\t\t\trowSize[smArray[i].col]++;\t\t// rowStart[i] = starting position of row i in b\t\trowStart[0] = 0;\t\tfor (i = 1; i &lt; cols; i++)\t\t\trowStart[i] = rowStart[i - 1] + rowSize[i - 1];\t\tfor (i = 0; i &lt; terms; i++)\t\t&#123; // copy from *this to b\t\t\tint j = rowStart[smArray[i].col];\t\t\tb.smArray[j].row = smArray[i].col;\t\t\tb.smArray[j].col = smArray[i].row;\t\t\tb.smArray[j].value = smArray[i].value;\t\t\trowStart[smArray[i].col]++;\t\t&#125; // end of for\t\tdelete[] rowSize;\t\tdelete[] rowStart;\t&#125; // end of if\treturn b;&#125;\n\n时间复杂度\nO(cols+terms)O(cols+terms)O(cols+terms)\n\n 字符串匹配算法\n 1. 暴力匹配法\n定义现有文本串S模式串P，假设现在文本串S匹配到i位置，模式串P匹配到j位置，则有：\n\n如果当前字符匹配成功（即S[i] == P[j]），则i++，j++，继续匹配下一个字符；\n*如果失配（即S[i]! = P[j]），令i = i - (j - 1)，j = 0。相当于每次匹配失败时，i 回溯，j 被置为0。\n\n12345678910111213141516171819202122232425262728int ViolentMatch(char* s, char* p)&#123;\tint sLen = strlen(s);\tint pLen = strlen(p);\tint i = 0;\tint j = 0;\twhile (i &lt; sLen &amp;&amp; j &lt; pLen)\t&#123;\t\tif (s[i] == p[j])\t\t&#123;\t\t\t//当前字符匹配成功（即S[i] == P[j]），则i++，j++\t\t\ti++;\t\t\tj++;\t\t&#125;\t\telse\t\t&#123;\t\t\t//失配（即S[i]! = P[j]），令i = i - (j - 1)，j = 0\t\t\ti = i - j + 1;\t\t\tj = 0;\t\t&#125;\t&#125;\t//匹配成功，返回模式串p在文本串s中的位置，否则返回-1\tif (j == pLen)\t\treturn i - j;\telse\t\treturn -1;&#125;\n\n  暴力匹配法没有利用已经匹配过的信息，实现简单但是效率低下。\n\n\n\n 2.KMP算法\n\n算法流程\n\n假设现在文本串S匹配到i位置，模式串P匹配到j位置\n\n如果j=-1，或者当前字符匹配成功（S[i]==P[j]），都令i++，j++，继续匹配下一个字符；\n如果j!=-1，且当前字符匹配失败（S[i]!=P[j]），则令i不变，j =next[j]。此举意味着失配时，模式串P相对于文本串S向右移动了j-next[j] 位。\n（当匹配失败时，模式串向右移动的位数为：失配字符所在位置 - 失配字符对应的next 值（next 数组的求解会在下文阐述），即移动的实际位数为j-next[j]，且此值大于等于1。next数组的值代表当前字符之前的字符串中，有多大长度的相同前缀后缀。例如如果next[j]=k，代表j之前的字符串中有最大长度为k 的相同前缀后缀。此也意味着在某个字符失配时，该字符对应的next值会告诉你下一步匹配中，模式串应该跳到哪个位置（跳到next[j]的位置）。如果next[j]等于0或-1，则跳到模式串的开头字符，若next[j]=k且k&gt;0，代表下次匹配跳到j之前的某个字符，而不是跳到开头，且具体跳过了k个字符。)\n\n\n\n\n\n123456789101112131415161718192021222324252627int KmpSearch(char* s, char* p)&#123;\tint i = 0;\tint j = 0;\tint sLen = strlen(s);\tint pLen = strlen(p);\twhile (i &lt; sLen &amp;&amp; j &lt; pLen)\t&#123;\t\t//如果j = -1，或者当前字符匹配成功（即S[i] == P[j]），都令i++，j++\t\tif (j == -1 || s[i] == p[j])\t\t&#123;\t\t\ti++;\t\t\tj++;\t\t&#125;\t\telse\t\t&#123;\t\t\t//如果j != -1，且当前字符匹配失败（即S[i] != P[j]），则令 i 不变，j = next[j]\t\t\t//next[j]即为j所对应的next值\t\t\tj = next[j];\t\t&#125;\t&#125;\tif (j == pLen)\t\treturn i - j;\telse\t\treturn -1;&#125;\n\n步骤\n\n\n寻找前缀后缀最长公共元素长度\n对于P = p0 p1 …pj-1 pj，寻找模式串P中长度最大且相等的前缀和后缀。如果存在p0 p1 …pk-1 pk = pj- k pj-k+1…pj-1 pj，那么在包含pj的模式串中有最大长度为k+1的相同前缀后缀。举个例子，如果给定的模式串为“abab”，那么它的各个子串的前缀后缀的公共元素的最大长度如下表格所示：\n\n\n\n\n模式串\na\nb\na\nb\n\n\n\n\n最大前缀后缀公共元素长度\n0\n0\n1\n2\n\n\n\n\n比如对于字符串aba来说，它有长度为1的相同前缀后缀a；而对于字符串abab来说，它有长度为2的相同前缀后缀ab（相同前缀后缀的长度为k+1，k+1=2）。\n\n\n求next数组\nnext数组考虑的是除当前字符外的最长相同前缀后缀，所以通过第①步骤求得各个前缀后缀的公共元素的最大长度后，只要稍作变形即可：将第①步骤中求得的值整体右移一位，然后初值赋为-1，如下表格所示：\n\n\n\n\n模式串\na\nb\na\nb\n\n\n\n\nnext数组\n-1\n0\n0\n1\n\n\n\n\n\n根据next数组进行匹配\n匹配失配，j=next[j]j=next[j]j=next[j]，模式串向右移动的位数为：j−next[j]j-next[j]j−next[j]。换言之，当模式串的后缀pj−kpj−k+1,...,pj−1pj-kpj-k+1,...,pj-1pj−kpj−k+1,...,pj−1跟文本串si−ksi−k+1,...,si−1si-ksi-k+1,...,si-1si−ksi−k+1,...,si−1匹配成功，但pjpjpj跟sisisi匹配失败时，因为next[j]=knext[j]=knext[j]=k，相当于在不包含pj的模式串中有最大长度为k的相同前缀后缀，即p0p1...pk−1=pj−kpj−k+1...pj−1p0p1...pk-1=pj-kpj-k+1...pj-1p0p1...pk−1=pj−kpj−k+1...pj−1，故令j=next[j]j=next[j]j=next[j]，从而让模式串右移j−next[j]j-next[j]j−next[j]位，使得模式串的前缀p0p1,...,pk−1p0p1,...,pk-1p0p1,...,pk−1对应着文本串si−ksi−k+1,...,si−1si-ksi-k+1,...,si-1si−ksi−k+1,...,si−1，而后让pkpkpk跟sssi继续匹配。如下图所示：\n​\t\n\n\n 解释\n\n\n寻找最长前缀后缀\n\n如果给定的模式串是：“ABCDABD”，从左至右遍历整个模式串，其各个子串的前缀后缀分别如下表格所示： \n\n也就是说，原模式串子串对应的各个前缀后缀的公共元素的最大长度表为：\n\n\n\n123456789101112131415161718192021void GetNext(char* p,int next[])&#123;\tint pLen = strlen(p);\tnext[0] = -1;\tint k = -1;\tint j = 0;\twhile (j &lt; pLen - 1)\t&#123;\t\t//p[k]表示前缀，p[j]表示后缀\t\tif (k == -1 || p[j] == p[k])\t\t&#123;\t\t\t++k;\t\t\t++j;\t\t\tnext[j] = k;\t\t&#125;\t\telse\t\t&#123;\t\t\tk = next[k];\t\t&#125;\t&#125;&#125;\n 波兰式、逆波兰式实现\n 简单技巧：\n中序表达式转后序表式式：\n将中序表达式所有括号补全，然后将所有运算符向右移出无匹配的第一个右括号，去掉括号即为后序表式式\n\n举例：\n​\t原式：a+b*(c+d/e)\n​\t补全括号：(a+(b*(c+(d/e))))\n​\t操作符右移：(a(b(c(de)/)+))+\n​\t去掉括号：abcde/++\n中序表达式转前序表式式：\n将中序表达式所有括号补全，然后将所有运算符向左移出无匹配的第一个左括号，去掉括号即为前序表式式\n\n举例：\n​    原式：a+b*(c+d/e)\n​    补全括号：(a+(b*(c+(d/e))))\n​    操作符右移：+(a*(b+(c/(de))))\n​    去掉括号：+a*b+c/de\n 算法：\n利用运算符栈(OPTR)和数据栈(OPND)将中缀表达式转化为后缀表达式。\n将结束标志字符’#’放入操作符栈（OPTR）；\n从中缀表达式pre左端依次读取pre[i]：\n1.若pre[i]为操作数，压入数据栈（OPND）；\n2.若pre[i]为左括号，压入操作符栈（OPTR）；\n3.若pre[i]为右括号，则将操作符栈（OPTR）中的运算符依次出栈并压入数据栈（OPND），直到遇到左括号为止，但是该左括号出栈但不压入数据栈（OPND）\n4.若pre[i]为操作符:\n（1）若操作符栈（OPTR）为空，将此操作符pre[i]压入数据栈（OPND）；\n（2）若pre[i]的优先级大于操作符栈（OPTR）顶的优先级，将此操作符pre[i]压入数据栈（OPND）；\n（3）若操作符栈（OPTR）不为空且pre[i]的优先级小于等于操作符栈（OPTR）顶的优先级，将操作符栈（OPTR）中的运算符依次出栈并压入数据栈（OPND），直到不满足条件，此操作符pre[i]压入数据栈（OPND）\n\n直到遍历完整个中序表达式之后，操作符栈（OPTR）中仍然存在运算符，那么将这些运算符依次出栈加入到数据栈（OPND）中，直到栈为空。\n按照上述步骤完成后，将操作符栈（OPTR）逆序即可得到逆波兰表达式。\n 实现\n1234567891011121314151617181920212223242526272829303132333435363738//把中缀表达式转换为后缀表达式void postfix(char pre[])&#123;    int i = 0;    stack&lt;char&gt; OPTR; //运算符栈    stack&lt;char&gt; OPND; //数据栈    OPTR.push('#'); // 首先把结束标志‘#’放入栈底    while(pre[i]!='#')    &#123;        if((pre[i]&gt;='a' &amp;&amp; pre[i] &lt;='z')) // 遇到点直接写入后缀表达式        &#123; OPND.push(pre[i]); &#125;        else if (pre[i]=='(') // 遇到“（”不用比较直接入栈            OPTR.push(pre[i]); else if(pre[i] ==')') // 遇到右括号将其对应左括号后的操作符（操作符栈中的）全部写入后缀表达式        &#123;            while(OPTR.top()!='(')            &#123;                OPND.push(OPTR.top()); OPTR.pop();            &#125;            OPTR.pop(); // 将“（”出栈，后缀表达式中不含小括号 &#125;            else if (isoperator(pre[i]))            &#123;                while(!OPTR.empty() &amp;&amp; priority(pre[i]) &lt;= priority(OPTR.top()))                &#123; // 当前的操作符小于等于栈顶操作符的优先级时，将栈顶操作符写入到后缀表达式，重复此过程                    OPND.push(OPTR.top()); OPTR.pop();                &#125;                OPTR.push(pre[i]); // 当前操作符栈为空或者当前操作符优先级大于栈顶操作符的优先级，将该操作符入栈            &#125;            i++;        &#125;        while(OPTR.top() != '#') // 将所有的操作符加入后缀表达式        &#123; OPND.push(OPTR.top()); OPTR.pop(); &#125;        OPTR.pop(); //利用操作符栈逆序即可得到后缀表达式        while(!OPND.empty())        &#123; OPTR.push(OPND.top()); OPND.pop(); &#125;        while(!OPTR.empty())        &#123; cout &lt;&lt; OPTR.top(); OPTR.pop(); &#125;        cout &lt;&lt; endl;    &#125;\n\n 二叉树\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140    tree *root;    Btree()    &#123;        root=NULL;    &#125;    void create_Btree(int);    void Preorder(tree *);                  //先序遍历    void inorder(tree *);                   //中序遍历    void Postorder(tree *);                 //后序遍历    void display1() &#123;Preorder(root); cout&lt;&lt;endl;&#125;    void display2() &#123;inorder(root);cout&lt;&lt;endl;&#125;    void display3() &#123;Postorder(root); cout&lt;&lt;endl;&#125;    int count(tree *);                      //计算二叉树的个数    int findleaf(tree *);                   //求二叉树叶子的个数    int findnode(tree *);                   //求二叉树中度数为1的结点数量,这是当初考数据结构时候的最后一道题目&#125;;int Btree::n=0;int Btree::m=0;void Btree::create_Btree(int x)&#123;    tree *newnode=new tree;    newnode-&gt;data=x;    newnode-&gt;right=newnode-&gt;left=NULL;    if(root==NULL)        root=newnode;    else    &#123;        tree *back;        tree *current=root;        while(current!=NULL)        &#123;            back=current;            if(current-&gt;data&gt;x)                current=current-&gt;left;            else                current=current-&gt;right;        &#125;        if(back-&gt;data&gt;x)            back-&gt;left=newnode;        else            back-&gt;right=newnode;    &#125;&#125;int Btree::count(tree *p)&#123;    if(p==NULL)        return 0;    else        return count(p-&gt;left)+count(p-&gt;right)+1;      //这是运用了函数嵌套即递归的方法。&#125;void Btree::Preorder(tree *temp)    //这是先序遍历二叉树，采用了递归的方法。&#123;    if(temp!=NULL)    &#123;        cout&lt;&lt;temp-&gt;data&lt;&lt;\" \";        Preorder(temp-&gt;left);        Preorder(temp-&gt;right);    &#125;&#125;void Btree::inorder(tree *temp)      //这是中序遍历二叉树，采用了递归的方法。&#123;    if(temp!=NULL)    &#123;        inorder(temp-&gt;left);        cout&lt;&lt;temp-&gt;data&lt;&lt;\" \";        inorder(temp-&gt;right);    &#125;&#125;void Btree::Postorder(tree *temp)     //这是后序遍历二叉树，采用了递归的方法。&#123;    if(temp!=NULL)    &#123;        Postorder(temp-&gt;left);        Postorder(temp-&gt;right);        cout&lt;&lt;temp-&gt;data&lt;&lt;\" \";    &#125;&#125;int Btree::findleaf(tree *temp)&#123;    if(temp==NULL)return 0;    else    &#123;        if(temp-&gt;left==NULL&amp;&amp;temp-&gt;right==NULL)return n+=1;        else        &#123;            findleaf(temp-&gt;left);            findleaf(temp-&gt;right);        &#125;        return n;    &#125;&#125;int Btree::findnode(tree *temp)&#123;    if(temp==NULL)return 0;    else    &#123;        if(temp-&gt;left!=NULL&amp;&amp;temp-&gt;right!=NULL)        &#123;            findnode(temp-&gt;left);            findnode(temp-&gt;right);        &#125;        if(temp-&gt;left!=NULL&amp;&amp;temp-&gt;right==NULL)        &#123;            m+=1;            findnode(temp-&gt;left);        &#125;        if(temp-&gt;left==NULL&amp;&amp;temp-&gt;right!=NULL)        &#123;            m+=1;            findnode(temp-&gt;right);        &#125;    &#125;    return m;&#125;void main()&#123;    Btree A;    int array[]=&#123;7,4,2,3,15,35,6,45,55,20,1,14,56,57,58&#125;;    int k;    k=sizeof(array)/sizeof(array[0]);    cout&lt;&lt;\"建立排序二叉树顺序: \"&lt;&lt;endl;    for(int i=0;i&lt;k;i++)    &#123;        cout&lt;&lt;array[i]&lt;&lt;\" \";        A.create_Btree(array[i]);    &#125;    cout&lt;&lt;endl;    cout&lt;&lt;\"二叉树节点个数： \"&lt;&lt;A.count(A.root)&lt;&lt;endl;    cout&lt;&lt;\"二叉树叶子个数：\"&lt;&lt;A.findleaf(A.root)&lt;&lt;endl;    cout&lt;&lt;\"二叉树中度数为1的结点的数量为：\"&lt;&lt;A.findnode(A.root)&lt;&lt;endl;    cout&lt;&lt;endl&lt;&lt;\"先序遍历序列: \"&lt;&lt;endl;    A.display1();    cout&lt;&lt;endl&lt;&lt;\"中序遍历序列: \"&lt;&lt;endl;    A.display2();    cout&lt;&lt;endl&lt;&lt;\"后序遍历序列: \"&lt;&lt;endl;    A.display3();&#125;\n 堆\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#include &lt;vector&gt;#include &lt;cassert&gt; using namespace std;class MaxHeap&#123;  private:\tvector&lt;int&gt; heap;\tint size;  public:\tvoid make_heap(vector&lt;int&gt; &amp; nums, int s)\t&#123; //构建堆\t\theap.assign(nums.begin(), nums.end());\t\tsize = s;\t\tfor (int i = size / 2 - 1; i &gt;= 0; i--)\t\t\tdown(i);\t&#125;\tvoid push(int num)\t&#123; //插入元素\t\theap.push_back(num);\t\tsize++;\t\tup(size - 1);\t&#125;\tint pop()\t&#123; //删除元素\t\tassert(size &gt; 0);\t\tint result = heap[0];\t\theap[0] = heap[size - 1];\t\theap.pop_back();\t\tsize--;\t\tdown(0);\t\treturn result;\t&#125;\tvoid down(int index)\t&#123;\t\tassert(index &gt;= 0);\t\tint temp = heap[index];\t\tindex = index * 2 + 1;\t\twhile (index &lt; size)\t\t&#123;\t\t\tif (index + 1 &lt; size &amp;&amp; heap[index] &lt; heap[index + 1])\t\t\t\tindex++;\t\t\tif (heap[index] &lt; temp)\t\t\t\tbreak;\t\t\telse\t\t\t&#123;\t\t\t\theap[(index - 1) / 2] = heap[index];\t\t\t\tindex = index * 2 + 1;\t\t\t&#125;\t\t&#125;\t\theap[(index - 1) / 2] = temp;\t&#125;\tvoid up(int index)\t&#123;\t\tassert(index &lt; size);\t\tint temp = heap[index];\t\twhile (index &gt; 0 &amp;&amp; temp &gt; heap[(index - 1) / 2])\t\t&#123;\t\t\theap[index] = heap[(index - 1) / 2];\t\t\tindex = (index - 1) / 2;\t\t&#125;\t\theap[index] = temp;\t&#125;&#125;;\n 胜者树\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include &lt;stdio.h&gt; #define K 10 #define MAX 65535 int leaves[K+1]; int successTree[K]; /* 对于单个内部节点进行调整 */ void adjust(int i) &#123;     int m,n;     if(2 * i &lt; K)               /* 获取它的左孩子结点 */         m = successTree[2 * i];     else         m = 2 * i - K + 1;     if(2*i+1&lt;K)                 /* 获取它的右孩子节点 */         n = successTree[2*i+1];     else         n = 2 * i + - K + 2;     successTree[i] = leaves[m] &gt; leaves[n] ? n : m; /* 进行胜负判定 */ &#125; /* 初始化叶子节点并对内部节点进行类似于堆的调整 */ void initTree() &#123;     for(int i=1;i&lt;K+1;i++)         scanf(\"%d\", &amp;leaves[i]);     for(int i=K-1;i&gt;0;i--)         adjust(i); &#125; /* 自下而上对胜者树进行调整 */ void adjustToRoot(int i) &#123;     int parent = (i + K - 1) / 2; /* 对从当前节点到根节点路径上的所有                                    * 节点进行调整 */     while(parent&gt;0)     &#123;         adjust(parent);         parent = parent / 2;     &#125; &#125; int main() &#123;     freopen(\"in\",\"r\",stdin);     initTree();     for(int i=1;i&lt;K+1;i++)      /* 每次用最大值替换掉冠军节点，并对树                                  * 进行调整,最终得到升序排序的序列 */     &#123;         printf(\"%d \", leaves[successTree[1]]);         leaves[successTree[1]]=MAX;         adjustToRoot(successTree[1]);     &#125;     return 0; &#125;\n 败者树\n12345678910111213141516171819202122232425262728293031int loserTree[K];               /* 存储中间节点值，下标0处存储冠军节点 */int leaves[K+1];                /* 从下标1开始存储叶子节点值，下标0处存储一个最小值节点 */void adjust(int i)&#123;    int parent=(i+K-1)/2;      /* 求出父节点的下标 */    while(parent&gt;0)    &#123;        if(leaves[i]&gt;leaves[loserTree[parent]])        &#123;            int temp=loserTree[parent];            loserTree[parent]=i;            /* i指向的是优胜者 */            i= temp;        &#125;        parent = parent / 2;    &#125;    loserTree[0]=i;&#125;void initLoserTree()&#123;    int i;    for(i=1;i&lt;K+1;i++)        scanf(\"%d\",&amp;leaves[i]);    leaves[0]=MIN;    for(int i=0;i&lt;K;i++)        loserTree[i]=0;    for(int i=K;i&gt;0;i--)        adjust(i);&#125;\n 最小生成树\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859typedef struct&#123;    char vertex[VertexNum];                                //顶点表    int edges[VertexNum][VertexNum];                       //邻接矩阵,可看做边表    int n,e;                                               //图中当前的顶点数和边数&#125;MGraph;typedef struct node&#123;    int u;                                                 //边的起始顶点    int v;                                                 //边的终止顶点    int w;                                                 //边的权值&#125;Edge;void kruskal(MGraph G)&#123;    int i,j,u1,v1,sn1,sn2,k;    int vset[VertexNum];                                    //辅助数组，判定两个顶点是否连通    int E[EdgeNum];                                         //存放所有的边    k=0;                                                    //E数组的下标从0开始    for (i=0;i&lt;G.n;i++)    &#123;        for (j=0;j&lt;G.n;j++)        &#123;            if (G.edges[i][j]!=0 &amp;&amp; G.edges[i][j]!=INF)            &#123;                E[k].u=i;                E[k].v=j;                E[k].w=G.edges[i][j];                k++;            &#125;        &#125;    &#125;    heapsort(E,k,sizeof(E[0]));                            //堆排序，按权值从小到大排列    for (i=0;i&lt;G.n;i++)                                    //初始化辅助数组    &#123;        vset[i]=i;    &#125;    k=1;                                                   //生成的边数，最后要刚好为总边数    j=0;                                                   //E中的下标    while (k&lt;G.n)    &#123;        sn1=vset[E[j].u];        sn2=vset[E[j].v];                                  //得到两顶点属于的集合编号        if (sn1!=sn2)                                      //不在同一集合编号内的话，把边加入最小生成树        &#123;            printf(\"%d ---&gt; %d, %d\",E[j].u,E[j].v,E[j].w);            k++;            for (i=0;i&lt;G.n;i++)            &#123;                if (vset[i]==sn2)                &#123;                    vset[i]=sn1;                &#125;            &#125;        &#125;        j++;    &#125;&#125;\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178// 单源最短路径Dijkstra算法实现.cpp : Defines the entry point for the console application.//#include \"stdafx.h\"#include&lt;iostream&gt;#define MAX 200#define Infinity 65535using namespace std;//边尾节点信息结构体struct edgeNode&#123; int no;   //尾接点序号 int cost;  //边权值 edgeNode *next; //其下一条邻接边尾节点指针&#125;;//节点信息结构体struct vexNode&#123; char info;  //节点名称 edgeNode *link; //与其相连的边的尾节点链表指针&#125;;struct Queue&#123; int no; //队列中节点序号 int cost; //以此为尾节点的边的权值&#125;;//优先队列Queue priQue[MAX];//节点数组vexNode adjlist[MAX];//指定源点到节点i的最短路径花费int lowcost[MAX];//指定源点到节点i路径中，节点i的前驱节点序号int parent[MAX];//建立图邻接表void createGraph(vexNode *adjlist,int *parent,int * lowcost,const int n,const int e)&#123; int i; for(i=1;i&lt;=n;i++) &#123;  cout&lt;&lt;\"请输入节点\"&lt;&lt;i&lt;&lt;\"的名称：\";  cin&gt;&gt;adjlist[i].info;  adjlist[i].link = NULL;  lowcost[i] = Infinity;  parent[i] = i; &#125; edgeNode *p1;   int v1,v2; for(i=1;i&lt;=e;i++) &#123;  cout&lt;&lt;\"请输入边\"&lt;&lt;i&lt;&lt;\"的起始节点与尾节点序号：\";  cin&gt;&gt;v1&gt;&gt;v2;  p1 = (edgeNode*)malloc(sizeof(edgeNode));  p1-&gt;no = v2;  cout&lt;&lt;\"此边的权值：\";  cin&gt;&gt;p1-&gt;cost;  p1-&gt;next = adjlist[v1].link;  adjlist[v1].link = p1; &#125;&#125;//当插入节点到优先队列时，保持队列优先性void keep_min_heap(Queue *priQue,int &amp;num,const int k)&#123; int l = 2*k; int r = 2*k + 1; int smallest = k; if(l&lt;=num&amp;&amp;priQue[l].cost&lt;priQue[k].cost)  smallest = l; if(r&lt;=num&amp;&amp;priQue[r].cost&lt;priQue[smallest].cost)  smallest = r; if(smallest != k) &#123;  Queue temp = priQue[smallest];  priQue[smallest] = priQue[k];  priQue[k] = temp;  keep_min_heap(priQue,num,smallest); &#125;&#125;//插入节点到优先队列时并且保持队列优先性void heap_insert(Queue *priQue,int &amp;num,int no,int cost)&#123; num +=1; priQue[num].no = no; priQue[num].cost = cost; int i = num; while(i&gt;1&amp;&amp;priQue[i/2].cost&gt;priQue[i].cost) &#123;  Queue temp = priQue[i];  priQue[i] = priQue[i/2];  priQue[i/2] = temp;  i = i/2; &#125;&#125;//取出优先队列的队头元素Queue heap_extract_min(Queue *priQue,int &amp;num)&#123; if(num&lt;1)  return priQue[0]; Queue min = priQue[1]; priQue[1] = priQue[num]; num -=1; keep_min_heap(priQue,num,1); return min;&#125;//打印指定源点带序号为i的点的最短路径void print_it(int *parent,vexNode *adjlist,int v)&#123; if(parent[v] == v)  cout&lt;&lt;\"(\"&lt;&lt;v&lt;&lt;\":\"&lt;&lt;adjlist[v].info&lt;&lt;\") \"; else &#123;  print_it(parent,adjlist,parent[v]);  cout&lt;&lt;\"(\"&lt;&lt;v&lt;&lt;\":\"&lt;&lt;adjlist[v].info&lt;&lt;\") \"; &#125;&#125;int _tmain(int argc, _TCHAR* argv[])&#123;int cases; cout&lt;&lt;\"请输入案例的个数：\"; cin&gt;&gt;cases; while(cases--) &#123;  int n,e;  cout&lt;&lt;\"请输入节点数：\";  cin&gt;&gt;n;  cout&lt;&lt;\"请输入边数：\";  cin&gt;&gt;e;  //队列中的元素，初始为0  int num = 0;  int i;  //创建邻接表  createGraph(adjlist,parent,lowcost,n,e);  cout&lt;&lt;endl;  cout&lt;&lt;\"从哪个节点开始：\";  int v0;  cin&gt;&gt;v0;  int v =v0;  lowcost[v0] = 0;  cout&lt;&lt;endl;  Queue queue;  for(i=1;i&lt;n;i++)  &#123;   edgeNode *p = adjlist[v0].link;   while(p != NULL)   &#123;    if(lowcost[v0] + p-&gt;cost&lt;lowcost[p-&gt;no])    &#123;     lowcost[p-&gt;no] = lowcost[v0] + p-&gt;cost;     parent[p-&gt;no] = v0;     heap_insert(priQue,num,p-&gt;no,lowcost[p-&gt;no]);    &#125;    p = p-&gt;next;   &#125;   queue = heap_extract_min(priQue,num);   v0 = queue.no;  &#125;  for(i=1;i&lt;=n;i++)  &#123;   mincost = 0;   cout&lt;&lt;\"从点\"&lt;&lt;adjlist[v].info&lt;&lt;\"开始到\"&lt;&lt;adjlist[i].info&lt;&lt;\"的最短路径为：\"&lt;&lt;endl;   print_it(parent,adjlist,i);   cout&lt;&lt;endl;   cout&lt;&lt;\"距离为：\"&lt;&lt;lowcost[i]&lt;&lt;endl;  &#125; &#125; system(\"pause\"); return 0;&#125;\n AOV\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980#include &lt;stdio.h&gt;#include &lt;malloc.h&gt;#define max 100typedef struct arcnode&#123;\tint adjvex;\tstruct arcnode *next;&#125; arcnode;typedef struct&#123;\tint vertex;\tarcnode *firstarc;&#125; vexnode;vexnode adjlist[max];int creatadjlist()&#123;\tarcnode *ptr;\tint arcnum, vexnum, k, v1, v2;\tprintf(\"input vexnum and arcnum:\");\tscanf(\"%d,%d\", &amp;vexnum, &amp;arcnum);\tfor (k = 1; k &lt;= vexnum; k++)\t&#123;\t\tadjlist[k].firstarc = NULL;\t\tadjlist[k].vertex = 0;\t&#125;\tfor (k = 1; k &lt;= arcnum; k++)\t&#123;\t\tprintf(\"v1,v2=\");\t\tscanf(\"%d,%d\", &amp;v1, &amp;v2);\t\tptr = (arcnode *)malloc(sizeof(arcnode));\t\tptr-&gt;adjvex = v2;\t\tptr-&gt;next = adjlist[v1].firstarc;\t\tadjlist[v1].firstarc = ptr;\t\tadjlist[v2].vertex++;\t&#125;\treturn vexnum;&#125;toposort(int n)&#123;\tint queue[max];\tint front = 0, rear = 0;\tint v, w, m;\tarcnode *p;\tm = 0;\tfor (v = 1; v &lt;= n; v++)\t\tif (adjlist[v].vertex == 0)\t\t&#123;\t\t\trear = (rear + 1) % max;\t\t\tqueue[rear] = v;\t\t&#125;\tprintf(\"the toposort:\\n\");\twhile (front != rear)\t&#123;\t\tfront = (front + 1) % max;\t\tv = queue[front];\t\tprintf(\"%d \", v);\t\tm++;\t\tp = adjlist[v].firstarc;\t\twhile (p != NULL)\t\t&#123;\t\t\tw = p-&gt;adjvex;\t\t\tadjlist[w].vertex--;\t\t\tif (adjlist[w].vertex == 0)\t\t\t&#123;\t\t\t\trear = (rear + 1) % max;\t\t\t\tqueue[rear] = w;\t\t\t&#125;\t\t\tp = p-&gt;next;\t\t&#125;\t&#125;\tif (m &lt; n)\t\tprintf(\"the toposort is fail.\");&#125;int main()&#123;\tint n;\tn = creatadjlist();\ttoposort(n);\treturn 0;&#125;\n AOE\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112#include&lt;iostream&gt;using namespace std;#define MAXN 100\t\t//顶点个数最大值#define MAXM 200\t\t//边数的最大值struct ArcNode&#123;\tint to, dur, no;\t//边的另一个顶点、持续时间、活动序号\tArcNode *next;&#125;;int n, m;\t\t\t\t//顶点个数、边数ArcNode *List1[MAXN];\t//每个顶点的边链表表头指针（出边表）ArcNode *List2[MAXM];\t//每个顶点的边链表表头指针（入边表）int count1[MAXN];\t\t//各顶点的入度int count2[MAXM];\t\t//各顶点的出度int Ee[MAXN];\t\t\t//各事件的最早可能开始时间int El[MAXN];\t\t\t//各事件的最迟允许开始时间int e[MAXM];\t\t\t//各活动的最早可能开始时间int L[MAXM];\t\t\t//各活动的最迟允许开始时间void CriticalPath()\t\t//求关键路径&#123;\t//拓扑排序求Ee\tint i, j, k;\tint top1 = -1;\tArcNode *temp1;\tmemset(Ee, 0, sizeof(Ee));\tfor(i = 0; i &lt; n; i++)\t\tif(count1[i] == 0) &#123; count1[i] = top1; top1 = i; &#125;\tfor(i = 0; i &lt; n; i++)\t&#123;\t\tif(top1 == -1) &#123; printf(\"Network has a cycle!\\n\"); return; &#125;\t\telse\t\t&#123;\t\t\tj = top1; top1 = count1[top1];\t\t\ttemp1 = List1[j];\t\t\twhile(temp1 != NULL)\t\t\t&#123;\t\t\t\tk = temp1-&gt;to;\t\t\t\tif(--count1[k] == 0) &#123; count1[k] = top1; top1 = k; &#125;\t\t\t\tif(Ee[j]+temp1-&gt;dur &gt; Ee[k]) Ee[k] = Ee[j] + temp1-&gt;dur;//有向边&lt;j, k&gt;\t\t\t\ttemp1 = temp1-&gt;next;\t\t\t&#125;\t\t&#125;\t&#125;\t//逆拓扑排序求El\tint top2 = -1;\tArcNode *temp2;\tfor(i = 0; i &lt; n; i++)\t&#123;\t\tEl[i] = Ee[n-1];\t\tif(count2[i] == 0) &#123; count2[i] = top2; top2 = i; &#125;\t&#125;\tfor(i = 0; i &lt; n; i++)\t&#123;\t\tj = top2; top2 = count2[top2];\t\ttemp2 = List2[j];\t\twhile(temp2 != NULL)\t\t&#123;\t\t\tk = temp2-&gt;to;\t\t\tif(--count2[k] == 0) &#123; count2[k] = top2; top2 = k; &#125;\t\t\tif(El[j]-temp2-&gt;dur &lt; El[k]) El[k] = El[j] - temp2-&gt;dur;//有向边&lt;k, j&gt;\t\t\ttemp2 = temp2-&gt;next;\t\t&#125;\t&#125;\t//求各活动的e[k]和L[k]\tmemset(e, 0, sizeof(e)); memset(L, 0, sizeof(L));\tprintf(\"The Critical activities are:\\n\");\tfor(i = 0; i &lt; n; i++)\t&#123;\t\ttemp1 = List1[i];\t\twhile(temp1 != NULL)\t\t&#123;\t\t\tj = temp1-&gt;to; k = temp1-&gt;no;\t//有向边&lt;i, j&gt;\t\t\te[k] = Ee[i]; L[k] = El[j] - temp1-&gt;dur;\t\t\tif(e[k] == L[k]) printf(\"a%d : %d-&gt;%d\\n\", k, i, j);\t\t\ttemp1 = temp1-&gt;next;\t\t&#125;\t&#125;&#125;int main()&#123;\tint i, u, v, w;\t//循环变量、边的起点和终点\tscanf(\"%d%d\", &amp;n, &amp;m);\t//读入顶点个数和边数\tmemset(List1, 0, sizeof(List1)); memset(List2, 0, sizeof(List2));\tmemset(count1, 0, sizeof(count1)); memset(count2, 0, sizeof(count2));\tArcNode *temp1, *temp2;\tfor(i = 0; i &lt; m; i++)\t&#123;\t\tscanf(\"%d%d%d\", &amp;u, &amp;v, &amp;w);\t//读入边的起点和终点\t\tcount1[v]++;\t\ttemp1 = new ArcNode;\t\t\t//构造邻接表\t\ttemp1-&gt;to = v; temp1-&gt;dur = w;\t\ttemp1-&gt;no = i + 1; temp1-&gt;next = NULL;\t\tif(List1[u] == NULL) List1[u] = temp1;\t\telse &#123; temp1-&gt;next = List1[u]; List1[u] = temp1; &#125;\t\tcount2[u]++;\t\ttemp2 = new ArcNode;\t\t\t//构造逆邻接表\t\ttemp2-&gt;to = u; temp2-&gt;dur = w;\t\ttemp2-&gt;no = i + 1; temp2-&gt;next = NULL;\t\tif(List2[v] == NULL) List2[v] = temp2;\t\telse &#123; temp2-&gt;next = List2[v]; List2[v] = temp2; &#125;\t&#125;\tCriticalPath();\tfor(i = 0; i &lt; n; i++)\t\t\t\t//释放边链表上各边结点所占用的存储空间\t&#123;\t\ttemp1 = List1[i]; temp2 = List2[i];\t\twhile(temp1 != NULL) &#123; List1[i] = temp1-&gt;next; delete temp1; temp1 = List1[i]; &#125;\t\twhile(temp2 != NULL) &#123; List2[i] = temp2-&gt;next; delete temp2; temp2 = List2[i]; &#125;\t&#125;\treturn 0;&#125;\n 图\n 邻接矩阵\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173/*    邻接矩阵实现图的广搜和深搜*/#include&lt;iostream&gt;#include&lt;queue&gt;#define inf 1000000 //假设的无穷大#define vertex_max_num 100  //设的最大顶点数using namespace std;typedef struct &#123;    int v[vertex_max_num];//顶点名称    int adj_matrix[vertex_max_num][vertex_max_num];//邻接矩阵    int v_num, arc_num;//顶点数，弧数    int kind;//图的种类,0有向图，1有向网，2无向图，3无向网&#125;graph;int vis[vertex_max_num+1];//标志数组//标志数组初始化void init() &#123;    memset(vis, 0, sizeof(vis));&#125;//创建有向图void dir_graph_create(graph &amp;G) &#123;    cout &lt;&lt; \"请输入要创建的有向图的顶点数和弧数：\"; cin &gt;&gt; G.v_num &gt;&gt; G.arc_num;    //结点初始化    for (int i = 1; i &lt;= G.v_num; i++) G.v[i] = i;//对结点编号    for (int i = 1; i &lt;= G.v_num; i++)        for (int j = 1; j &lt;= G.v_num; j++)            G.adj_matrix[i][j] = 0;    cout &lt;&lt; \"请依次输入邻接可达的成对结点：\" &lt;&lt; endl;    for (int i = 1; i &lt;= G.arc_num; i++) &#123;        int v1, v2;        cin &gt;&gt; v1 &gt;&gt; v2;        G.adj_matrix[v1][v2] = 1;    &#125;&#125;//创建有向网（带权有向图）void dir_net_create(graph &amp;G) &#123;    cout &lt;&lt; \"请输入要创建的有向网的顶点数和弧数：\"; cin &gt;&gt; G.v_num &gt;&gt; G.arc_num;    //结点初始化    for (int i = 1; i &lt;= G.v_num; i++) G.v[i] = i;//对结点编号    for (int i = 1; i &lt;= G.v_num; i++)        for (int j = 1; j &lt;= G.v_num; j++)            G.adj_matrix[i][j] = inf;    cout &lt;&lt; \"请依次输入邻接可达的成对结点及弧长：\" &lt;&lt; endl;    for (int i = 1; i &lt;= G.arc_num; i++) &#123;        int v1, v2,w;        cin &gt;&gt; v1 &gt;&gt; v2 &gt;&gt; w;        G.adj_matrix[v1][v2] = w;    &#125;&#125;//创建无向图void udir_graph_create(graph &amp;G) &#123;    cout &lt;&lt; \"请输入要创建的无向图的顶点数和弧数：\"; cin &gt;&gt; G.v_num &gt;&gt; G.arc_num;    //结点初始化    for (int i = 1; i &lt;= G.v_num; i++) G.v[i] = i;//对结点编号    for (int i = 1; i &lt;= G.v_num; i++)        for (int j = 1; j &lt;= G.v_num; j++)            G.adj_matrix[i][j] = 0;    cout &lt;&lt; \"请依次输入邻接的成对结点：\" &lt;&lt; endl;    for (int i = 1; i &lt;= G.arc_num; i++) &#123;        int v1, v2;        cin &gt;&gt; v1 &gt;&gt; v2;        G.adj_matrix[v1][v2] = 1;        G.adj_matrix[v2][v1] = 1;    &#125;&#125;//创建无向网（带权无向图）void udir_net_create(graph &amp;G) &#123;    cout &lt;&lt; \"请输入要创建的无向网的顶点数和弧数：\"; cin &gt;&gt; G.v_num &gt;&gt; G.arc_num;    //结点初始化    for (int i = 1; i &lt;= G.v_num; i++) G.v[i] = i;//对结点编号    for (int i = 1; i &lt;= G.v_num; i++)        for (int j = 1; j &lt;= G.v_num; j++)            G.adj_matrix[i][j] = inf;    cout &lt;&lt; \"请依次输入邻接的成对结点及弧长：\" &lt;&lt; endl;    for (int i = 1; i &lt;= G.arc_num; i++) &#123;        int v1, v2, w;        cin &gt;&gt; v1 &gt;&gt; v2 &gt;&gt; w;        G.adj_matrix[v1][v2] = w;        G.adj_matrix[v2][v1] = w;    &#125;&#125;void graph_create(graph &amp;G) &#123;    cout &lt;&lt; \"************\" &lt;&lt; endl;    cout &lt;&lt; \"0-----有向图\" &lt;&lt; endl;    cout &lt;&lt; \"1-----有向网\" &lt;&lt; endl;    cout &lt;&lt; \"2-----无向图\" &lt;&lt; endl;    cout &lt;&lt; \"3-----无向网\" &lt;&lt; endl;    cout &lt;&lt; \"************\" &lt;&lt; endl;    cout &lt;&lt; \"根据上方菜单，输入相应数字，来创建你想要类型的图\" &lt;&lt; endl;    cin &gt;&gt; G.kind;    switch (G.kind) &#123;    case 0:dir_graph_create(G); break;    case 1:dir_net_create(G); break;    case 2:udir_graph_create(G); break;    case 3:udir_net_create(G); break;    default:return;    &#125;&#125;//图深度优先遍历void dfs1(graph G, int v) &#123;    if (!vis[v]) &#123;        cout &lt;&lt; G.v[v]&lt;&lt;\" \";        vis[v] = 1;    &#125;    for (int i = 1; i &lt;= G.v_num; i++)        if (!vis[i] &amp;&amp; G.adj_matrix[v][i]==1)            dfs1(G, i);&#125;//网深度优先遍历void dfs2(graph G, int v) &#123;    if (!vis[v]) &#123;        cout &lt;&lt; G.v[v]&lt;&lt;\" \";        vis[v] = 1;    &#125;    for (int i = 1; i &lt;= G.v_num; i++) &#123;        if (!vis[i] &amp;&amp; G.adj_matrix[v][i] != inf)            dfs2(G, i);    &#125;&#125;//深度优先遍历void dfs(graph G, int v) &#123;    init();    cout &lt;&lt; \"深度优先遍历结果：\";    switch (G.kind) &#123;    case 0:    case 2:dfs1(G, v); break;    case 1:    case 3:dfs2(G, v); break;    default:return;    &#125;    cout &lt;&lt; endl;&#125;//广度优先遍历void bfs(graph G, int v) &#123;    init();    cout &lt;&lt; \"广度优先遍历结果：\";    queue&lt;int&gt;que;    if (!vis[v]) &#123;        cout &lt;&lt; G.v[v] &lt;&lt; \" \";        vis[v] = 1;        que.push(v);    &#125;    while (!que.empty()) &#123;        int vertex = que.front();        que.pop();        for (int i = 1; i &lt;= G.v_num; i++) &#123;            if (!vis[i]) &#123;                if (((G.kind == 0 || G.kind == 2) &amp;&amp; G.adj_matrix[vertex][i] == 1) ||                    ((G.kind==1 || G.kind==3) &amp;&amp; G.adj_matrix[vertex][i]!=inf)) &#123;                    cout &lt;&lt; G.v[i] &lt;&lt; \" \";                    vis[i] = 1;                    que.push(i);                &#125;            &#125;        &#125;    &#125;    cout &lt;&lt; endl;&#125;\n 邻接表\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134#include&lt;iostream&gt;#include&lt;queue&gt;using namespace std;const int vertex_max = 100;typedef char vertex_type;//边typedef struct edge_node &#123;    int vertex;//边所指向的结点编号    struct edge_node *next;//下一条边&#125;edge;//结点typedef struct vertex_node &#123;    vertex_type e;//结点名字    edge *side;&#125;vertex;typedef struct Graph &#123;    vertex adj_list[vertex_max+1];//邻接表    int w[vertex_max+1][vertex_max + 1];//边权重    int v_num, e_num;//结点数、边数&#125;graph;bool vis[vertex_max + 1];void init() &#123;    memset(vis, 0, sizeof(vis));&#125;//建立图void graph_create(graph &amp;G) &#123;    cout &lt;&lt; \"请输入要创建的图的结点数和边数：\";    cin &gt;&gt; G.v_num &gt;&gt; G.e_num;    cout &lt;&lt; \"========================================\" &lt;&lt; endl;    cout &lt;&lt; \"结点信息如下\"&lt;&lt;endl;    for (int i = 1; i &lt;= G.v_num; i++) &#123;        cout &lt;&lt; \"第\" &lt;&lt; i &lt;&lt; \"个结点是\"; cin &gt;&gt; G.adj_list[i].e;        G.adj_list[i].side = nullptr;    &#125;    cout &lt;&lt; \"========================================\" &lt;&lt; endl;    cout &lt;&lt; \"边信息如下\" &lt;&lt; endl;    for (int i = 1; i &lt;= G.e_num; i++) &#123;        cout &lt;&lt; \"请输入第\" &lt;&lt; i &lt;&lt; \"条边相连的两个结点编号及边的权重：\";        int x, y,weight;        cin &gt;&gt; x &gt;&gt; y &gt;&gt; weight;        G.w[x][y] = G.w[y][x] = weight;        edge *p_edge = new edge;        edge *q_edge = new edge;        p_edge-&gt;next = nullptr; p_edge-&gt;vertex = y;        q_edge-&gt;next = nullptr; q_edge-&gt;vertex = x;        edge *tmp1 = G.adj_list[x].side;        edge *tmp2 = G.adj_list[y].side;        //把x结点指向y结点        while (tmp1) &#123;            if (tmp1-&gt;next == nullptr) break;            tmp1 = tmp1-&gt;next;        &#125;        if (tmp1 == nullptr) G.adj_list[x].side = p_edge;        else tmp1-&gt;next = p_edge;        //把y结点指向x结点        while (tmp2) &#123;            if (tmp2-&gt;next == nullptr) break;            tmp2 = tmp2-&gt;next;        &#125;        if (tmp2 == nullptr) G.adj_list[y].side = q_edge;        else tmp2-&gt;next = q_edge;    &#125;&#125;//打印邻接表void adj_list_print(graph G) &#123;    for (int i = 1; i &lt;= G.v_num; i++) &#123;        cout &lt;&lt; G.adj_list[i].e;        edge *tmp = G.adj_list[i].side;        while (tmp) &#123;            cout &lt;&lt;\"→\"&lt;&lt; G.adj_list[tmp-&gt;vertex].e;            tmp = tmp-&gt;next;        &#125;        cout &lt;&lt; endl;    &#125;&#125;//深搜（从某结点出发搜索）void dfs1(graph G, int v) &#123;    if (!vis[v]) &#123;        cout &lt;&lt; G.adj_list[v].e &lt;&lt; \" \"; vis[v] = true;    &#125;    edge *p = G.adj_list[v].side;    while (p) &#123;        if (!vis[p-&gt;vertex]) dfs1(G, p-&gt;vertex);        p = p-&gt;next;    &#125;&#125;//深搜（从各个结点出发搜索）void dfs(graph G) &#123;    for (int i = 1; i &lt;= G.v_num; i++) &#123;        init();        dfs1(G, i);        cout &lt;&lt; endl;    &#125;&#125;//广搜（从某个结点出发搜索）void bfs1(graph G,int i) &#123;        init();        queue&lt;int&gt;que;        if (!vis[i]) &#123;            cout &lt;&lt; G.adj_list[i].e &lt;&lt; \" \";            que.push(i);            vis[i] = 1;        &#125;        while (!que.empty()) &#123;            int ii = que.front();            que.pop();            edge *p = G.adj_list[ii].side;            while (p) &#123;                if (!vis[p-&gt;vertex]) &#123;                    cout &lt;&lt; G.adj_list[p-&gt;vertex].e &lt;&lt; \" \";                    que.push(p-&gt;vertex);                    vis[p-&gt;vertex] = 1;                &#125;                p = p-&gt;next;            &#125;        &#125;&#125;//广搜（从各个结点出发搜索）void bfs(graph G) &#123;    for (int i = 1; i &lt;= G.v_num; i++) &#123;        bfs1(G, i);        cout &lt;&lt; endl;    &#125;&#125;\n Dijkstra算法\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111class MatrixUDG &#123;    #define MAX    100    #define INF    (~(0x1&lt;&lt;31))        // 无穷大(即0X7FFFFFFF)    private:        char mVexs[MAX];    // 顶点集合        int mVexNum;             // 顶点数        int mEdgNum;             // 边数        int mMatrix[MAX][MAX];   // 邻接矩阵    public:        // 创建图(自己输入数据)        MatrixUDG();        // 创建图(用已提供的矩阵)        //MatrixUDG(char vexs[], int vlen, char edges[][2], int elen);        MatrixUDG(char vexs[], int vlen, int matrix[][9]);        ~MatrixUDG();        // 深度优先搜索遍历图        void DFS();        // 广度优先搜索（类似于树的层次遍历）        void BFS();        // prim最小生成树(从start开始生成最小生成树)        void prim(int start);        // 克鲁斯卡尔（Kruskal)最小生成树        void kruskal();        // Dijkstra最短路径        void dijkstra(int vs, int vexs[], int dist[]);        // 打印矩阵队列图        void print();    private:        // 读取一个输入字符        char readChar();        // 返回ch在mMatrix矩阵中的位置        int getPosition(char ch);        // 返回顶点v的第一个邻接顶点的索引，失败则返回-1        int firstVertex(int v);        // 返回顶点v相对于w的下一个邻接顶点的索引，失败则返回-1        int nextVertex(int v, int w);        // 深度优先搜索遍历图的递归实现        void DFS(int i, int *visited);        // 获取图中的边        EData* getEdges();        // 对边按照权值大小进行排序(由小到大)        void sortEdges(EData* edges, int elen);        // 获取i的终点        int getEnd(int vends[], int i);&#125;;/* * Dijkstra最短路径。 * 即，统计图中\"顶点vs\"到其它各个顶点的最短路径。 * * 参数说明： *       vs -- 起始顶点(start vertex)。即计算\"顶点vs\"到其它顶点的最短路径。 *     prev -- 前驱顶点数组。即，prev[i]的值是\"顶点vs\"到\"顶点i\"的最短路径所经历的全部顶点中，位于\"顶点i\"之前的那个顶点。 *     dist -- 长度数组。即，dist[i]是\"顶点vs\"到\"顶点i\"的最短路径的长度。 */void MatrixUDG::dijkstra(int vs, int prev[], int dist[])&#123;    int i,j,k;    int min;    int tmp;    int flag[MAX];      // flag[i]=1表示\"顶点vs\"到\"顶点i\"的最短路径已成功获取。    // 初始化    for (i = 0; i &lt; mVexNum; i++)    &#123;        flag[i] = 0;              // 顶点i的最短路径还没获取到。        prev[i] = 0;              // 顶点i的前驱顶点为0。        dist[i] = mMatrix[vs][i]; // 顶点i的最短路径为\"顶点vs\"到\"顶点i\"的权。    &#125;    // 对\"顶点vs\"自身进行初始化    flag[vs] = 1;    dist[vs] = 0;    // 遍历mVexNum-1次；每次找出一个顶点的最短路径。    for (i = 1; i &lt; mVexNum; i++)    &#123;        // 寻找当前最小的路径；        // 即，在未获取最短路径的顶点中，找到离vs最近的顶点(k)。        min = INF;        for (j = 0; j &lt; mVexNum; j++)        &#123;            if (flag[j]==0 &amp;&amp; dist[j]&lt;min)            &#123;                min = dist[j];                k = j;            &#125;        &#125;        // 标记\"顶点k\"为已经获取到最短路径        flag[k] = 1;        // 修正当前最短路径和前驱顶点        // 即，当已经\"顶点k的最短路径\"之后，更新\"未获取最短路径的顶点的最短路径和前驱顶点\"。        for (j = 0; j &lt; mVexNum; j++)        &#123;            tmp = (mMatrix[k][j]==INF ? INF : (min + mMatrix[k][j]));            if (flag[j] == 0 &amp;&amp; (tmp  &lt; dist[j]) )            &#123;                dist[j] = tmp;                prev[j] = k;            &#125;        &#125;    &#125;    // 打印dijkstra最短路径的结果    cout &lt;&lt; \"dijkstra(\" &lt;&lt; mVexs[vs] &lt;&lt; \"): \" &lt;&lt; endl;    for (i = 0; i &lt; mVexNum; i++)        cout &lt;&lt; \"  shortest(\" &lt;&lt; mVexs[vs] &lt;&lt; \", \" &lt;&lt; mVexs[i] &lt;&lt; \")=\" &lt;&lt; dist[i] &lt;&lt; endl;&#125;\n 归并排序（递归）\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// 归并排序_递归.cpp:// 以数组为例子#include \"stdafx.h\"#include&lt;iostream&gt;using namespace std;// 在原始数组上进行操作，将前后两个有序序列合并到一个临时数组中，并将合并后的数组复制给原始数组arrvoid merge(int arr[], int low, int middle, int high)&#123;\tint i, j, k;\ti = low; // low为第一个有序区的第一个元素\tj = middle + 1; // middle+1为第二个有序区的第一个元素\tk = 0;\tint *temp = new(nothrow) int[high - low + 1];\tif (!temp)\t&#123;\t\tcout &lt;&lt; \"内存分配失败！\" &lt;&lt; endl;\t\treturn;\t&#125;\t// 依次比较两个有序序列的第一个元素，将较小的一方存放到temp数组中\twhile (i &lt;= middle &amp;&amp; j &lt;= high)\t&#123;\t\tif (arr[i] &lt; arr[j])\t\t\ttemp[k++] = arr[i++];\t\telse\t\t\ttemp[k++] = arr[j++];\t&#125;\twhile (i &lt;= middle)\t\ttemp[k++] = arr[i++];\twhile (j &lt;= high)\t\ttemp[k++] = arr[j++];\t// 将排好序的存回arr中low到high该区间内\tfor (i = low, k = 0; i &lt;= high; i++, k++)\t\tarr[i] = temp[k];\t// 删除指针，由于指向的是数组，必须用delete []\tdelete[]temp;&#125;void mergeSort(int arr[], int low, int high)&#123;\t// 用递归应用二路归并函数实现排序——分治法\tif (low &lt; high)  //（是if，不是while！，且不含等号！否则死循环！）\t&#123;\t\tint mid = (low + high) / 2;\t\tmergeSort(arr, low, mid);\t\tmergeSort(arr, mid + 1, high);\t\tmerge(arr, low, mid, high);\t&#125;        else            return;&#125;int main()&#123;\tint x[] = &#123; -3,5,7,-7,4,1,0,9&#125;;\tint n = sizeof(x) / sizeof(int);\tmergeSort(x, 0, n-1);\tfor (int i = 0; i&lt;8; i++)\t\tcout &lt;&lt; x[i] &lt;&lt; \" \";\treturn 0;&#125;\n k路归并\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;list&gt;#include &lt;iterator&gt;#include &lt;cstdlib&gt;using namespace std;template&lt;class T&gt; class MinHeap&#123;public:    MinHeap();    MinHeap(const size_t size);    ~MinHeap();    T get_min() const;    void delete_min();    void insert_element(const T&amp; e);    void adjust_min_heap(const size_t i);    size_t get_heap_size() const;    int compare(const T&amp; t1,const T&amp; t2);private:    T *heap;    size_t heap_size;&#125;;template&lt;class T&gt;MinHeap&lt;T&gt;::MinHeap():heap(NULL),heap_size(0)&#123;&#125;template&lt;class T&gt;MinHeap&lt;T&gt;::MinHeap(const size_t size)&#123;    if(!heap)        delete [] heap;    heap = new T[size+1];    heap_size = 0;&#125;template&lt;class T&gt;MinHeap&lt;T&gt;::~MinHeap()&#123;    if(!heap)        delete [] heap;    heap_size = 0;&#125;template&lt;class T&gt;T MinHeap&lt;T&gt;::get_min() const&#123;    if(heap_size &gt; 0)        return heap[1];    else        return T();&#125;template&lt;class T&gt;void MinHeap&lt;T&gt;::delete_min()&#123;    if(heap_size &gt; 0)    &#123;        heap[1] = heap[heap_size];        heap_size = heap_size - 1;        adjust_min_heap(1);    &#125;    else    &#123;        cout&lt;&lt;\"Error: the min heap is empty\"&lt;&lt;endl;    &#125;&#125;template&lt;class T&gt;void MinHeap&lt;T&gt;::insert_element(const T&amp; e)&#123;    size_t i,parent;    T temp;    heap_size = heap_size + 1;    heap[heap_size] = e;    i = heap_size;    parent = i/2;    while(i&gt;1 &amp;&amp; compare(heap[parent],heap[i]) &gt; 0)    &#123;        temp = heap[parent];        heap[parent] = heap[i];        heap[i] = temp;        i = parent;        parent = i/2;    &#125;&#125;template&lt;class T&gt;void MinHeap&lt;T&gt;::adjust_min_heap(const size_t i)&#123;    size_t left,right,least;    T temp;    left = i*2;    right = i*2+1;    if(left &lt;= heap_size &amp;&amp; compare(heap[left],heap[i]) &lt; 0)        least = left;    else        least = i;    if(right &lt;= heap_size &amp;&amp; compare(heap[right],heap[least]) &lt; 0)        least = right;    if(least != i)    &#123;        temp = heap[least];        heap[least] = heap[i];        heap[i] = temp;        adjust_min_heap(least);    &#125;&#125;template&lt;class T&gt;size_t MinHeap&lt;T&gt;::get_heap_size() const&#123;    return heap_size;&#125;template&lt;class T&gt;int MinHeap&lt;T&gt;::compare(const T&amp; t1,const T&amp; t2)&#123;    return (*t1-*t2);&#125;const static int k = 3;int main()&#123;    list&lt;int&gt; lists[k];    list&lt;int&gt;::iterator iters[k];    list&lt;int&gt; retlist;    list&lt;int&gt;::iterator retiter;    list&lt;int&gt;::iterator iter;    MinHeap&lt;list&lt;int&gt;::iterator&gt; minheap(k);    //first list &lt;12,24,52&gt;    lists[0].push_back(12);    lists[0].push_back(24);    lists[0].push_back(52);    cout&lt;&lt;\"First list: \";    for(iter=lists[0].begin();iter != lists[0].end();++iter)          cout&lt;&lt;*iter&lt;&lt;\"-&gt;\";    cout&lt;&lt;\"NULL\"&lt;&lt;endl;    //second list &lt;9,32&gt;    lists[1].push_back(9);    lists[1].push_back(32);    cout&lt;&lt;\"Second list: \";    for(iter=lists[1].begin();iter != lists[1].end();++iter)          cout&lt;&lt;*iter&lt;&lt;\"-&gt;\";    cout&lt;&lt;\"NULL\"&lt;&lt;endl;    //third list &lt;34,42,78&gt;    lists[2].push_back(34);    lists[2].push_back(42);    lists[2].push_back(78);    cout&lt;&lt;\"Third list: \";    for(iter=lists[2].begin();iter != lists[2].end();++iter)          cout&lt;&lt;*iter&lt;&lt;\"-&gt;\";    cout&lt;&lt;\"NULL\"&lt;&lt;endl;    iters[0] = lists[0].begin();    iters[1] = lists[1].begin();    iters[2] = lists[2].begin();    minheap.insert_element(iters[0]);    minheap.insert_element(iters[1]);    minheap.insert_element(iters[2]);    while(minheap.get_heap_size())    &#123;        iter = minheap.get_min() ;        retlist.push_back(*iter);        minheap.delete_min();        ++iter;        if(iter != lists[0].end() &amp;&amp; iter != lists[1].end()           &amp;&amp;iter != lists[2].end())            minheap.insert_element(iter);    &#125;    cout&lt;&lt;\"Merge the there list is: \"&lt;&lt;endl;    for(retiter = retlist.begin();retiter!= retlist.end();retiter++)        cout&lt;&lt;*retiter&lt;&lt;\"-&gt;\";    cout&lt;&lt;\"NULL\"&lt;&lt;endl;    exit(0);&#125;\nHanyuu Furude @ 2019 all right saved.\n","plink":"ilucia.github.io/Review/dataStructure/"},{"title":"Latex","date":"2018-12-01T01:09:23.000Z","updated":"2022-04-27T15:24:01.559Z","content":"\n\n\n描述\n渲染样式\n代码\n\n\n\n\nalpha\nα\\alphaα\n\\alpha\n\n\nAlpha\nA\\AlphaA\n\\Alpha\n\n\nbeta\nβ\\betaβ\n\\beta\n\n\nBeta\nB\\BetaB\n\\Beta\n\n\ngamma\nγ\\gammaγ\n\\gamma\n\n\nGamma\nΓ\\GammaΓ\n\\Gamma\n\n\ndelta\nδ\\deltaδ\n\\delta\n\n\nDelta\nΔ\\DeltaΔ\n\\Delta\n\n\nepsilon\nϵ\\epsilonϵ\n\\epsilon\n\n\nvarepsilon\nε\\varepsilonε\n\\varepsilon\n\n\nE\nEEE\nE\n\n\nzeta\nζ\\zetaζ\n\\zeta\n\n\nZeta\nZ\\ZetaZ\n\\Zeta\n\n\neta\nη\\etaη\n\\eta\n\n\nEta\nH\\EtaH\n\\Eta\n\n\ntheta\nθ\\thetaθ\n\\theta\n\n\nvartheta\nϑ\\varthetaϑ\n\\vartheta\n\n\nTheta\nΘ\\ThetaΘ\n\\Theta\n\n\niota\nι\\iotaι\n\\iota\n\n\nIota\nI\\IotaI\n\\Iota\n\n\nkappa\nκ\\kappaκ\n\\kappa\n\n\nKappa\nK\\KappaK\n\\Kappa\n\n\nlambda\nλ\\lambdaλ\n\\lambda\n\n\nLambda\nΛ\\LambdaΛ\n\\Lambda\n\n\nmu\nμ\\muμ\n\\mu\n\n\nMu\nM\\MuM\n\\Mu\n\n\nN\nNNN\n\\N\n\n\nxi\nξ\\xiξ\n\\xi\n\n\nXi\nΞ\\XiΞ\n\\Xi\n\n\no\nooo\n\\o\n\n\nO\nOOO\n\\O\n\n\npi\nπ\\piπ\n\\pi\n\n\nPi\nΠ\\PiΠ\n\\Pi\n\n\nrho\nρ\\rhoρ\n\\rho\n\n\nvarrho\nϱ\\varrhoϱ\n\\varrho\n\n\nP\nPPP\n\\P\n\n\nsigma\nσ\\sigmaσ\n\\sigma\n\n\nSigma\nΣ\\SigmaΣ\n\\Sigma\n\n\ntau\nτ\\tauτ\n\\tau\n\n\nT\nTTT\n\\T\n\n\nupsilon\nυ\\upsilonυ\n\\upsilon\n\n\nUpsilon\nΥ\\UpsilonΥ\n\\Upsilon\n\n\nphi\nϕ\\phiϕ\n\\phi\n\n\nvarphi\nφ\\varphiφ\n\\varphi\n\n\nPhi\nΦ\\PhiΦ\n\\Phi\n\n\npsi\nψ\\psiψ\n\\psi\n\n\nPsi\nΨ\\PsiΨ\n\\Psi\n\n\nomega\nω\\omegaω\n\\omega\n\n\nOmega\nΩ\\OmegaΩ\n\\Omega\n\n\n&amp;\n&amp;\\And&amp;\n\\and\n\n\n向上取整\n⌈x⌉\\lceil x \\rceil⌈x⌉\n\\lceil x \\rceil\n\n\n向下取整\n⌊x⌋\\lfloor x \\rfloor⌊x⌋\n\\floor x \\rfloor\n\n\n除法\nab\\frac{a}{b}ba​\n\\frac{a}{b}\n\n\n点乘\n⋅\\cdot⋅\n\\cdot\n\n\n求和\n∑abc\\sum_a^bc∑ab​c\n\\sum_a^bc\n\n\n分号\nab\\frac{a}{b}ba​\n\\frac{a}{b}\n\n\n积分\n∫01x\\int_0^1{x}∫01​x\n\\int_0^1{x}\n\n\n封闭积分\n∮01x\\oint_0^1{x}∮01​x\n\\oint_0^1{x}\n\n\n根号\nyx\\sqrt[x]{y}xy​\n\\sqrt[x]{y}\n\n\nmatrix\nabcd\\begin{matrix}a&amp;b\\\\c&amp;d\\end{matrix}ac​bd​\n\\begin{matrix}a&amp;\\c&amp;d\\end{matrix}\n\n\nmatrix\n(abcd)\\begin{pmatrix}a&amp;b\\\\c&amp;d\\end{pmatrix}(ac​bd​)\n\\begin{pmatrix}a&amp;\\c&amp;d\\end{pmatrix}\n\n\nmatrix\n[abcd]\\begin{bmatrix}a&amp;b\\\\c&amp;d\\end{bmatrix}[ac​bd​]\n\\begin{bmatrix}a&amp;\\c&amp;d\\end{bmatrix}\n\n\nmatrix\n{abcd}\\begin{Bmatrix}a&amp;b\\\\c&amp;d\\end{Bmatrix}{ac​bd​}\n\\begin{Bmatrix}a&amp;\\c&amp;d\\end{Bmatrix}\n\n\nmatrix\n∣abcd∣\\begin{vmatrix}a&amp;b\\\\c&amp;d\\end{vmatrix}∣∣∣∣​ac​bd​∣∣∣∣​\n\\begin{vmatrix}a&amp;\\c&amp;d\\end{vmatrix}\n\n\nmatrix\n∥abcd∥\\begin{Vmatrix}a&amp;b\\\\c&amp;d\\end{Vmatrix}∥∥∥∥​ac​bd​∥∥∥∥​\n\\begin{Vmatrix}a&amp;\\c&amp;d\\end{Vmatrix}\n\n\nuparrow\n↑\\uparrow↑\n\\uparrow\n\n\ndownarrow\n↓\\downarrow↓\n\\downarrow\n\n\nUparrow\n⇑\\Uparrow⇑\n\\Uparrow\n\n\nDownarrow\n⇓\\Downarrow⇓\n\\Downarrow\n\n\nupdownarrow\n↕\\updownarrow↕\n\\updownarrow\n\n\nUpdownarrow\n⇕\\Updownarrow⇕\n\\Updownarrow\n\n\nrightarrow\n→\\rightarrow→\n\\rightarrow\n\n\nleftarrow\n←\\leftarrow←\n\\leftarrow\n\n\nRightarrow\n⇒\\Rightarrow⇒\n\\Rightarrow\n\n\nLeftarrow\n⇐\\Leftarrow⇐\n\\Leftarrow\n\n\nleftrightarrow\n↔\\leftrightarrow↔\n\\leftrightarrow\n\n\nLeftrightarrow\n⇔\\Leftrightarrow⇔\n\\Leftrightarrow\n\n\nlongrightarrow\n⟶\\longrightarrow⟶\n\\longrightarrow\n\n\nongleftarrow\n⟵\\longleftarrow⟵\n\\longleftarrow\n\n\nLongrightarrow\n⟹\\Longrightarrow⟹\n\\Longrightarrow\n\n\nLongleftarrow\n⟸\\Longleftarrow⟸\n\\Longleftarrow\n\n\nlongleftrightarrow\n⟷\\longleftrightarrow⟷\n\\longleftrightarrow\n\n\nLongleftrightarrow\n⟺\\Longleftrightarrow⟺\n\\Longleftrightarrow\n\n\nmapsto\n↦\\mapsto↦\n\\mapsto\n\n\nlongmapsto\n⟼\\longmapsto⟼\n\\longmapsto\n\n\nhookleftarrow\n↩\\hookleftarrow↩\n\\hookleftarrow\n\n\nhookrightarrow\n↪\\hookrightarrow↪\n\\hookrightarrow\n\n\nleftharpoonup\n↼\\leftharpoonup↼\n\\leftharpoonup\n\n\nrightharpoonup\n⇀\\rightharpoonup⇀\n\\rightharpoonup\n\n\nleftharpoondown\n↽\\leftharpoondown↽\n\\leftharpoondown\n\n\nrightharpoondown\n⇁\\rightharpoondown⇁\n\\rightharpoondown\n\n\nrightleftharpoons\n⇌\\rightleftharpoons⇌\n\\rightleftharpoons\n\n\nleadsto\n⇝\\leadsto⇝\n\\leadsto\n\n\nnearrow\n↗\\nearrow↗\n\\nearrow\n\n\nsearrow\n↘\\searrow↘\n\\searrow\n\n\nswarrow\n↙\\swarrow↙\n\\swarrow\n\n\nnwarrow\n↖\\nwarrow↖\n\\nwarrow\n\n\nnleftarrow\n↚\\nleftarrow↚\n\\nleftarrow\n\n\nnrightarrow\n↛\\nrightarrow↛\n\\nrightarrow\n\n\nnLeftarrow\n⇍\\nLeftarrow⇍\n\\nLeftarrow\n\n\nnRightarrow\n⇏\\nRightarrow⇏\n\\nRightarrow\n\n\nnleftrightarrow\n↮\\nleftrightarrow↮\n\\nleftrightarrow\n\n\nnLeftrightarrow\n⇎\\nLeftrightarrow⇎\n\\nLeftrightarrow\n\n\ndashrightarrow\n⇢\\dashrightarrow⇢\n\\dashrightarrow\n\n\ndashleftarrow\n⇠\\dashleftarrow⇠\n\\dashleftarrow\n\n\nleftleftarrows\n⇇\\leftleftarrows⇇\n\\leftleftarrows\n\n\nleftrightarrows\n⇆\\leftrightarrows⇆\n\\leftrightarrows\n\n\nLleftarrow\n⇚\\Lleftarrow⇚\n\\Lleftarrow\n\n\ntwoheadleftarrow\n↞\\twoheadleftarrow↞\n\\twoheadleftarrow\n\n\nleftarrowtail\n↢\\leftarrowtail↢\n\\leftarrowtail\n\n\nlooparrowleft\n↫\\looparrowleft↫\n\\looparrowleft\n\n\nleftrightharpoons\n⇋\\leftrightharpoons⇋\n\\leftrightharpoons\n\n\ncurvearrowleft\n↶\\curvearrowleft↶\n\\curvearrowleft\n\n\ncirclearrowleft\n↺\\circlearrowleft↺\n\\circlearrowleft\n\n\nLsh\n↰\\Lsh↰\nLsh⇈\n\n\nupharpoonleft\n↿\\upharpoonleft↿\n\\upharpoonleft\n\n\ndownharpoonleft\n⇃\\downharpoonleft⇃\n\\downharpoonleft\n\n\nmultimap\n⊸\\multimap⊸\n\\multimap\n\n\nleftrightsquigarrow\n↭\\leftrightsquigarrow↭\n\\leftrightsquigarrow\n\n\nrightrightarrows\n⇉\\rightrightarrows⇉\n\\rightrightarrows\n\n\nrightleftarrows\n⇄\\rightleftarrows⇄\n\\rightleftarrows\n\n\nrightrightarrows\n⇉\\rightrightarrows⇉\n\\rightrightarrows\n\n\nrightleftarrows\n⇄\\rightleftarrows⇄\n\\rightleftarrows\n\n\ntwoheadrightarrow\n↠\\twoheadrightarrow↠\n\\twoheadrightarrow\n\n\nrightarrowtail\n↣\\rightarrowtail↣\n\\rightarrowtail\n\n\nlooparrowright\n↬\\looparrowright↬\n\\looparrowright\n\n\nrightleftharpoons\n⇌\\rightleftharpoons⇌\n\\rightleftharpoons\n\n\ncurvearrowright\n↷\\curvearrowright↷\n\\curvearrowright\n\n\ncirclearrowright\n↻\\circlearrowright↻\n\\circlearrowright\n\n\nRsh\n↱\\Rsh↱\nRsh\n\n\nupharpoonright\n↾\\upharpoonright↾\n\\upharpoonright\n\n\ndownharpoonright\n⇂\\downharpoonright⇂\n\\downharpoonright\n\n\nrightsquigarrow\n⇝\\rightsquigarrow⇝\n\\rightsquigarrow\n\n\n\n","plink":"ilucia.github.io/Others/Latex/"},{"title":"清除windows更新缓存","date":"2018-10-20T00:00:00.000Z","updated":"2022-04-27T15:24:01.595Z","content":"我们将手动清除Windows Update缓存以修复Windows 10上的下载问题。在清除缓存之前，您需要停止Windows更新服务。 为此，请搜索“服务”并以管理员身份打开它。 找到“Windows Update”服务，右键单击它，然后选择“停止”选项。\n要清除缓存，请执行以下操作：\n\n\n按“Win + R”，进入C:\\WINDOWS\\SoftwareDistribution\\并按下Enter按钮。\n\n\n此文件夹包含与Windows更新相关的所有文件。\n\n\n选择所有文件并删除所有文件。\n\n\n您需要重新启动Windows Update。 为此，请再次打开服务并启动Windows Update服务。 要启动该服务，请右键单击该服务并在上下文菜单中选择开始。\n要安装最新更新，请导航到设置 - &gt;更新和安全 - &gt; Windows Update，并检查更新。\n","plink":"ilucia.github.io/Others/windowsUpdateCacheClear/"},{"title":"OpenCV basic operations","date":"2018-10-02T00:00:00.000Z","updated":"2022-04-27T15:24:01.559Z","content":" 1.Accessing and Modifying pixel values\n\n12345678910import cv2import numpy as np# Load a color image.img = cv2.imread('example.jpg')px = img[100,100]print(px)# accessing only blue pixel# BGR color system!blue = img[100,100,0]print(blue)\n\nYou can access a pixel value by its row and column coordinates. For BGR image, it returns an array of Blue, Green, Red values. For grayscale image, just corresponding intensity is returned.\nYou can modify the pixel values the same way.\n\n12img[100,100]=[255,255,255]print(img[100,100])\n\nNumpy is a optimized library for fast array calculations. So simply accessing each and every pixel values and modifying it will be very slow and it is discouraged.\nAbove mentioned method is normally used for selecting a region of array, say first 5 rows and last 3 columns like that. For individual pixel access, Numpy array methods, and ```array.itemset()``` is considered to be better. But it always returns a scalar. So if you want to access all **B,G,R values**, you need to call ```array.item()``` separately for all.12345678* example: ```py# accessing RED valueimg.item(10,10,2)# modifying RED valueimg.itemset((10,10,2),100)img.item(10,10,2)\n\n 2. Accessing Image Properties\n\nimg.shape\n\n1print(img.shape)\n\nImage properties include number of rows, columns and channels, type of image data, number of pixels etc.\\\nShape of image is accessed by img.shape. It returns a tuple of number of rows, columns and channels (if image is color).\\\nIf image is grayscale, tuple returned contains only number of rows and columns. So it is a good method to check if loaded image is grayscale or color image.\nimg.size\n\n1print(img.size)\n\n\nTotal number of pixels is accessed by 123* img.dtype``` pyprint(img.dtype)\n\n\nis very important while debugging because a large number of errors in OpenCV-Python code is caused by invalid datatype.123456## 3. Image ROI* Sometimes, you will have to play with certain region of images. For eye detection in images, first perform face detection over the image until the face is found, then search within the face region for eyes. This approach improves accuracy (because eyes are always on faces :D ) and performance (because we search for a small area).* ROI is again obtained using Numpy indexing.``` pyclip = img[280:340, 330:390]img[273:333, 100:160] = clip\n\n\n 4.Splitting and Merging Image Channels\nThe B,G,R channels of an image can be split into their individual planes when needed. Then, the individual channels can be merged back together to form a BGR image again. This can be performed by:\n12b,g,r = cv2.split(img)img = cv2.merge((b,g,r))\nOr\n1b = img[:,:,0]\nSuppose, you want to make all the red pixels to zero, you need not split like this and put it equal to zero. You can simply use Numpy indexing which is faster.\n12# BRG color systemimg[:,:,2] = 0\n*is a costly operation (in terms of time), so only use it if necessary. Numpy indexing is much more efficient and should be used if possible.*1234567891011121314151617181920212223242526272829303132333435## 5.Making Borders for Images (Padding)If you want to create a border around the image, something like a photo frame, you can use ```cv2.copyMakeBorder()``` function. But it has more applications for convolution operation, zero padding etc. This function takes following arguments:* **src** - input image* **top, bottom, left, right** - border width in number of pixels in corresponding directions* **borderType - Flag defining what kind of border to be added. It can be following types:**   * **cv2.BORDER_CONSTANT** - Adds a constant colored border. The value should be given as next argument.   * **cv2.BORDER_REFLECT** - Border will be mirror reflection of the border elements, like this : fedcba|abcdefgh|hgfedcb   * **cv2.BORDER_REFLECT_101** or **cv2.BORDER_DEFAULT** - Same as above, but with a slight change, like this : gfedcb|abcdefgh|gfedcba   * **cv2.BORDER_REPLICATE** - Last element is replicated throughout, like this: aaaaaa|abcdefgh|hhhhhhh   * **cv2.BORDER_WRAP** - Can’t explain, it will look like this : cdefgh|abcdefgh|abcdefg* value - Color of border if border type is cv2.BORDER_CONSTANTBelow is a sample code demonstrating all these border types for better understanding:``` pyimport cv2import numpy as npfrom matplotlib import pyplot as pltBLUE = [255,0,0]img1 = cv2.imread(&apos;opencv_logo.png&apos;)replicate = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_REPLICATE)reflect = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_REFLECT)reflect101 = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_REFLECT_101)wrap = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_WRAP)constant= cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_CONSTANT,value=BLUE)plt.subplot(231),plt.imshow(img1,&apos;gray&apos;),plt.title(&apos;ORIGINAL&apos;)plt.subplot(232),plt.imshow(replicate,&apos;gray&apos;),plt.title(&apos;REPLICATE&apos;)plt.subplot(233),plt.imshow(reflect,&apos;gray&apos;),plt.title(&apos;REFLECT&apos;)plt.subplot(234),plt.imshow(reflect101,&apos;gray&apos;),plt.title(&apos;REFLECT_101&apos;)plt.subplot(235),plt.imshow(wrap,&apos;gray&apos;),plt.title(&apos;WRAP&apos;)plt.subplot(236),plt.imshow(constant,&apos;gray&apos;),plt.title(&apos;CONSTANT&apos;)\nSee the result below. (Image is displayed with matplotlib. So RED and BLUE planes will be interchanged):\n\n\n Example\n123456789101112131415import cv2img = cv2.imread('example.jpg')print('img[300,300]=%s' % img[300,300])print('blue pixel %s' %img[300,300,0])print('green pixel %s' %img[300,300,1])print('red pixel %s' %img[300,300,2])print(img[300,300,3])cv2.imshow('img', img)k = cv2.waitKey(0)  # &amp; 0xffif k == 27:  # ESC\tcv2.destroyAllWindows()elif k == ord('s'):\tcv2.imwrite('Save.jpg', img)","plink":"ilucia.github.io/OpenCV/OpenCVBasicOperations/"},{"title":"OpenCV function reference","date":"2018-10-02T00:00:00.000Z","updated":"2022-04-27T15:24:01.559Z","content":" 1.图像读取\n\ncv2.imread()\n\n123import numpy as mpimport cv2img =cv2.imread('example.jpg',0)\n\nUse the function cv2.imread() to read an image. The image should be in the working directory or a full path of image should be given.[[/]]\nSecond argument is a flag which specifies the way image should be read.\\\n\ncv2.IMREAD_COLOR : Loads a color image. Any transparency of image will be neglected. It is the default flag.\ncv2.IMREAD_GRAYSCALE : Loads image in grayscale mode\ncv2.IMREAD_UNCHANGED : Loads image as such including alpha channel\n\nInstead of these three flags, you can simply pass integers 1, 0 or -1 respectively.\n*Even if the image path is wrong, it won’t throw any error, but img``` will give you ```None```*1234567## 2.图像显示* cv2.inshow()``` pycv2.imshow(&apos;image&apos;,img)cv2.waitKey(0)cv2.destroyAllWindows()\n\n\n\n\nUse the function cv2.imshow() to display an image in a window. The window automatically fits to the image size. \nFirst argument is a window name which is a string. second argument is our image. You can create as many windows as you wish, but with different window names.\n\n\ncv2.waitKey()\n\n\ncv2.waitKey() is a keyboard binding function. Its argument is the time in milliseconds. The function waits for specified milliseconds for any keyboard event. If you press any key in that time, the program continues. If 0 is passed, it waits indefinitely for a key stroke. It can also be set to detect specific key strokes like, if key a is pressed etc which we will discuss below.\n\n\nBesides binding keyboard events this function also processes many other GUI events, so you MUST use it to actually display the image.\n\n\n\n\ncv2.destoryAllWindows()\n\n\ncv2.destroyAllWindows() simply destroys all the windows we created. If you want to destroy any specific window, use the function cv2.destroyWindow() where you pass the exact window name as the argument.\n\n\nThere is a special case where you can already create a window and load image to it later. In that case, you can specify whether window is resizable or not. It is done with the function cv2.namedWindow(). By default, the flag is cv2.WINDOW_AUTOSIZE. But if you specify flag to be cv2.WINDOW_NORMAL, you can resize window. It will be helpful when image is too large in dimension and adding track bar to windows.\n\n\n\n 3.图像写入\n\ncv2.imwrite()\n\n1cv2.imwrite('messigray.png',img)\n\nUse the function cv2.imwrite() to save an image. \nFirst argument is the file name, second argument is the image you want to save.\n\n 4.SumUp\n1234567891011import numpy as npimport cv2img = cv2.imread('messi5.jpg',0)cv2.imshow('image',img)k = cv2.waitKey(0)if k == 27:         # wait for ESC key to exit    cv2.destroyAllWindows()elif k == ord('s'): # wait for 's' key to save and exit    cv2.imwrite('messigray.png',img)    cv2.destroyAllWindows()\n\n\n*If you are using a 64-bit machine, you will have to modify 12345678910111213141516171819202122## 5.视频写入&gt; 由于暂时没有需求，本部分暂时未深入，[跳转到相关链接](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html)## 6.绘画操作### common arguments&gt;* img : The image where you want to draw the shapes&gt;* color : Color of the shape. for BGR, pass it as a tuple, eg: (255,0,0) for blue. For grayscale, just pass the scalar value.&gt;* thickness : Thickness of the line or circle etc. If -1 is passed for closed figures like circles, it will fill the shape. default thickness = 1&gt;* lineType : Type of line, whether 8-connected, anti-aliased line etc. By default, it is 8-connected. cv2.LINE_AA gives anti-aliased line which looks great for curves.* cv2.line()``` pyimport numpy as npimport cv2# Create a black imageimg = np.zeros((512,512,3), np.uint8)# Draw a diagonal blue line with thickness of 5 pximg = cv2.line(img,(0,0),(511,511),(255,0,0),5)\n\n\n\ncv2.circle()\n\n1img = cv2.circle(img,(447,63), 63, (0,0,255), -1)\n\ncv2.rectangle()\n\n1img = cv2.rectangle(img,(384,0),(510,128),(0,255,0),3)\n\ncv2.ellipse()\n\n1img = cv2.ellipse(img,(256,256),(100,50),0,0,180,255,-1)\n\n\nTo draw the ellipse, we need to pass several arguments. One argument is the center location (x,y). Next argument is axes lengths (major axis length, minor axis length). is the angle of rotation of ellipse in anti-clockwise direction. ```startAngle``` and ```endAngle``` denotes the starting and ending of ellipse arc measured in clockwise direction from major axis. i.e. giving values 0 and 360 gives the full ellipse. For more details, check the documentation of ```cv2.ellipse()```. Below example draws a half ellipse at the center of the image.123456*  cv2.polylines()``` pypts = np.array([[10,5],[20,30],[70,20],[50,10]], np.int32)pts = pts.reshape((-1,1,2))img = cv2.polylines(img,[pts],True,(0,255,255))\n\n\n\n\nTo draw a polygon, first you need coordinates of vertices. Make those points into an array of shape where ROWS are number of vertices and it should be of type ```int32```. Here we draw a small polygon of with four vertices in yellow color.123456&gt;* If third argument is False, you will get a polylines joining all the points, not a closed shape.&gt;* ```cv2.polylines()``` can be used to draw multiple lines. Just create a list of all the lines you want to draw and pass it to the function. All lines will be drawn individually. It is more better and faster way to draw a group of lines than calling ```cv2.line()``` for each line.* cv2.putText()``` pyfont = cv2.FONT_HERSHEY_SIMPLEXcv2.putText(img,&apos;OpenCV&apos;,(10,500), font, 4,(255,255,255),2,cv2.LINE_AA)\n\n\n\nTo put texts in images, you need specify following things.\n\nText data that you want to write\nPosition coordinates of where you want put it (i.e. bottom-left corner where data starts).\nFont type (Check cv2.putText() docs for supported fonts)\nFont Scale (specifies the size of font)\nregular things like color, thickness, lineType etc. For better look, lineType = cv2.LINE_AA is recommended.\n\n\n\n\n123456789101112131415161718192021222324252627282930313233&gt;Converts an image from one color space to another.&gt;* C++: void cvtColor(InputArray src, OutputArray dst, int code, int dstCn=0 )&gt; *  Python: cv2.cvtColor(src, code[, dst[, dstCn]]) → dst&gt; *  C: void cvCvtColor(const CvArr* src, CvArr* dst, int code)&gt; * s  Python: cv.CvtColor(src, dst, code) → None&gt;&gt;Parameters:&gt;* src – input image: 8-bit unsigned, 16-bit unsigned ( CV_16UC… ), or single-precision floating-point.&gt;* dst  – output image of the same size and depth as src.&gt;* code – color space conversion code (see the description below).&gt;* dstCn – number of channels in the destination image; if the parameter is 0, the number of the channels is derived automatically from src and code.&gt;&gt; The function converts an input image from one color space to another. In case of a transformation to-from RGB color space, the order of the channels should be specified explicitly (RGB or BGR). Note that the default color format in OpenCV is often referred to as RGB but it is actually BGR (the bytes are reversed). So the first byte in a standard (24-bit) color image will be an 8-bit Blue component, the second byte will be Green, and the third byte will be Red. The fourth, fifth, and sixth bytes would then be the second pixel (Blue, then Green, then Red), and so on.## 3. example``` pyimport cv2 as cv2import numpy as npimg=cv2.imread(&apos;a&apos;)img = cv2.imread(&apos;example.jpg&apos;, 1)font = cv2.FONT_HERSHEY_SIMPLEXcv2.putText(img, &apos;OpenCV&apos;, (10, 500), font, 4, (255, 0, 0), 2, cv2.LINE_AA)cv2.imshow(&apos;image&apos;, img)# Create a black imageimg = np.zeros((512, 512, 3), np.uint8)cv2.imshow(&apos;image0&apos;, img)# Draw a diagonal blue line with thickness of 5 pximg = cv2.line(img, (0, 0), (511, 511), (255, 0, 0), 5)cv2.imshow(&apos;image1&apos;, img)k = cv2.waitKey(0) &amp; 0xffaif k == 27:  # ESC    cv2.destroyAllWindows()elif k == ord(&apos;s&apos;):    cv2.imwrite(&apos;Save.jpg&apos;, img)\n\n","plink":"ilucia.github.io/OpenCV/OpenCVFunctionRef/"},{"title":"Python Excel file reader","date":"2018-10-01T00:00:00.000Z","updated":"2022-04-27T15:24:01.731Z","content":" python xlrd\n1、导入模块\nimport xlrd\n2、打开Excel文件读取数据\n1data = xlrd.open_workbook('excelFile.xls')\n3、使用方法\n获取一个工作表\n12345678910111213141516171819202122232425262728table = data.sheets()[0]      #通过索引顺序获取table = data.sheet_by_index(0) #通过索引顺序获取table = data.sheet_by_name(u'Sheet1')#通过名称获取#获取整行和整列的值（数组）table.row_values(i)table.col_values(i)#获取行数和列数nrows = table.nrowsncols = table.ncols#循环行列表数据for i in range(nrows ):print table.row_values(i)#单元格cell_A1 = table.cell(0,0).valuecell_C4 = table.cell(2,3).value#使用行列索引cell_A1 = table.row(0)[0].valuecell_A2 = table.col(1)[0].value#简单的写入row = 0col = 0#类型 0 empty,1 string, 2 number, 3 date, 4 boolean, 5 errorctype = 1 value = '单元格的值'xf = 0 # 扩展的格式化table.put_cell(row, col, ctype, value, xf)table.cell(0,0)  #单元格的值'table.cell(0,0).value #单元格的值'# python xlrd\n Demo\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354# -*- coding: utf-8 -*- import  xdrlib ,sysimport xlrddef open_excel(file= 'file.xls'):    try:        data = xlrd.open_workbook(file)        return data    except Exception,e:        print str(e)#根据索引获取Excel表格中的数据   参数:file：Excel文件路径     colnameindex：表头列名所在行的所以  ，by_index：表的索引def excel_table_byindex(file= 'file.xls',colnameindex=0,by_index=0):    data = open_excel(file)    table = data.sheets()[by_index]    nrows = table.nrows #行数    ncols = table.ncols #列数    colnames =  table.row_values(colnameindex) #某一行数据     list =[]    for rownum in range(1,nrows):         row = table.row_values(rownum)         if row:             app = &#123;&#125;             for i in range(len(colnames)):                app[colnames[i]] = row[i]              list.append(app)    return list#根据名称获取Excel表格中的数据   参数:file：Excel文件路径     colnameindex：表头列名所在行的所以  ，by_name：Sheet1名称def excel_table_byname(file= 'file.xls',colnameindex=0,by_name=u'Sheet1'):    data = open_excel(file)    table = data.sheet_by_name(by_name)    nrows = table.nrows #行数     colnames =  table.row_values(colnameindex) #某一行数据     list =[]    for rownum in range(1,nrows):         row = table.row_values(rownum)         if row:             app = &#123;&#125;             for i in range(len(colnames)):                app[colnames[i]] = row[i]             list.append(app)    return listdef main():   tables = excel_table_byindex()   for row in tables:       print row   tables = excel_table_byname()   for row in tables:       print rowif __name__==\"__main__\":    main()","plink":"ilucia.github.io/python/xlrd/"},{"title":"Python function reference","date":"2018-10-01T00:00:00.000Z","updated":"2022-04-27T15:24:01.731Z","content":" Sys\n\n sys模块包含了与python解释器和它的环境有关的函数，这个你可以通过dir(sys)来查看他里面的方法和成员属性。\n\n\n\n```  123456789101112查询系统环境变量，返回一个list。* ```sys.path.append(&apos;address&apos;)```  添加定义的搜索目录到环境变量。&gt;作用域仅在该脚本运行时，运行完毕即失效* ```sys.path.insert(0,&apos;address&apos;)```  同上，不过是插入。&gt;如果您想要添加永久路径  &gt;1.将py文件置于环境变量目录下(注意路径顺序和文件名冲突)  &gt;2.[尚未验证对python3是否可用]在 /usr/lib/python2.6/site-packages 下面新建一个.pth 文件(以pth作为后缀名)将模块的路径写进去，一行一个路径，如```vim pythonmodule.pth```  &gt;3.使用PYTHONPATH环境变量```export PYTHONPATH=$PYTHONPATH:/home/liu/shell/config\n\n","plink":"ilucia.github.io/python/PythonFunctionRef/"},{"title":"Hanyuu's  blog.","date":"2018-01-01T00:00:00.000Z","updated":"2022-04-27T15:24:01.559Z","content":"\n该站点目前由GitHub Actions自动部署\n最近更新：\n\n12345678                  ##         .            ## ## ##        ==         ## ## ## ## ##    ===     /\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\\___/ ===~~~ &#123;~~ ~~~~ ~~~ ~~~~ ~~~ ~ /  ===- ~~~     \\______ o           __/       \\    \\         __/        \\____\\_______/\n\nCopyright © 2017-2020 Hanyuu Lu  All Right Reserved\n\n","plink":"ilucia.github.io/Blog/"},{"title":"LICENSE","date":"2018-01-01T00:00:00.000Z","updated":"2022-04-27T15:24:01.727Z","content":"123456789The MIT License (MIT)Copyright (c) 2018-2019 Hanyuu FurudePermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the &quot;Software&quot;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sub license, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,FITNESS FOR A PARTICULAR PURPOSE AND NON INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","plink":"ilucia.github.io/license/"},{"title":"Title","date":"2000-03-05T00:00:00.000Z","updated":"2022-04-27T15:24:01.559Z","content":"","plink":"ilucia.github.io/Template/"}]